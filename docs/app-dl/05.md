# 5.正规化

在这一章中，你将会看到在训练深层网络时经常用到的一个非常重要的技术:正则化。你会看到一些技巧，比如ℓ方法、退出方法和提前停止方法。您将看到这些方法如何帮助避免过度拟合的问题，并在正确应用时从您的模型中获得更好的结果。您将看到方法背后的数学原理，以及如何用 Python 和 TensorFlow 正确地实现它。

## 复杂网络和过度拟合

在前面的章节中，你已经学习了如何建立和训练复杂的网络。使用复杂网络时，你会遇到的一个最常见的问题是过度拟合。复习第 [3](03.html) 章，了解什么是过度配合。在这一章中，你将面临一个极端的过度拟合的情况，我将讨论一些策略来避免它。研究这个问题的一个完美的数据集是第二章[中讨论的波士顿房价数据集。让我们回顾一下如何获得数据(更详细的讨论请参考第](02.html) [2](02.html) 章)。从我们需要的包开始。

```py
import matplotlib.pyplot as plt
%matplotlib inline

import tensorflow as tf
import numpy as np

from sklearn.datasets import load_boston
import sklearn.linear_model as sk

```

然后导入数据集。

```py
boston = load_boston()
features = np.array(boston.data)
target = np.array(boston.target)

```

数据集有 13 个特征(包含在`features NumPy`数组中)和包含在`target NumPy`数组中的房价。如第 2 章[中的](02.html)所示，为了规范化特征，我们将使用函数

```py
def normalize(dataset):
    mu = np.mean(dataset, axis = 0)
    sigma = np.std(dataset, axis = 0)
    return (dataset-mu)/sigma

```

为了结束我们的数据集准备，让我们将其规范化，然后创建训练和开发数据集。

```py
features_norm = normalize(features)
np.random.seed(42)
rnd = np.random.rand(len(features_norm)) < 0.8

train_x = np.transpose(features_norm[rnd])
train_y = np.transpose(target[rnd])
dev_x = np.transpose(features_norm[~rnd])
dev_y = np.transpose(target[~rnd])

```

`np.random.seed(42)`的存在是为了让你总是得到相同的`training`和`dev`数据集(这样，你的结果将是可重复的)。现在，让我们重塑我们需要的阵列。

```py
train_y = train_y.reshape(1,len(train_y))
dev_y = dev_y.reshape(1,len(dev_y))

```

接下来，让我们建立一个复杂的神经网络，它有 4 层，每层有 20 个神经元。定义以下函数来构建每一层:

```py
def create_layer (X, n, activation):
    ndim = int(X.shape[0])
    stddev = 2.0 / np.sqrt(ndim)
    initialization = tf.truncated_normal((n, ndim), stddev = stddev)
    W = tf.Variable(initialization)
    b = tf.Variable(tf.zeros([n,1]))
    Z = tf.matmul(W,X)+b
    return activation(Z), W, b

```

注意，这一次，我们返回权重张量`W`和偏差`b`。在实施正规化时，我们将需要它们。你已经在第 [3](03.html) 章的结尾看到了这个函数，所以你应该明白它是做什么的。我们在这里使用 he 初始化，因为我们将使用 ReLU 激活函数。可以使用以下代码创建网络:

```py
tf.reset_default_graph()

n_dim = 13
n1 = 20
n2 = 20
n3 = 20
n4 = 20
n_outputs = 1

tf.set_random_seed(5)

X = tf.placeholder(tf.float32, [n_dim, None])
Y = tf.placeholder(tf.float32, [1, None])

learning_rate = tf.placeholder(tf.float32, shape=())

hidden1, W1, b1 = create_layer (X, n1, activation = tf.nn.relu)
hidden2, W2, b2 = create_layer (hidden1, n2, activation = tf.nn.relu)
hidden3, W3, b3 = create_layer (hidden2, n3, activation = tf.nn.relu)
hidden4, W4, b4 = create_layer (hidden3, n4, activation = tf.nn.relu)
y_, W5, b5 = create_layer (hidden4, n_outputs, activation = tf.identity)

cost = tf.reduce_mean(tf.square(y_-Y))

optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8).minimize(cost)

```

在我们的输出层中，我们有一个神经元具有用于回归的身份激活功能。此外，我们使用 Adam 优化器，如第 [4](04.html) 章所述。现在让我们用下面的代码运行这个模型:

```py
sess = tf.Session()
sess.run(tf.global_variables_initializer())

cost_train_history = []
cost_dev_history = []
for epoch in range(10000+1):

    sess.run(optimizer, feed_dict = {X: train_x, Y: train_y, learning_rate: 0.001})
    cost_train_ = sess.run(cost, feed_dict={ X:train_x, Y: train_y, learning_rate: 0.001})
    cost_dev_ = sess.run(cost, feed_dict={ X:dev_x, Y: dev_y, learning_rate: 0.001})
    cost_train_history = np.append(cost_train_history, cost_train_)
    cost_dev_history = np.append(cost_test_history, cost_test_)

    if (epoch % 1000 == 0):
        print("Reached epoch",epoch,"cost J(train) =", cost_train_)
        print("Reached epoch",epoch,"cost J(test) =", cost_test_)

```

你可能已经注意到了，和我们之前做的有一些不同。为了使事情更简单，我避免了编写函数，而是简单地将所有值硬编码在代码中，因为在这种情况下，我们不需要对参数进行太多调整。我在这里没有使用小批量，因为我们只有几百个观察值，我用下面几行计算训练和开发数据集的 MSE(均方误差):

```py
cost_train_ = sess.run(cost, feed_dict={ X:train_x, Y: train_y, learning_rate: 0.001})
cost_dev_ = sess.run(cost, feed_dict={ X:dev_x, Y: dev_y, learning_rate: 0.001})

```

这样，我们可以同时检查两个数据集上发生了什么。现在，如果您让代码运行并绘制两个 MSE，一个用于训练，我们将用 *MSE* <sub>*train*</sub> 表示，另一个用于开发数据集，用 *MSE* <sub>*dev*</sub> 表示，我们得到图 [5-1](#Fig1) 。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig1_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig1_HTML.jpg)

图 5-1

用于训练的 MSE(实线)和用于具有 4 层的神经网络的 dev 数据集(虚线),每层具有 20 个神经元

您会注意到训练误差如何下降到零，而 dev 误差在开始时快速下降后，保持恒定在大约 20 的值。如果你还记得基本误差分析的介绍，你应该知道这意味着我们处于一个极度过拟合的状态(当*MSE*<sub>*train*</sub>≪*MSE*<sub>*dev*</sub>)。训练数据集上的误差实际上为零，而 dev 数据集上的误差则不是。当应用于新数据时，该模型根本不能概括。在图 [5-2](#Fig2) 中，您可以看到预测值与实际值的对比图。您会注意到，在左侧的图中，对于训练数据，预测几乎是完美的，而右侧的图中，对于 dev 数据集，预测不是那么好。你会记得一个完美的模型会给你一个与测量值完全相等的预测值。因此，当绘制一个对另一个时，它们都位于图的 45 度线上，如图 [5-2](#Fig2) 左侧所示。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig2_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig2_HTML.jpg)

图 5-2

目标变量(房价)的预测值与实际值。您会注意到，在左边的图中，对于训练数据，预测几乎是完美的，而在右边的图中，对于 dev 数据集，预测更加分散。

在这种情况下，我们可以做什么来避免过度拟合的问题？当然，一种解决方案是降低网络的复杂性，即减少层数和/或每层中神经元的数量。但是，可以想象，这种策略非常耗时。您必须尝试几种网络架构，看看训练错误和开发错误是如何表现的。在这种情况下，这仍然是一个可行的解决方案，但是如果您正在处理一个训练阶段需要几天时间的问题，这可能会非常困难并且非常耗时。已经开发了几种策略来处理这个问题。最常见的称为正规化，这是本章的重点。

## 什么是正规化？

在进入不同的方法之前，我想快速讨论一下深度学习社区对术语*正则化*的理解。随着时间的推移，这个术语已经发生了深刻的变化。例如，在传统意义上(从 90 年代开始)，该术语仅保留为损失函数中的惩罚项(Christopher M. Bishop，*模式识别的神经网络*，纽约:牛津大学出版社，1995)。最近这个术语获得了更广泛的含义。例如，Ian Goodfellow 等人(*深度学习*，马萨诸塞州剑桥，麻省理工学院出版社，2016 年)将其定义为*“*我们对学习算法进行的任何修改，旨在减少其测试错误，而不是训练错误。”Jan Kukač ka 等人(“深度学习的正则化:分类法”，arXiv:1710.10686v1，可在 [`https://goo.gl/wNkjXz`](https://goo.gl/wNkjXz) 获得)进一步概括了该术语，并提供了以下定义:“正则化是任何旨在使模型更好地泛化的补充技术，即在测试集*上产生更好的结果。”因此，在使用这个术语时要小心，并始终准确表达你的意思。*

你可能也听说过或读过这样的说法，即正则化是为了对抗过度拟合而发展起来的。这也是理解它的一种方式。请记住:过度拟合训练数据集的模型不能很好地推广到新数据。这个定义也可以在网上找到，还有其他所有的定义。虽然仅仅是定义，但熟悉它们是很重要的，这样你在阅读论文或书籍时可以更好地理解它们的含义。这是一个非常活跃的研究领域，为了给你一个思路，Kukač ka 等人在上面提到的综述论文中列出了 58 种不同的正则化方法。对，58；这不是打印错误。但重要的是要理解，在他们的一般定义中，SGD(随机梯度下降)也被认为是一种正则化方法，这不是每个人都同意的。因此，请注意，在阅读研究材料时，检查一下术语*正规化*所理解的内容。

在这一章中，你将看到三种最常见和最著名的方法: *ℓ* <sub>1</sub> 、 *ℓ* <sub>2</sub> 和辍学，我将简要讨论早期停止，尽管从技术上来说，这种方法不能防止过度拟合。 *ℓ* <sub>1</sub> 和 *ℓ* <sub>2</sub> 通过向成本函数添加所谓的正则化项来实现所谓的权重衰减，而丢弃只是在训练阶段以随机方式从网络中移除节点。为了正确理解这三种方法，我们必须详细研究它们。先说可能最有启发性的一个:*ℓ*t18】2 正规化。

在这一章的最后，我们将探讨一些关于如何对抗过度拟合和使模型更好地泛化的其他想法。我们不会改变或修改模型或学习算法，而是考虑修改训练数据的策略，以使学习更有效。

### 关于网络复杂性

我想花点时间简单讨论一下我经常使用的一个术语:网络复杂性。你在这里读到过，几乎在任何地方都能读到，通过规范化，你想降低网络的复杂性。但是这到底意味着什么呢？实际上，给网络复杂性下一个定义是相对困难的，以至于没人去做。你可以找到几篇关于模型复杂性问题的研究论文(注意我没有说*网络*复杂性)，根源在信息论。例如，您将在本章中看到，非零权重的数量将如何随着历元数、优化算法等发生显著变化，从而使这种模糊直观的复杂性概念也取决于您训练模型的时间。长话短说，术语*网络复杂性*应该只在直觉层面上使用，因为从理论上讲，这是一个非常复杂的概念。对这个问题的全面讨论超出了本书的范围。

## √t0〔t1〕p〔T2〕T3〕标准

在我们开始研究什么是*ℓ*T2】1 和*ℓ*T6】2 正则化之前，我必须先介绍一下 *ℓ* <sub>*p*</sub> 范数表示法。我们定义*<sub>*p*</sub>定额的一个矢量**x*<sub>*I*</sub>分量为****

****![$$ \left\Vert {x}_p\right\Vert =\sqrt[p]{\sum \limits_{\kern1.5em i}{\left|{x}_i\right|}^p}\kern2.125em p\in \mathbb{R} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equa.png)****

 ****其中对矢量***×矢量*** 的所有分量进行求和。

让我们从最有指导意义的规范开始:ℓ*<sub>2</sub>。*

 *## ℓ <sub>2</sub> 正规化

最常见的正则化方法之一， *ℓ* <sub>2</sub> 正则化包括向成本函数中添加一项，其目标是有效降低网络的容量以适应复杂数据集。让我们先来看看该方法背后的数学原理。

### ℓ理论 <sub>2</sub> 正规化

当进行简单回归时，你会记得从第 2 章开始，我们的成本函数就是 MSE

![$$ J(w)=\frac{1}{m}\sum \limits_{i=1}^m{\left({y}_i-{\widehat{y}}_i\right)}^2 $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equb.png)

其中*y*<sub>T3】IT5】是我们测量的目标变量，![$ {\widehat{y}}_i $](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_IEq1.png)是预测值， *** w *** 是我们网络所有权值的向量，包括偏差， *m* 是观测值的个数。现在让我们定义一个新的成本函数![$ \tilde{J}\left(w,b\right). $](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_IEq2.png)</sub>

![$$ \tilde{J}(w)=J(w)+\frac{\lambda }{2m}{{\left|w\right|}^2}_2 $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equc.png)

这个附加术语，

![$$ \frac{\lambda }{2m}{{\left\Vert w\right\Vert}^2}_2 $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equd.png)

被称为正则化项，不是别的，就是*ℓ*T2 2-*t5】wT7】的范数平方乘以常数因子 *λ* /2 *m* 。 *λ* 称为正则化参数。*

### 注意

新的正则化参数 *λ* 是一个新的超参数，您必须调整它以找到最佳值。

现在让我们试着直观地了解一下这一项对 GD(梯度下降)算法的影响是什么。让我们考虑重量的更新方程式*w*<sub>T3】jT5】</sub>

![$$ {w}_{j,\left[n+1\right]}={w}_{j,\left[n\right]}-\gamma \frac{\partial \tilde{J}\left({w}_{\left[n\right]}\right)}{\partial {w}_j}={w}_{j,\left[n\right]}-\gamma \frac{\partial J\left({w}_{\left[n\right]}\right)}{\partial {w}_j}-\frac{\gamma \lambda}{m}{w}_{j,\left[n\right]} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Eque.png)

因为

![$$ \frac{\partial }{\partial {w}_j}{{\left\Vert w\right\Vert}^2}_2=2{w}_j $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equf.png)

这给了我们

![$$ {w}_{j,\left[n+1\right]}={w}_{j,\left[n\right]}\left(1-\frac{\gamma \lambda}{m}\right)-\lambda \frac{\partial J\left({w}_{\left[n\right]}\right)}{\partial {w}_j} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equg.png)

这是我们必须用于权重更新的等式。与我们从 plain GD 已经知道的不同之处在于，现在，权重 *w* <sub>*j* ，[*n*】</sub>乘以常数![$$ 1-\frac{\gamma \lambda}{m}&lt;1 $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_IEq3.png)，因此，这具有在更新期间将权重值有效地移向零的效果，使得网络不那么复杂(直观地)，从而对抗过拟合。让我们通过将该方法应用于波士顿住房数据集，来看看权重究竟发生了什么。

### tensorflow 实现

`tensorflow`中的实现相当容易。记住:我们必须计算附加项![$$ {\left\Vert w\right\Vert}_2^2 $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_IEq4.png)，然后将其添加到成本函数中。模型结构几乎保持不变。我们可以用下面的代码来实现:

```py
tf.reset_default_graph()

n_dim = 13
n1 = 20
n2 = 20
n3 = 20
n4 = 20
n_outputs = 1

tf.set_random_seed(5)

X = tf.placeholder(tf.float32, [n_dim, None])
Y = tf.placeholder(tf.float32, [1, None])

learning_rate = tf.placeholder(tf.float32, shape=())

hidden1, W1, b1 = create_layer (X, n1, activation = tf.nn.relu)
hidden2, W2, b2 = create_layer (hidden1, n2, activation = tf.nn.relu)
hidden3, W3, b3 = create_layer (hidden2, n3, activation = tf.nn.relu)
hidden4, W4, b4 = create_layer (hidden3, n4, activation = tf.nn.relu)
y_, W5, b5 = create_layer (hidden4, n_outputs, activation = tf.identity)

lambd = tf.placeholder(tf.float32, shape=())
reg = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3) + \
          tf.nn.l2_loss(W4) + tf.nn.l2_loss(W5)

cost_mse = tf.reduce_mean(tf.square(y_-Y))
cost = tf.reduce_mean(cost_mse + lambd*reg)

optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8).minimize(cost)

```

对于我们新的正则化参数 *λ* ，我们创建一个占位符。

```py
lambd = tf.placeholder(tf.float32, shape=())

```

记住，在 Python 中，`lambda`是一个保留字，所以我们不能使用它。这就是我们使用`lambd`的原因。然后我们计算我们的正则项![$$ {\left\Vert w\right\Vert}_2^2\. $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_IEq5.png)

```py
reg = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3) + \
          tf.nn.l2_loss(W4) + tf.nn.l2_loss(W5)

```

用有用的 TensorFlow 函数`tf.nn.l2_loss()`，然后我们把它加到 MSE 函数`cost_mse`。

```py
cost_mse = tf.reduce_mean(tf.square(y_-Y))
cost = tf.reduce_mean(cost_mse + lambd*reg)

```

现在我们的张量将包含 MSE 和正则项。然后我们只需要训练网络，观察会发生什么。为了训练网络，我们使用这个函数:

```py
def model(training_epochs, features, target, logging_step = 100, learning_r = 0.001, lambd_val = 0.1):
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

    cost_history = []
    for epoch in range(training_epochs+1):

        sess.run(optimizer, feed_dict = {X: features, Y: target, learning_rate: learning_r, lambd: lambd_val})
        cost_ = sess.run(cost_mse, feed_dict={ X:features, Y: target, learning_rate: learning_r, lambd: lambd_val})
        cost_history = np.append(cost_history, cost_)

        if (epoch % logging_step == 0):
                pred_y_test = sess.run(y_, feed_dict = {X: test_x, Y: test_y})
                print("Reached epoch",epoch,"cost J =", cost_)
                print("Training MSE = ", cost_)
                print("Dev MSE      = ", sess.run(cost_mse, feed_dict = {X: test_x, Y: test_y}))

    return sess, cost_history

```

这次，我打印了来自训练( *MSE* <sub>*train*</sub> )和 dev(*MSE*<sub>*dev*</sub>)数据集的 MSE，以检查发生了什么。如上所述，应用这种方法使许多权重变为零，有效地降低了网络的复杂性，从而防止了过拟合。让我们运行 *λ* = 0，没有正则化，并且 *λ* = 10.0 的模型。我们可以用下面的代码运行我们的模型:

```py
sess, cost_history = model(learning_r = 0.01,
                                training_epochs = 5000,
                                features = train_x,
                                target = train_y,
                                logging_step = 5000,
                                lambd_val = 0.0)

```

这给了我们

```py
Reached epoch 0 cost J = 238.378
Training MSE = 238.378
Dev MSE = 205.561
Reached epoch 5000 cost J = 0.00527479
Training MSE = 0.00527479
Dev MSE = 28.401

```

正如所料，我们在 5000 个纪元后处于一个极端的过度拟合状态(*MSE*<sub>*train*</sub>≪*MSE*<sub>*dev*</sub>)。现在我们用 *λ* = 10 来试试。

```py
sess, cost_history = model(learning_r = 0.01,
                                training_epochs = 5000,
                                features = train_x,
                                target = train_y,
                                logging_step = 5000,
                                lambd_val = 10.0)

```

这给出了结果

```py
Reached epoch 0 cost J = 248.026
Training MSE = 248.026
Dev MSE = 214.921
Reached epoch 5000 cost J = 23.795
Training MSE = 23.795
Dev MSE = 21.6406

```

现在，我们不再处于过拟合状态，因为两个 MSE 值具有相同的数量级。检查发生了什么的最好方法是研究每一层的权重分布。在图 [5-3](#Fig3) 中，绘制了前 4 层的重量分布。浅灰色直方图用于未进行正则化的权重，而较暗(且更集中在零周围)的区域用于进行正则化的权重。我忽略了第 5 层，因为它是输出层。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig3_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig3_HTML.jpg)

图 5-3

每层的权重分布

你可以清楚地看到，当我们应用正则化时，权重更加集中在零附近，这意味着它们比没有正则化时小得多。这使得正则化的权重衰减效应非常明显。我想借此机会简单地谈一谈网络复杂性。我说这个方法降低了网络复杂度。我在第 [3](03.html) 章中告诉过你，你可以将可学习参数的数量视为网络复杂性的一个指标，但我也警告过你，这可能会产生误导。现在我想告诉你为什么。你会从第 3 章[中记起，我们在网络中拥有的可学习参数的总数是由以下公式决定的](03.html)

![$$ Q=\sum \limits_{j=1}^L{n}_l\left({n}_{l-1}+1\right) $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equh.png)

其中 *n* <sub>*l*</sub> 为层 *l* 的神经元数， *L* 为总层数，包括输出层。在我们的例子中，输入层有 13 个特征，然后是 4 层，每层有 20 个神经元，然后是输出层有 1 个神经元。因此， *Q* 由下式给出

![$$ Q=20\times \left(13+1\right)+20\times \left(20+1\right)+20\times \left(20+1\right)+20\times \left(20+1\right)+1\times \left(20+1\right)=1561 $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equi.png)

*Q* 是一个相当大的数字。但是，在没有正则化的情况下，有趣的是，我们注意到大约 48%的权重在 10，000 个时期后小于 10<sup>-10</sup>，因此，实际上为零。这就是我警告你不要用可学习参数的数量来谈论复杂性的原因。此外，使用正则化将完全改变这种情况。复杂性是一个很难定义的概念:它取决于许多因素，其中包括架构、优化算法、成本函数和训练的纪元数量。

### 注意

仅仅根据权重的数量来定义网络的复杂性是不完全正确的。总的权重数给出了一个概念，但它可能具有相当大的误导性，因为许多权重在训练后可能为零，实际上从网络中消失，使网络变得不那么复杂。更正确的说法是“模型复杂性”，而不是网络复杂性，因为它涉及到许多方面，而不仅仅是网络有多少神经元或层。

令人难以置信的是，最终只有一半的权重在预测中起作用。这就是我在第 [3](03.html) 章告诉你的原因，仅仅用参数 *Q* 来定义网络复杂性是误导的。给定你的问题，你的损失函数和优化器，你很可能最终得到一个训练后比构建阶段简单得多的网络。因此，在深度学习领域使用术语*复杂性*时要非常小心。意识到其中的微妙之处。

为了让您了解正则化在减少权重方面的有效性，请参见表 [5-1](#Tab1) ，其中比较了每层 1000 个时期后正则化前后小于 1e-3 的权重百分比。

表 5-1

1000 个时期后，有和没有正则化的小于 1e-3 的权重的百分比

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

层

 | 

对于 ***λ =*** **0** ，权重小于 1e-3 的百分比

 | 

对于 ***λ =*** **3** ，权重小于 1e-3 的百分比

 |
| --- | --- | --- |
| **1** | Zero | Twenty |
| **2** | Zero point two five | Forty-one point five |
| **3** | Zero point seven five | Sixty point five |
| **4** | Zero point two five | Sixty-six |
| **5** | Zero | Thirty-five |

但是我们应该如何选择 *λ* ？为了得到一个想法(跟我重复:“在深度学习的世界里，没有放之四海而皆准的规则。”)，这有助于了解当将参数 *λ* 改变为您的优化指标(在本例中为 MSE)时会发生什么。在图 [5-4](#Fig4) 中，您可以看到*MSE*<sub>*train*</sub>(连续线)和*MSE*<sub>*dev*</sub>(虚线)数据集在 1000 个代之后变化 *λ* 的行为。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig4_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig4_HTML.jpg)

图 5-4

我们的网络的训练(实线)数据集和 dev(虚线)数据集的 MSE 行为变化 *λ* 。

如您所见，使用小值 *λ* (实际上没有调整)，我们处于过拟合状态(*MSE*<sub>*train*</sub>≪*MSE*<sub>*dev*</sub>):*MSE*<sub>*train*</sub>缓慢增加，而 *MSE* <sub>*dev* 直到 *λ* ≈ 7.5，模型对训练数据进行过拟合，然后两个值交叉，过拟合结束。之后，它们一起增长，此时模型不再能够捕获精细的数据结构。在越过这些线之后，模型变得太简单而不能捕捉问题的特征，因此，误差一起增长，并且训练数据集上的误差变得更大，因为模型甚至不能很好地拟合训练数据。在这种特定情况下，为 *λ* 选择的一个好值大约是 7.5，接近两条线交叉时的值，因为在那里，您不再处于过度拟合区域，因为*MSE*<sub>*train*</sub>≈*MSE*<sub>*dev*</sub>。记住:使用正则项的主要目的是获得一个在应用于新数据时尽可能以最佳方式概括的模型。你甚至可以用不同的方式来看:一个值 *λ* ≈ 7.5 给出了在过度拟合区域之外*MSE*<sub>*dev*</sub>的最小值(对于*λ*≲7.5)；因此，这将是一个不错的选择。请注意，对于您的问题，您可能会观察到您的优化指标有非常不同的行为，因此您必须根据具体情况来决定最适合您的 *λ* 值。</sub>

### 注意

估计正则化参数 *λ* 的最佳值的一个好方法是为训练和开发数据集绘制您的优化度量(在本例中为 MSE ),并观察它们在不同的 *λ* 值下的表现。然后选择在 dev 数据集上给出最小优化度量的值，同时，给你一个不再过度拟合你的训练数据的模型。

我现在想以一种更加直观的方式向你们展示*ℓ*T2】2 正规化的效果。让我们考虑使用以下代码生成的数据集:

```py
nobs = 30

np.random.seed(42)

xx1 = np.array([np.random.normal(0.3,0.15) for i in range (0,nobs)])
yy1 = np.array([np.random.normal(0.3,0.15) for i in range (0,nobs)])
xx2 = np.array([np.random.normal(0.1,0.1) for i in range (0,nobs)])
yy2 = np.array([np.random.normal(0.3,0.1) for i in range (0,nobs)])

c1_ = np.c_[xx1.ravel(), yy1.ravel()]
c2_ = np.c_[xx2.ravel(), yy2.ravel()]

c = np.concatenate([c1_,c2_])

yy1_ = np.full(nobs, 0, dtype=int)
yy2_ = np.full(nobs, 1, dtype=int)
yyL = np.concatenate((yy1_, yy2_), axis = 0)

train_x = c.T
train_y = yyL.reshape(1,60)

```

我们的数据集有两个特征: *x* 和 *y* 。我们从正态分布中生成两组点，`xx1,yy1`和`xx2,yy2`。对于第一组，我们指定标签 0(包含在数组`yy1_`中)，对于第二组，指定标签 1(在数组`yy2_`中)。现在，让我们使用之前描述的网络(有 4 层，每层有 20 个神经元)对这个数据集进行一些二元分类。我们可以采用之前给出的相同代码，修改输出层和成本函数。您会记得，对于二元分类，我们需要在输出层中有一个具有 sigmoid 激活函数的神经元

```py
y_, W5, b5 = create_layer (hidden4, n_outputs, activation = tf.sigmoid)

```

以及下面的成本函数:

```py
cost_class = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))
cost = tf.reduce_mean(cost_class + lambd*reg)

```

其余的都和前面描述的一样。让我们为这个问题画出决策边界 <sup>[1](#Fn1)</sup> 。这意味着我们将使用代码在数据集上运行我们的网络

```py
sess, cost_history = model(learning_r = 0.005,
                                training_epochs = 100,
                                features = train_x,
                                target = train_y,
                                logging_step = 10,
                                lambd_val = 0.0)

```

在图 [5-5](#Fig5) 中，你可以看到我们的数据集，其中白点属于第一类，黑点属于第二类。灰色区域是网络分类为一类的区域，白色区域是另一类的区域。你可以看到网络能够以灵活的方式捕捉我们数据的复杂结构。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig5_HTML.png](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig5_HTML.png)

图 5-5

没有正则化的判定边界。白点是第一类，黑点是第二类。

现在，让我们将正则化应用于网络，就像我们之前所做的那样，并看看如何修改决策边界。这里，我们将使用一个正则化参数 *λ* = 0.1。

你可以清楚地看到，在图 [5-6](#Fig6) 中，决策边界几乎是线性的，不再能够捕捉我们数据的复杂结构。正如我们所预期的:正则化项使模型更简单，因此更难捕捉精细结构。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig6_HTML.png](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig6_HTML.png)

图 5-6

决策边界，由具有*ℓ*T2】2 正则化和正则化参数 *λ* = 0.1 的网络预测

将我们的网络的决策边界与只有一个神经元的逻辑回归的结果进行比较是有趣的。出于篇幅的考虑，这里就不放代码了，但是如果你对比一下图 [5-7](#Fig7) 中的两个决策边界(来自有一个神经元的网络的是线性的)，你可以看到它们几乎是一样的。 *λ* = 0.1 的正则项有效地给出了与只有一个神经元的网络相同的结果。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig7_HTML.png](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig7_HTML.png)

图 5-7

*λ* = 0.1 的复杂网络和只有一个神经元的复杂网络的决策边界。两个边界几乎完全重叠。

## ℓ <sub>1</sub> 正规化

现在我们来看一个非常类似于*ℓ*T2】2 正则化的正则化技术。它基于相同的原理，在成本函数中增加了一项。这一次，附加项的数学形式有所不同，但方法与我在前面几节中解释的非常相似。让我们再次先看看算法背后的数学。

### ℓ理论 <sub>1</sub> 正则化与张量流实现

ℓ <sub>1</sub> 正则化在向成本函数添加附加项时也起作用

![$$ \tilde{J}(w)=J(w)+\frac{\lambda }{m}{\left\Vert w\right\Vert}_1 $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equj.png)

它对学习的影响实际上与用*ℓ*T2】2 正则化描述的相同。TensorFlow 没有，至于 *ℓ* <sub>2</sub> ，一个随时可以使用的函数。我们必须使用以下代码对其进行手动编码:

```py
reg = tf.reduce_sum(tf.abs(W1))+tf.reduce_sum(tf.abs(W2))+tf.reduce_sum(tf.abs(W3))+\
        tf.reduce_sum(tf.abs(W4))+tf.reduce_sum(tf.abs(W5))

```

讨论的代码的其余部分保持不变。我们可以再次比较没有正则项的模型( *λ* = 0)和有正则项的模型( *λ* = 3，图 [5-8](#Fig8) )之间的权重分布。我们使用波士顿数据集进行计算。我们通过以下调用训练了该模型:

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig8_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig8_HTML.jpg)

图 5-8

没有 *ℓ* <sub>1</sub> 正则项( *λ* = 0，浅灰色)和有 *ℓ* <sub>1</sub> 正则项( *λ* = 3，深灰色)的模型之间的权重分布比较

```py
sess, cost_history = model(learning_r = 0.01,
                                training_epochs = 1000,
                                features = train_x,
                                target = train_y,
                                logging_step = 1000,
                                lambd_val = 3.0)

```

一次是 *λ* = 0，一次是 *λ* = 3。

如你所见， *ℓ* <sub>1</sub> 正则化与 *ℓ* <sub>2</sub> 具有相同的效果。它降低了网络的有效复杂性，将许多权重减少到零。

为了让您了解正则化在减少权重方面的有效性，请参见表 [5-2](#Tab2) ，该表比较了 1000 个时期后正则化前后小于 1e-3 的权重的百分比。

表 5-2

调整前后小于 1e-3 的权重百分比比较

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

层

 | 

对于****= 0**，权重小于 1e-3 的百分比**

 | 

对于****= 3**，权重小于 1e-3 的百分比**

 |
| --- | --- | --- |
| **1** | Zero | Fifty-two point seven |
| **2** | Zero point two five | Fifty-three point eight |
| **3** | Zero point seven five | Forty-six point three |
| **4** | Zero point two five | Forty-five point three |
| **5** | Zero | Sixty |

### 重量真的会变为零吗？

看到重量如何趋向于零是很有启发性的。在图 [5-9](#Fig9) 中，您可以看到绘制的权重![$$ {w}_{12,5}^{\left[3\right]} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_IEq6.png)(来自第 3 层)与我们的具有两个特征的人工数据集的历元数的关系，*ℓ*t5】2 正则化，*γ*= 10<sup>-3</sup>， *λ* = 0.1，经过 1000 个历元。你可以看到它是如何迅速减少到零的。1000 个周期后的值为 2 ^ 10<sup>-21</sup>，因此，出于所有目的，该值为零。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig9_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig9_HTML.jpg)

图 5-9

为我们的具有两个特征的人工数据集绘制的权重![$$ {w}_{12,5}^{\left[3\right]} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_IEq7.png)与历元的关系，*ℓ*T3】2 正则化，*γ*= 10<sup>3</sup>， *λ* = 0.1，训练了 1000 个历元

如果你想知道的话，重量几乎以指数形式变为零。下面是理解为什么会这样的一种方法。让我们考虑一个权重的权重更新方程。

![$$ {w}_{j,\left[n+1\right]}={w}_{j,\left[n\right]}\left(1-\frac{\gamma \lambda}{m}\right)-\frac{\gamma \partial J\left({w}_{\left[n\right]}\right)}{\partial {w}_j} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equk.png)

现在假设我们发现自己接近最小值，在成本函数 *J* 的导数几乎为零的区域，因此我们可以忽略它。换句话说，让我们假设

![$$ \frac{\partial J\left({w}_{\left[n\right]}\right)}{\partial {w}_j}\approx 0 $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equl.png)

我们可以将权重更新等式改写为

![$$ {w}_{j,\left[n+1\right]}-{w}_{j,\left[n\right]}=-{w}_{j,\left[n\right]}\frac{\gamma \lambda}{m} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equm.png)

现在，该等式可以理解如下:权重相对于迭代次数的变化率与权重本身成比例。对于那些有微分方程知识的人来说，你可能会意识到我们可以将下面的方程画一条平行线:

![$$ \frac{dx(t)}{dt}=-\frac{\gamma \lambda}{m}x(t) $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equn.png)

这可以理解为 *x* ( *t* )相对于时间的变化率与函数本身成正比。对于那些知道如何解这个方程的人来说，你可能知道一个通用的解是

![$$ x(t)=A{e}^{-\frac{\gamma \lambda}{m}\left(t-{t}_0\right)} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_Equo.png)

通过在两个方程之间画一条平行线，你现在可以明白为什么重量衰减会有类似于指数函数的衰减。在图 [5-10](#Fig10) 中，你可以看到已经讨论过的重量衰减，纯指数衰减。正如所料，两条曲线并不完全相同，因为，尤其是在开始时，成本函数的梯度肯定不为零。但是这种相似性是显著的，并且给了我们一个概念，权重可以多快变为零(阅读:真的很快)。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig10_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig10_HTML.jpg)

图 5-10

绘制的权重![$$ {w}_{12,5}^{\left[3\right]} $$](../images/463356_1_En_5_Chapter/463356_1_En_5_Chapter_TeX_IEq8.png)相对于我们的人工数据集的历元，该数据集具有两个特征，*ℓ*T3】2 正则化，*γ*= 10<sup>3</sup>， *λ* = 0.1，训练了 1000 个历元(实线)以及纯指数衰减(虚线)，用于说明目的

请注意，当使用正则化时，您最终会得到包含许多零元素的张量，称为稀疏张量。然后，您可以从对稀疏张量极其有效的特殊例程中获益。当你开始转向更复杂的模型时，这是需要记住的，但是这个主题对于本书来说太深奥了，需要太多的篇幅。

## 拒绝传统社会的人

放弃的基本思想是不同的:在训练阶段，你以一个概率*p*<sup>[*l*</sup>随机地从层 *l* 中删除节点。在每次迭代中，您删除不同的节点，有效地在每次迭代中训练不同的网络(例如，当使用小批量时，您为每批训练不同的网络)。通常，概率(在 Python 中通常称为`keep_prob`)对于所有网络都设置为相同的(但是，从技术上讲，它可以是特定于图层的)。直观的，我们来考虑一层 *l* 的输出张量`Z`。在 Python 中，我们可以定义一个向量，比如

```py
d = np.random.rand(Z.shape[0], Z.shape[1]) < keep_prob

```

然后简单地将层输出`Z`乘以`d`，如下所示:

```py
Z = np.multiply(Z, d)

```

这有效地删除了所有概率小于`keep_prob`的元素。在 dev 数据集上进行预测时，最重要的一点是不要使用漏失！

### 注意

在训练过程中，dropout 会在每次迭代中随机删除节点。但是，当在 dev 数据集上进行预测时，必须使用整个网络，不能有任何遗漏。换句话说，你必须设置`keep_prob=1`。

丢弃可以是特定于层的。比如神经元多的层，`keep_prob`可以很小。对于具有少数神经元的层，可以设置`keep_prob = 1.0`，有效地将所有神经元保持在这样的层中。

TensorFlow 中的实现很简单。首先，定义一个占位符，它将包含参数`keep_prob`的值

```py
keep_prob = tf.placeholder(tf.float32, shape=())

```

然后，对于每一层，您以这种方式添加正则化操作:

```py
hidden1, W1, b1 = create_layer (X, n1, activation = tf.nn.relu)
hidden1_drop = tf.nn.dropout(hidden1, keep_prob)

```

然后，在创建下一层时，不使用`hidden1`，而是使用`hidden1_drop`。整个构造代码如下所示:

```py
tf.reset_default_graph()

n_dim = 13
n1 = 20
n2 = 20
n3 = 20
n4 = 20
n_outputs = 1

tf.set_random_seed(5)

X = tf.placeholder(tf.float32, [n_dim, None])
Y = tf.placeholder(tf.float32, [1, None])

learning_rate = tf.placeholder(tf.float32, shape=())
keep_prob = tf.placeholder(tf.float32, shape=())

hidden1, W1, b1 = create_layer (X, n1, activation = tf.nn.relu)
hidden1_drop = tf.nn.dropout(hidden1, keep_prob)
hidden2, W2, b2 = create_layer (hidden1_drop, n2, activation = tf.nn.relu)
hidden2_drop = tf.nn.dropout(hidden2, keep_prob)
hidden3, W3, b3 = create_layer (hidden2, n3, activation = tf.nn.relu)
hidden3_drop = tf.nn.dropout(hidden3, keep_prob)
hidden4, W4, b4 = create_layer (hidden3, n4, activation = tf.nn.relu)
hidden4_drop = tf.nn.dropout(hidden4, keep_prob)
y_, W5, b5 = create_layer (hidden4_drop, n_outputs, activation = tf.identity)

cost = tf.reduce_mean(tf.square(y_-Y))

optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8).minimize(cost)

```

现在我们来分析一下使用 dropout 时成本函数会发生什么变化。让我们运行应用于波士顿数据集的模型，获取变量`keep_prob`的两个值:1.0(无遗漏)和 0.5。在图 [5-11](#Fig11) 中，可以看到在应用 dropout 时，代价函数非常不规则。它剧烈震荡。这两个模型已经通过调用进行了评估

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig11_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig11_HTML.jpg)

图 5-11

我们的模型的训练数据集的成本函数，具有变量`keep_prob`的两个值:`1.0`(无辍学)和`0.5`。其他参数为: *γ* = 0.01。这些模型已经被训练了 5000 个纪元。没有使用小批量。振荡线是用正则化评估的线。

```py
sess, cost_history05 = model(learning_r = 0.01,
                                training_epochs = 5000,
                                features = train_x,
                                target = train_y,
                                logging_step = 1000,
                                keep_prob_val = 1.0)

for keep_prob_val = 1.0 and for 0.5.

```

在图 [5-12](#Fig12) 中，您可以看到在退出(`keep_prob=0.4`)的情况下，训练和 dev 数据集的 MSE 的演变。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig12_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig12_HTML.jpg)

图 5-12

带有漏失(`keep_prob=0.4`)的训练和开发数据集的 MSE

在图 [5-13](#Fig13) 中，你可以看到相同的情节，但没有辍学。差别非常明显。很有意思的一点是，在没有辍学的情况下，*MSE*<sub>T5】dev</sub>随着时代的发展而增长，而使用辍学，则相当稳定。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig13_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig13_HTML.jpg)

图 5-13

无脱落的训练和开发数据集的 MSE(`keep_prob=1.0`)

在图 [5-13](#Fig13) 中，*MSE*<sub>T5】dev</sub>在开始下降后增长。该模型处于明显的极端过拟合状态(*MSE*<sub>*train*</sub>≪*MSE*<sub>*dev*</sub>)，并且当应用于新数据时，它概括得越来越差。在图 [5-12](#Fig12) 中可以看到*MSE*<sub>*train*</sub>和*MSE*<sub>*dev*</sub>是同一个数量级，*MSE*<sub>*dev*</sub>没有继续增长。因此，我们有一个比图 [5-13](#Fig13) 所示结果更好的模型。

### 注意

当应用 dropout 时，您的指标(在这种情况下，MSE)将会振荡，所以当您试图找到最佳超参数时，如果您看到您的优化指标振荡，请不要感到惊讶。

## 提前停止

还有另一种技术，有时用于对抗过度拟合。严格地说，这种方法不能避免过度拟合；它只是在过拟合问题变得太糟糕之前停止学习。考虑上一节中的例子。在图 [5-14](#Fig14) 中，可以看到*MSE*<sub>T5】列车</sub> 和*MSE*<sub>*dev*</sub>绘制在同一地块上。

![../images/463356_1_En_5_Chapter/463356_1_En_5_Fig14_HTML.jpg](../images/463356_1_En_5_Chapter/463356_1_En_5_Fig14_HTML.jpg)

图 5-14

无脱落的训练和开发数据集的 MSE(`keep_prob=1.0`)。早期停止包括当 *MSE* <sub>*dev*</sub> 最小时(在图中用垂直线表示)在迭代中停止学习阶段。在右图中，您可以看到左图的前 1000 个时期的放大图。

提前停止简单地包括在 *MSE* <sub>*dev*</sub> 达到最小值的点停止训练(见图 [5-14](#Fig14) ，最小值在图中用垂直线表示)。注意，这不是解决过拟合问题的理想方法。你的模型仍然很可能对新数据进行非常糟糕的概括。我通常更喜欢使用其他技术。此外，这也非常耗时，并且是一个非常容易出错的手动过程。您可以通过检查 Wikipedia 页面获得不同应用程序上下文的概述，以便提前停止: [`https://goo.gl/xnKo2s`](https://goo.gl/xnKo2s) 。

## 其他方法

到目前为止，我讨论的所有方法都以某种形式存在，都是为了使模型不那么复杂。您保持数据不变，并修改您的模型。但是我们可以试着反其道而行之:让模型保持原样，处理数据。这里有两个对付过度拟合的常用策略(但不是很容易适用):

*   *获取更多数据*。这是对抗过度拟合的最简单的方法。不幸的是，在现实生活中，这往往是不可能的。请记住，这是一个复杂的问题，我将在下一章详细讨论。如果你正在对用智能手机拍摄的猫图片进行分类，你可能会想到从网络上获取更多的数据。虽然这似乎是一个非常好的主意，但你可能会发现这些图像质量不一，可能并不是所有的图像都是真正的猫(猫玩具呢？).此外，你可能只找到年轻的白猫的图像，等等。基本上，您的额外观察值可能来自与原始数据非常不同的分布，正如您将看到的，这将是一个问题。因此，在获取额外数据时，在继续之前要充分考虑潜在的问题。

*   *扩充你的数据*。例如，如果您正在处理图像，您可以通过旋转、拉伸、移动等方式生成其他图像。，你的图像。这是一个非常常见的技术，可能真的有用。

解决让模型在新数据上更好地推广的问题是机器学习的最大目标之一。这是一个复杂的问题，需要经验和考验。很多测试。在处理非常复杂的问题时，许多研究都在试图解决这类问题。我将在下一章讨论更多的技术。

<aside class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

在一个有两个类的[统计分类](https://en.wikipedia.org/wiki/Statistical_classification)问题中，一个决策边界或决策面是一个[面](https://en.wikipedia.org/wiki/Hypersurface)，它将底层空间分成两组，每组一个。(来源:维基百科， [`https://goo.gl/E5nELL`](https://goo.gl/E5nELL) )。

 </aside>*****
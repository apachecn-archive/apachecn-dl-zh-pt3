# 七、卷积神经网络

使用前馈神经网络，我们在 MNIST 和时尚 MNIST 数据集上取得了良好的训练性能。但是这些数据集中的图像很简单，并且位于包含它们的输入空间的中心。也就是说，它们在容纳它们的像素矩阵内居中。**输入空间**是模型的所有可能输入。

前馈神经网络非常擅长识别模式。因此，如果图像在其输入空间中占据相同的位置，前馈网络可以快速有效地识别图像模式。而且，如果图像在图像像素数量方面很简单，图案就更容易出现。但是，如果图像在它们的输入空间中没有占据相同的位置，前馈网络很难识别模式，从而表现得很糟糕！所以我们需要一个不同的模型来处理这些类型的图像。

我们可以用卷积神经网络对复杂的、偏离中心的图像进行训练，得到很好的效果。一个**卷积神经网络** (CNN 或 ConvNet)是一类最常用于视觉图像分析的深度神经网络。CNN 的灵感来自于它们与生物过程的相似性，因为神经元之间的连接类似于人类视觉皮层的组织。

CNN 的工作方式与前馈网络不同，因为它将数据视为空间数据。神经元不是连接到前一层的每个神经元，而是*只*连接到靠近它们的神经元，并且都具有相同的权重。连接的简化意味着网络支持数据集的空间特征。

假设图像是一个孩子的脸的侧面。一个 CNN 不认为孩子的眼睛在图像上到处重复。由于它所进行的过滤过程，它可以有效地在图像中定位孩子的眼睛。

CNN 通过为每个图像中的各种元素分配重要性来处理图像数据集，这使其能够区分图像。重要性是用可学习的权重和偏差来校准的。与其他分类算法相比，预处理要低得多，因为 CNN 有能力在训练期间学习如何调整其滤波器。

CNN 的核心构件是卷积层。**卷积层**包含一系列过滤器，通过将特征提取到特征图来转换输入图像，以供网络中的下一层使用。该变换将图像与一组具有小接收域的可学习滤波器(或卷积核)进行卷积。

**卷积**通过使用输入数据的小方块学习图像特征来保持像素之间的关系。**卷积核**是一种用于输入图像像素值的*子集*的过滤器。因此，卷积核是学习图像特征的输入数据的小方块之一。**感受域**是图像的一部分，其中卷积核在给定的时间点进行操作。*CNN 的特征图*捕捉将卷积核应用于输入图像的结果。因此，单个神经元只在感受野(或视野)的有限区域内对刺激做出反应。

咻！简单地说，卷积核是一个小矩阵，其高度和宽度小于要卷积的图像。在训练期间，核在输入图像的整个高度和宽度上滑动，并且在图像的每个空间位置计算核和图像的点积。这些计算创建特征地图作为输出。所以整个图像是由卷积核卷积的！这种卷积是 CNN 效率的关键，因为滤波过程允许它在训练期间调整滤波器参数。

我们从讨论 CNN 架构开始。我们从一些示例图像开始，以帮助您理解我们正在处理的数据类型。我们继续构建一个完整的 CNN 实验。我们使用著名的 *cifar10* 数据集。该数据集包含 60，000 张图像，旨在让深度学习爱好者创建和测试深度学习模型。我们演示了如何加载数据、构建输入流水线以及对数据建模。我们还将向您展示如何进行预测。

章节的笔记本位于以下网址: [`https://github.com/paperd/tensorflow`](https://github.com/paperd/tensorflow) 。

启用 GPU(如果尚未启用):

1.  点击左上角菜单中的*运行时*。

2.  从下拉菜单中点击*改变运行时间类型*。

3.  从*硬件加速器*下拉菜单中选择 *GPU* 。

4.  点击*保存*。

测试 GPU 是否处于活动状态:

```py
import tensorflow as tf

# display tf version and test if GPU is active
tf.__version__, tf.test.gpu_device_name()

```

导入 *tensorflow* 库。如果显示“/设备:GPU:0”，则 GPU 处于活动状态。如果'..'显示时，常规 CPU 处于活动状态。

## CNN 架构

像前馈神经网络一样，CNN 由多层组成。但是，卷积层和池化层使其独一无二。与其他神经网络一样，它也有一个 ReLU(整流线性单元)层和一个全连接层。 *any* 神经网络中的 ReLU 层充当激活函数，确保数据通过网络每一层时的非线性。如果没有 ReLU 激活，输入到每一层的数据将会失去我们希望它保持的维度。也就是说，当数据在网络中传输时，我们会丢失原始数据的完整性。全连接层允许 CNN 对数据进行分类。

如前所述，CNN 最重要的组成部分是卷积层。第一卷积层中的神经元连接到输入图像中的每一个像素，但只连接到其感受野中的像素，即只连接到靠近它们的像素。卷积层通过在图像像素阵列上放置过滤器(或卷积核)来工作。过滤过程创建一个*卷积特征图*，这是一个卷积层的输出。

一个*特征地图*通过将输入特征从我们的数据投影到隐藏单元来创建，以形成新的特征来提供给下一层。一个*隐藏单元*对应于输入体积中单个特定 x/y 偏移处的单个滤波器的输出。简单地说，隐藏单元是输出体积中特定 x，y，z 坐标处的值。

一旦我们有一个卷积的要素地图，我们移动到池层。*池层*对特定的特征地图进行子采样。子采样缩小了输入图像的大小，以减少计算负载、内存使用和参数数量。减少网络需要处理的参数数量也限制了过度拟合的风险。汇集图层的输出是一个*汇集的要素地图*。

我们可以通过两种方式汇集要素地图。 *Max pooling* 取特定卷积特征图的最大输入。*平均池*取特定卷积特征图的平均输入。

创建汇集的要素地图的过程会导致要素提取，从而使网络能够构建影像数据的图片。有了图像数据的图片，网络进入全连通层进行分类。正如我们对前馈网络所做的那样，我们将数据展平以供全连接层使用，因为它只能处理线性数据。

从概念上讲，CNN 是相当复杂的，你可以从我们的讨论中看出。但是在 TensorFlow 中实现 CNN 非常简单。每个输入图像通常被表示为形状为*高*、*宽*和*通道*的 3D 张量。当对 3D 彩色图像进行分类时，我们在三个通道中馈送 CNN 图像数据，即*红色*、*绿色*和*蓝色*。彩色图像通常被称为 *RGB* 图像。一个批次(例如小批次)被表示为形状为*的 4D 张量，批次大小*、*高度*、*宽度*和*通道*。

## 加载样本图像

sci kit-learn*load _ sample _ image*方法允许我们使用两种彩色图像进行练习——china.jpg 和 flower.jpg 的*。该方法加载单个示例图像的 numpy 数组，并将其作为由高度乘宽度乘颜色组成的 3D numpy 数组返回。*

加载图像:

```py
from sklearn.datasets import load_sample_image

china, flower = load_sample_image('china.jpg'),\
load_sample_image('flower.jpg')
china.shape, flower.shape

```

中国和花卉图像都表示为 427 个 640 像素的矩阵，有三个通道来表示 RGB 颜色。

## 显示图像

列表 [7-1](#PC3) 显示图像。

```py
import matplotlib.pyplot as plt

# function to plot RGB images
def plot_color_image(image):
    plt.imshow(image, interpolation="nearest")
    plt.axis("off")

plot_color_image(china)
plt.show()
plot_color_image(flower)

Listing 7-1Display china and flower images

```

## 缩放图像

缩放图像提高了训练性能。因为每个图像像素由一个从 0 到 255 的字节表示，所以我们将每个图像除以 255 来缩放它。

清单 [7-2](#PC4) 缩放图像。

```py
import numpy as np

# slice off a few pixels prior to scaling

br = '\n'

print ('pixels as loaded:', br)

print ('china pixels:', end = '  ')
print (np.around(china[0][0]))

print ('flower pixels:', end = ' ')
print (np.around(flower[0][0]), br)

# scale images
china_sc, flower_sc = china / 255., flower / 255.

# slice off some pixels to verify that scaling worked

print ('pixels scaled:', br)

print ('china pixels:', end = '  ')
print (np.around(china_sc[0][0], decimals=3))

print ('flower pixels:', end = ' ')
print (np.around(flower_sc[0][0], decimals=3))

Listing 7-2Scale images

```

缩放有效，因为像素强度介于 0 和 1 之间。

## 显示缩放图像

绘制缩放图像:

```py
plot_color_image(china_sc)
plt.show()
plot_color_image(flower_sc)

```

缩放不会影响图像，这是有意义的，因为缩放会按比例修改像素强度。也就是说，每个像素数都按比例转换为 0 到 1 之间的数。

## 获取更多图像

我们再拍几张照片。要获取本书的图片，只需遵循以下简单步骤:

1.  前往 GitHub 的这本书的网址: [`https://github.com/paperd/tensorflow`](https://github.com/paperd/tensorflow) 。

2.  找到您要下载的图像，然后单击它。

3.  点击*下载*按钮。

4.  右键单击图像内的任意位置。

5.  点击*将图像另存为…*

6.  将图像保存在您的计算机上。

7.  将图像拖放到 Google Drive*Colab Notebooks*文件夹中。

8.  对于多个图像，根据需要重复步骤 1-7。

对于本课，请转到图书 URL，单击*第 7 章*，单击*图像*，单击*fish.jpg*，单击*下载*按钮，在图像内单击右键，然后单击*将图像另存为…* 将其保存到您的计算机上。将图像拖放到 Google Drive*Colab Notebooks*文件夹中。对 *happy_moon.jpg* 图片重复同样的过程。

![img/501128_1_En_7_Figa_HTML.jpg](img/501128_1_En_7_Figa_HTML.jpg) ![img/501128_1_En_7_Figb_HTML.jpg](img/501128_1_En_7_Figb_HTML.jpg)

## 安装 Google Drive

Mount Colab 到 Google Drive:

```py
from google.colab import drive
drive.mount('/content/drive')

```

点击网址，选择一个谷歌账户，点击*允许*，复制授权码并粘贴到 Colab 的*文本框中，输入你的授权码:*，按下键盘上的*回车键*。

## 将图像复制到 Google Drive

在执行本节中的代码之前，请确保您的 Google Drive 上的 *Colab Notebooks* 目录中有*fish.jpg*和 *happy_moon.jpg* 图片！

请检查您的 Google Drive 帐户以验证正确的路径。我们将图像保存到 Colab 笔记本目录，这是推荐的。如果您将它们保存在其他地方，您必须相应地更改路径。

清单 [7-3](#PC7) 将图像加载到 Colab 环境，缩放图像，并显示它们。

```py
# be sure to copy images to the directory on Google Drive

from PIL import Image
import numpy as np

# create paths to images
fish_path = 'drive/My Drive/Colab Notebooks/fish.jpg'
moon_path = 'drive/My Drive/Colab Notebooks/happy_moon.jpg'

# create images
fish, moon  = Image.open(fish_path), Image.open(moon_path)

# convert images to numpy arrays and scale
fish_np, moon_np = np.array(fish), np.array(moon)
fish_sc, moon_sc = fish_np / 255., moon_np / 255.

# display images
plot_color_image(fish_sc)
plt.show()
plot_color_image(moon_sc)

Listing 7-3Load, scale, and display images

```

验证新图像是否正确缩放:

```py
# slice off some pixels and display

print ('fish pixels:', end = ' ')
print (np.around(fish_sc[0][0], decimals=3), br)

print ('moon pixels:', end = ' ')
print (np.around(moon_sc[0][0], decimals=3))

```

到目前为止一切都很好。

## 检查图像形状

对于机器学习应用，图像必须是*相同的*形状。

让我们探索图像形状:

```py
print ('original shapes:')
display (china_sc.shape, flower_sc.shape)
print (), print ('new shapes:')
display (fish_sc.shape, moon_sc.shape)

```

啊哦！形状不一样！我们该怎么办？

## 调整图像大小

让我们调整鱼和月亮图像的大小来均衡形状:

```py
fish_rs = np.array(tf.image.resize(
    fish_sc, [427, 640]))

moon_rs = np.array(tf.image.resize(
    moon_sc, [427, 640]))

fish_rs.shape, moon_rs.shape

```

现在，所有四个图像的大小都是(427，640，3)。

绘制调整大小的图像:

```py
plot_color_image(fish_rs)
plt.show()
plot_color_image(moon_rs)

```

成功！我们调整了新图像的大小，使之与原始图像一致。

## 创建一批图像

使用所有四个图像创建一个批处理:

```py
new_images = np.array([china_sc, flower_sc,
                       fish_rs, moon_rs])

new_images.shape

```

现在，我们有一批*四* 427 `×` 640 的彩色图像。RGB 颜色由三维表示。

## 创建过滤器

让我们创建两个简单的 7 `×` 7 过滤器。我们希望第一个过滤器中间有一条垂直白线，第二个过滤器中间有一条水平白线。*滤波器*用于在卷积过程中从图像中提取特征。通常，滤波器被称为*卷积核*。

创建过滤器:

```py
# assign some variables
batch_size, height, width, channels = new_images.shape

# create 2 filters
ck = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)
ck.shape

```

*zeros* 方法返回用零填充的给定形状和类型。因为变量 *ck* 被填充了零，所以它的所有像素都是黑色的。请记住，像素图像值是范围从 0(黑色)到 255(白色)的整数。

所以 *ck* 是一个包含*两个* 7 `×` 7 个三通道卷积核的 4D 张量。过滤器必须有三个通道来匹配我们创建的一批图像中的彩色图像。

添加垂直白线和水平白线:

```py
ck[:, 3, :, 0] = 1  # add vertical line
ck[3, :, :, 1] = 1  # add horizontal line

```

该代码改变选择像素的强度，以获得一条垂直白线和一条水平白线。

## 绘制卷积核

清单 [7-4](#PC15) 描绘了我们刚刚创建的两个卷积核。

```py
# function to plot filters

def plot_image(image):
    plt.imshow(image, cmap="gray", interpolation="nearest")
    plt.axis("off")

print ('vertical convolutional kernels:')

plot_image(ck[:, :, 0, 0])
plt.show()

print ('horizontal convolutional kernels:')
plot_image(ck[:, :, 0, 1])

Listing 7-4Convolutional kernel plots

```

我们看到垂直和水平的白线(或卷积核)已经就位。所以我们已经成功地创建了两个简单的卷积核。

## 应用 2D 卷积层

对该批图像应用 2D 卷积层:

```py
# apply a 2D convolutional layer
outputs = tf.nn.conv2d(new_images, ck, strides=1,
 padding='SAME')

```

给定 4D 输入和卷积核张量， *tf.nn.conv2d* 方法计算 2d 卷积。我们设置步长等于 *1* 。一个**步距**是我们在训练期间在输入矩阵上移动卷积核的像素数。步长为 1 时，我们一次移动卷积核一个像素。我们将填充设置为与相同的*。**填充**是 CNN 处理图像时添加到图像中的像素数量。例如，如果填充设置为零，则添加的每个像素值将为零值。填充设置为相同意味着我们使用零填充。*

在应用卷积层之后，变量*输出*包含基于我们的图像的特征图。因为每个卷积核创建一个特征图(我们有两个卷积核)，所以每个图像有两个特征图。

## 可视化要素地图

如清单 [7-5](#PC17) 所示，可视化我们刚刚创建的特征地图。

```py
rows = 4  # one row for each image
columns = 2  # two feature maps for each image
cnt = 1
fig = plt.figure(figsize=(8, 8))
for i, img in enumerate(outputs):
  for j in (0, 1):
    fig.add_subplot(rows, columns, cnt)
    plt.imshow(outputs[i, :, :, j], cmap="gray")
    plt.axis('off')
    cnt += 1
plt.show()

Listing 7-5Feature maps plot

```

由于我们有两个卷积核和四个图像，卷积层产生八个特征图。2 乘以 4 就行了！所以我们对每张图片都有两张特征图。哇！使用两个简单的卷积核，我们能够通过应用单个卷积层来提取一批图像的优秀复制品。

## 带有可训练过滤器的 CNN

我们只是*手动*定义了两个卷积核。但是，在真实的 CNN 中，我们通常将卷积核定义为可训练变量，这样神经网络就可以学习效果最好的卷积核。

创建一个简单的模型，让网络决定最佳卷积核:

```py
conv = tf.keras.layers.Conv2D(filters=32, kernel_size=3,
                              strides=1, padding="SAME",
                              activation='relu')

```

我们用 32 个卷积核创建了一个 *Conv2D* 层。每个卷积核是由 *kernel_size* 表示的 3 `×` 3 张量。我们在水平和垂直方向上都使用了 *1* 的步幅。填充与*相同*。最后，我们对输出应用 *relu* 激活。

卷积层具有相当多的超参数，包括滤波器(或卷积核)的数量、卷积核的高度和宽度、步长、填充类型和激活类型。为了获得最佳性能，我们可以调整超参数。但是调音是一个高级主题，我们认为不适合作为入门书籍。相反，我们提供了一些基本的例子，你可以通过练习来发展实用技能。

## 建立一个 CNN

虽然 CNN 是一个序列神经网络，但它在两个重要方面不同于前馈序列神经网络。首先，它有一个未完全连接的卷积基。第二，它有一个汇集层来减少每个卷积层创建的要素地图的样本大小。我们仍然使用全连通层进行分类。

我们从加载彩色图像数据集开始这个实验。我们继续准备TensorFlow消耗的数据。然后，我们构建并测试一个 CNN 模型。我们使用的数据集是 *cifar10* 。我们之前用前馈模型模拟了这个数据集，但是我们的结果很糟糕。所以我们想向你展示 CNN 如何更好地处理复杂的彩色图像。

### 加载数据

建议以 TFDS 方式加载 cifar10:

```py
# import TFDS library
import tensorflow_datasets as tfds

```

负载训练和测试集:

```py
train, info = tfds.load('cifar10', split="train",
                        with_info=True, shuffle_files=True)
test = tfds.load('cifar10', split="test")

```

因为我们已经有了来自训练集的*信息*,所以我们不再需要它用于测试集。

验证张量:

```py
train.element_spec, test.element_spec

```

训练和测试形状为 32 `×` 32 `×` 3。所以每个图像是一个 32 `×` 32 三通道图像。 *3* 维度告知模型图像是 RGB 颜色。

### 显示关于数据集的信息

*信息*对象显示关于数据的信息:

```py
info

```

我们可以看到特征图像和标签的名称、描述、主页、形状和数据类型。我们还看到数据集有 60，000 幅图像，训练和测试分割分别为 50，000 和 10，000。

### 提取类别标签

从*信息*对象中提取一些有用的信息:

```py
br = '\n'

num_classes = info.features['label'].num_classes
class_labels = info.features['label'].names
print ('number of classes:', num_classes, br)
print ('class labels:', class_labels)

```

### 展示样品

*show_examples* 方法展示了几个例子:

```py
fig = tfds.show_examples(train, info)

```

### 构建一个自定义函数来显示示例

清单 [7-6](#PC25) 是显示样本的函数。

```py
import matplotlib.pyplot as plt, numpy as np

def display_samples(data, num, cmap):
  for example in data.take(num):
    image, label = example['image'], example['label']
    print ('Label:', class_labels[label.numpy()], end=', ')
    print ('Index:', label.numpy())
    plt.imshow(image.numpy()[:, :, 0].astype(np.float32),
               cmap=plt.get_cmap(cmap))
    plt.show()

Listing 7-6Function to display samples

```

该函数检索图像和标签名称。然后，它显示图像及其标签名称和索引。索引是作为数字的类标签。

调用函数:

```py
# choose colormap by changing 'indx'

cmap = ['coolwarm', 'viridis', 'plasma',
        'seismic', 'twilight', 'Spectral']
indx, samples = 5, 3
display_samples(train, samples, cmap[indx])

```

通过在 0 和 5 之间调节 *indx* 来改变颜色。通过调节*样品*改变显示的样品数量。仔细阅读以下网址，了解更多关于色彩映射表的信息: [`https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html`](https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html) 。

### 构建一个自定义函数来显示示例网格

首先从清单 [7-7](#PC27) 所示的训练集中抽取 30 个样本。

```py
num = 30
images, labels = [], []
for example in train.take(num):
  image, label = example['image'], example['label']
  images.append(tf.squeeze(image.numpy()))
  labels.append(label.numpy())

Listing 7-7Processed examples from the train set

```

为了能够绘制图像，我们从图像矩阵中移除(或挤压)三维。

构建如清单 [7-8](#PC28) 所示的函数。

```py
def display_grid(feature, target, n_rows, n_cols, cl):
  plt.figure(figsize=(n_cols * 1.5, n_rows * 1.5))
  for row in range(n_rows):
    for col in range(n_cols):
      index = n_cols * row + col
      plt.subplot(n_rows, n_cols, index + 1)
      plt.imshow(feature[index], cmap="binary",
                 interpolation='nearest')
      plt.axis('off')
      plt.title(cl[target[index]], fontsize=12)
  plt.subplots_adjust(wspace=0.2, hspace=0.5)

Listing 7-8Function to display a grid of examples

```

调用函数:

```py
rows, cols = 5, 6
display_grid(images, labels, rows, cols, class_labels)

```

给你！

### 精确定位元数据

利用信息对象精确定位元数据:

```py
print ('Number of training examples:', end=' ')
print (info.splits['train'].num_examples)

print ('Number of test examples:', end=' ')
print (info.splits['test'].num_examples)

```

### 构建输入流水线

如清单 [7-9](#PC31) 所示构建输入流水线。

```py
BATCH_SIZE = 128
SHUFFLE_SIZE = 5000

train_1 = train.shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE)
train_2 = train_1.map(lambda items: (
    tf.cast(items['image'], tf.float32) / 255., items['label']))
train_cf = train_2.cache().prefetch(1)

test_1 = test.batch(BATCH_SIZE)
test_2 = test_1.map(lambda items: (
    tf.cast(items['image'], tf.float32) / 255., items['label']))
test_cf = test_2.cache().prefetch(1)

Listing 7-9Build the input pipeline

```

我们通过混洗训练数据、批处理、缩放、缓存和预取来构建输入流水线。我们通过使用 lambda 函数映射来缩放图像。添加*缓存*方法可以提高 TFDS 的性能，因为数据只被读写一次，而不是在每个时期。添加*预取*方法是一个好主意，因为它增加了批处理过程的效率。也就是说，当我们的训练算法处理一批时，TensorFlow 正在并行处理数据集，以准备下一批。因此预取可以极大地提高训练成绩。

验证是否正确创建了训练集和测试集:

```py
train_cf.element_spec, test_cf.element_spec

```

### 创建模型

从相对健壮的 CNN 模型开始，因为这是从复杂的彩色图像中获得良好性能的唯一方法。不要被层数吓倒！请记住，CNN 有一个卷积基础和全连接网络。所以我们可以把 CNN 分成两部分。首先，我们构建包含一个或多个卷积层和池层的卷积基础。包括汇集层以对从卷积层输出的特征图进行二次采样，从而减少计算开销。接下来，我们构建一个用于分类的全连通层。

按照以下步骤创建模型:

1.  导入库。

2.  清除以前的模型。

3.  创建模型。

导入库:

```py
# import libraries

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D,\
Dense, Flatten, Dropout

```

清除以前的模型并播下种子:

```py
# clear previous models and generate a seed
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建如清单 [7-10](#PC35) 所示的模型。

```py
# build the model

model = Sequential([
  Conv2D(32, (3, 3), activation = 'relu', padding="same",
         input_shape=[32, 32, 3], strides=1),
  MaxPooling2D(2),
  Conv2D(64, (3, 3), activation="relu", padding="same"),
  MaxPooling2D(2),
  Conv2D(64, (3, 3), activation="relu", padding="same"),
  Flatten(),
  Dense(64, activation="relu"),
  Dropout(0.5),
  Dense(10, activation="softmax")
])

Listing 7-10Build the model

```

第一层是卷积基，使用 32 个卷积核，核大小为 3 `×` 3。我们使用 *relu* 激活、*相同*填充、 *1* 的步幅。我们还将形状设置为 32 `×` 32 `×` 3，以匹配 32 `×` 32 像素的图像。因为图像是彩色的，所以我们在末尾包含了 3 值。接下来，我们包括一个大小为 2 的最大池图层(因此它将每个空间维度除以因子 2 ),以从第一个卷积图层对要素地图进行二次采样。然后，我们重复相同的结构两次，但是将卷积核的数量增加到 64。通常的做法是在每个池层之后加倍卷积核的数量。

我们继续使用全连通网络，该网络使其输入变平，因为密集网络需要每个实例的 1D 要素阵列。我们需要添加完全连接的层，以便对我们的 10 个标签进行分类。我们继续研究 64 个神经元的密集层。我们添加辍学，以减少过度拟合。最终的密集层接受十个输入以匹配标签的数量。它使用 *softmax* 激活。

### 模型摘要

检查模型:

```py
model.summary()

```

**参数**是训练期间可学习的重量数。卷积层是 CNN 开始学习的地方。但是计算 CNN 的参数比前馈网络更复杂。

第一层是卷积层，有 32 个神经元作用于数据。过滤器尺寸为 3 `×` 3。所以我们有一个 3 `×` 3 `×` 32 过滤器，因为我们的输入有 32 个维度(或神经元),总共 288 个。乘以 288 `by` 3，得到总共 864 张 3D RGB 彩色图像。在这一层加上 32 个神经元，总共得到 896 个参数。

在池层没有需要学习的参数。所以我们有 0 个参数。

第二个卷积层有 64 个神经元对数据起作用。过滤器尺寸为 3 `×` 3。所以我们有一个 3 `×` 3 `×` 64 的过滤器，因为我们有 64 个维度，总共 576 个。将前一卷积层的 32 个神经元乘以 576，得到总数 18，432。在这一层加上 64 个神经元，总共得到 18，496 个参数。

第三卷积层有 64 个神经元对数据起作用。过滤器尺寸为 3 `×` 3。所以我们有一个 3 `×` 3 `×` 64 的过滤器，因为我们有 64 个维度，总共 576 个。将前一卷积层的 64 个神经元乘以 576，得到总数 36，864。在这一层加上 64 个神经元，总共得到 36，928 个参数。

完全连接的密集层如前计算。我们将这一层的 4096 个神经元乘以上一层的 64 个神经元，得到 262144。在这一层加上 64 个神经元，总共得到 262，208 个参数。

通过将前一层的 64 个神经元乘以该层的 10 个，并在该层添加 10 个神经元，输出层具有 650 个参数。咻！

### 模型层

检查模型层:

```py
model.layers

```

### 编译模型

通过实验，我们发现 *Nadam* 优化器表现最佳:

```py
model.compile(optimizer='nadam',
 loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

```

### 训练模型

为十个时期训练模型:

```py
epochs = 10
history = model.fit(train_cf, epochs=epochs,
                    verbose=1, validation_data=test_cf)

```

虽然我们的模型不是最先进的，但我们比使用前馈网络做得好得多。

### 对测试数据进行归纳

概括:

```py
print('Test accuracy:', end=' ')
test_loss, test_acc = model.evaluate(test_cf, verbose=2)

```

### 可视化培训表现

清单 [7-11](#PC41) 可视化训练。

```py
plt.plot(history.history['accuracy'], label="accuracy")
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')
plt.show()

plt.plot(history.history['loss'], label="loss")
plt.plot(history.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.5, 1.0])
plt.legend(loc='lower right')
plt.show()

Listing 7-11Visualization of training performance

```

### 预测测试图像的标签

根据 *test_cf* 数据进行预测:

```py
predictions = np.argmax(model.predict(test_cf), axis=-1)

```

用 *argmax* 方法包装*预测*方法，以直接获得预测的标签，而不是生成概率数组。

通过类别号获得预测:

```py
# predictions by class number
predictions

```

通过标签获取预测:

```py
# predictions by class label
np.array(class_labels)[predictions]

```

获得前五个预测:

```py
# 5 predictions
pred_5 = predictions[:5]
pred_5

```

将标签编号转换为标签名称:

```py
pred_labels = np.array(class_labels)[pred_5]
pred_labels

```

获取前五个实际标签，如清单 [7-12](#PC47) 所示。

```py
# take the first batch of images
ls = []
for _, label in test_cf.take(1):
  ls.append(label.numpy())

# slice first five from batch
actuals = ls[0][0:5]

# convert to labels
actuals = [class_labels[row] for row in actuals]
actuals

Listing 7-12First five actual labels

```

获取第一批图像。因为我们将批量大小设置为 128，所以我们得到了前 128 个图像。从批次中截取前五个图像。转换为标签名称。

将*预测标签*与*实际标签*进行比较，以了解预测性能。

### 构建预测图

如清单 [7-13](#PC48) 所示，从测试集中抽取 20 个样本开始。

```py
num = 20
images, labels = [], []
for example in test.take(num):
  image, label = example['image'], example['label']
  images.append(tf.squeeze(image.numpy()))
  labels.append(label.numpy())

Listing 7-13Take samples from the test set

```

### 构建自定义函数

构建一个函数来显示结果，如清单 [7-14](#PC49) 所示。

```py
def display_test(feature, target, num_images,
                 n_rows, n_cols, cl, p):
  for i in range(num_images):
    plt.subplot(n_rows, 2*n_cols, 2*i+1)
    plt.imshow(feature[i])
    title_obj = plt.title(cl[target[i]] + ' (' +\
 cl[p[i]] + ') ')
    if cl[target[i]] == cl[p[i]]:
      title_obj
    else:
      plt.getp(title_obj, 'text')
      plt.setp(title_obj, color="r")
  plt.tight_layout()
plt.show()

Listing 7-14Function to display results

```

调用函数:

```py
num_rows, num_cols = 5, 4
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
display_test(images, labels, num_images, num_rows,
             num_cols, class_labels, predictions)

```

红色标题表示分类错误。

## 用 Keras 数据建立一个 CNN

虽然建议以 TFDS 的形式加载数据，但 Keras 在业界非常流行。因此，让我们从 *keras.datasets* 建立一个模型。

加载训练和测试数据:

```py
train_k, test_k = tf.keras.datasets.cifar10.load_data()

```

验证数据形状:

```py
print ('train data:', br)
print (train_k[0].shape)
print (train_k[1].shape, br)
print ('test data:', br)
print (test_k[0].shape)
print (test_k[1].shape)

```

创建类别标签名称:

```py
class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                'dog', 'frog', 'horse', 'ship', 'truck']

```

### 创建变量以保存训练和测试样本

创建变量来保存训练和测试数据，如清单 [7-15](#PC54) 所示。

```py
# create simple variables from train tuple
train_images = train_k[0]
train_labels = train_k[1]

# display first train label
print ('1st train label:', class_labels[train_labels[0][0]])

# create simple variables from test tuple
test_images = test_k[0]
test_labels = test_k[1]

# display first test label
print ('1st test label: ', class_labels[test_labels[0][0]])

Listing 7-15Create variables to hold train and test data

```

### 显示样本图像

展示一些图像总是一个好主意。在这种情况下，我们显示来自训练数据集的 30 幅图像。可视化使我们能够验证图像和标签是否对应。也就是把一个青蛙形象贴上青蛙的标签等等。

清单 [7-16](#PC55) 显示了来自训练集的样本图像。

```py
n_rows = 5
n_cols = 6
plt.figure(figsize=(n_cols * 1.5, n_rows * 1.5))
for row in range(n_rows):
  for col in range(n_cols):
    index = n_cols * row + col
    plt.subplot(n_rows, n_cols, index + 1)
    plt.imshow(train_images[index], cmap="binary",
               interpolation='nearest')
    plt.axis('off')
    plt.title(class_labels[int(train_labels[index])],
 fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)

Listing 7-16Display sample images

```

### 创建输入流水线

通过缩放图像并将它们分割成 TensorFlow 可消耗的片段来构建输入流水线。继续混洗(如果合适)、批处理和预取。

清单 [7-17](#PC56) 创建输入流水线。

```py
# scale images

train_img_sc = train_images / 255\.  # divide by 255 to scale
train_lbls = train_labels.astype(np.int32)

test_img_sc = test_images/255\.  # divide by 255 to scale
test_lbls = test_labels.astype(np.int32)

# slice data

train_ks = tf.data.Dataset.from_tensor_slices(
    (train_img_sc, train_lbls))
test_ks = tf.data.Dataset.from_tensor_slices(
    (test_img_sc, test_lbls))

# shuffle, batch, and prefetch

BATCH_SIZE = 128
SHUFFLE_BUFFER_SIZE = 5000

train_ds = train_ks.shuffle(
    SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(1)
test_ds = test_ks.batch(BATCH_SIZE).prefetch(1)

Listing 7-17Build the input pipeline

```

检查张量:

```py
train_ds, test_ds

```

### 创建模型

清单 [7-18](#PC58) 创建模型。

```py
# import libraries
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D,\
Dense, Flatten, Dropout

# clear previous models and generate a seed
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

# build the model
model = Sequential([
  Conv2D(32, 3, activation = 'relu', padding="same",
         input_shape=[32, 32, 3]),
  MaxPooling2D(2),
  Conv2D(64, 3, activation="relu", padding="same"),
  MaxPooling2D(2),
  Conv2D(64, 3, activation="relu", padding="same"),
  Flatten(),
  Dense(64, activation="relu"),
  Dropout(0.5),
  Dense(10, activation="softmax")
])

Listing 7-18Create the model

```

### 编译和训练

清单 [7-19](#PC59) 编译并训练模型。

```py
# compile
model.compile(optimizer='nadam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# train
epochs = 10
history = model.fit(train_ds, epochs=epochs,
                    verbose=1, validation_data=test_ds)

Listing 7-19Compile and train the model

```

### 预测

从模型预测:

```py
pred_ks = np.argmax(model.predict(test_images), axis=-1)

```

### 可视化结果

清单 [7-20](#PC61) 将培训绩效结果可视化。

```py
# plot the first X (num_rows * num_cols) test images
# (true and predicted labels)

num_rows = 5
num_cols = 4
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  ax = plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plt.imshow(test_images[i])
  title = class_labels[int(test_labels[i])] +
  ' (' +\class_labels[pred_ks[i]] + ') '
  plt.title(title)
  if class_labels[int(test_labels[i])] !=\
     class_labels[pred_ks[i]]:
    ax.set_title(title, style="italic", color="red")
  plt.axis('off')
plt.tight_layout()

Listing 7-20Visualize

training performance results

```

## 收场白

在过去的几年中，对基本 CNN 架构的许多改进已经被开发出来，极大地提高了预测性能。虽然我们在本课中没有涉及这些进步，但我们相信我们提供了 CNN 的基本基础，可以帮助您轻松地使用这些最新的进步，甚至是未来的许多进步。
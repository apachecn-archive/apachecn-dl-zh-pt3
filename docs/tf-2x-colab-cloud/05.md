# 5.分类

**分类**是一种监督学习方法，用于预测给定输入数据示例的类别标签。虽然我们用 MNIST 介绍了分类，但我们通过著名的时尚-MNIST 数据集来更深入地研究这个主题。

*时尚-MNIST* 旨在作为 MNIST 的直接替代者，以更好地基准测试机器学习算法。它共享相同的图像大小和结构的训练和测试分裂，但更具挑战性的分类问题。

MNIST 基准有几个相关的问题。标准的机器学习算法要达到 97%以上的准确率太容易了。深度学习模型更容易达到 99%以上的准确率。数据集被过度使用。最后，MNIST 不能代表现代计算机视觉任务。

章节的笔记本位于以下网址: [`https://github.com/paperd/tensorflow`](https://github.com/paperd/tensorflow) 。

启用 GPU(如果尚未启用):

1.  点击左上角菜单中的*运行时*。

2.  从下拉菜单中点击*改变运行时间类型*。

3.  从*硬件加速器*下拉菜单中选择 *GPU* 。

4.  点击*保存*。

测试 GPU 是否处于活动状态:

```py
import tensorflow as tf

# display tf version and test if GPU is active
tf.__version__, tf.test.gpu_device_name()

```

导入 *tensorflow* 库。如果显示“/设备:GPU:0”，则 GPU 处于活动状态。如果'..'显示时，常规 CPU 处于活动状态。

## 时尚 MNIST 数据集

**时尚-MNIST** 是由 Zalando Research 创建的服装图片数据集，由 60，000 个样本的训练集和 10，000 个样本的测试集组成。每个示例都是一个 28 × 28 灰度图像，与来自 10 个类别的标签相关联。

Zalando Research 是一家利用敏捷设计流程的组织，该流程将宝贵的人类经验与机器学习的能力相结合。Zalando 专注于探索在时装设计中使用生成模型的新方法，以实现快速可视化和原型制作。

## 加载时尚-MNIST 作为一个 TFDS

由于时尚 MNIST 是一个 tfds.data.Dataset，我们可以很容易地用 tfds.load 加载它。要获得所有 tfds 的列表，只需运行 tfds.list_builders 方法，如第 [3](03.html) 章所示。

将训练和测试示例作为 tf.data.Dataset 加载:

```py
import tensorflow_datasets as tfds

train, info = tfds.load('fashion_mnist', split="train",
                        with_info=True, shuffle_files=True)
test = tfds.load('fashion_mnist', split="test")

```

由于我们已经从训练数据中获得了*信息*，我们不需要为测试数据再次加载它。

验证培训和测试数据:

```py
train.element_spec, test.element_spec

```

每幅图像由 28 个像素组成。 *1* 尺寸表示图像为灰度。每个标签都是一个标量。

### 浏览数据集

显示关于数据集的信息:

```py
info

```

我们可以看到名称、描述和主页。我们还可以看到特征图像和标签的形状和数据类型。我们看到，我们有 70，000 个示例，训练和测试拆分分别为 60，000 和 10，000。还包括许多其他信息。

提取类别和类别标签的数量:

```py
br = '\n'

num_classes = info.features['label'].num_classes
class_labels = info.features['label'].names
print ('number of classes:', num_classes, br)
print ('class labels:', class_labels)

```

我们有十个类别，代表十种服装。

让我们看一些培训示例:

```py
fig = tfds.show_examples(train, info)

```

show_examples 方法显示样本图像和标签。标签名称和相关的类别号显示在每个图像下。例如，*套头衫*的分类编号是 *2* ，因为它是分类标签列表中的第三个标签。

清单 [5-1](#PC7) 是一个自定义函数，显示来自训练数据集的样本。

```py
import matplotlib.pyplot as plt, numpy as np

def display_samples(data, num, cmap):
  for example in data.take(num):
    image, label = example['image'], example['label']
    print ('Label:', class_labels[label.numpy()], end=', ')
    print ('Index:', label.numpy())
    plt.imshow(image.numpy()[:, :, 0].astype(np.float32),
               cmap=plt.get_cmap(cmap))
    plt.show()

Listing 5-1Custom function for displaying sample data

```

导入几个库。该函数接受数据集、要显示的样本数和色彩映射表。一个**色图**是一个颜色数组，用于将像素数据映射到实际的颜色值。matplotlib 库提供了各种内置的色彩映射表。

我们将示例图像和标签分配给变量。然后，我们显示标签名及其相关的类别号。最后，我们用 *imshow()* 函数显示图像。我们使用 *[:，:，0]* 从每幅图像中抓取所有像素。

调用该函数显示几幅训练图像:

```py
# choose colormap by changing 'indx'

indx = 5
cmap = ['coolwarm', 'viridis', 'plasma',
        'seismic', 'copper', 'twilight']
samples = 2
display_samples(train, samples, cmap[indx])

```

现在，让我们构建一个自定义函数来显示样本网格。

在我们创建函数之前，从清单 [5-2](#PC9) 所示的训练集中提取 30 个样本。

```py
num = 30
images, labels = [], []
for example in train.take(num):
  image, label = example['image'], example['label']
  images.append(tf.squeeze(image.numpy()))
  labels.append(tf.squeeze(label.numpy()))

Listing 5-2Take samples from the train set

```

创建如清单 [5-3](#PC10) 所示的函数。

```py
def display_grid(feature, target, n_rows, n_cols, cl):
  plt.figure(figsize=(n_cols * 1.5, n_rows * 1.5))
  for row in range(n_rows):
    for col in range(n_cols):
      index = n_cols * row + col
      plt.subplot(n_rows, n_cols, index + 1)
      plt.imshow(feature[index], cmap="binary",
                 interpolation='nearest')
      plt.axis('off')
      plt.title(cl[target[index]], fontsize=12)
  plt.subplots_adjust(wspace=0.2, hspace=0.5)

Listing 5-3Function that displays a grid of examples

```

调用函数:

```py
rows = 5
cols = 6
display_grid(images, labels, rows, cols, class_labels)

```

我们还可以使用 DatasetInfo 精确定位元数据:

```py
print ('Number of training examples:', end=' ')
print (info.splits['train'].num_examples)

print ('Number of test examples:', end=' ')
print (info.splits['test'].num_examples)

```

### 构建输入流水线

如清单 [5-4](#PC13) 所示，建立训练和测试数据的输入流水线。

```py
BATCH_SIZE = 128
SHUFFLE_SIZE = 5000

train_f1 = train.shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE)
train_f2 = train_f1.map(lambda items: (
    tf.cast(items['image'], tf.float32) / 255., items['label']))
train_fs = train_f2.cache().prefetch(1)

test_f1 = test.batch(BATCH_SIZE)
test_f2 = test_f1.map(lambda items: (
    tf.cast(items['image'], tf.float32) / 255., items['label']))
test_fs = test_f2.cache().prefetch(1)

Listing 5-4Build the input pipeline

```

混洗和批量训练数据。缩放列车图像。缓存和预取训练图像。批量测试数据。缩放测试图像。缓存和预取测试图像。在这个实验中，批量大小为 128，随机缓冲区大小为 5，000。

Note

不要混洗测试数据，因为它被认为是神经网络模型的新数据。

缓存 TFDS 可以显著提高性能。tf.data.Dataset 的 *cache* 方法可以在内存或本地存储上缓存数据集，这样可以避免在每个 epoch 期间执行文件打开和数据读取等操作。

添加预取是一个好主意，因为它提高了批处理过程的效率。当我们的训练算法处理一批时，TensorFlow 正在并行处理数据集，以准备下一批。因此预取可以极大地提高训练成绩。

有关 TFDS 性能改进的更多信息，请阅读

*   [T2`www.tensorflow.org/datasets/performances`](http://www.tensorflow.org/datasets/performances)

*   [T2`www.tensorflow.org/guide/data_performance`](http://www.tensorflow.org/guide/data_performance)

验证训练和测试张量:

```py
train_fs.element_spec, test_fs.element_spec

```

训练和测试图像都是 28 `×` 28 `×` 1。1 值意味着图像是灰度的。也就是说，图像是黑白的。

### 建立模型

让我们构建一个简单的前馈神经网络，如清单 [5-5](#PC15) 所示。

```py
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout

# clear previous model and generate a seed
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

model = Sequential([
  Flatten(input_shape=[28, 28, 1]),
  Dense(512, activation="relu"),
  Dropout(0.4),
  Dense(10, activation="softmax")
])

Listing 5-5Simple feedforward neural network

```

导入必需的库。清除任何以前的模型会话，并生成种子以促进结果的再现性。第一层使图像变平。第二层使用 512 个神经元上的 *relu* 激活来处理数据。第三层使用 dropout 来减少过拟合。第四层使用十个神经元上的 softmax 激活来说明类别标签。

### 模型摘要

显示模型的摘要:

```py
model.summary()

```

第一层的输出形状是(无，784)。我们用 28 乘以 28 得到 784。我们在这一层没有参数，因为它仅用于将数据引入模型。

第二层的输出形状是(无，512)，因为在这一层有 512 个神经元。我们通过将这一层的 512 个神经元乘以上一层的 784 个神经元，再加上这一层的 512，得到参数 401，920。

第三层的输出形状为(None，512)，参数为 0，因为 dropout 不会影响神经元或参数。第四层的输出形状是(None，10 ),因为我们在这一层有十个神经元来处理十个输出类。我们把这一层的 10 个神经元乘以上一层的 512，再加上这一层的 10 个神经元，得到参数 5130。

Note

因为 TensorFlow 模型可以接受任何批量，所以没有使用。

### 编译模型

定义调整模型参数以最小化损失函数的梯度下降优化器:

```py
model.compile(optimizer='adam',
 loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

```

### 训练模型

用十个纪元训练模型:

```py
epochs = 10
history = model.fit(train_fs, epochs=epochs,
                    verbose=1, validation_data=test_fs)

```

我们得到了相当好的精度，没有太多的过度拟合。

### 对测试数据进行归纳

虽然训练提供了准确性和损失度量，但明确地评估测试数据上的模型以查看模型在新数据上的概括程度始终是一个好主意:

```py
print('Test accuracy:', end=' ')
test_loss, test_acc = model.evaluate(test_fs, verbose=2)

```

### 可视化性能

*fit* 方法自动将训练过程的历史记录为字典。所以我们可以把训练信息赋给一个变量。在这种情况下，我们将其分配给历史。变量的历史属性包含字典信息。

显示字典键，通知我们如何绘制结果:

```py
hist_dict = history.history
print (hist_dict, '\n')
print (hist_dict.keys())

```

字典 history.history 包含模型在训练集和验证(或测试)集的每个时期结束时测量的 loss、accuracy、val_loss 和 val_accuracy 度量。

*params* 变量提供了与训练相关的所有参数:

```py
history.params

```

绘制训练性能，如清单 [5-6](#PC22) 所示。

```py
plt.plot(history.history['accuracy'], label="accuracy")
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')
plt.show()

plt.plot(history.history['loss'], label="loss")
plt.plot(history.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.05, .7])
plt.legend(loc='lower right')
plt.show()

Listing 5-6Plot training performance

```

我们没有太多的过度拟合，对于这样一个简单的神经网络，我们的模型精度相当好。

我们也可以用熊猫来策划训练表演:

```py
import pandas as pd

pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1)

```

### 预测测试图像的标签

现在我们有了一个训练好的模型，我们可以根据测试图像进行预测。我们根据测试图像进行预测，因为模型将这些图像视为新的数据。

首先预测测试集中每个图像的标签:

```py
tf.random.set_seed(0)

predictions = model.predict(test_fs)

```

我们在处理过的测试集 *test_fs* 上使用 *predict* 方法。

因为《时尚-MNIST》有十个类别标签，所以每个预测都由十个数字组成的数组组成，这些数字代表模特对图像与十件不同服装的对应程度的*信心*。

先来看看*第一个*预测:

```py
predictions[0]

```

第一个预测是在索引 0 处，因为对于 10，000 的测试集大小，Python 索引的范围是从 0 到 9999。通过查看浮点数值的数组，很难判断哪个值的数字最大。

对预测数组中的数字进行舍入，以便更容易看到数组中可信度最高的位置:

```py
np.round(predictions[0], 2)

```

现在，我们可以清楚地看到数字最高的值。置信度最高的位置对应于类别标签数组中的位置。

我们可以用下面的代码直接导出预测的置信度:

```py
c = 100*np.max(predictions[0])
c

```

展示自信:

```py
'{:.2%}'.format(np.max(predictions[0]))

```

显示测试集中第*张*图像的预测:

```py
np.argmax(predictions[0])

```

预测值必须在 0 到 9 之间，因为我们的目标值在 0 到 9 之间。

使用我们之前创建的 *class_labels* 数组来查看实际的时尚文章:

```py
class_labels[np.argmax(predictions[0])]

```

因此，我们有了测试集中第一幅图像的预测服装。

显示第*张*实际测试图像:

```py
# take the first batch of images

for image, label in test_fs.take(1):
  label

class_labels[label[0].numpy()]

```

我们从一批 128 个图像中取出第一个图像，因为我们将批量大小设置为 128。如果预测与测试图像匹配，则它是正确的预测。

### 构建预测图

现在我们有了一个训练好的模型，我们可以建立一个预测图。

因为我们想看看模型在新数据上的表现如何，所以从测试集中抽取 30 个样本，如清单 [5-7](#PC32) 所示。

```py
num = 30
images, labels = [], []
for example in test.take(num):
  image, label = example['image'], example['label']
  images.append(tf.squeeze(image.numpy()))
  labels.append(tf.squeeze(label.numpy()))

Listing 5-7Take samples from the test set

```

挤压每个图像以移除 1 维，以便绘图。

构建一个绘图函数，如清单 [5-8](#PC33) 所示。

```py
def display_test(feature, target, num_images,
                 n_rows, n_cols, cl, p):
  for i in range(num_images):
    plt.subplot(n_rows, 2*n_cols, 2*i+1)
    if cl[target[i]] != cl[np.argmax(p[i])]:
      plt.imshow(feature[i], cmap="Reds")
    else:
      plt.imshow(feature[i], cmap="Blues")
    val = 100*np.max(p[i])
    rounded = str(np.round(val, 2)) + '%'
    plt.title(cl[target[i]] + ' (' +\
 cl[np.argmax(p[i])] + ') ' +\
              rounded )
  plt.tight_layout()
plt.show()

Listing 5-8Function to build a prediction plot

```

调用如清单 [5-9](#PC34) 所示的函数。

```py
num_rows, num_cols = 6, 5
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
display_test(images, labels, num_images, num_rows,
             num_cols, class_labels, predictions)

Listing 5-9Invoke the prediction plot function

```

任何红色*的衣服都意味着预测不正确。每件衣服上面都是实际标签，括号里是预测，以及对预测的信心。*

## 将时尚-MNIST 作为 Keras 数据集加载

尽管建议将 TFDS 用于 TensorFlow 2.x 应用，但我们将向您展示如何使用 Keras 数据集，因为它在行业中很受欢迎。TensorFlow 2.x 的新颖性意味着它还没有 Keras 的行业渗透率。

加载 Keras 数据集:

```py
train, test = tf.keras.datasets.fashion_mnist.load_data()

```

### 探索数据

让我们看看数据形状:

```py
print ('train data:', br)
print (train[0].shape)
print (train[1].shape, br)
print ('test data:', br)
print (test[0].shape)
print (test[1].shape)

```

Keras 数据集包含与时尚-MNIST TFDS 相同的数据。训练数据由 60，000 个 28 `×` 28 特征图像和 60，000 个标签组成。测试数据由 10，000 个 28 `×` 28 特征图像和 10，000 个标签组成。训练图像包含在训练元组中。因此，train[0]代表图像，train[1]代表标签。

让我们看看第一张图片代表了什么:

```py
class_labels[train[1][0]]

```

因为我们使用 train[1]访问训练标签，所以我们使用 train[1][0]获取第一个标签。

### 想象第一幅图像

使用 Matplotlib 的 imshow 函数绘制第一幅图像:

```py
plt.imshow(train[0][0], cmap="binary")
plt.axis('off')

```

为方便起见，将图像和标签分配给变量:

```py
train_images = train[0]
train_labels = train[1]

```

根据 train_images 变量绘制第一幅图像:

```py
plt.imshow(train_images[0], cmap="binary")
plt.axis('off')

```

访问第一个图像的标签名称:

```py
class_labels[train_labels[0]]

```

标签是从 0 到 9 的类 id:

```py
train_labels

```

### 可视化样本图像

由于我们不能使用 TFDS 的 show_examples 方法，我们创建如清单 [5-10](#PC43) 所示的代码。

```py
n_rows = 5
n_cols = 6
plt.figure(figsize=(n_cols * 1.5, n_rows * 1.5))
for row in range(n_rows):
  for col in range(n_cols):
    index = n_cols * row + col
    plt.subplot(n_rows, n_cols, index + 1)
    plt.imshow(train_images[index], cmap="binary",
               interpolation='nearest')
    plt.axis('off')
    plt.title(class_labels[train_labels[index]], fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)

Listing 5-10Code to visualize examples

```

### 为培训准备数据

为了准备 TensorFlow 消费的训练数据，我们需要从训练和测试数据中获取图像和标签。我们缩放图像以确保每个输入参数(在我们的例子中是一个像素)具有相似的数据分布。这种数据的分布类似于以零为中心的高斯曲线。在训练网络时，缩放数据可以加快收敛速度。

我们知道，像素数据由 0 到 255 的范围来表示。所以我们把每个特征图像除以 255 来缩放。一旦图像被缩放，我们就把图像和标签转换成一个 tf。带有 from_tensor_slices 的张量对象如清单 [5-11](#PC44) 所示。

```py
# add test images and labels to the mix

test_images, test_labels = test

train_pictures = train_images / 255\.  # divide by 255 to scale
train_targets = train_labels.astype(np.int32)

test_pictures = test_images / 255\.  # divide by 255 to scale
test_targets = test_labels.astype(np.int32)

print ('train images:', len(train_pictures))
print ('train labels:', len(train_targets), br)
print ('test images', len(test_pictures))
print ('test labels', len(test_targets))

train_ds = tf.data.Dataset.from_tensor_slices(
    (train_pictures, train_targets))
test_ds = tf.data.Dataset.from_tensor_slices(
    (test_pictures, test_targets))

Listing 5-11Prepare the input pipeline

```

显示张量:

```py
train_ds.element_spec, test_ds.element_spec

```

通过混洗、批处理和预取训练数据以及批处理和预取测试数据来完成输入流水线:

```py
BATCH_SIZE = 128
SHUFFLE_BUFFER_SIZE = 5000

train_ks = train_ds.shuffle(
    SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(1)
test_ks = test_ds.batch(BATCH_SIZE).prefetch(1)

```

将 BATCH_SIZE 设置为 128，这样模型的运行速度会比使用较小的批处理更快。用这个数字做实验，看看会发生什么。我们还将 SHUFFLE_BUFFER_SIZE 设置为 5000，这样 SHUFFLE 方法就能很好地工作。再次用这个数字做实验，看看会发生什么。

显示最终输入流水线张量:

```py
train_ks.element_spec, test_ks.element_spec

```

### 建立模型

创建与我们为 TFDS 创建的模型相同的模型，如清单 [5-12](#PC48) 所示。

```py
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout

# clear previous model and generate a seed
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

model = Sequential([
  Flatten(input_shape=[28, 28]),
  Dense(512, activation="relu"),
  Dropout(0.4),
  Dense(10, activation="softmax")
])

Listing 5-12Keras model

```

正如我们已经知道的，清除任何以前的建模会话总是一个好主意。请记住，我们已经在本章前面创建了一个模型并对其进行了训练。此外，生成种子可以确保结果的一致性。在机器学习中，这样的一致性被称为*再现性*。也就是说，种子为随机生成器提供了一个起点，允许我们以一致的方式再现结果。您可以使用任意整数值作为随机种子数。我们用 *0* 。

第一层，Flatten()，将 28 个 28 图像的 2D 矩阵展平为 784 像素的 1D 阵列。第二层是第一个真正的层。它接受输入图像到 128 个神经元，并执行 *relu* 激活。最后一层是输出层。它接受来自具有十个神经元的输入层的输出，这十个神经元代表十类服装，并执行 softmax 激活。

### 模型摘要

检查模型:

```py
model.summary()

```

### 编译模型

编译:

```py
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

```

### 训练模型

符合模型。传递(要素，标注)对的数据集是 Model.fit 和 Model.evaluate 所需的全部内容:

```py
history = model.fit(train_ks, epochs=10, validation_data=test_ks)

```

### 对测试数据进行归纳

尽管模型拟合信息提供了训练期间的验证损失和准确性，但根据测试数据明确评估模型始终是一个好主意，因为准确性和损失值可能不同:

```py
print('Test accuracy:', end=' ')
test_loss, test_acc = model.evaluate(test_ks, verbose=2)

```

### 可视化培训

fit 方法自动将训练过程的历史记录为字典。所以我们可以将训练历史赋给一个变量。在这种情况下，我们将其分配给*历史*。变量的历史属性包含字典信息。

显示字典键，通知我们如何绘制结果:

```py
hist_dict = history.history
print (hist_dict, '\n')
print (hist_dict.keys())

```

字典 *history.history* 包含模型在训练集和验证集的每个时期结束时测量的损失和其他度量。

*params* 变量提供了与模型相关的所有参数:

```py
history.params

```

列表 [5-13](#PC55) 描绘了训练历史。

```py
plt.plot(history.history['accuracy'], label="accuracy")
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')
plt.show()

plt.plot(history.history['loss'], label="loss")
plt.plot(history.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.05, .7])
plt.legend(loc='lower right')
plt.show()

Listing 5-13Training history plots

```

过度拟合是最小的，因为训练精度与测试精度紧密相关。我们在模型中采用了辍学来减少过度拟合。 **Dropout** 是一种近似并行训练大量不同架构的神经网络的正则化方法。这个定义并没有让刚接触深度学习的人更容易理解。所以我们来解释一下它是如何工作的。

在训练期间，一些层输出被随机忽略或*被丢弃*。通过随机丢弃图层输出，实际上该图层看起来和被视为与前一图层具有不同数量的节点和连通性的图层。因此，在训练期间对层的每次更新都是用配置层的不同*视图*来执行的。辍学是一个简单但非常有效的技术，以减少过度拟合。

将 dropout 设置为 *0.4* 意味着我们随机丢弃 40%的层输出。通过更改该值，您可以很容易地尝试辍学。然而，你应该将辍学率保持在或低于 *0.5* ，因为否则你会删除太多的数据！

Tip

尝试丢弃级别，但将其保持在 0.5 或小于 0.5，以避免删除太多数据。

如果模型过拟合(训练精度大于测试精度)您设置的下降值，您可以增加它。如果模型拟合不足(训练精度低于测试精度)，您可以降低它。

用熊猫来绘图:

```py
import pandas as pd

pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1)

```

### 预测测试图像的标签

我们可以对测试图像进行预测，因为我们有一个经过训练的模型。

从测试集 *test_ks* 中预测每个图像的标签:

```py
predictions = model.predict(test_ks)

```

与时尚 MNIST TFDS 一样，预测是一个由 10 个数字组成的数组，表示模特对图像与 10 件衣服中的每一件相对应的信心。

#### 预测第一幅图像

先来看*第一个*预测:

```py
predictions[0]

```

为方便起见，对数组值进行舍入:

```py
np.round(predictions[0], 2)

```

直接评估预测的可信度:

```py
100*np.max(predictions[0])

```

将值转换为百分比:

```py
str(np.round(100*np.max(predictions[0]), 2)) + '%'

```

显示第一幅图像的预测:

```py
np.argmax(predictions[0])

```

预测只能在 0 到 9 之间，因为我们的目标在 0 到 9 之间。

使用前面创建的 class_labels 数组来查看实际的时尚文章:

```py
class_labels[np.argmax(predictions[0])]

```

显示用于比较的第一个实际测试标签:

```py
class_labels[test_labels[0]]

```

如果预测和实际图像匹配，则预测是正确的。

#### 预测四幅图像

从测试集中做出四个预测:

```py
pred_4 = predictions[:4]

```

显示预测:

```py
ls = [np.argmax(row) for row in pred_4]
ls

```

获取类别标签:

```py
np.array(class_labels)[ls]

```

将预测与测试数据集进行比较:

```py
actual_4 = test_labels[:4]
actual_4

```

将实际值显示为分类标签:

```py
np.array(class_labels)[actual_4]

```

如清单 [5-14](#PC70) 所示可视化。

```py
# slice off the first four images from the test data
img_4 = test_images[:4]

# plot images

plt.figure(figsize=(7.2, 2.4))
for index, image in enumerate(img_4):
  plt.subplot(1, 4, index + 1)
  plt.imshow(image, cmap="twilight", interpolation="nearest")
  plt.axis('off')
  plt.title(class_labels[actual_4[index]], fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)

Listing 5-14Visualize the first four actual test images

```

### 探究错误分类

让我们探索预测和实际测试图像标签，以找到一些错误分类。

第一步是识别预测标签:

```py
rng = (len(predictions))
y_pred = [np.argmax(row) for row in predictions]

```

*y_pred* 变量保存预测标签列表。

接下来，抓住一些预测和实际目标:

```py
# find first n predictions and actual targets

n = 20
y_n = [y_pred[i] for i, row in enumerate(range(n))]
y_actual = [test_labels[i] for i, row in enumerate(range(n))]

y_n, y_actual

```

查找错误分类:

```py
# compare predictions against actual targets

miss_indx_list = [index for index, (x, y) in
                  enumerate(zip(y_n, y_actual))
                  if x != y]

miss_indx_list

```

如果您没有得到任何错误分类，请增加 *n* 的大小，并重新运行最后两个代码片段。

我们现在有一系列错误的分类。

清单 [5-15](#PC74) 显示了错误分类的置信度。

```py
# display confidence for each misclassification:

for row in miss_indx_list:
  val = 100*np.max(predictions[row])
  rounded = str(round(val, 2)) + '%'
  print ('index:', row, 'confidence:', rounded,
         'pred:', class_labels[np.argmax(predictions[row])],
         'actual:', class_labels[test_labels[row]])

Listing 5-15Confidence in misclassifications

```

### 可视化错误分类

创建一个函数来可视化错误分类，如清单 [5-16](#PC75) 所示。

```py
def see_misses(indx):
  plt.imshow(test_images[indx], cmap="nipy_spectral")
  plt.show()
  print ('actual:', class_labels[test_labels[indx]])
  print ('predicted:',
 class_labels[np.argmax(predictions[indx])])
  print ('confidence', rounded)

Listing 5-16Function to visualize misclassifications

```

调用函数:

```py
for row in miss_indx_list:
  val = 100*np.max(predictions[row])
  rounded = str(round(val, 2)) + '%'
  see_misses(row)

```

即使预测是不正确的，置信度可能仍然很高。虽然神经网络往往在预测方面表现良好，但它们通过 softmax 层的输出估计的预测概率往往过高。也就是说，他们对自己的预测过于自信。请记住，具有最高值的概率是预测数组中的预测类。而这个概率就是置信度。但是，除非模型具有 100%的准确性，否则预测不一定正确。

创建一个更复杂的可视化，如清单 [5-17](#PC77) 所示。

```py
# Plot the first X test images, their true labels,
# their predicted labels, and prediction confidence.

num_rows = 8
num_cols = 8
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  if class_labels[test_labels[i]] != class_labels[y_pred[i]]:
    plt.imshow(test_images[i], cmap="Reds")
  else:
    plt.imshow(test_images[i], cmap="Blues")
  val = 100*np.max(predictions[i])
  rounded = str(np.round(val, 2)) + '%'
  plt.title(class_labels[test_labels[i]] + ' (' +\
            class_labels[y_pred[i]] + ') ' + rounded )
plt.tight_layout()
plt.show()

Listing 5-17Sophisticated visualization of misclassifications

```

错误分类，如果有的话，用红色表示。每件衣服上面都是实际标签，括号里是预测，以及对预测的信心。

### 从单一图像预测

我们可以对单个图像进行预测。我们选择 0 到 9，999 之间的一个数字，因为我们想要测试集中的一个图像。或者，我们可以生成一个 0 到 9，999 之间的随机数。

从测试集中随机选择一个图像:

```py
beg, end = 0, len(test_images) - 1
rng = np.random.default_rng()
indx = int(rng.uniform(beg, end, size=1))
indx

```

显示的是随机选择的图像的索引。

从测试集中抓取图像:

```py
# Grab the image from the test dataset

img = test_images[indx]
label = class_labels[test_labels[indx]]
img.shape, label

```

TensorFlow 模型经过优化，可以一次对一批或一组实例进行预测。因此，将单个图像添加到它是唯一成员的批处理中。

使用单个图像创建批处理:

```py
img_batch = (np.expand_dims(img, 0))
img_batch.shape

```

*expand_dims* 方法插入一个新轴，该轴出现在展开的数组形状的轴位置。所以新的形状是(1，28，28)。

现在，我们可以预测:

```py
pred_single = model.predict(img_batch)

```

显示预测:

```py
np.argmax(pred_single)

```

显示预测数组中的索引位置。

为方便起见，按标签名称显示预测:

```py
class_labels[np.argmax(pred_single)]

```

显示实际标签:

```py
class_labels[test_labels[indx]]

```

### 可视化单一图像预测

将预测可视化，如清单 [5-18](#PC85) 所示。

```py
pred = class_labels[np.argmax(pred_single)]
actual = class_labels[test_labels[indx]]

# get confidence from the predictions object
val = 100*np.max(predictions[indx])
rounded = str(np.round(val, 2)) + '%'

# display actual image
plt.imshow(test_images[indx], cmap=plt.cm.binary)
plt.show()

print ('actual:', actual)
print ('predicted:', pred)
print ('confidence', rounded)

Listing 5-18Visualization of single image prediction

```

通过标签名称和图像的实际标签名称获得预测。从我们之前创建的预测对象中获得预测可信度。预测对象保存基于测试集的所有预测。 *indx* 值提供了置信度值在预测对象中的位置。

### 混淆矩阵

创建一个混淆矩阵，直观展示该模型对 MNIST 时装周的服装商品进行分类的效果:

```py
tf.math.confusion_matrix(test_labels, y_pred)

```

为了理解TensorFlow混淆矩阵，想象在矩阵的第一行上面从左到右是 0-9 类。这些代表预测。假设矩阵第一列的左边从上到下是 0-9 级。这些代表实际的标签。正确的分类是沿着对角线。误分类不在对角线上。

第一组正确的分类位于第一行第一列，代表类别 0。第二个集合位于第二行第二列，代表类别 1。诸如此类…

一个错误分类集合的例子是第一行第二列。这表示被错误分类为类别 0 的类别 1 的预测数。有关 TensorFlow 混淆矩阵的技术解释，请阅读以下 URL:

[T2`https://stackoverflow.com/questions/46616837/understanding-a-tensorflow-confusion-matrix-for-binary-classification`](https://stackoverflow.com/questions/46616837/understanding-a-tensorflow-confusion-matrix-for-binary-classification)

有关混淆矩阵的一般解释，请阅读以下 URL:

[T2`www.dataschool.io/simple-guide-to-confusion-matrix-terminology/`](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)

## 隐藏层数

对于许多问题，我们可以从一个单一的隐藏层开始，并得到合理的结果，就像我们在本章中对时尚-MNIST 模型所做的那样。对于更复杂的问题，我们应该增加层，直到我们开始过度适应训练集。

## 隐藏层中的神经元数量

输入和输出层中神经元的数量取决于任务所需的输入和输出类型。例如，时尚-MNIST 任务需要 28 个`×` 28 = 784 输入神经元和 10 个输出神经元。对于隐藏层，很难确定。你可以试着逐渐增加神经元的数量，直到网络开始超负荷。在实践中，我们通常选择一个比我们需要更多的层和神经元的模型，然后使用早期停止和其他正则化技术来减少过度拟合。由于这是一个介绍，我们不会深入研究调整网络。

通常，我们通过增加层数而不是每层神经元的数量来获得更好的模型。当然，我们包括的层和神经元的数量受到我们可用的计算资源的限制。
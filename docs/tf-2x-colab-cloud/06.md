# 六、回归

**回归**是一种监督学习方法，用于根据从数据集获得的变量(或特征)之间的关系来预测事件的连续输出。一个**连续**结果是一个真实值，比如一个整数或浮点值，通常被量化为数量和大小。回归是一种广泛流行的深度学习建模类型。

因为回归预测一个量，所以性能是在那些预测中测量的误差。回归性能可以用许多方法来衡量。但最常见的是均方误差(MSE)、平均绝对误差(MAE)和均方根误差(RMSE)。

MSE 是最常用的指标之一。然而，当一个错误的预测会破坏整个模型的预测能力时，它是最没用的。也就是说，当数据集包含大量噪声时。当数据集包含异常值或意外值时，它最有用。意外值是过高或过低的值。

与 MSE 相比，MAE 对异常值不太敏感，因为它不会惩罚巨大的错误。它通常用于在连续可变数据上测量性能。它提供了平均加权个体差异的线性值。

*RMSE* 误差在被平均之前被平方。因此，RMSE 对较大的错误赋予较高的权重。因此，当存在较大误差时，RMSE 更有用，它们会显著影响模型的性能。RMSE 的一个好处是误差分值的单位与预测值相同。

我们彻底研究了著名的*波士顿住房*数据集。我们演示了如何加载数据、构建输入流水线以及对数据建模。我们还将向您展示如何使用该模型进行预测。最后，我们对不同的数据集进行建模。*汽车*数据集可能不那么受欢迎，但我们想让你体验另一组数据。

章节的笔记本位于以下网址: [`https://github.com/paperd/tensorflow`](https://github.com/paperd/tensorflow) 。

启用 GPU(如果尚未启用):

1.  点击左上角菜单中的*运行时*。

2.  从下拉菜单中点击*改变运行时间类型*。

3.  从*硬件加速器*下拉菜单中选择 *GPU* 。

4.  点击*保存*。

测试 GPU 是否处于活动状态:

```py
import tensorflow as tf

# display tf version and test if GPU is active
tf.__version__, tf.test.gpu_device_name()

```

导入 *tensorflow* 库。如果显示“/设备:GPU:0”，则 GPU 处于活动状态。如果'..'显示时，常规 CPU 处于活动状态。

## 波士顿住房数据集

**波士顿住房**是一个数据集，来自美国人口普查局收集的马萨诸塞州波士顿地区的住房信息。它是从 StatLib 档案( [`http://lib.stat.cmu.edu/datasets/boston`](http://lib.stat.cmu.edu/datasets/boston) )中获得的，并在整个机器学习文献中被广泛用于基准算法。数据集很小，只有 506 个案例。

这个数据集的名字是*波士顿*。它包含 12 个特征和 1 个结果(或目标)。其特点如下:

1.  CRIM——城镇人均犯罪率

2.  ZN——面积超过 25，000 平方英尺的住宅用地比例。制成

3.  印度河——每个城镇非零售商业英亩数的比例

4.  CHAS–Charles River 虚拟变量(如果区域边界为河流，则为 1，否则为 0)

5.  NOX——氧化氮浓度(百万分之一)

6.  RM——每个住宅的平均房间数

7.  楼龄——1940 年之前建造的自住单元的比例

8.  DIS 到五个波士顿就业中心的加权距离

9.  RAD——放射状公路可达性指数

10.  税收——每 10，000 美元的全价值财产税税率

11.  pt ratio——按城镇划分的师生比率

12.  LSTAT –%较低的人口地位

目标是

*   MEDV——以千美元计的自有住房中值

数据是在 20 世纪 70 年代收集的，所以不要对房屋的低中值感到震惊。

### 波士顿数据

您可以通过几个简单的步骤直接从 GitHub 访问这本书的任何数据集:

1.  访问本书网址: [`https://github.com/paperd/tensorflow`](https://github.com/paperd/tensorflow) 。

2.  找到数据集并单击它。

3.  点击 *Raw* 按钮。

4.  将 URL 复制到 Colab，并将其赋给一个变量。

5.  使用 Pandas read_csv 方法读取数据集。

为了方便起见，我们已经找到了适当的 URL 并将其赋给了一个变量:

```py
url = 'https://raw.githubusercontent.com/paperd/tensorflow/\
master/chapter6/data/boston.csv'

```

将数据集读入熊猫数据帧:

```py
import pandas as pd

data = pd.read_csv(url)

```

验证数据集是否被正确读取:

```py
data.head()

```

### 浏览数据集

获取数据类型:

```py
data.dtypes

```

所有要素的数据类型都是 float64 或 int64。标签 *MEDV* 的数据类型为 float64。

获取一般信息:

```py
data.info()

```

数据集包含 506 条记录。

使用*描述*方法创建一个保存基本统计数据的数据框架，并将其转置以便于查看:

```py
data_t = data.describe()
desc = data_t.T
desc

```

转置数据帧中的目标特定统计数据:

```py
desc[['mean', 'std']]

```

描述原始数据帧中的特定特征:

```py
data.describe().LSTAT

```

获取列:

```py
cols = list(data)
cols

```

### 创建功能和目标集

创建目标:

```py
# create a copy of the DataFrame
df = data.copy()

# create the target
target = df.pop('MEDV')
print (target.head())

```

因为我们从副本中取出了 MEDV，所以它应该只包含以下特征:

```py
df.head()

```

### 从特征数据框中获取特征名称

由于目标不再是数据帧的一部分，因此很容易获得以下特性:

```py
feature_cols = list(df)
feature_cols

```

获取特征的数量:

```py
len(feature_cols)

```

### 转换要素和标注

使用*值*方法将 pandas dataframe 值转换为 float 值:

```py
features = df.values
labels = target.values

type(features), type(labels)

```

### 将数据集分为训练集和测试集

清单 [6-1](#PC16) 创建训练和测试集。

```py
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.33, random_state=0)

br = '\n'

print ('X_train shape:', end=' ')
print (X_train.shape, br)

print ('X_test shape:', end=' ')
print (X_test.shape)

Listing 6-1Train and test sets

```

### 缩放数据并创建 TensorFlow 张量

对于图像数据，我们通过将每个元素除以 255.0 来进行缩放，以确保每个输入参数(在我们的例子中是一个像素)具有相似的数据分布。但是，由连续值表示的要素的比例有所不同。我们将连续数据的均值(μ)定为 0，标准差(σ)为 1。符号μ读作 mu，符号σ读作 sigma。西格玛值为 1 称为单位方差。

清单 [6-2](#PC17) 显示训练和测试数据。

```py
# scale feature data and create TensorFlow tensors

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.fit_transform(X_test)

train = tf.data.Dataset.from_tensor_slices(
    (X_train_std, y_train))
test = tf.data.Dataset.from_tensor_slices(
    (X_test_std, y_test))

Listing 6-2Scale train and test sets

```

让我们来看看第一个张量，如清单 [6-3](#PC18) 所示。

```py
def see_samples(data, num):
  for feat, targ in data.take(num):
    print ('Features: {}'.format(feat), br)
    print ('Target: {}'.format(targ))

n = 1
see_samples(train, n)

Listing 6-3Display the first tensor

```

第一个样品看起来和我们预期的一样。

### 准备张量训练

混洗训练数据、批处理和预取训练和测试数据:

```py
BATCH_SIZE, SHUFFLE_BUFFER_SIZE = 16, 100

train_bs = train.shuffle(
    SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(1)
test_bs = test.batch(BATCH_SIZE).prefetch(1)

```

检查张量:

```py
train_bs, test_bs

```

### 创建模型

如果我们没有大量的训练数据，避免过度拟合的一种技术是创建一个隐藏层很少的小网络。我们就是这么做的！

64 神经元输入层容纳了我们的 12 个输入特征。我们有一个有 64 个神经元的隐藏层。输出层有一个神经元，因为我们使用一个目标的回归。

创建一个如清单 [6-4](#PC21) 所示的模型。

```py
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
import numpy as np

# clear any previous model
tf.keras.backend.clear_session()

# generate a seed for replication purposes
np.random.seed(0)
tf.random.set_seed(0)

# notice input shape accommodates 12 features!
model = Sequential([
  Dense(64, activation="relu", input_shape=[12,]),
  Dense(64, activation="relu"),
  Dense(1)
])

Listing 6-4Create a model

```

### 模型摘要

检查模型:

```py
model.summary()

```

第一层的输出形状是(无，64)，因为我们在这一层有 64 个神经元。我们将这一层的 64 个神经元乘以 12 个特征，再加上这一层的 64 个神经元，得到 832 的参数。

第二层的输出形状是(无，64)，因为我们在这一层有 64 个神经元。我们通过将这一层的 64 个神经元乘以上一层的 64 个神经元，再加上这一层的 64 个，得到参数 4160。

第三层的输出形状是(None，1 ),因为我们有一个目标。我们通过将前一层的 64 个神经元加到这一层的 1 个神经元上，得到参数 65。

### 编译模型

编译:

```py
rmse = tf.keras.metrics.RootMeanSquaredError()

model.compile(loss='mse', optimizer="RMSProp",
              metrics=[rmse, 'mae', 'mse'])

```

均方误差(MSE)是用于回归问题的常见损失函数。平均绝对误差(MAE)和 RMSE 也是常用的指标。通过一些实验，我们发现优化器 *RMSProp* 在这个数据集上表现得非常好。RMSProp 是一种用于整批优化的算法。它试图通过仅使用梯度的符号来解决梯度在幅度上可能变化很大的问题，这保证了所有权重更新具有相同的大小。

### 训练模型

为 50 个时期训练模型:

```py
history = model.fit(train_bs, epochs=50,
 validation_data=test_bs)

```

### 可视化培训

创建变量 *hist* 以熊猫数据帧的形式保存模型的历史。创建另一个变量 *hist['纪元']* 来保存纪元历史。显示最后五行以了解性能。

代码如下:

```py
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

```

如清单 [6-5](#PC26) 所示构建图表。

```py
import matplotlib.pyplot as plt

def plot_history(history, limit1, limit2):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure()
  plt.xlabel('epoch')
  plt.ylabel('MAE [MPG]')
  plt.plot(hist['epoch'], hist['mae'],
 label='Train Error')
  plt.plot(hist['epoch'], hist['val_mae'],
 label = 'Val Error')
  plt.ylim([0, limit1])
  plt.legend()
  plt.title('MAE by Epoch')
  plt.show()

  plt.clf()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('MSE [MPG]')
  plt.plot(hist['epoch'], hist['mse'],
 label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
 label = 'Val Error')
  plt.ylim([0, limit2])
  plt.legend()
  plt.title('MSE by Epoch')
  plt.show()

  plt.clf()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('RMSE [MPG]')
  plt.plot(hist['epoch'], hist['root_mean_squared_error'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_root_mean_squared_error'],
           label = 'Val Error')
  plt.ylim([0, limit2])
  plt.legend()
  plt.title('RMSE by Epoch')
  plt.show()

# set limits to make plot readable

mae_limit, mse_limit = 10, 100
plot_history(history, mae_limit, mse_limit)

Listing 6-5Visualize training performance

```

由于验证误差比训练误差更严重，因此模型过拟合。我们能做什么？第一步是估计性能何时开始下降。从图像中，你能看出这是什么时候发生的吗？

### 提前停止

对于分类，我们的目标是最大限度地提高准确性。当然，我们也想把损失降到最低。对于回归，我们的目标是最小化 MSE 或其他常见的误差指标。从可视化中，我们看到我们的模型过拟合，因为验证误差高于训练误差。我们还看到，一旦训练错误和验证错误交叉，性能就开始下降。

我们可以运行一个简单的调优实验来使这个模型更加有用。当训练和验证误差非常接近时，我们可以停止模型。这种技术被称为提前停止。**提前停止**是一种广泛使用的方法，在验证数据集的性能开始下降时停止训练。

让我们修改我们的训练实验，当验证分数没有提高时，自动停止训练。我们使用 *EarlyStopping* 回调来测试每个时期的训练条件。当性能开始下降时，训练会自动停止。

我们需要做的就是更新 fit 方法并重新训练，如清单 [6-6](#PC27) 所示。

```py
# clear the previous model
tf.keras.backend.clear_session()

# generate a seed for replication purposes
np.random.seed(0)
tf.random.set_seed(0)

# monitor 'val_loss' for early stopping
early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss')

history = model.fit(train_bs, epochs=50,
 validation_data=test_bs,
                    callbacks=[early_stop])

Listing 6-6Early stopping

```

我们可以添加一些控制，而不是让算法自动提前停止。只需包含一个参数，该参数强制模型继续到给我们最佳性能的点。可以将*耐心*参数设置为给定的周期数，在此之后，如果没有改善，将停止训练。

让我们尝试一下，看看会发生什么，如清单 [6-7](#PC28) 所示。

```py
# clear the previous model
tf.keras.backend.clear_session()

# generate a seed for replication purposes
np.random.seed(0)
tf.random.set_seed(0)

# set number of patience epochs
n = 4

early_stop = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', patience=n)

history = model.fit(train_bs, epochs=50,
 validation_data=test_bs,
                    callbacks=[early_stop])

Listing 6-7Early stopping with patience

```

尝试耐心参数以找到更好的结果。

让我们想象一下:

```py
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch

train_limit, test_limit = 10, 100
plot_history(history, train_limit, test_limit)

```

### 删除错误数据

波士顿数据集有一些固有的坏数据。数据有什么问题？房价被限制在 50，000 美元，因为人口普查局审查了数据。他们决定将价格变量的最大值设置为 50，000 美元，因此任何价格都不能超过该值。

我们该怎么办？虽然可能不理想，但我们可以删除价格在 50，000 美元或以上的数据。这并不理想，因为我们可能会删除非常好的数据，但没有办法知道这一点。另一个原因是因为数据集本来就很小。神经网络意味着在处理大型数据集时表现最佳。

要进一步探索这个主题，我们推荐以下 URL:

[T2`https://towardsdatascience.com/things-you-didnt-know-about-the-boston-housing-dataset-2e87a6f960e8`](https://towardsdatascience.com/things-you-didnt-know-about-the-boston-housing-dataset-2e87a6f960e8)

### 检索数据

我们不想尝试清理为 TensorFlow 消费而处理的数据集。所以只需重新加载原始数据集:

```py
# get the raw data
url = 'https://raw.githubusercontent.com/paperd/tensorflow/\
master/chapter6/data/boston.csv'

boston = pd.read_csv(url)

```

验证数据:

```py
boston.head()

```

### 消除噪音

移除坏数据，这有望减少固有噪声:

```py
print ('data set before removing noise:', boston.shape)

# remove noise
noise = boston.loc[boston['MEDV'] >= 50]
data = boston.drop(noise.index)

print ('data set without noise:', data.shape)

```

**噪声**是数据集中不相关的信息或随机性。我们从数据集中删除了几条记录。

### 创建要素和目标数据

创建功能和目标集:

```py
# create a copy of the dataframe
df = data.copy()

# create feature and target sets
target, features = df.pop('MEDV'), df.values
labels = target.values

```

### 构建输入流水线

通过将数据分割成训练集和测试集、缩放特征数据以及将数据分割成 TensorFlow 可消费部分来创建输入流水线。通过混洗训练数据、批处理以及预取训练和测试数据来完成流水线。

清单 [6-8](#PC34) 包括构建输入流水线的代码。

```py
X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.33, random_state=0)

# standardize feature data and create TensorFlow tensors
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.fit_transform(X_test)

# slice data for TensorFlow consumption
train = tf.data.Dataset.from_tensor_slices(
    (X_train_std, y_train))
test = tf.data.Dataset.from_tensor_slices(
    (X_test_std, y_test))

# shuffle, batch, prefetch

BATCH_SIZE = 16
SHUFFLE_BUFFER_SIZE = 100

train_n = train.shuffle(
    SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(1)
test_n = test.batch(BATCH_SIZE).prefetch(1)

Listing 6-8Build the input pipeline

```

检查张量:

```py
train_n, test_n

```

### 编译和训练

清单 [6-9](#PC36) 包括编译和训练模型的代码。

```py
rmse = tf.keras.metrics.RootMeanSquaredError()

model.compile(loss='mse', optimizer="RMSProp",
              metrics=[rmse, 'mae', 'mse'])

tf.keras.backend.clear_session()

# generate a seed for replication purposes
np.random.seed(0)
tf.random.set_seed(0)

n = 4

early_stop = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', patience=n)

history = model.fit(train_n, epochs=50,
 validation_data=test_n,
                    callbacks=[early_stop])

Listing 6-9Compile and train the model

```

### 设想

绘图结果:

```py
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch

train_limit, test_limit = 10, 100

plot_history(history, train_limit, test_limit)

```

我们的模型并不完美，但我们确实提高了性能。

### 对测试数据进行归纳

评估:

```py
loss, rmse, mae, mse = model.evaluate(test_n, verbose=2)

print ()

print('"Testing set Mean Abs Error: {:5.2f} thousand dollars'.
      format(mae))

```

MAE 以一种易于理解的方式为线性连续数据的性能提供了一个很好的概念。有了这个数据集，我们可以预期模型预测的平均误差值为几千美元。

### 做预测

使用*预测*方法从处理后的测试数据 *test_n* 中进行预测:

```py
predictions = model.predict(test_n)

```

显示第*个*预测:

```py
# predicted housing price
first = predictions[0]
print ('predicted price:', first[0], 'thousand')

# actual housing price
print ('actual price:', y_test[0], 'thousand')

```

比较预测价格和实际价格以评估模型性能。

显示前五个预测值，并与实际目标值进行比较:

```py
five = predictions[:5]
actuals = y_test[:5]
print ('pred', 'actual')
for i, p in enumerate(range(5)):
  print (np.round(five[i][0],1), actuals[i])

```

### 可视化预测

列表 [6-10](#PC42) 显示对实际房价的预测。

```py
fig, ax = plt.subplots()
ax.scatter(y_test, predictions)
ax.plot([y_test.min(), y_test.max()],\
        [y_test.min(), y_test.max()], 'k--', lw=4)
ax.set_xlabel('Measured')
ax.set_ylabel('Predicted')
plt.show()

Listing 6-10Predictions against actual prices plot

```

对角线是实际房价的曲线图。预测离对角线越远，误差就越大。

### 从 Scikit-Learn 加载波士顿数据

由于波士顿数据包含在 *sklearn.datasets* 中，我们可以从这个环境中加载它:

```py
from sklearn import datasets

dataset = datasets.load_boston()
data, target = dataset.data, dataset.target

```

访问键:

```py
dataset.keys()

```

按键列表告诉我们如何访问功能名称:

```py
feature_names = dataset.feature_names
feature_names

```

注意，sklearn 数据集有一个额外的特性 *B* 。这个专栏可能会被一些人认为是有争议的，因为它挑出了一个镇上的黑人(或非裔美国人)。

我们希望从整个数据集中移除噪声，因此使用要素数据构建数据框架并添加目标数据:

```py
df_sklearn = pd.DataFrame(dataset.data, columns=feature_names)

df_sklearn['MEDV'] = dataset.target
df_sklearn.head()

```

检查信息:

```py
df_sklearn.info()

```

### 消除噪音

移除有噪声的数据:

```py
# remove noisy data

print ('data set before removing noise:', df_sklearn.shape)

noise = df_sklearn.loc[df_sklearn['MEDV'] >= 50]
df_clean = df_sklearn.drop(noise.index)

print ('data set without noise:', df_clean.shape)

```

### 构建输入流水线

如清单 [6-11](#PC49) 所示构建流水线。

```py
# create a copy of the dataframe
df = df_clean.copy()

# create the target
target = df.pop('MEDV')

# convert features and target data
features = df.values
labels = target.values

# create train and test sets

X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.33, random_state=0)

X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.fit_transform(X_test)

# slice data into a TensorFlow consumable form

train = tf.data.Dataset.from_tensor_slices(
    (X_train_std, y_train))
test = tf.data.Dataset.from_tensor_slices(
    (X_test_std, y_test))

# finalize the pipeline

BATCH_SIZE = 16
SHUFFLE_BUFFER_SIZE = 100

train_sk = train.shuffle(
    SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(1)
test_sk = test.batch(BATCH_SIZE).prefetch(1)

Listing 6-11Build the input pipeline

```

### 模型数据

型号数据如清单 [6-12](#PC50) 所示。

```py
# clear any previous model
tf.keras.backend.clear_session()

# generate a seed for replication purposes
np.random.seed(0)
tf.random.set_seed(0)

# new model with 13 input features

model = Sequential([
  Dense(64, activation="relu", input_shape=[13,]),
  Dense(64, activation="relu"),
  Dense(1)
])

# compile the new model

rmse = tf.keras.metrics.RootMeanSquaredError()

model.compile(loss='mse', optimizer="RMSProp",
              metrics=[rmse, 'mae', 'mse'])

# train

n = 4

early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',
                                              patience=n)

history = model.fit(train_sk, epochs=50,
 validation_data=test_sk,
                    callbacks=[early_stop])

Listing 6-12Model data

```

## 模型汽车数据

让我们用另一个数据集来练习。

### 从 GitHub 获取汽车数据

我们已经找到了 URL 并将其赋给了一个变量:

```py
cars_url = 'https://raw.githubusercontent.com/paperd/tensorflow/\
master/chapter6/data/cars.csv'

```

将数据读入熊猫数据帧:

```py
cars = pd.read_csv(cars_url)

```

验证数据:

```py
cars.head()

```

获取有关数据集的信息:

```py
cars.info()

```

### 将分类列转换为数字

机器学习算法只能训练数值数据。所以我们必须转换任何非数字特征。*原点*列是分类的，不是数字的。为了补救，一种解决方案是将数据编码为独热码。 **One-hot encoding** 是一个将分类数据转换成数字形式供机器学习算法使用的过程。

我们首先将原始数据帧中的原始特征列分割成它自己的数据帧。然后，我们使用该数据框架作为模板，在原始数据框架中为来自原始原始特征的每个类别构建新的特征列。

创建数据帧的副本:

```py
# create a copy of dataframe
df = cars.copy()

origin = df.pop('Origin')

```

为美国、欧洲和日本汽车定义一次性编码特征列:

```py
df['US'] = (origin == 'US') * 1.0
df['Europe'] = (origin == 'Europe') * 1.0
df['Japan'] = (origin == 'Japan') * 1.0
df.tail(8)

```

对于 *US* origin，我们赋值 *1.0 0.0 0.0* 。对于*欧洲*原点，我们指定 *0.0 1.0 0.0* 。对于*日本*产地，我们指定 *0.0 0.0 1.0* 。因此，我们用三个独热编码特征替换原始特征。

或者，我们可以用熊猫一次性编码。首先创建数据帧的拷贝:

```py
# create a copy of df
alt = cars.copy()

```

一键编码:

```py
# get one hot encoding of columns 'Origin'
one_hot = pd.get_dummies(alt['Origin'])

```

删除原始列:

```py
# drop column as it is now encoded
alt = alt.drop('Origin', axis=1)

```

将编码列连接到数据帧:

```py
# join the encoded df
alt = alt.join(one_hot)
alt.tail(8)

```

### 切片无关数据

由于每辆车的名称对我们可能想要做出的任何预测都没有影响，我们可以将它放入自己的数据框架中，以备将来再次使用:

```py
try:
  name = df.pop('Car')
except:
  print("An exception occurred")

```

如果出现异常，则*车*列已经被移除。您可以多次运行这段代码，而不会影响结果。

验证:

```py
df.tail(8)

```

### 创建要素和标签

我们的目标是预测该数据集中汽车的每加仑英里数。所以目标是 *MPG* ，特征是剩余的特征列。

创建特性和目标集，如清单 [6-13](#PC63) 所示。

```py
# create data sets
features = df.copy()
target = features.pop('MPG')

# get feature names
feature_cols = list(features)
print (feature_cols)

# get number of features
num_features = len(feature_cols)
print (num_features)

# convert feature and target data to float
features = features.values
labels = target.values
(type(features), type(labels))

Listing 6-13Create feature and target sets

```

### 构建输入流水线

如清单 [6-14](#PC64) 所示构建输入流水线。

```py
# split
X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.33, random_state=0)

print ('X_train shape:', end=' ')
print (X_train.shape, br)

print ('X_test shape:', end=' ')
print (X_test.shape)

# scale
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.fit_transform(X_test)

# slice

train = tf.data.Dataset.from_tensor_slices(
    (X_train_std, y_train))
test = tf.data.Dataset.from_tensor_slices(
    (X_test_std, y_test))

# shuffle, batch, prefetch

BATCH_SIZE = 16
SHUFFLE_BUFFER_SIZE = 100

train_cars = train.shuffle(
    SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(1)
test_cars = test.batch(BATCH_SIZE).prefetch(1)

Listing 6-14Build the input pipeline

```

检查张量:

```py
train_cars, test_cars

```

### 模型数据

型号数据如清单 [6-15](#PC66) 所示。

```py
# clear any previous model
tf.keras.backend.clear_session()

# create the model

model = Sequential([
  Dense(64, activation="relu", input_shape=[num_features]),
  Dense(64, activation="relu"),
  Dense(1)
])

# compile
rmse = tf.keras.metrics.RootMeanSquaredError()
optimizer = tf.keras.optimizers.RMSprop(0.001)

model.compile(loss='mse',
 optimizer=optimizer,
              metrics=[rmse, 'mae', 'mse'])

# train
tf.keras.backend.clear_session()

n = 4

early_stop = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', patience=n)

car_history = model.fit(train_cars, epochs=100,
 validation_data=test_cars,
                        callbacks=[early_stop])

Listing 6-15Model data

```

### 检查模型

总结:

```py
model.summary()

```

第一层的输出形状是(无，64)，因为我们在这一层有 64 个神经元。我们将这一层的 64 个神经元乘以 9 个特征，再加上这一层的 64 个神经元，得到 640 的参数。

第二层的输出形状是(无，64)，因为我们在这一层有 64 个神经元。我们通过将这一层的 64 个神经元乘以上一层的 64 个神经元，再加上这一层的 64 个，得到参数 4160。

第三层的输出形状是(None，1 ),因为我们有一个目标。我们通过将前一层的 64 个神经元加到这一层的 1 个神经元上，得到参数 65。

### 可视化培训

视觉化:

```py
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch

train_limit, test_limit = 10, 100

plot_history(history, train_limit, test_limit)

```

### 对测试数据进行归纳

概括:

```py
loss, rmse, mae, mse = model.evaluate(test_cars, verbose=2)

print ()

print('Testing set Mean Abs Error: {:5.2f} MPG'.format(mae))

```

### 做预测

预测:

```py
predictions = model.predict(test_cars)

```

### 可视化预测

将预测可视化，如清单 [6-16](#PC71) 所示。

```py
fig, ax = plt.subplots()
ax.scatter(y_test, predictions)
ax.plot([y_test.min(), y_test.max()],\
        [y_test.min(), y_test.max()], 'k--', lw=4)
ax.set_xlabel('Measured')
ax.set_ylabel('Predicted')
plt.show()

Listing 6-16Visualize predictions for cars data

```

预测离对角真值线越远，误差就越大。
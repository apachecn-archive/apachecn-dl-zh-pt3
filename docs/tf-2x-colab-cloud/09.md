# 9.情感分析

我们已经演示了如何训练角色级别的 RNN 来创建原始文本。现在，我们创建一个*单词级* RNN 来分析情绪。

**情感分析**是使用 NLP 文本分析工具对文本数据中的极性、情感和意图进行解释和分类。极性可以是正的、负的或中性的。情绪可以在广泛的感觉范围内变化，例如愤怒、快乐、沮丧和悲伤等等。意图也可能因各种动机而异，如感兴趣或不感兴趣。情感分析的一个常见应用是通过在线反馈来识别客户对产品、品牌或服务的情感。一般应用包括社交媒体监控、品牌监控、客户服务、客户反馈和市场研究。

有关情绪分析的精彩讨论，请参考以下 URL:

[T2`https://monkeylearn.com/sentiment-analysis/#:~:text=Sentiment%20analysis%20is%20the%20interpretation,or%20services%20in%20online%20feedback`](https://monkeylearn.com/sentiment-analysis/%2523:%253F:text%253DSentiment%2520analysis%2520is%2520the%2520interpretation,or%2520services%2520in%2520online%2520feedback)

情感分析是一项非常常见的自然语言处理任务。在技术上，它通过计算识别和分类文本语料库中表达的观点，以确定态度或情绪。通常，情感分析用于确定对特定主题或产品的积极、消极或中立的看法。

章节的笔记本位于以下网址: [`https://github.com/paperd/tensorflow`](https://github.com/paperd/tensorflow) 。

## IMDb 数据集

用于实践自然语言处理的一个流行数据集是 IMDb 评论数据集。 **IMDb** 是二元情感分类的基准数据集。该数据集包含 50，000 条标记为正面(1)或负面(0)的电影评论。评论被预处理，每个评论被编码为整数形式的单词索引序列。评论中的单词根据它们在数据集中的总频率进行索引。这 50，000 条评论分成 25，000 条用于训练，25，000 条用于测试。所以我们可以使用分类或其他深度学习算法来预测正面和负面评论的数量。

IMDb 很受欢迎，因为它使用简单，相对容易处理，并且对机器学习爱好者来说具有足够的挑战性。我们喜欢和 IMDb 一起工作，因为处理电影数据非常有趣。

启用 GPU(如果尚未启用):

1.  点击左上角菜单中的*运行时*。

2.  从下拉菜单中点击*改变运行时间类型*。

3.  从*硬件加速器*下拉菜单中选择 *GPU* 。

4.  点击*保存*。

测试 GPU 是否处于活动状态:

```py
import tensorflow as tf

# display tf version and test if GPU is active
tf.__version__, tf.test.gpu_device_name()

```

导入 *tensorflow* 库。如果显示“/设备:GPU:0”，则 GPU 处于活动状态。如果'..'显示时，常规 CPU 处于活动状态。

## 将 IMDb 加载为 TFDS

推荐的加载 IMDb 的方式是作为 TFDS:

```py
import tensorflow_datasets as tfds

imdb, info = tfds.load(
    'imdb_reviews/subwords8k', with_info=True,
    as_supervised=True, shuffle_files=True)

```

我们使用*IMDB _ reviews/subwords 8k*TFDS，因此我们在较小的词汇表上训练模型。*子词 8k* 子集的词汇量为 8000，这意味着我们正在用评论中最常用的 8000 个词来训练模型。这也意味着我们不必建立自己的词汇词典！我们可以通过这个子集获得良好的性能，并大大减少训练时间。加载 tfds 还可以让我们访问*tfds . features . text . subwordtextencoder*，这是 TFDS 文本编码器。

我们设置 *with_info=True* 以允许访问关于数据集和编码器的信息。我们根据*builder . info . supervised _ keys*设置 *as_supervised=True* ，以便返回的 TFDS 具有二元组结构(输入，标签)。如果设置为 *False* (默认)，返回的 TFDS 将有一个包含所有特性的字典。我们设置 *shuffle_files=True* ，因为洗牌通常会提高性能。

### 显示密钥

通过将数据集作为 TFDS 加载，我们可以访问它的键:

```py
imdb.keys()

```

我们看到数据集被分成测试样本、训练样本和无监督样本。

### 分为训练集和测试集

因为我们正在构建一个监督模型，所以我们只对训练和测试样本感兴趣:

```py
train, test = imdb['train'], imdb['test']

```

### 显示第一个样本

从数据集中探索样本总是一个好主意:

```py
br ='\n'

for sample, target in train.take(1):
  print ('encoded review:')
  print (sample, br)
  print ('target:', target.numpy())

```

第一个训练示例包含一个编码的评论和一个标签。评论已经被编码为数据类型为 int64 的整数张量。标签是数据类型为 *int64* 的标量值 0(负)或 1(正)。

复习张量的形状表示它包含的单词数。为了可读性，我们用 *numpy* 方法将目标张量转换成值。

### 显示关于 TFDS 的信息

*info* 对象让我们可以访问元数据:

```py
info

```

### 仔细阅读元数据

查看训练和测试分割中的示例数量:

```py
train_size = info.splits['train'].num_examples
test_size = info.splits['test'].num_examples

train_size, test_size

```

查看被监督的按键:

```py
info.supervised_keys

```

查看功能信息:

```py
info.features

```

查看 TFDS 的名字和一段描述:

```py
info.name, info.description[0:25]

```

我们甚至可以将引用字符串切片得到标题:

```py
info.citation[184:242]

```

### 创建编码器

编码器内置在 TFDS *子字文本编码器*中。有了编码器，我们可以很容易地解码(整数到文本)和编码(文本到整数)。我们从数据集的*信息*对象访问编码器。

基于我们加载到内存中的 IMDb 数据集创建一个编码器:

```py
encoder = info.features['text'].encoder

```

现在编码器已经构建好了，我们可以用它来对字符串进行矢量化，并将矢量化后的字符串解码回文本字符串。

测试编码器:

```py
sample_string = 'What a Beautiful Day!'

encoded_string = encoder.encode(sample_string)
print ('Encoded string:', encoded_string)

original_string = encoder.decode(encoded_string)
print ('Original string:', original_string)

```

### 对样本使用编码器

创建一个以可读形式返回标签评级的函数:

```py
def rev(d):
  if tf.math.equal(d, 0): return 'negative review'
  elif tf.math.equal(d, 1): return 'positive review'

```

显示第一次评审，如清单 [9-1](#PC15) 所示。

```py
for sample, target in train.take(1):
  print ('review:', end=' ')
  text = encoder.decode(sample)
  print (text[0:100])
  print ('opinion:', end=' ')
  print ('\'' + rev(target) + '\'')

Listing 9-1Display the first review

```

显示多个评论，如清单 [9-2](#PC16) 所示。

```py
n = 6

for i, sample in enumerate(train.take(n)):
  if i > 0:
    print ('review', str(i+1) +':', end=' ')
    text = encoder.decode(sample[0])
    print (text[0:100])
    print ('opinion:', end=' ')
    print ('\'' + rev(sample[1]) + '\'')
    if i < n-1:
      print ()

Listing 9-2Display multiple reviews

```

我们跳过第一次复习，因为我们已经看过了。

显示词汇大小:

```py
print('Vocabulary size: {}'.format(encoder.vocab_size))

```

### 完成输入管道

创建编码字符串(或评论)的批次，以大大提高性能。由于机器学习算法期望批次具有相同的大小，因此使用 *padded_batch* 方法对序列进行零填充，以便每个评论与批次中最长的字符串具有相同的长度。

初始化变量:

```py
BUFFER_SIZE = 10000
BATCH_SIZE = 64

```

如清单 [9-3](#PC19) 所示的混洗(在适当的情况下)、批处理、缓存以及预取训练和测试集。

```py
train_ds = (train
            .shuffle(BUFFER_SIZE)
            .padded_batch(BATCH_SIZE)
            .cache().prefetch(1))

test_ds = (test
           .padded_batch(BATCH_SIZE)
           .cache().prefetch(1))

Listing 9-3Finish the input pipeline

```

检查张量:

```py
train_ds, test_ds

```

有关填充字符张量的更新，请参考以下 URL:

[T2`www.tensorflow.org/tutorials/text/text_classification_rnn`](http://www.tensorflow.org/tutorials/text/text_classification_rnn)

### 创建模型

种植种子，导入库，清除以前的模型，并创建如清单 [9-4](#PC21) 所示的模型。

```py
import numpy as np

# generate seed for reproducibility
tf.random.set_seed(0)
np.random.seed(0)

# import libraries
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense,\
Embedding

# clear any previous models
tf.keras.backend.clear_session()

# build the model
embed_size = 128
model = Sequential([
  Embedding(encoder.vocab_size, embed_size, mask_zero=True,
            input_shape=[None]),
  GRU(128, return_sequences=True),
  GRU(128),
  Dense(1, activation="sigmoid")
])

Listing 9-4Create the model

```

第一层是嵌入层。*嵌入*层用于为输入单词创建单词向量。在训练期间，单词类别(或单词向量)的表示以相似类别彼此更接近的方式被学习。因此，单词向量可以存储像*好*和*好*这样的单词之间的关系。单词向量是密集的，因为我们的模型学习单词关系。因此，单词向量不会像我们用一键编码那样用大量的零填充。

嵌入层接受词汇大小、嵌入大小和输入形状。我们设置 *mask_zero=True* 来通知模型忽略所有下游层的填充标记。忽略填充标记可以提高性能。

接下来的两层是 GRU 层，最后一层是单神经元密集输出层。输出层使用 sigmoid 激活来输出评论表达关于电影的正面或负面情绪的估计概率。

### 模型摘要

检查模型:

```py
model.summary()

```

第一层是嵌入。因此，通过将 8185 的词汇大小乘以 128 的嵌入维数(embed_size)来计算可学习参数的数量，总数为 1，047，680。

第二层是 GRU。可学习参数的数量因此基于公式*3*`×`*(n*<sup>*2*</sup>`×`*Mn+2n)*其中 *m* 是输入维度而 *n* 是输出维度。乘以 *3* 因为 GRU 有三组运算需要这些大小的权重矩阵。由于 RNN 的反馈回路，将 *n* 乘以 *2* 。所以我们有 99072 个可学习的参数。

下面是我们分析结果的方式:

*   * 3`×`(128<sup>2</sup>+128`×`128+2`×`128)

*   * 3 `×` (16384 + 16384 + 256)

*   * 3 `×` 33024

*   * 99,072

正如我们所见，计算第二层的可学习参数相当复杂。所以我们来逻辑分解一下。GRU 层是具有反馈回路的前馈层。前馈网络的可学习参数通过将前一层(128 个神经元)的输出乘以当前层(128 个神经元)的神经元来计算。对于前馈网络，我们还必须考虑这一层的 128 个神经元。但是由于 RNN 的反馈机制，我们将这一层的 128 个神经元乘以 2。最后，当前层的 128 个神经元被反馈，产生 128 个 <sup>2</sup> 可学习参数。GRU 使用三组需要权重矩阵的操作(隐藏状态、重置门和更新门)，因此我们将可学习参数乘以 3。

第三层是 GRU，我们得到 99072 个可学习参数，因为 *n* 和 *m* 与第二层完全相同。所以计算是一样的。

最后一层是致密的。因此，通过将输出维度 1 乘以输入维度 128 并加上 1 来计算可学习参数的数量，以说明这一层的神经元总数为 129。

### 编译模型

编译:

```py
model.compile(loss='binary_crossentropy', optimizer="adam",
              metrics=['accuracy'])

```

### 训练模型

我们发现两个时期在没有调整的情况下提供了相当好的精确度。但是，您的结果可能会有所不同。所以你可以尽情地实验。但是请记住，训练文本模型需要大量的训练时间！

```py
# to suppress unimportant error messages
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

history = model.fit(train_ds, epochs=2, validation_data=test_ds)

```

### 对测试数据进行归纳

尽管模型拟合信息在训练过程中提供了验证损失和准确度值，但根据测试数据明确评估模型始终是一个好主意，因为准确度和损失值可能不同:

```py
test_loss, test_acc = model.evaluate(test_ds)

```

### 可视化培训表现

如清单 [9-5](#PC26) 所示可视化。

```py
import matplotlib.pyplot as plt

# history.history contains the training record
history_dict = history.history

acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']

epochs = range(1, len(acc) + 1)

plt.figure(figsize=(12,9))
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.ylim((0.5,1))

plt.show()

# clear previous figure
plt.clf()

plt.figure(figsize=(12,9))
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

Listing 9-5Visualize training performance

```

### 从捏造的评论中做出预测

让我们从我们编造的评论中做出预测。首先创建一个返回预测的函数。由于我们创建了自己的评论，该函数必须为 TensorFlow 消费转换文本评论。

创建函数:

```py
def predict_review(text):
  encoded_text = encoder.encode(text)
  encoded_text = tf.cast(encoded_text, tf.float32)
  prediction = model.predict(tf.expand_dims(encoded_text, 0))
  return prediction

```

该函数接受文本审查。它从对评论进行编码开始。然后，它将编码后的评论转换为 float32。该函数通过进行预测并将其返回到调用环境来结束。我们将 *1* 维度添加到编码文本中，以便 TensorFlow 模型可以使用它。

用虚构的审查来测试功能:

```py
review = ('Just loved it. My kids thought the movie was cool. '
         'Even my wife liked it.')

pred = predict_review(review)
pred, pred.shape

```

我们有一个预测。预测值大于 0.5 意味着评论是正面的。否则，审查是负面的。

让我们通过创建另一个函数来使预测更容易接受:

```py
def palatable(pred):
  score = tf.squeeze(pred, 0).numpy()
  return score[0]

```

该函数将预测转换为 numpy 标量。

调用函数:

```py
score = palatable(pred)
score, score.shape

```

该函数从预测中删除 *1* 维度。

让我们更进一步，创建一个用简单英语返回评论的函数:

```py
def impression(score):
  if score >= 0.5:
    return 'positive impression'
  else:
    return 'negative impression'

```

调用函数:

```py
impression(score)

```

不出所料，评论是正面的。

让我们试试另一个:

```py
review = ('The movie absolutely sucked. '
          'No character development. '
          'Dialogue just blows.')

pred = predict_review(review)
score = palatable(pred)
print (impression(score))

```

不出所料，评论是负面的。

### 对测试数据批次进行预测

我们也可以从测试集中预测。让我们用*预测*方法对第*批*进行预测。由于测试数据已经是张量形式，我们不需要编码。

根据测试集批次进行预测，并显示第一次审查，如清单 [9-6](#PC34) 所示。

```py
# get predictions from 1st test batch
for sample, target in test_ds.take(1):
  y_pred_64 = model.predict(sample)

# display first review from this batch
print ('review:', end=' ')
print (encoder.decode(sample[0])[177:307])

# display first label from this batch
print ('label:', end=' ')
print (target[0].numpy(), br)

# display number of examples in the batch
print ('samples and target in first batch:', end=' ')
len(sample), len(target)

Listing 9-6Make predictions based on a batch from the test set

```

我们从 *test_ds* 取第一批。我们使用*预测*方法进行预测，并将它们放置在 y_pred_64 中。变量 *y_pred_64* 保存 64 个预测，因为批量大小是 64。然后，我们显示该批次中的第一篇评论及其相关标签。请记住，标签 *1* 表示审核结果为正面，标签 *0* 表示审核结果为负面。最后，我们显示样本和目标的大小，以验证我们在第一批中有 64 个样本。

得到第一个预测:

```py
print (y_pred_64[0])

```

让它变得可口:

```py
impression(y_pred_64[0])

```

将预测与实际标签进行比较:

```py
impression(y_pred_64[0]), impression(target[0].numpy())

```

如果预测与实际标签相匹配，那么它就是正确的。

列表 [9-7](#PC38) 显示了前五个预测的预测功效。

```py
for i in range(5):
  p = impression(y_pred_64[i])
  t = impression(target[i].numpy())
  print (i, end=': ')
  if p == t: print ('correct')
  else: print ('incorrect')

Listing 9-7Prediction efficacy for five predictions

```

### 第一批的预测准确度

创建一个函数，将印象转换回标签 1 或 0:

```py
def convert_label(feeling):
  if feeling == 'positive impression':
    return 1
  else: return 0

```

返回整个第一批的预测精度，如清单 [9-8](#PC40) 所示。

```py
ls = []
n = len(target)
for i, _ in enumerate(range(n)):
  t = target[i].numpy() # labels
  p = convert_label(impression(y_pred_64[i])) # predictions
  if t == p: ls.append(True)
correct = ls.count(True)
acc = correct / n
batch_accuracy = str(int(np.round(acc, 2) * 100)) + '%'
print ('accuracy for the first batch:', batch_accuracy)

Listing 9-8Prediction accuracy for the first batch

```

我们首先遍历第一批，并将标签与预测进行比较。如果一个预测是正确的，我们将这个信息添加到一个列表中。我们继续计算正确预测的数量。最后，我们将正确的预测除以批量大小，以获得整体预测精度。

## 利用预训练嵌入

令人惊讶的是，我们可以在 IMDb 数据集上重用预训练模型中的模块。 *TensorFlow Hub 项目*是一个拥有数百个可重用机器学习模块的库。一个**模块**是一个TensorFlow图的独立部分，以及它的权重和资产，可以在一个称为迁移学习的过程中跨不同的任务重用。**迁移学习**是一种机器学习方法，其中为一项任务开发的模型被重新用作另一项任务的模型的起点。

您可以通过阅读以下 URL 来浏览该库:

[T2`http://tfhub.dev`](http://tfhub.dev)

一旦找到一个模块，就将 URL 复制到您的模型中。该模块及其预训练重量会自动下载。使用预训练模型的一个巨大优势是，我们不必从头开始创建和训练我们自己的模型！

### 加载 IMDb 数据集

由于我们使用的是预训练模型，我们可以用完整的词汇加载 IMDb 数据集:

```py
data, info = tfds.load('imdb_reviews', as_supervised=True,
                       with_info=True, shuffle_files=True)

```

我们使用完整的词汇，因为我们不必担心用它来训练！

显示元数据:

```py
info

```

### 构建输入管道

创建训练集和测试集:

```py
train, test = data['train'], data['test']

```

批处理和预取:

```py
batch_size = 32
train_set = train.repeat().batch(batch_size).prefetch(1)
test_set = test.batch(batch_size).prefetch(1)

```

检查张量:

```py
train_set, test_set

```

### 创建预训练模型

导入 TF Hub 库并创建一个骨架模型来容纳预训练模块，如清单 [9-9](#PC46) 所示。

```py
import tensorflow_hub as hub

# clear any previous models
tf.keras.backend.clear_session()

model = tf.keras.Sequential([
  hub.KerasLayer(
      'https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1',
      dtype=tf.string, input_shape=[], output_shape=[50]),
  Dense(128, activation="relu"),
  Dense(1, activation="sigmoid")
])

Listing 9-9Create the model

```

*中枢。KerasLayer* 下载句子编码器模块。输入到该层的每个字符串都被自动编码为一个 50D 矢量。所以每个向量代表 50 个单词。每个单词都是根据 70 亿个单词的谷歌新闻语料库中预先训练的嵌入矩阵嵌入的。添加接下来的两个密集层是为了提供情感分析的基本模型。使用 TF Hub 既方便又高效，因为我们可以使用已经从预训练模型中学到的东西。

### 编译模型

编译模型:

```py
model.compile(loss='binary_crossentropy', optimizer="adam", metrics=['accuracy'])

```

### 训练模型

训练模型:

```py
# to suppress unimportant error messages
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

history = model.fit(train_set,
                    steps_per_epoch=train_size // batch_size,
                    epochs=5, validation_data=test_set)

```

培训时间大幅减少！

### 做预测

根据第一批*测试集*进行预测:

```py
for sample, target in test_set.take(1):
  y_pred_32 = model.predict(sample)

```

因为批量大小是 32，所以我们对每批有 32 个预测。

按索引显示 test_set 中的错误分类，如清单 [9-10](#PC50) 所示。

```py
for i in range(batch_size):
  p = convert_label(impression(y_pred_32[i]))
  l = target[i].numpy()
  if p != l:
    print ('pred:', p, 'actual:', l, 'indx:', i)

Listing 9-10Misclassifications in the first batch by index

```

### 计算第一批的预测准确度

清单 [9-11](#PC51) 显示了计算第一批预测准确度的代码。

```py
ls = []
n = len(target)
for i, _ in enumerate(range(n)):
  t = target[i].numpy() # labels
  p = convert_label(impression(y_pred_32[i])) # predictions
  if t == p: ls.append(True)
correct = ls.count(True)
acc = correct / n
batch_accuracy = str(int(np.round(acc, 2) * 100)) + '%'
print ('accuracy for the first batch:', batch_accuracy)

Listing 9-11Calculate prediction accuracy for the first batch

```

代码没有找到错误的分类，而是找到了正确的预测。代码从比较实际标签和预测标签开始。如果实际标签被正确预测，布尔值 *True* 被附加到列表。一旦遍历了第一批，就计算列表中元素的数量。该计数除以 32 的批次大小以确定精确度，精确度显示为百分比。

## 和 Keras 一起探索 IMDb

由于 Keras 在行业中非常受欢迎，我们演示了如何用 keras.datasets 训练 IMDb。我们使用*Keras . datasets . IMDB . load _ data*函数以格式就绪的方式加载数据集，以用于神经网络和深度学习模型。

装载喀拉斯 IMDb 有一些优势。首先，单词已经用整数编码了。第二，编码单词按照它们在数据集中的绝对流行度排列。所以每篇评论中的句子都是由一系列整数组成的。第三，第一次调用 *imdb.load_data* 将 imdb 下载到你的电脑上，存放在你的 home 目录下 *~/。keras/datasets/imdb.pkl* 作为 32 兆字节的文件。imdb.load_data 函数还提供了额外的参数，包括要加载的顶部单词的数量(其中具有较小整数的单词在返回的数据中被标记为 0)、要跳过的顶部单词的数量(以避免像*这样的单词)以及要支持的评论的最大长度。*

 *加载硬 IMDb：

```py
train, test = tf.keras.datasets.imdb.load_data()

```

该函数将数据加载到训练和测试元组中。因此 *train[0]* 包含培训评论， *train[1]* 包含培训标签。并且*测试[0]* 包含测试评论，*测试[1]* 包含测试标签。每个评论被表示为一个整数数组，每个整数代表一个单词。标签包含整数标签列表(0 表示负面评价，1 表示正面评价)。

为了可读性，创建变量来表示评论和标签:

```py
train_reviews, train_labels = train[0], train[1]
test_reviews, test_labels = test[0], test[1]

```

显示训练和测试评审样本的形状:

```py
train_reviews.shape, test_reviews.shape

```

正如预期的那样，我们有 25，000 次训练和 25，000 次测试评审。

显示训练和测试标签的形状:

```py
train_labels.shape, test_labels.shape

```

正如所料，我们有 25，000 个训练和 25，000 个测试标签。

### 探索火车样本

显示标签类别和唯一单词数:

```py
print ('categories:', np.unique(train_labels))
print ('number of unique words:',
       len(np.unique(np.hstack(train_reviews))))

```

数据集由两个类别标记，这两个类别代表每个评论的情感。并且训练样本包含 88，585 个唯一单词。

我们来看看最长的训练复习有多少单词:

```py
longest = np.amax([len(i) for i in train_reviews])

print ('longest review:', longest)

```

我们创建一个包含每篇评论字数的列表，然后找出字数最多的评论的长度。

获取最长评论的索引:

```py
mid_result = np.where([len(i) for i in train_reviews] == longest)
longest_index = mid_result[0][0]
longest_index

```

我们使用 *np.where* 函数来查找索引。我们使用双重索引，因为该函数返回一个元组，其中包含一个包含我们需要的索引的列表。

### 创建一个解码函数

创建一个将评论解码成英文可读形式的函数，如清单 [9-12](#PC59) 所示。

```py
def readable(review):
  index = tf.keras.datasets.imdb.get_word_index()
  reverse_index = dict([(value, key)\
                        for (key, value) in index.items()])
  return ' '.join( [reverse_index.get(i - 3, '?')\
                    for i in review])

Listing 9-12Function that decodes a review

```

该函数使用*TF . keras . datasets . IMDB . get _ word _ index*实用程序来获取单词及其唯一分配的整数的字典。然后，该函数创建另一个字典，其中包含作为第一个字典中的值和键分组的键值分组。最后，它根据单词的 id(或键)返回单词。索引偏移 3，因为 0、1 和 2 是为*填充*、*序列开始*和*未知*保留的索引。

### 调用解码功能

让我们看看清单 [9-13](#PC60) 中最长的评论是什么样的。

```py
review = readable(train_reviews[longest_index])
print ()
print ('review:', end=' ')

# just display a slice of the full review
print (review[:50] + ' ...', br)

label = train_labels[longest_index]
idea = impression(label)
print (idea, br)

# verify length of review
print (len(train_reviews[longest_index]))

Listing 9-13Decode the longest review

```

由于我们已经知道最长评论的索引，我们可以很容易地从 *train_reviews* 中检索到它。展示一部分，因为评论很长。我们也可以很容易地从 *train_labels* 中检索标签。使标签可读并显示出来。最后，显示最长评论的长度。

让我们看看最短的评论是什么样的。但是我们不能直接这么做。

我们必须首先找到最少的字数:

```py
shortest = np.amin([len(i) for i in train_reviews])
print ('shortest review:', shortest)

```

由于我们不知道哪个评论最短，所以我们使用 *amin* 方法返回最小值。

我们现在可以得到训练样本中最短评论的索引:

```py
result = np.where([len(i) for i in train_reviews] == shortest)
shortest_index = result[0][0]
shortest_index

```

我们使用 *where* 方法返回我们寻找的索引。因为该方法返回所有符合标准的评论，所以我们获取第一个评论并显示其索引。

清单 [9-14](#PC63) 显示了评论、可读形式的标签和长度。

```py
review = readable(train_reviews[shortest_index])
print (review[2:], br)

label = train_labels[shortest_index]
idea = impression(label)
print (idea, br)

# verify length of review
print (len(train_reviews[shortest_index]))

Listing 9-14Display the shortest review

```

### 继续探索训练样本

返回平均评论长度:

```py
length = [len(i) for i in train_reviews]

print ('average review length:', np.mean(length))

```

显示第一个标签及其编码为整数的评论，如清单 [9-15](#PC65) 所示。

```py
first_label = train_labels[0]

print('label:', first_label, end=' ')

idea = impression(first_label)
print ('(' + idea + ')', br)

# display slice of first review
print (train_reviews[0][:20])

# display readable slice of first review
print (readable(train_reviews[0][:20]))

Listing 9-15First label and its review

```

以可读的形式显示第一条评论:

```py
review = readable(train_reviews[0])
print (review[2:105] + ' ...')

```

## 培训一次 IMDb 数据

限制词汇大小以提高性能:

```py
# limit vocabulary to 8000 most commonly used words in reviews
vocab_size = 8000

```

将文本大小缩减为 80 个字以提高性能:

```py
maxlen = 80

```

### 加载数据

用有限的词汇加载数据:

```py
(x_train, y_train), (x_test, y_test) =\
tf.keras.datasets.imdb.load_data(num_words=vocab_size)

```

显示有关训练和测试数据的信息:

```py
print ('train and test features:')
print (len(x_train), 'train sequences')
print (len(x_test), 'test sequences', br)
print ('sequence shape before padding:')
print ('x_train shape:', x_train.shape)
print ('x_test shape:', x_test.shape)

```

### 衬垫样品

将训练集和测试集转换为 numpy:

```py
x_train = np.asarray(x_train)
x_test = np.asarray(x_test)

```

导入适当的库:

```py
from tensorflow.keras.preprocessing.sequence import pad_sequences

```

填充样本以确保所有序列长度相同:

```py
print('padded sequences (samples, maxlen):')
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)
print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)

```

### 构建输入管道

初始化管道变量:

```py
buffer_size = 10000
batch_size = 512

```

为 TensorFlow 消耗准备训练数据:

```py
train_k = tf.data.Dataset.from_tensor_slices(
    (x_train, y_train))
train_ks = train_k.shuffle(
    buffer_size).batch(batch_size).prefetch(1)

```

准备TensorFlow消耗的测试数据:

```py
test_k = tf.data.Dataset.from_tensor_slices(
    (x_test, y_test))
test_ks = test_k.batch(batch_size).prefetch(1)

```

### 建立模型

清除任何以前的型号:

```py
tf.keras.backend.clear_session()

```

创建模型:

```py
embed_size = 128
model = Sequential([
  Embedding(vocab_size, embed_size, mask_zero=True,
            input_shape=[None]),
  GRU(128, return_sequences=True),
  GRU(128),
  Dense(1, activation="sigmoid")
])

```

### 编译模型

编译:

```py
model.compile(loss='binary_crossentropy', optimizer="adam",
              metrics=['accuracy'])

```

### 训练模型

隐藏错误消息:

```py
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

```

火车:

```py
epochs = 2

model.fit(train_ks, batch_size=BATCH_SIZE,
          epochs=epochs, validation_data=(test_ks))

```

### 预测

获得预测:

```py
k_pred = model.predict(test_ks)

```

显示第一个预测:

```py
impression(k_pred[0][0])

```

显示评论片段:

```py
pred_first = readable(x_test[0])
pred_first[26:53]

```

展示印象:

```py
impression(y_test[0])

```*
# 2.传统的异常检测方法

在本章中，您将了解异常检测的传统方法。您还将了解各种统计方法和机器学习算法的工作原理，以及它们如何用于检测异常，以及如何使用多种算法实现异常检测。

简而言之，本章将涵盖以下主题:

*   数据科学评论

*   异常检测的三种类型

*   隔离森林

*   一类支持向量机(OC-SVM)

## 数据科学评论

了解一些基本的数据科学概念非常重要，这样您才能评估模型的性能，并将其性能与其他模型进行比较。

首先，异常检测的目标是确定给定点是否是异常点。本质上，你是在用类别 **y** 标记数据点 **x** 。假设在某种情况下，你试图对动物是否对某种疾病呈阳性(意味着是)进行分类。如果动物患病并且测试呈阳性，这种情况就是**真阳性**。如果动物是健康的，测试显示为阴性(意味着它没有疾病)，那么它就被称为真正的阴性。但是，也有测试失败的情况。如果动物是健康的，但测试显示为阳性，这种情况是**假阳性。**如果动物患病，但测试显示为阴性，这种情况为**假阴性**。

在统计学中，有类似于假阳性和假阴性的术语:**I 型误差**和**II 型误差**。这些错误用于假设检验，假设检验中有一个零假设(通常表示两个观察到的现象之间没有关系)和一个替代假设(旨在推翻零假设，意味着两个观察结果之间有统计学上的显著关系)。

第一类错误是当零假设被证明是真的，但你还是拒绝了它，而选择了另一个假设。换句话说，假阳性，因为你拒绝了原来是真的东西，接受了假的东西。一个**第二类错误**是当零假设被接受为真时(意味着你没有拒绝零假设)，但结果是零假设是假的，而替代假设是真的。这是一个错误的否定，因为你接受错误的东西，但拒绝真实的东西。

对于以下定义的上下文，假设条件是您试图证明的。可能是简单的“这是动物疾病”动物的状况是生病还是健康，你试图预测它是生病还是健康。以下是一些定义:

*   **真正**:当条件为真时，预测也为真

*   **真否定**:当条件为假时，预测也为假

*   **假阳性**:当条件为假，但预测为真时

*   **假阴性**:条件为真，但预测为假

把它们放在一起，你可以形成所谓的**混淆矩阵**(图 [2-1](#Fig1) )。需要注意的一点是，在异常检测的情况下，您只需要一个 2x2 混淆矩阵，因为数据点要么是异常数据，要么是正常数据。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig1_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig1_HTML.jpg)

图 2-1

混淆矩阵

从四个方格中的每个方格的值，您可以推导出**精确度**、**精确度**和**召回**的值，以更好地了解您的模型的性能。

以下是包含所有公式的混淆矩阵(图 [2-2](#Fig2) ):

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig2_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig2_HTML.jpg)

图 2-2。

精确度、准确度和召回率

*   精度是一种衡量标准，它描述了你的真实预测有多少被证明是真实的。换句话说，在你所有的真实预测中，有多少是正确的？

*   **准确性**是一个衡量标准，它描述了在整个数据集上你有多少预测是正确的。换句话说，对于整个数据集，模型正确预测了多少个正和负？

*   **回忆**是一个衡量标准，它描述了对于所有实际上为真的数据点，您预测了多少为真。换句话说，对于数据集中的所有真实数据点，模型正确预测了多少？

从这里，你可以推导出更多的值。

**F1 得分**是精确度和召回率的调和平均值。这是一个可以告诉我们模型有多准确的指标，因为它考虑了模型做出的真实预测有多准确，以及模型正确预测的真实预测总数有多少。

![$$ \mathrm{F}1\ \mathrm{Score}=\frac{2\ast Precision\ast Recall}{Precision+ Recall} $$](../images/483137_1_En_2_Chapter/483137_1_En_2_Chapter_TeX_Equa.png)

**真阳性率** = **回忆** = **灵敏度**。与 recall 相同，TPR 告诉我们有多少实际上为真的数据点被模型预测为真。

![$$ \mathrm{The}\ \mathrm{false}\ \mathrm{positive}\ \mathrm{rate}\ (FPR)=\left(\ 1\hbox{--} \mathrm{specificity}\right)=\frac{FP}{FP+ TN} $$](../images/483137_1_En_2_Chapter/483137_1_En_2_Chapter_TeX_Equb.png)

FPR 告诉我们有多少实际上为假的数据点被模型预测为正。该公式类似于 recall，但不是真阳性占所有真数据点的比例，而是假阳性占所有假数据点的比例。

![$$ \mathrm{Specificity}=1\hbox{--} FPR=\frac{TN}{TN+ FP} $$](../images/483137_1_En_2_Chapter/483137_1_En_2_Chapter_TeX_Equc.png)

特异性与回忆非常相似，因为它告诉我们有多少实际上错误的数据点被模型预测为错误。

我们可以使用 TPR 和 FPR 来形成一个图表，称为**接收机工作特性**曲线，或 **ROC** 曲线。从曲线下的**区域，或 **AUC** (你可以看到在接收器操作特性**曲线下的这个被称为**的区域，或 **AUROC** )，一个数据点，意味着模型具有真正或真负情况的概率。这条曲线也可以称为 **AUCROC** 曲线。**

**ROC 曲线 AUC = 1.0 (** **图** [**2-3**](#Fig3) **)。**

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig3_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig3_HTML.jpg)

图 2-3

AUC = 1.0 的 ROC 曲线

这是最理想的 AUC 曲线。然而，这几乎不可能实现，因此 AUC > 0.95 的目标是最理想的。我们越是能使模型达到 AUC 值 1.0，模型预测真阳性或真阴性情况的概率就越大。上图中的 AUC 值表明这一概率为 1.0，这意味着它的预测正确率为 100%。然而，非常高的 AUC 值，比如 0.99999，可能表明该模型正在**过度拟合**，这意味着它在预测这个特定数据集的标签方面变得非常好。您将在支持向量机的上下文中进一步探索这一概念，但是您希望尽可能避免过度拟合，以便模型即使在引入包含意外变化的新数据时也能表现良好。

值得一提的是，虽然 AUC 可以是 0.99，但不能保证模型将继续在超出**训练数据集**(用于训练模型的数据，以便它可以学习对异常和正常数据进行分类)的水平上运行。这是因为在现实世界中，存在不可预测的因素，有时甚至会让人类感到困惑。可以说，如果数据是黑白的，这个世界会变得更简单，但更多的时候，有一个巨大的灰色区域(我们确定那个点是 X 而不是 Y 吗？这真的是一个异常现象，还是只是一个正常点的怪异情况？).对于深度学习模型来说，当暴露于包含大量变异的新数据时，保持获得高 AUC 分数是很重要的。基本上，当将模型暴露给训练集之外的新数据时，预期性能会略有下降是合理的假设。

训练模型的目标是避免过度拟合，并保持尽可能高的 AUC。如果 AUC 结果是 0.99999，即使在暴露于包含大量变化的新数据的极大样本之后，这意味着该模型基本上是我们可以获得的理想模型，并且已经远远超过了人类的表现，这暂时是不可能的。

**ROC 曲线 AUC = 0.75 (** **图**[T5】2-4](#Fig4)**)**

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig4_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig4_HTML.jpg)

图 2-4

AUC = 0.75 的 ROC 曲线

AUC 值表明该模型仅在 75%的时间内正确预测数据点的标签。不算差，但也不算好，所以显然还有提升的空间。

**ROC 曲线 AUC = 0.5 (** **图**[T5】2-5](#Fig5)**)**

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig5_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig5_HTML.jpg)

图 2-5

AUC = 0.5 的 ROC 曲线

AUC 值表明该模型只有 50%的机会或 0.5 的概率来预测正确的标签。这是你能得到的最差的 AUC 值，因为它意味着模型不能区分正类和负类。

**ROC 曲线 AUC = 0.25 (** **图**[T5】2-6](#Fig6)**)**

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig6_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig6_HTML.jpg)

图 2-6

AUC = 0.25 的 ROC 曲线

在这种情况下，模型只有 0.25 的概率预测正确的标签，但这仅仅意味着它有 0.75 的概率预测不正确的标签。在 AUC 为 0 的情况下，这意味着该模型在预测错误标签方面是完美的，这意味着标签被交换了。如果 AUC 为< 0.5, this means the model gets better at predicting incorrectly as the AUC approaches 0.0\. It’s the perfectly opposite case of when the AUC is > 0.5，当 AUC 接近 1.0 时，模型在正确预测方面变得更好。

在任何情况下，您都希望 AUC > 0.5，并且至少大于 0.9，理想情况下大于 0.95。

## 隔离森林

隔离林是对数据集进行递归分区的单个树结构的集合。在该过程的每次迭代中，选择一个随机特征，并且基于在所选特征的最小值和最大值之间随机选择的值来分割数据。重复这一过程，直到整个数据集被分区以在林中形成一个单独的树。与正常数据点相比，异常通常从根点形成更短的路径，因为它们更容易被隔离。您可以通过使用涉及平均路径长度的数据点的函数来找到异常分数。

对未标记的数据集应用隔离森林以捕捉异常是**无监督异常检测**的一个例子。

### 变异鱼

为了更好地理解隔离林的作用，我们来看一个假想的场景。在一个特别大的湖中，一个不负责任的鱼类养殖者释放了一种突变的鱼类，这种鱼看起来与本地物种非常相似，但平均比本地物种大。此外，它的尾鳍长度与身体长度的比例比本土物种大。总而言之，有三个特征可以用来区分入侵的突变物种和本地物种。

这里有一个直观的例子，详细说明了两个物种的平均标本的差异。图 [2-7](#Fig7) 中可以看到**本土物种**。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig7_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig7_HTML.jpg)

图 2-7

这是这个湖里本地物种的一个例子

图 [2-8](#Fig8) 中可以看到**入侵物种**。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig8_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig8_HTML.jpg)

图 2-8

这是一个新的变异物种被释放到湖里的例子

入侵物种更大，周长更大，平均尾鳍更长(比较图 [2-7](#Fig7) 和图 [2-8](#Fig8) )。然而，问题是，虽然每个物种的平均样本之间有一些明显的区别，但这两个物种之间有很多重叠，其中一些本地物种长得很大，一些突变物种只是较小，两者的尾鳍大小不同，等等。因此，差异可能并不总是那么明显。

为了查明这种渗透的程度，一大群渔民被召集起来，面临的任务是在捕获的 1000 条鱼中识别每条鱼的种类。在这种情况下，假设每个渔民将随机对每条鱼进行描述，以确定它是否是本地物种的成员。

现在开始评估。每个渔民首先挑选一个随机特征来判断样本:鱼的长度，鱼的周长，或者它的尾鳍占其总长度的比例。然后，渔民在本地物种的相应测量值的已知最小值和最大值之间选择一个随机值，并相应地分割所有的鱼(例如，所有相关测量值等于或大于所选值的鱼都向右，其他的都向左)。渔夫一遍又一遍地重复整个过程，直到每一条鱼都被分割，鱼的“树”被创建。

在这种情况下，每个渔民代表隔离林中的一棵树，整个渔民群体的结果树代表一个隔离林。现在，给定一条随机捕获的鱼，你可以得到一个异常分数，看看有多少渔夫发现这条鱼是异常的。根据您为异常分数选择的阈值，您可以将某些鱼类标记为入侵物种，而将其他鱼类标记为本地物种。

然而，问题是，这不是一个完美的系统；会有一些外来入侵鱼类冒充本地鱼类，也有一些本地鱼类冒充外来入侵物种。这些情况代表假阳性和假阴性。

### 隔离森林异常检测

现在，您对隔离林的工作原理有了更多的了解，您可以继续将其应用于数据集。在开始之前，一定要注意隔离林在高维数据上表现良好。对于入侵鱼类的例子，您需要处理三个特征:鱼的长度、周长和尾鳍长度占总长度的比例。在下一个示例中，每个数据条目将有 42 个特征。

您将使用 KDDCUP 1999 数据集，它包含大量代表各种入侵攻击的数据。特别是，您将关注所有涉及 HTTP 攻击的数据条目。数据集可以在 [`http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html`](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) 找到。打开链接后，您应该会看到类似图 [2-9](#Fig9) 的内容。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig9_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig9_HTML.jpg)

图 2-9

这是您打开链接时应该看到的内容

下载 kddcup.data.gz 文件并解压。

版本不匹配和代码功能不应该有任何问题，但为了以防万一，本例中使用的确切 Python 3 包如下:

*   数字版本 1.15.3

*   熊猫

*   学习 0.19.1

*   matplotlib 2.2.2

首先，导入代码调用的所有必要模块(图 [2-10](#Fig10) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig10_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig10_HTML.png)

图 2-10

导入 numpy、pandas、matplotlib.pyplot 和硬化模块

模块 **numpy** 是许多其他模块的依赖项，因为它允许它们执行高级别的计算。 **Pandas** 是一个模块，它允许我们读取各种格式的数据文件，以便将它们存储为数据框对象，它是一个普遍的数据科学框架。这些数据框以类似于数组的方式保存数据条目，可以看作是一个值表。 **Matplotlib** 是一个 Python 库，允许我们定制和绘制数据。最后， **scikit-learn** 是一个包，它允许我们将各种机器学习模型应用于数据集，并提供数据分析工具。

`%matplotlib inline`允许图表显示在单元格下方，并保存在笔记本旁边。

接下来，定义列并加载数据框(图 [2-11](#Fig11) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig11_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig11_HTML.png)

图 2-11

您定义所有的列，并将数据集保存为一个名为`df`的变量

每个数据条目都很庞大，每个条目有 42 列数据。确切的名称并不重要，但重要的是“服务”和“标签”保持不变。列名的完整列表如下:

*   期间

*   协议类型

*   服务

*   旗

*   src_bytes

*   dst_bytes

*   陆地

*   错误 _ 片段

*   急迫的

*   热的

*   登录失败次数

*   已登录

*   num _ 妥协

*   root_shell

*   su _ 已尝试

*   num_root

*   数量 _ 文件 _ 创作

*   炮弹数量

*   数量访问文件

*   数量 _ 出站 _ 命令

*   是主机登录

*   是 _ 来宾 _ 登录

*   数数

*   服务数量

*   错误率

*   误差率

*   错误率

*   误差率

*   相同比率

*   差异利率

*   服务价格差异主机价格

*   dst _ 主机 _ 计数

*   dst 主机服务器计数

*   dst _ 主机 _ 相同 _ 服务比率

*   dst _ 主机 _ 差异 _ 服务比率

*   dst _ 主机 _ 相同 _ src _ 端口 _ 速率

*   dst _ host _ srv _ diff _ 主机速率

*   dst _ host _ ser error _ rate

*   dst_host_srv_serror_rate

*   dst _ 主机 _ 错误率

*   dst_host_srv_rerror_rate

*   标签

为了得到桌子的尺寸，或者熊猫中提到的形状

```
df.shape

```

如果你不在朱庇特，那就去吧

```
print(df.shape)

```

在 Jupyter 中，运行代码后，您应该会看到类似图 [2-12](#Fig12) 的内容。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig12_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig12_HTML.jpg)

图 2-12

输出是一个描述数据帧维度的元组

如你所见，这是一个庞大的数据集。

接下来，过滤掉整个数据帧，只包含涉及 HTTP 攻击的数据条目，并删除服务列(图 [2-13](#Fig13) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig13_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig13_HTML.png)

图 2-13

过滤`df`以只有 HTTP 攻击，并从`df`中删除服务列

为了确保安全，再次检查 df 的形状(图 [2-14](#Fig14) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig14_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig14_HTML.jpg)

图 2-14

过滤后的维度`df`

行数大幅减少，列数减少了一列，因为您删除了 service 列，因为您实际上不再需要它了。

让我们检查所有可能的标签和每个标签的计数，只是为了对数据分布有一个感觉。

运行以下命令:

```
df["label"].value_counts()

```

或者

```
print(df["label"].value_counts())

```

您应该会看到类似图 [2-15](#Fig15) 的内容。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig15_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig15_HTML.jpg)

图 2-15

`df`中的唯一标签以及`df`中带有该特定标签的数据点的实例数量

数据集的绝大部分由正常的数据条目组成，所有 HTTP 攻击的大约 0.649%的数据条目由实际的入侵攻击组成。

此外，有些列具有分类数据值，这意味着模型在对它们进行定型时会遇到问题。为了绕过这个问题，您可以使用 scikit-learn 的一个内置特性，称为**标签编码器**。

图 [2-16](#Fig16) 显示了您当前运行`df.head(5)`所看到的内容，这意味着您希望显示五个条目。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig16_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig16_HTML.jpg)

图 2-16

显示表中前五个条目的一行代码。在这种情况下，图像被裁剪以显示前几列

您也可以运行`print(df.head(5))`，但它以文本格式打印(图 [2-17](#Fig17) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig17_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig17_HTML.jpg)

图 2-17

与图 [2-16](#Fig16) 中的功能相同，但为文本格式

为了解决这个问题，**标签编码器**获取唯一的(意味着每个分类值一个条目，而不是多个)分类值列表，并为每个分类值分配一个数字。如果你有这样一个数组

```
[ "John", "Bob", "Robert"],

```

标签编码器将创建一个数字表示，如

```
[0, 1, 2], where 0 represents "John", 1 represents "Bob", and 2 represents "Robert."

```

现在对数据框中的标注进行同样的操作。

运行图 [2-18](#Fig18) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig18_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig18_HTML.png)

图 2-18

将标签编码器应用于数据值为字符串的列

`encoded.fit(df[col])`为标签编码器提供从中提取唯一分类值的列中的所有数据。当你跑步的时候

```
df[col] = encoded.transform(df[col])

```

将每个分类值的编码表示分配给 df[col]。

现在让我们检查数据帧(图 [2-19](#Fig19) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig19_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig19_HTML.jpg)

图 2-19

应用标签编码器后查看`df`的前五个条目

很好，所有的分类值都被替换成了等价的数字。

现在运行图 [2-20](#Fig20) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig20_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig20_HTML.png)

图 2-20

打乱`df`中的值，创建您的训练、测试和验证数据集

随着

```
df = df.iloc[np.random.permutation(len(df))]

```

您正在随机调整数据集中的所有条目，以避免在数据集中的任何一个区域出现异常条目汇集的问题。

随着

```
df2 = df[:500000]

```

您将 df 的前 500，000 个条目分配给一个变量 df2。

在下一行代码`labels = df2["label"]`中，将标签列分配给变量标签。接下来，将数据帧的剩余部分分配给一个名为 df_validate 的变量，以创建带有`df_validate = df[500000:]`的验证数据集。

要将您的数据分成**训练集**和**测试集**，您可以使用名为`train_test_split`的内置 scikit-learn 函数，如下所述:

```
x_train, x_test, y_train, y_test = train_test_split(df2, labels, test_size = 0.2, random_state = 42)

```

参数如下:x，y，test_size 和 random_state。请注意，x 和 y 应该分别是训练数据和训练标签，test_size 表示用作测试数据的数据集的百分比。random_state 是用于初始化随机数生成器的数字，该随机数生成器确定为训练数据集和测试数据集选择什么数据条目。

最后，您将剩余的数据委托给**验证集**。要再次定义术语:

*   **训练数据**是模型训练和学习的数据。对于隔离林，该集合是模型分区的基础。对于神经网络，这个集合是模型调整其权重的依据。

*   **测试数据**是用于测试模型性能的数据。`train_test_split()`函数基本上将数据分成一部分用于训练，一部分用于测试模型的性能。

*   **验证数据**在训练过程中用于衡量模型的训练进展如何。它基本上有助于确保随着模型在训练数据上更好地执行任务，它也在新的但相似的数据上更好地执行相同的任务。通过这种方式，该模型不仅能够很好地对训练数据执行任务，还能够对新数据执行类似的任务。换句话说，您希望避免**过度拟合**，这种情况下，模型在特定数据集(可以是训练数据集)上表现非常好，但当新数据出现时，性能会明显下降。当模型暴露于数据中的新变化时，性能会略有下降，但在这种情况下，这种下降更明显。

在此示例中，您在训练期间不使用验证集或测试集，但这将在以后训练神经网络时发挥作用。相反，您可以使用它们来评估模型的性能。

让我们通过运行图 [2-21](#Fig21) 中的代码来看看你的新变量的形状。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig21_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig21_HTML.jpg)

图 2-21

获得训练、测试和验证数据集的形状

要构建隔离林模型，请运行以下命令:

```
isolation_forest = IsolationForest(n_estimators=100, max_samples=256, contamination=0.1, random_state=42)

```

以下是对参数的解释:

*   **n_estimators** 是森林中使用的树木数量。默认值为 100。

*   **max_samples** 是树应该建立的数据点的最大数量。缺省值为 256 或数据集中的样本数中的较小值。

*   **污染**是对整个数据集应被视为异常/异常值的百分比的估计。默认情况下为 0.1。

*   **random_state** 是在训练过程中初始化随机数发生器时使用的数字。隔离林在训练过程中非常广泛地使用随机数生成器。

现在，让我们通过运行来训练您的隔离森林模型

```
isolation_forest.fit(x_train)

```

这个过程需要一些时间，所以起来伸展一下吧！

一旦完成，你就可以开始计算异常分数了。让我们创建一个在验证集上测试时异常分数的直方图。

运行图 [2-22](#Fig22) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig22_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig22_HTML.png)

图 2-22

从训练好的隔离森林模型中获取异常分数并绘制直方图

您应该会看到类似图 [2-23](#Fig23) 的图表。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig23_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig23_HTML.jpg)

图 2-23

绘制数据点平均路径长度的直方图。它通过使用最短的路径长度集来帮助您确定什么是异常，因为这表明模型能够轻松地隔离这些点

一个小提示:如果你有`%matplotlib inline`，在 Jupyter 上`plt.show()`是不必要的，但是如果你正在使用其他的，这将打开一个新的图形窗口。

让我们计算一下 **AUC** 来看看这个模型做得有多好。查看图表，似乎有一些平均路径小于-0.15 的异常数据。您预计在正常的数据范围内会有一些异常值，所以让我们选择一些更极端的值，比如-0.19。请记住，路径长度越短，数据越有可能出现异常，这就是为什么随着图表向右移动，曲线会急剧增加。运行图 [2-24](#Fig24) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig24_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig24_HTML.png)

图 2-24

根据从图表中选择的阈值对异常进行分类，并根据该组标签为每个点生成 AUC 分数

您应该会看到类似图 [2-25](#Fig25) 的内容。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig25_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig25_HTML.jpg)

图 2-25

运行代码后生成的 AUC 分数

这是一个令人印象深刻的分数！但会不会是过度拟合的结果呢？让我们得到测试集的异常分数来找出答案。

运行图 [2-26](#Fig26) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig26_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig26_HTML.png)

图 2-26

为测试集而不是验证集创建如图 [2-23](#Fig23) 所示的直方图

你应该得到一个类似图 [2-27](#Fig27) 的图。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig27_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig27_HTML.jpg)

图 2-27

类似于图 [2-23](#Fig23) 的直方图，但用于测试集

在-0.15 的左侧有一个类似的异常数据模式。同样，假设存在预期的异常值，选择任何小于-0.19 的平均路径长度作为异常值的截止值。

运行图 [2-28](#Fig28) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig28_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig28_HTML.png)

图 2-28

将图 [2-24](#Fig24) 中的代码应用于测试装置。在这种情况下，阈值是相同的，但是您仍然是基于直方图选择的

它应该如图 [2-29](#Fig29) 所示。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig29_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig29_HTML.jpg)

图 2-29

为测试集生成的 AUC 分数

那真是太好了！它似乎在验证数据和测试数据上都表现得非常好。

希望到现在为止，您已经对什么是隔离林以及如何应用它有了更好的理解。请记住，隔离林适用于多维数据(在这种情况下，删除服务列后有 41 列)，并且当以本节中实现的方式应用时，可以用于**无监督异常检测**。

## 单类支持向量机

一类 SVM 是一种改进的支持向量机模型，非常适合于新颖性检测(半监督异常检测的一个例子**)。其思想是，模型训练正常数据，并用于在新数据出现时检测异常。虽然 OC-SVM 可能最适合半监督异常检测，但由于只对一个类进行训练意味着当考虑整个数据集时，它仍然是“部分标记的”，因此它也可以用于非监督异常检测。您将在与隔离林示例相同的 KDDCUP 1999 数据集上执行半监督异常检测。与隔离森林类似，OC-SVM 也适用于高维数据。此外，OC-SVM 可以很好地捕捉数据集的形状，这一点将在下面详细阐述。**

为了理解支持向量机如何工作，首先在 2D 平面上可视化一些数据(图 [2-30](#Fig30) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig30_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig30_HTML.jpg)

图 2-30

一些点被标绘成一组，在图上分成两个区域

如何用一条线将数据分成两个不同的区域？嗯，挺简单的(图 [2-31](#Fig31) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig31_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig31_HTML.jpg)

图 2-31

根据绘制的点分隔两个区域的线

现在有两个区域代表两个不同的标签。然而，问题比这更深一层。

该模型被称为“支持向量机”的原因是因为这些“支持向量”实际上在模型如何绘制决策边界方面起着巨大的作用，在这种情况下由图 [2-32](#Fig32) 中的线表示。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig32_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig32_HTML.jpg)

图 2-32

用支持向量绘制决策边界

基本上，**支持向量**是平行于作为决策边界的超平面的向量，包含最接近**超平面**的点，并帮助建立决策边界的余量。在这个例子中，超平面是一条线，因为只有两个维度。在三维空间中，超平面将是一个平面，在四维空间中，它将是一个三维空间，以此类推。

最佳超平面将涉及为超平面建立最大边缘的支持向量。图 [2-32](#Fig32) 中的例子不是最优的，所以让我们在图 [2-33](#Fig33) 中寻找一个更优的超平面。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig33_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig33_HTML.jpg)

图 2-33

具有支持向量的超平面，允许更大的余量

随着超平面的绘制，它们各自的支持向量所经过的点是最接近超平面的。对于超平面来说，这是一个更优的解决方案，因为超平面的余量比上一个例子大得多(图 [2-32](#Fig32) )。

然而，实际上，你会看到更像图 [2-34](#Fig34) 的超平面。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig34_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig34_HTML.jpg)

图 2-34

超平面如何工作的更现实的例子

总会有异常值妨碍两个分类之间的清晰区分。如果你回想一下入侵鱼类的例子，有些本地鱼类看起来像入侵鱼类，有些入侵鱼类看起来像本地鱼类。

或者，图 [2-35](#Fig35) 显示了一种可能的解决方案。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig35_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig35_HTML.jpg)

图 2-35

完全分离两个区域的超平面的例子。然而，这是一个过度拟合的例子

虽然这确实算作分类问题的解决方案，但这会导致**过度拟合**，从而导致另一个问题。如果 SVM 在训练数据上表现得太好，它在包含不同变化的新数据上的表现可能会更差。

决策界限也不会那么简单。您可能会遇到如图 [2-36](#Fig36) 所示的情况。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig36_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig36_HTML.jpg)

图 2-36

展示不同类型的数据点分组的图表

你不能为此画一条线，所以你必须用不同的方式思考，而不是使用线性 SVM。让我们试着通过一些函数将每个点距离暗点中心的距离映射到 3D 平面上(见图 [2-37](#Fig37) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig37_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig37_HTML.jpg)

图 2-37

将这些点标绘到 3D 平面上表明您现在可以分离这些区域

现在这两个类之间有了清晰的分离，你可以继续将数据点分成两个区域，如图 [2-38](#Fig38) 所示。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig38_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig38_HTML.jpg)

图 2-38

由于增加了第三维，超平面现在是一个实际的平面

当你回到点的 2D 表示时，你可以看到类似图 [2-39](#Fig39) 的东西。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig39_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig39_HTML.png)

图 2-39

这是当你回到 2D 时超平面的样子

你刚才所做的是使用一个**内核**将数据转换到另一个维度，在这个维度中，数据类别之间有着明显的区别。这种数据映射被称为**内核技巧**。有不同类型的内核，包括你在前面的例子中看到的**线性内核**。其他类型的内核包括**多项式内核**，它使用多项式函数将数据映射到某个第 n 维，以及**指数内核**，它根据指数函数映射数据。

另一个术语是**正则化**，这是一个参数，它告诉 SVM 您有多希望避免错误分类。**较低的正则化**值会导致像您之前看到的图表一样，在超平面的任何一侧都有一些异常值。**更高的正则化**值会导致图形中你看到超平面分隔每个单点，代价是可能会过度拟合数据。

**Gamma** 告诉 SVM 需要考虑多少远离类间分离区域的点。**较高的伽马值**告诉 SVM 只考虑附近的点，而**较低的伽马值**告诉 SVM 也考虑更远的点。

最后， **margin** 是每个类和超平面之间的间隔。如前所述，**理想余量**包括每个最接近超平面的最大等距间隔。对于每个点或支持向量来说,**差裕度**或**次优裕度**使超平面过于接近一个类，或者距离远到超平面。

对于单类支持向量机，图 [2-40](#Fig40) 显示了该图的样子。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig40_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig40_HTML.jpg)

图 2-40

一类支持向量机的决策边界示例

在训练过程中，OC-SVM 学习正常观测值的决策边界，解释一些异常值。如果**新奇点**(模型从未见过的新数据点)落在此决策边界内，则它们被模型视为正常。如果它们落在边界之外，就被认为是异常的。这种技术是半监督新颖性检测的一个例子，目标是在正常数据上训练模型，然后尝试在新数据中发现异常。

通过这样做，OC-SVM 可以很好地捕捉数据的形状，这要归功于捕捉大多数训练观察的决策边界。

### OC-SVM 异常检测

既然您对 SVM 的工作原理有了更多的了解，让我们从对 KDDCUP 1999 数据集应用单类 SVM 开始。

导入您的模块并加载数据集(参见图 [2-41](#Fig41) 和图 [2-42](#Fig42) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig42_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig42_HTML.png)

图 2-42

定义数据集的列，并将数据集导入数据框变量`df`

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig41_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig41_HTML.png)

图 2-41

为 OC-SVM 导入您的模块

现在，让我们继续过滤掉所有正常的数据条目。您将创建两个数据框，其中包含正常条目以及异常和正常数据条目的等量混合。

运行图 [2-43](#Fig43) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig43_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig43_HTML.png)

图 2-43

过滤掉异常数据点和正常数据点，以构建两者混合的新数据集

图 [2-44](#Fig44) 显示了两个数据框的形状。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig44_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig44_HTML.jpg)

图 2-44

打印出新奇和正常数据集的形状

数据帧“新奇”的前半部分由异常组成，后半部分由正常数据条目组成。

现在，继续对数据帧中的所有分类值进行编码(见图 [2-45](#Fig45) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig45_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig45_HTML.png)

图 2-45

将标签编码器应用于数据集

现在运行图 [2-46](#Fig46) 中的代码来设置你的训练、测试和验证集。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig46_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig46_HTML.png)

图 2-46

打乱正常数据集中的条目，并定义训练集、测试集和验证集

图 [2-47](#Fig47) 显示了数据集的形状。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig47_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig47_HTML.jpg)

图 2-47

打印训练集、测试集和验证集的输出形状

您只使用整个数据集的子集来训练模型，因为训练数据越大，OC-SVM 训练的时间就越长。

运行图 [2-48](#Fig48) 中的代码，声明并初始化模型。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig48_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig48_HTML.png)

图 2-48

定义您的 OC-SVM 模型

默认情况下，**内核**设置为‘RBF’，意思是径向基函数。它类似于您在前面的示例中看到的圆形决策边界，您在这里使用它是因为您想要在包含正常数据的一组区域周围定义一个圆形边界。正如在前面的例子中所看到的，落在该区域之外的任何点都被认为是异常。 **Gamma** 告诉模型你想要考虑离超平面多远的点。因为它很小，这意味着你想强调更远的点。 **random_state** 只是一个初始化随机数生成器的种子，类似于隔离森林模型。下一个参数 **nu** ，指定了训练集中有多少包含异常值。同样，您将它设置为 0.1，类似于隔离林模型。这类似于您之前看到的正则化参数，因为它告诉模型您预计模型会错误分类多少个数据点。

现在让我们训练模型并评估预测(见图 [2-49](#Fig49) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig49_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig49_HTML.png)

图 2-49

在训练数据上训练 OC-SVM 模型

需要注意的一点是，您无法获得 x_test 和 x_validation 的 AUC 曲线值，因为它们完全由正常数据值组成。您无法获得真阴性或假阳性的值，因为数据集中没有异常可以错误地归类为正常或正确地归类为异常。

但是，您仍然可以在测试集和验证集上度量模型的准确性。尽管准确性不是最好的衡量标准，但它仍然可以为您提供模型性能的良好指标。

还有一点需要注意:这种情况下的准确性是预测中正常数据点所占百分比的度量。请记住，您假设数据集中大约有 10%的数据点是异常的，因此获得的最佳“准确性”是 90%。

运行图 [2-50](#Fig50) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig51_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig51_HTML.jpg)

图 2-51

测试数据集的最终输出精度

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig50_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig50_HTML.png)

图 2-50

做出预测并生成“准确性”分数

图 [2-51](#Fig51) 显示准确率约为 89.1%，考虑到你假设 10%的数据会被错误分类，这已经相当不错了。

这次让我们运行 x_validation 上的代码(见图 [2-52](#Fig52) )。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig53_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig53_HTML.jpg)

图 2-53

预测中被视为正常的数据点所占的百分比

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig52_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig52_HTML.png)

图 2-52

为验证集生成准确性分数

这一次的准确率甚至更高，约为 89.5%(图 [2-53](#Fig53) )。

现在来测试一下新奇的数据集。这一次，您可以找到 AUC 分数，因为异常数据和正常数据各占一半。其他两个数据集，x_test 和 x_validation，只有正常数据，但这次模型有可能对假阳性和真阴性进行分类。

运行图 [2-54](#Fig54) 中的代码。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig55_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig55_HTML.jpg)

图 2-55

根据新奇集的预测生成的 AUC 分数

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig54_HTML.png](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig54_HTML.png)

图 2-54

生成 AUC 分数的代码

图 [2-55](#Fig55) 显示分数。对于 AUC 分数来说，这已经相当不错了！

我们来看看图 [2-56](#Fig56) 中的预测分布。

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig57_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig57_HTML.jpg)

图 2-57

结果输出。1 代表正常数据点，而-1 代表异常数据点

![../images/483137_1_En_2_Chapter/483137_1_En_2_Fig56_HTML.jpg](../images/483137_1_En_2_Chapter/483137_1_En_2_Fig56_HTML.jpg)

图 2-56

用于显示图表的代码，该图表显示预测的分布

正如您在图 [2-57](#Fig57) 中看到的，该模型最终预测了比正常数据点更多的异常，但从 AUC 告诉我们的情况来看，它成功地对大多数数据条目进行了正确分类。

希望到现在为止，你已经更好地理解了什么是 OC-SVM，以及如何应用它。请记住，OC-SVM 适用于多维数据(在这种情况下，删除服务列后有 41 列)，并且当以本节中实现的方式应用时，可以用于**半监督异常检测**。

## 摘要

在这一章中，我们讨论了传统的异常检测方法，以及如何使用它们以**无监督**和**半监督**的方式实现异常检测。

在下一章，我们将关注深度学习网络的出现。
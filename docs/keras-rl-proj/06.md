

# 六、旋转机械系统的连续平衡

动态系统的自动控制(例如，电机、工业设备或生物功能，如心跳)旨在通过操纵适当数量的系统输入来修改待控制系统的行为或其输出。

神经网络在生成符合高度结构化数据标准的结果方面特别有效。然后，我们可以用神经网络来表示我们的 Q 函数，它将状态和动作作为输入，然后输出(给出)相应的 Q 值。深度强化学习方法使用深度神经网络来近似价值函数、策略和模型的强化学习组件。在本章中，我们将学习如何使用深度强化学习方法来平衡旋转机械系统。

本章将涵盖以下主题:

*   神经网络基本概念
*   Keras 神经网络模型
*   深度强化学习
*   Keras–RL 套装
*   演员-评论家方法

在本章结束时，您将了解人工神经网络的基本概念，如何将神经网络方法应用于您的数据，神经网络算法如何工作，深度神经网络用于近似强化学习组件的基本概念，如何使用 Python 和 Keras 功能实现深度 Q-网络，以及如何实现 DQN 来平衡旋转的机械系统。



# 神经网络基本概念

**人工神经网络** ( **ANN** )是模拟典型人脑活动的数学模型，如图像感知、模式识别、语言理解、感觉-运动协调等。这些模型由节点系统组成，相当于人脑的神经元，这些节点通过加权链接相互连接，相当于神经元之间的突触，如下图所示:

![](Images/b7b3836c-84e5-42a3-8a13-56b088d90be1.png)

网络的输出迭代地从链路权重变化到收敛。原始数据被提供给输入层，网络的结果从输出层返回。输入节点代表用于预测因变量(即输出神经元)的独立变量或预测变量。

串行计算机及其程序是非常强大的工具，用于执行需要重复许多明确定义的操作的任务，其中准确性、可靠性和速度是最重要的特征。这些信息处理系统非常有用，但并不智能；在整个过程中，唯一的智能要素是已经分析了任务并创建了程序的程序员。对于一个智能的人工系统来说，它至少应该能够解决人类认为简单、琐碎和自然的问题。

人工神经网络是试图在计算机系统中模拟生物神经系统功能的信息处理系统，生物神经系统由大量神经细胞或神经元组成，它们在复杂的网络中相互连接。平均而言，每个神经元都与成千上万的其他神经元相连，有数千亿个连接。智能行为来自这些相互联系的单元之间的许多相互作用。

这些单元中的一些从环境接收信息，另一些向环境发出响应，还有一些(如果存在的话)只与网络内的单元通信。这三种类型的单元分别被定义为输入单元、输出单元和隐藏单元。

下图显示了一般的神经网络体系结构:

![](Images/9ed67144-a119-49b2-9b6c-352fa65459d2.png)

每个单元执行非常简单的操作，如果接收的信号总量超过激活阈值，则激活该操作。如果一个单元被激活，它会发出一个信号，该信号通过通信信道被传输到与之相连的其它单元。每个连接点都充当一个过滤器，将接收到的消息转换为兴奋或抑制信号，同时根据其各自的特征增加或减少强度。输入-输出链接(换句话说，网络传递函数)不是编程的，而是简单地从基于经验数据的学习过程中获得的，该过程可能涉及监督、非监督或强化学习。

神经网络并行工作，因此能够同时处理大量数据，这与串行计算机相反，串行计算机中的每一条数据都是单独和连续处理的。尽管每个单独的神经元都相对较慢，但并行性在一定程度上解释了大脑在执行需要同时处理大量数据的任务时速度更快的原因，例如视觉对象识别。这本质上是一个具有良好抗噪性的复杂统计系统。

如果系统的某些单元出现故障，整个网络的性能会下降，但不太可能出现系统关闭。下图显示了**串行处理**和**并行处理**的对比:

![](Images/2353e462-6167-4c25-8f87-1c4c9360c7ba.png)

神经网络产生的模型，虽然非常高效，却无法用人类的符号语言解释；结果必须照原样接受，作为一种黑箱。

与任何建模算法一样，只有仔细选择预测变量，神经网络才是有效的。它们需要一个设置单个神经元权重的系统训练阶段，如果分析的记录和变量数量非常大，这个阶段可能需要很长时间。没有定理或模型可以让我们定义网络，所以一个网络的成功很大程度上取决于创造者的经验。

神经网络通常用于数据可能部分不正确的情况，或者没有可用的分析模型来处理问题的情况。它们的典型用途是在 OCR 软件、面部识别系统中，以及更一般地，在处理易受误差或噪声影响的数据的系统中。它们也是数据挖掘分析中最常用的工具之一。神经网络也被用作预测金融或气象分析的手段。近年来，它们在生物信息学领域的重要性显著增加，在该领域它们被用于寻找核酸和蛋白质的功能和/或结构模式。通过提供一长组输入数据，网络能够返回最可能的输出。



# Keras 神经网络模型

Keras 是一种高级神经网络 API，用 Python 编写，能够在 TensorFlow、CNTK 或 Theano 之上运行。它的开发重点是支持快速实验。使用 Keras，我们将能够在最短的时间内从想法到结果，这样您就可以花更多的时间来分析结果。

Keras 的广泛使用归功于它的极端易用性。Keras 遵循最佳实践来减少用户的工作量。它提供一致而简单的 API，最大限度地减少常见用例所需的用户操作数量，并在出现网络错误时提供清晰可行的反馈。

Keras 确保其成功的另一个特征是其模块化。模型旨在作为一系列自治且完全可配置的模块，这些模块可以以尽可能少的限制进行连接，特别是神经层、成本函数、优化器、初始化方案、激活函数和正则化方案都是独立的模块，可以组合起来创建新的模型。

Keras 也很容易扩展:新的模块很容易添加(像新的类和函数)，现有的模块提供了许多例子。轻松创建新模块的可能性允许库的广泛传播，使 Keras 适合大多数不同的任务。

最后，正如我们刚才所说，Keras 是用 Python 编写的:不需要声明格式的单独模板配置文件。这些模型是用 Python 代码描述的，Python 代码简洁、易于调试，并允许最大的可扩展性。

Keras 模型实现提供了以下步骤:

1.  准备输入并指定输入尺寸。
2.  定义模型架构并构建计算图。
3.  指定优化器并配置学习过程。
4.  指定计算模型和损失函数的输入和输出。
5.  在数据集上训练和测试模型。

现在，我们通过所需的代码来分析这个过程。最简单的模型类型是`Sequential`模型，一个线性的层堆栈。我们刚刚看到的过程中列出的步骤转化为以下几行代码:

```py
from keras.models import Sequential
model = Sequential()
```

首先，我们从`keras.models`导入了一个`Sequential`类，并且我们已经设置了将要定义的模型类型。现在，我们将堆叠这些层，如下所示:

```py
from keras.layers import Dense
model.add(Dense(units=64, activation='relu', input_dim=100))
model.add(Dense(units=10, activation='softmax'))
```

为了堆叠这些层，使用了`.add()`方法。这种方法只是将层添加到模型中。增加了两个密集层:第一个是具有 100 个输入节点、64 个输出节点和一个`'relu'`激活函数的密集层，第二个是具有 10 个输出节点和一个`'softmax'`激活函数的密集层。此时，我们可以配置模型，如下所示:

```py
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])
```

为了配置学习过程，使用了`.compile`方法。传递了以下参数:

*   `loss`:字符串(目标函数的名称)或目标函数。你可以用这个来看损失。如果模型有多个输出，您可以通过传递字典或损失列表，对每个输出使用不同的损失。模型将最小化的损失值将是所有单个损失的总和。
*   `optimizer`:字符串(优化器名称)或优化器实例。优化器是编译 Keras 模型所需的两个参数之一。您可以在将优化器传递给`model.compile()`之前实例化它，就像前面的例子一样，或者您可以通过它的名字调用它。在后一种情况下，将使用优化器的默认参数。
*   `metrics`:模型在训练和测试过程中要评估的指标列表。通常，您会使用`metrics=['accuracy']`。为多输出模型的不同输出指定不同的度量。你也可以通过字典，比如`metrics={'output_a': 'accuracy'}`。

训练模型的时间到了，如下所示:

```py
model.fit(x_train, y_train, epochs=5, batch_size=32)
```

`.fit`方法为给定数量的历元(数据集上的迭代)训练模型。传递了以下参数:

*   `x_train`:训练数据的 NumPy 数组(如果模型有单个输入)，或者 NumPy 数组的列表(如果模型有多个输入)。如果模型中的输入层是命名的，您还可以传递一个字典，用于将输入名称映射到 NumPy 数组。如果以框架原生张量为基础，`x`参数可以是`None`(默认)。

*   `y_train`:目标(标签)数据的 NumPy 数组(如果模型有单个输出)，或者 NumPy 数组列表(如果模型有多个输出)。如果模型中的输出层被命名，您还可以传递一个将输出名称映射到 NumPy 数组的字典。如果以框架原生张量为基础，`y`参数可以是`None`(默认)。
*   `epochs`:整数。这说明了训练模型的时期数。一个历元是对所提供的全部`x`和`y`数据的迭代。请注意，`epochs`与`initial_epoch`一起被理解为“最终纪元”。该模型不是针对由`epochs`给定的迭代次数来训练的，而仅仅是直到到达索引历元的历元。
*   `batch_size`:整数或者`None`。这表示每次梯度更新的样本数。如果未指定，`batch_size`将默认为`32`。

我们现在可以评估模型的性能，如下所示:

```py
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)
```

`.evaluate`方法返回测试模式下模型的损失值和度量值。最后，我们可以根据新数据生成预测，如下所示:

```py
classes = model.predict(x_test, batch_size=128)
```

`.predict`方法为输入样本生成输出预测。计算是分批进行的。以下是可用的参数:

*   `x_test`:输入数据，作为 NumPy 数组(或 NumPy 数组列表，如果模型有多个输入)。
*   `batch_size`:整数。如果未指定，则默认为`32`。
*   `verbose`:详细模式，0 或 1。
*   `steps`:宣布预测回合结束前的总步骤数(样本批次)。用默认值`None`忽略。

正如我们所看到的，使用 Keras 定义人工神经网络模型真的是轻而易举。



# 使用神经网络对乳腺癌进行分类

乳房由一组腺体和脂肪组织组成，位于皮肤和胸壁之间。事实上，它不是一个单独的腺体，而是一组称为小叶的腺体结构，连接在一起形成一个叶。一个乳房有 15 到 20 个叶。乳汁通过称为乳管的小管从小叶到达乳头。

乳腺癌如果长期得不到检测和治疗，是一种潜在的严重疾病。它是由乳腺中一些转化为恶性细胞的细胞不受控制的增殖引起的。这意味着它们有能力从产生它们的组织中脱离出来，侵入周围的组织，并最终侵入身体的其他器官。理论上，所有类型的乳腺组织都可以形成癌症，但最常见的是腺细胞或形成导管壁的细胞。

以下示例的目的是识别多个可能的乳腺癌的良性或恶性病例中的每一个。为此，我们将使用名为`BreastCancer`(来自威斯康星州乳腺癌数据库)的数据集中包含的数据。这些数据来自 UCI 机器学习数据库。当沃尔伯格医生报告他的临床病例时，随着+DNA 样本的定期到来，这个数据库不断扩大。因此，数据库反映了数据的时间分组。这种分组信息立即出现，已经从数据本身中删除。除了第一个变量之外，每个变量都被转换成 11 个原始的数值属性，值的范围从 0 到 10。

为了获得数据，我们利用了位于 http://archive.ics.uci.edu/ml[的 UCI 机器学习知识库中的大量可用数据。](http://archive.ics.uci.edu/ml)

数据框包含 11 个变量(1 个因子、9 个整数和 1 个目标类)的 699 个观测值，如下表所示:

*   `Id`:样品代码号
*   `Cl.thickness`:团块厚度
*   `Cell.size`:细胞大小的均匀性
*   `Cell.shape`:细胞形状的均匀性
*   `Marg.adhesion`:边缘粘连
*   `Epith.c.size`:单个上皮细胞大小

*   `Bare.nuclei`:裸核
*   平淡无奇的染色质
*   `Normal.nucleoli`:正常核仁
*   `Mitoses`:有丝分裂
*   `Class`:类(`0`为良性，`1`为恶性)

如前所述，本示例的目的是识别多个良性或恶性类别中的每一个。以下代码用于将病例分类为乳腺癌:

```py
import numpy
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense
numpy.random.seed(1)
dataset = numpy.loadtxt("BreastCancer.csv", delimiter=",")
X = dataset[:,1:10]
Y = dataset[:,10]
X = (X - numpy.min(X, 0)) / (numpy.max(X, 0) - numpy.min(X, 0))
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)
model = Sequential()
model.add(Dense(10, input_dim=9, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, Y_train, epochs=200, batch_size=10)
ResultEval = model.evaluate(X_test, Y_test)
print("\n%s: %.2f%%" % (model.metrics_names[1], ResultEval [1]*100))
```

我已经知道你想知道为什么代码这么少。这是因为 Keras 用尽可能少的代码做所有的事情。正如我们在迄今为止看到的所有示例中所做的那样，我们将逐行分析这段代码，以理解它的操作原理。代码的第一部分用于导入库，如下所示:

```py
import numpy
```

首先，我们导入将用于设置种子值和缩放数据的`numpy`库。然后从`sklearn.model_selection`库中导入`train_test_split()`函数，如下所示:

```py
from sklearn.model_selection import train_test_split
```

`sklearn`短语指的是 Python 编程语言的免费机器学习库。它具有各种分类、回归和聚类算法，包括支持向量机、随机森林、梯度推进、 *k* -means 和 DBSCAN，它旨在与 Python 数值和科学库 NumPy 和 SciPy 进行互操作。

然后，从 Keras 中导入模型和层，如下所示:

```py
from keras.models import Sequential
from keras.layers import Dense
```

就目前而言，我们只限于进口；当我们使用它时，我们将深化这个代码。要设置种子值，使用`numpy.random.seed()`功能，如下所示:

```py
numpy.random.seed(1)
```

`seed`函数设置随机数发生器的种子，这对于创建模拟或可再现的随机对象很有用。每当你想得到一个可重复的随机结果时，你必须使用这个函数。现在，我们必须加载数据集，如下所示:

```py
dataset = numpy.loadtxt("BreastCancer.csv", delimiter=",")
```

`numpy.loadtxt()`函数已经用于加载数据集。这个函数从文本文件中加载数据。文本文件中的每一行都必须有相同数量的值。我们的数据包含在一个名为`BreastCancer.csv`的`.csv`文件中。传递了`delimiter`参数，它指定了用于分隔值的字符串(在我们的例子中，是一个逗号)。为了向后兼容，字节字符串将被解码为“`latin1`”。默认为空白。现在，我们必须将数据集分成输入(`X`)和输出(`Y`)变量，如下所示:

```py
X = dataset[:,1:10]
Y = dataset[:,10]
```

第一个变量被省略，因为它表示没有信息添加到数据中的 ID。在使用这些数据之前，有必要澄清一下。通常，数据会包含不同范围的变量。当预测值具有不同的范围时，具有较大数值范围的特征对响应变量的影响可能大于具有较小数值范围的特征，这反过来会影响预测的准确性。我们的目标是提高预测的准确性，不允许某个特定的特征因为数值范围大而影响预测。因此，我们可能需要调整不同特性下的值，以便它们落在一个共同的范围内。通过这种统计程序，可以比较属于不同分布的相同变量，也可以比较不同的变量，或者以不同单位表示的变量。

请记住，在训练机器学习算法之前，重新调整数据是一种很好的做法。通过重新缩放，消除了数据单元，使您可以轻松比较不同位置的数据。

在这种情况下，我们将使用 *min* - *max* 方法(通常称为特征缩放)来获取范围(0，1)内的所有缩放数据。实现这一点的公式如下:

![](Images/71068ce5-3fdf-43c9-802a-127881b5aec1.png)

以下命令执行要素缩放:

```py
X = (X - numpy.min(X, 0)) / (numpy.max(X, 0) - numpy.min(X, 0))
```

`numpy.min()`和`numpy.max()`函数用于计算每个数据库列的最小值和最大值。

现在，让我们拆分训练模型和测试模型的数据。训练和测试该模型形成了在预测分析中进一步使用该模型进行预测的基础。给定一个包含 100 行数据的数据集，其中包括预测变量和响应变量，我们将数据集分成一个合适的比例(比如 80:20)，并分配 80 行用于训练，20 行用于测试。随机选择行以减少偏差。一旦训练数据可用，这些数据就会被输入到机器学习算法中，以实现大规模的通用功能。为了分割数据集，我们将使用`sklearn.model_selection.train_test_split()`函数，如下所示:

```py
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)
```

`train_test_split()`函数将数组或矩阵分成随机的`train`和`test`子集。前两个参数是`X`(预测器)和`Y`(目标)NumPy 数组。允许的输入是列表、NumPy 数组、SciPy-sparse 矩阵或 pandas 数据帧。然后，添加两个选项:

*   `test_size`:该值应介于 0.0 和 1.0 之间，代表测试分割中包含的数据集的比例
*   `random_state`:这是随机数生成器使用的种子

在适当地准备了数据之后，是时候定义我们基于神经网络的模型了。正如已经预料的那样，我们将使用 Keras liberia 来完成这项工作。Keras 中的模型被定义为一系列级别。要开始创建顺序模型，请使用以下命令:

```py
model = Sequential()
```

现在，让我们一次添加一个级别，直到我们对网络架构满意为止，如下所示:

```py
model.add(Dense(10, input_dim=9, activation='relu'))
```

要添加的第一个级别将定义输入级别—您需要确保它具有正确的输入数量。这可以在用`input_dim`参数创建第一层时指定。在我们的例子中，已经给出了第一个变量(ID ),我们将它设置为`9`,表示有九个输入变量。在设定了输入变量的数量后，有必要确定有多少神经元必须拥有这个级别，以及我们的网络必须由多少个级别组成。

在进行代码分析之前，应该先澄清一下。细心的读者可能会问，我们选择隐藏层的数量和每个隐藏层的神经元数量的原因是什么。不幸的是，没有精确的规则，甚至没有一个数学公式可以让我们确定哪些数字适合那个特定的问题。这是因为每个问题都与其他问题不同，每个网络对系统的近似程度也不同。那么，一种模式和另一种模式有什么区别呢？答案是显而易见的，也是非常清楚的——研究者的经验。

我能给出的建议，源于我在数据分析方面的丰富经验，就是尝试，尝试，再尝试。实验活动的秘密就在于此。在神经网络的情况下，这包括尝试建立不同的网络，然后验证它们的性能。

然而，有一些事情是可以说的，例如，关于我们需要的神经元数量的最佳选择，如下:

*   少量的神经元将导致系统的高错误率，因为预测因素对于少量的神经元来说可能太复杂而难以捕捉
*   大量的神经元会过度适应你的训练数据，并且不能很好地概括
*   每个隐藏层中的神经元数量应该介于输入层和输出层的大小之间，可能是平均值
*   每个隐藏层中的神经元数量不应该超过输入神经元数量的两倍，因为在这一点上您可能会严重过度拟合

在我们的例子中，我们使用了具有两个层次的全连接网络结构。在第一级中，设置 10 个神经元。让我们添加第二层，如下所示:

```py
model.add(Dense(1, activation='sigmoid'))
```

这一层定义输出，用 1 个神经元来预测类。在继续之前，让我们讨论一下选择的`activation`函数。我们在第一层使用了整流器(`'relu'`)激活功能，在输出层使用了`'sigmoid'`功能。我们在输出层使用了一个`'sigmoid'`来确保我们的网络输出在 0 和 1 之间。现在，我们将编译该模型，如下所示:

```py
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
```

`.compile`方法已用于配置学习过程。传递了以下参数:

*   `loss`:通过使用`binary_crossentropy`，我们使用了对数损失，对于二元分类问题，在 Keras 中定义为`'binary_crossentropy'`。
*   `optimizer`:已经使用了`'adam'`优化器，这是在遵循原始文件中提供的参数时使用的默认参数。
*   `metrics`:通过使用`'accuracy'`，我们已经收集并报告了分类准确度作为度量，因为这是一个分类问题。

使用以下命令执行模型拟合:

```py
model.fit(X_train, Y_train, epochs=200, batch_size=10)
```

`.fit`方法为给定数量的历元(数据集上的迭代)训练模型。传递了以下参数:

*   `x_train`:对初始数据集进行拆分操作返回的训练数据的 NumPy 数组
*   `y_train`:对初始数据集进行拆分操作返回的目标数据的 NumPy 数组
*   `epochs`:在这种情况下，`200`，训练模型的时期数
*   `batch_size`:在这种情况下，`10`，每次梯度更新的样本数

最后，我们要做的就是在我们为测试阶段留出的数据集上评估网络性能。这将让我们了解我们对数据集的建模有多好，以及模型能够概括多少。`.evaluate`方法已用于评估模型，如下所示:

```py
ResultEval = model.evaluate(X_test, Y_test)
print("\n%s: %.2f%%" % (model.metrics_names[1], ResultEval [1]*100))
```

`.evaluate`方法返回测试模式下模型的损失和度量值。度量是在编译模型时设置的。我们将分类准确度设置为度量，因为这是一个分类问题。将返回以下结果:

```py
acc: 96.43%
```

结果真的很好；`96.43%`的准确度告诉我们，该模型能够在`96.43%`个病例中识别乳腺癌。事实上，分类器的准确度被定义为相对于分类样本总数的正确分类样本数。



# 深度强化学习

在前面几章的例子中，价值函数的估计是用一个表格作出的，其中每个方框代表一个状态或一个状态-动作对。使用表来表示价值函数允许创建简单的算法，并且如果环境条件是马尔可夫的，则允许精确地估计价值函数，因为它将在策略迭代期间学习到的预期回报分配给来自环境的每个可能的配置。然而，该表的使用也导致了局限性；事实上，这些方法仅适用于状态和操作数量减少的环境。问题不仅限于存储该表所需的大量内存，还包括精确估计每个状态-动作对所需的大量数据和时间。换句话说，主要问题是泛化。

为了解决这个问题，我们可以采用一种基于强化学习方法和函数逼近方法相结合的方法。下图显示了深度 Q 学习方案:

![](Images/9886af12-0242-4ad9-b4cb-6f16c04032e7.png)

术语深度 Q 学习是指采用神经网络作为函数逼近的强化学习方法。因此，它代表了基本 Q 学习方法的发展，因为状态-动作表被神经网络取代，目的是逼近最优值函数。

与前面章节中看到的方法相比，深度 Q-learning 用于构建网络以请求输入和动作，并提供其预期回报，深度 Q-learning 彻底改变了结构，以便仅请求输入环境中的状态，并提供与环境中可以执行的动作一样多的状态-动作值。



# Keras–RL 套装

在前面的章节中，我们学习了如何用 Keras 制作一个简单的神经网络。但是，我们的目标是在 Keras 环境中开发基于强化学习的算法。为此，可以使用的有效工具是`keras-rl`包。这个包用 Python 实现了一些深度强化学习算法，并与 Keras 的深度学习库无缝集成。

此外，`keras-rl`立即与 OpenAI 健身房合作。OpenAI Gym 是一个帮助你实现基于强化学习的算法的库。它包括越来越多的基准问题，这些问题揭示了一个公共接口和一个网站，人们可以在那里分享他们的结果并比较算法性能。这个库将在下一章中充分讨论——现在，我们将仅限于使用它。

这些特权并不限制`keras-rl`包的使用，因为`keras-rl`的使用可以很容易地适应我们的需求。您可以使用内置的 Keras 回调和指标，或者定义其他指标。因此，通过扩展一些简单的抽象类，很容易实现自己的环境甚至算法。

目前，已经实现了以下算法:

*   **深度 Q 学习** ( **DQN** )
*   双 dql
*   **深度确定性政策梯度** ( **DDPG** )
*   **连续 DQN** ( **CDQN** 或 **NAF** )
*   **交叉熵方法** ( **CEM** )
*   **决斗网 DQN** ( **决斗 DQN** )
*   深沙司
*   **异步优势演员——评论家** ( **A3C** )
*   **近似策略优化算法** ( **PPO** )

卡尔斯鲁厄理工学院(位于德国卡尔斯鲁厄)的科学家 Matthias Plappert 已经实现了这个包，他致力于机器学习，特别是机器人技术中的深度强化学习。

你可以在 https://github.com/matthiasplappert 的 GitHub 版块了解更多信息。

安装`keras-rl`很容易。只需运行以下命令，您就可以开始了:

```py
pip install keras-rl
```

这将安装`keras-rl`和所有必要的依赖项。在接下来的部分，我们将分析一个使用`keras-rl`的持续深度 Q 学习的例子。



# 具有深度强化学习的连续控制

在这个例子中，我们将解决倒立摆向上摆动的问题——这是控制理论中的一个经典问题。在这个版本的问题中，钟摆从一个随机的位置开始，目标是把它摆起来，使它保持直立。扭矩限制防止代理直接摆动钟摆。下图显示了该问题:

![](Images/ac65c4c4-b6ac-4312-9cbe-86f5d6051929.png)

在`keras-rl`图书馆(`DDPGAgent`)的 DDPG 代理的帮助下，使用 OpenAI 体育馆图书馆(`Pendulum-v0`)中可用的环境解决了这个问题。

OpenAI Gym 是一个帮助我们实现基于强化学习的算法的库。它包括越来越多的基准问题，这些问题揭示了一个公共接口和一个网站，人们可以在那里分享他们的结果并比较算法性能。目前，我们将模仿 OpenAI 健身房库的使用；对于更多的细节，我们将深化我们即将在[第 7 章](fcec1d5f-4ab5-4f86-bae8-56cfdee94ec6.xhtml)、*中看到的概念，Segway 作为倒立摆系统的动态建模*。`Pendulum-v0`环境非常类似于`CartPole`环境(我们将在下一章中使用)，但是有一个本质的区别——我们正在从离散环境(`CartPole`)扩展到连续环境(`Pendulum-v0`)。

DDPG 代理基于深度 Q 学习对连续动作领域的适应。这是一个演员-评论家算法，缺乏模型，基于一个确定性的政策梯度，可以在连续的行动空间上操作。使用相同的学习算法、网络架构和超参数，该算法有效地解决了几个模拟的物理活动，包括经典问题，例如倒立摆问题。

行动者-批评者方法实现了一个通用的策略迭代，在策略评估和策略改进步骤之间交替进行。有两个密切相关的行动者改进过程，旨在改进当前政策和批评家评估，评估当前政策。如果通过自举方法对批评家建模，则它减少了方差，使得学习比纯策略梯度方法更稳定。

下面详细分析一下代码。和往常一样，我们将从导入计算所需的库开始，如下所示:

```py
import numpy as np
import gym
```

如下面的代码所示，首先我们导入`numpy`库，它将用于设置种子值。然后，我们导入`gym`库，这将帮助我们定义环境。完成这些后，我们导入`keras`库的一些函数来构建一个神经网络模型:

```py
from keras.models import Sequential, Model
from keras.layers import Dense, Activation, Flatten, Input, Concatenate
from keras.optimizers import Adam
```

首先导入`Sequential`模型，`Sequential`模型是层的线性堆叠。然后，导入一些`keras`图层— `Dense`、`Activation`、`Flatten`、`Input`和`Concatenate`。`Dense`模型是一个全连接的神经网络层。`Activation`层将激活功能应用于输出。`Flatten`层使输入变平——这不会影响批处理大小。`Input`层用于实例化一个 Keras 张量。Keras 张量是来自底层后端(Theano、TensorFlow 或 CNTK)的张量对象，我们用某些属性对其进行了扩充，使我们只需知道模型的输入和输出就可以构建 Keras 模型。最后，`Concatenate`层连接一个输入列表。它将一列张量作为输入，这些张量除了连接轴之外都是相同的形状，并返回一个张量，即所有输入的连接。

让我们导入`keras-rl`库，如下所示:

```py
from rl.agents import DDPGAgent
from rl.memory import SequentialMemory
from rl.random import OrnsteinUhlenbeckProcess
```

`DDPGAgent`、存储器和随机模型被导入。现在，我们将定义环境，如下所示:

```py
ENV_NAME = 'Pendulum-v0'
gym.undo_logger_setup()
```

这样，我们就设置了环境的名称。然后，调用`gym.undo_logger_setup()`来撤销 Gym 的日志设置并手动配置。大多数情况下，默认设置应该没问题。让我们来看看环境，如下所示:

```py
env = gym.make(ENV_NAME)
```

NumPy `random.seed()`函数用于设置种子值，如下所示:

```py
np.random.seed(123)
```

`seed`函数设置随机数发生器的种子，这对于创建模拟或可再现的随机对象很有用。每当你想得到一个可重复的随机结果时，你必须使用这个函数。还必须为环境设置`seed`功能，如下所示:

```py
env.seed(123)
```

现在，我们将提取代理可用的操作，如下所示:

```py
assert len(env.action_space.shape) == 1
nb_actions = env.action_space.shape[0]
```

当遇到一个`assert`语句时，Python 会对伴随的表达式求值，希望是`true`。如果表达式是`false`，Python 会引发一个`AssertionError`异常。`nb_actions`变量现在包含了所选环境中所有可用的动作。`gym`不会一直告诉你这些动作是什么意思，只会告诉你哪些是可用的。现在，我们将使用 Keras 库构建一个简单的神经网络模型，从`actor`模型定义开始，如以下代码所示:

```py
actor = Sequential()
actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))
actor.add(Dense(16))
actor.add(Activation('relu'))
actor.add(Dense(16))
actor.add(Activation('relu'))
actor.add(Dense(16))
actor.add(Activation('relu'))
actor.add(Dense(nb_actions))
actor.add(Activation('linear'))
print(actor.summary())
```

在给定环境当前状态的情况下，`actor`模型决定了要采取的最佳行动。在这一阶段，只处理数字数据，因此网络中不会有比我们目前使用的密集/全连接层更复杂的层。由此可见，`actor`模型是一系列完全连接的层，它们从环境观察映射到环境空间中的一个点。现在，让我们转到评论家网络，如下:

```py
action_input = Input(shape=(nb_actions,), name='action_input')
observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')
flattened_observation = Flatten()(observation_input)
x = Concatenate()([action_input, flattened_observation])
x = Dense(32)(x)x = Activation('relu')(x)
x = Dense(32)(x)
x = Activation('relu')(x)
x = Dense(32)(x)
x = Activation('relu')(x)
x = Dense(1)(x)
x = Activation('linear')(x)
critic = Model(inputs=[action_input, observation_input], outputs=x)
print(critic.summary())
```

在这种情况下，我们基本上面临着相反的问题。也就是说，网络定义稍微复杂一些，但是它的训练相对简单。批评家网络旨在将环境状态和行动作为输入，并计算相应的估价。既然神经网络模型已经准备好使用，让我们配置和编译我们的代理。使用 DQN 的一个问题是，算法中使用的神经网络往往会忘记以前的经验，因为它会用新的经验覆盖它们。所以，我们需要一个以前的经验和观察的列表，用以前的经验来改造模型。为此，定义了一个包含先前经验的`memory`变量，如下所示:

```py
memory = SequentialMemory(limit=100000, window_length=1)
```

现在，我们将定义一个`random_process`，如下所示:

```py
random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.15, mu=0., sigma=.3)
```

所以现在，我们只需定义`agent`，如下所示:

```py
agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input, memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100, random_process=random_process, gamma=.99, target_model_update=1e-3)
```

让我们使用下面的代码来编译这个模型:

```py
agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])
```

这个命令编译一个`agent`和用于训练和测试的底层模型。现在`agent`已经准备好了，我们可以训练它，如下所示:

```py
agent.fit(env, nb_steps=50000, visualize=True, verbose=1, nb_max_episode_steps=200)
```

`fit()`函数在给定的环境下训练`agent`。在训练结束时，我们必须保存获得的权重，如下所示:

```py
agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)
```

保存网络或整个结构的重量发生在 HDF5 文件中，这是一种高效灵活的存储系统，支持复杂的多维数据集。最后，我们将评估我们针对`10`集的算法，如下所示:

```py
agent.test(env, nb_episodes=10, visualize=True, nb_max_episode_steps=200)
```

从模拟中，我们可以验证我们的代理能够以良好的近似值平衡系统。



# 摘要

在本章中，我们学习了人工神经网络的基本概念。我们还学习了如何将神经网络方法应用于我们的数据，以及神经网络算法如何工作。我们了解了深度神经网络用来近似强化学习组件的基本概念。

然后，我们查看了 Keras 神经网络模型的基础知识，以及 Keras 神经网络模型的实际示例。然后，我们继续探索深度 Q 学习的概念。术语“深度 Q 学习”是指采用神经网络作为函数逼近的强化学习方法。因此，它代表了基本 Q 学习方法的发展，因为状态-动作表被神经网络取代，目的是逼近最优值函数。这个网络把当前状态作为输入，把每个动作的相应 Q 值作为输出。

然后，我们介绍了`keras-rl`包，它用 Python 实现了一些深度强化学习算法，并与 Keras 的深度学习库无缝集成。最后，我们看了一个使用 Keras 和`keras-rl`的深度强化学习算法的实例。
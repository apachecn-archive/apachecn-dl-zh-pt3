        

# 一、神经网络概述

向你问候，同胞众生；欢迎来到我们激动人心的旅程。旅程本身是为了理解一个难以捉摸的强大计算范式背后的概念和内部工作方式:人工神经网络 ( **安**)。虽然这一概念已经存在了将近半个世纪，但被认为是其诞生的想法(如*什么是智能体*，或者*智能体如何从其周围环境中学习*)可以追溯到亚里士多德时代，甚至可能追溯到文明本身的黎明。不幸的是，亚里士多德时代的人们没有幸运地拥有无处不在的大数据，或者图形处理单元的速度——加速和大规模并行计算，这在今天为我们开辟了一些非常有前途的途径。我们现在生活在一个时代，在这个时代，我们大多数物种都可以获得组装人工智能系统所需的积木和工具。虽然涵盖今天将我们带到这里的整个发展时间表略微超出了本书的范围，但我们将尝试简要总结一些关键的概念和想法，这将有助于我们直观地思考我们的问题。

在本章中，我们将讨论以下主题:

*   定义我们的目标
*   了解我们的工具
*   理解神经网络
*   观察大脑
*   信息建模和功能表示
*   数据科学中的一些基本刷新器

        

# 定义我们的目标

本质上，我们在这里的任务是构思一种机制，它能够处理任何引入的数据。在这样做的时候，我们希望这种机制能够检测数据中存在的任何潜在模式，以便利用它为我们自己谋福利。成功完成这一任务意味着我们将能够将任何形式的原始数据转化为知识，转化为可操作的商业见解、减轻负担的服务或拯救生命的药物。因此，我们实际上想要的是构建一种机制，它能够通用地逼近任何可能的函数，这些函数可以表示我们的数据；知识的灵丹妙药，如果你愿意的话。请退后一步，想象一下这样一个世界；一个最致命的疾病可以在几分钟内治愈的世界。一个所有人都有饭吃的世界，所有人都可以选择在任何领域追求人类成就的顶峰，而不用担心受到迫害、骚扰或贫困。承诺太多了？也许吧。实现这个乌托邦需要的不仅仅是设计高效的计算机系统。这需要我们同时进化我们的道德观，重新考虑我们作为个体、作为一个物种和作为一个整体在这个星球上的位置。但是你会惊讶于计算机对我们的帮助有多大。

重要的是要明白，我们谈论的不是任何一种计算机系统。这与我们的计算前辈，如巴贝奇和图灵，所处理的东西非常不同。这不是一个简单的图灵机或差异引擎(尽管我们将在旅程中回顾的许多概念，如果不是全部的话，都与那些开明的思想和他们的发明直接相关)。因此，我们的目标将是涵盖关键的学术贡献，实践实验，以及从几个世纪，如果不是几十年的科学研究中得出的关于产生智能的基本概念的实施见解；这个概念可以说是我们人类与生俱来的，但却很少被理解。

        

# 了解我们的工具

我们将主要与现有的两个最受欢迎的深度学习框架合作，并免费提供给公众。这并不意味着我们将把我们的实现和练习完全限制在这两个平台上。我们很可能会尝试其他著名的深度学习框架和后端。然而，我们将尝试使用 TensorFlow 或 Keras，因为它们广受欢迎，支持社区庞大，并且在与其他著名的后端和前端框架(分别如 Theano、Caffe 或 Node.js)接口时非常灵活。我们现在将提供一些关于 Keras 和 TensorFlow 的背景信息:

![](Images/815fa0e1-067d-4b25-a6c6-e698f9b3f879.png)

        

# Keras

由于其用户友好性、模块化和可扩展性，许多人将 Keras 命名为深度学习的通用语言。Keras 是一个用于神经网络的高级应用编程接口，专注于实现快速实验。它是用 Python 编写的，能够在 TensorFlow 或 Keras 等后端上运行。Keras 最初是作为 ONEIROS(开放式神经电子智能机器人操作系统)项目研究工作的一部分开发的。它的名字参考了希腊语单词![](Images/5cd7fa77-066f-42ed-aa01-4a3a6e07fdd5.png)，字面意思是*号角*。这个词避开了可追溯到古希腊文学的文字游戏，指的是阿玛耳忒亚之角(也被称为**聚宝盆**)，一个永恒的富足象征。

Keras 的一些功能包括:

*   简单快速的原型制作
*   支持多种最新神经网络架构的实施，以及预训练模型和练习数据集
*   在 CPU 和 GPU 上完美执行

        

# TensorFlow

TensorFlow 是一个用于高性能数值计算的开源软件库，使用一种称为**张量**的数据表示。它允许像你我这样的人实现一种叫做**数据流图**的东西。数据流图本质上是一种描述数据如何通过网络或一系列处理神经元移动的结构。网络中的每一个神经元都代表一个数学运算，神经元之间的每一个连接(或*边*)都是一个多维数据数组，或*张量*。通过这种方式，TensorFlow 提供了一种灵活的 API，允许跨各种平台(如 CPU、GPU 及其自己的**张量处理单元** ( **TPUs** ))轻松部署计算，从桌面到服务器集群，再到移动和边缘设备。它最初由谷歌大脑团队的研究人员和工程师开发，提供了一个支持神经网络设计和深度学习的优秀编程接口。

        

# 神经学习的基础

我们从试图获得对学习概念的基本理解开始我们的旅程。此外，我们真正感兴趣的是，像学习这样丰富而复杂的现象是如何在许多人称之为人类已知的最先进的计算机上实现的。正如我们将观察到的，科学家似乎不断从我们自己的生物神经网络的内部工作中找到灵感。如果大自然确实已经找到了一种方法来利用来自外部世界的松散连接的信号，并将它们拼凑成一个连续的响应和适应意识流(大多数人都会同意这一点)，我们确实想知道它可能使用了什么技巧和方法来做到这一点。然而，在我们继续讨论这些话题之前，我们必须建立一个基线来理解为什么神经网络的概念与大多数现代的**机器学习** ( **ML** )技术有很大的不同。

        

# 什么是神经网络？

迄今为止，很难将神经网络与任何其他现有的解决问题的算法风格相提并论。例如，线性回归简单地处理从标绘的观察点计算关于误差平方平均值的最佳拟合线。类似地，质心聚类只是通过迭代计算相似点之间的理想距离来递归地分离数据，直到它达到渐近配置。

另一方面，神经网络不是那么容易解释的，原因有很多。看待这个问题的一种方式是，神经网络是一种算法，它本身由不同的算法组成，在数据通过它传播时执行较小的局部计算。当然，这里给出的神经网络的定义是不完整的。随着我们对更复杂的概念和神经网络架构的研究，我们将在整本书中反复改进它。然而，现在，我们可以从一个外行的定义开始:神经网络是一种自动学习输入(如图像)和感兴趣的输出(即图像是狗、猫还是攻击直升机)之间联系的机制。

所以，现在我们对什么是神经网络有了一个初步的想法——一种接受输入并学习关联以预测一些输出的机制。当然，这种多用途的机制不仅限于接收图像。事实上，这种网络同样能够接受输入，如一些文本或录音，并分别猜测它是在看莎士比亚的*哈姆雷特*，还是在听*比莉·吉恩*。但是，这样一种机制如何补偿数据在形式和大小上的多样性，同时仍然产生相关的结果呢？为了理解这一点，许多学者发现研究自然如何解决这个问题是有用的。事实上，通过基因突变和环境条件，在我们的星球上发生的数百万年的进化产生了非常相似的东西。更好的是，大自然甚至给我们每个人都配备了一种通用函数逼近器，就在我们的两耳之间！当然，我们说的是人脑。

        

# 观察大脑

在我们简短地探究这个臭名昭著的比较之前，我们有必要在这里澄清一下，这确实只是一个比较，而不是一个比较。我们并不主张神经网络完全按照我们大脑的方式工作，因为这不仅会激怒相当多的神经科学家，而且对哺乳动物大脑解剖所代表的工程奇迹也不公平。然而，这种比较有助于我们更好地理解工作流程，通过它我们可以设计出能够从数据中提取相关模式的系统。人类大脑的多功能性，无论是在制作音乐管弦乐队，艺术杰作，还是大型 Hydron 对撞机等先驱科学机器方面，都表明了相同的架构如何能够学习和应用高度复杂和专业的知识来完成伟大的壮举。事实证明，大自然是一块非常聪明的饼干，因此我们可以通过观察它是如何作为学习代理来实现如此新颖的东西，从而学到很多有价值的经验。

        

# 构建一个生物大脑

夸克组成原子，原子组成分子，分子组合在一起，偶尔会组成化学上可兴奋的生物力学单元。我们称这些单元为**细胞**；所有生物生命形式的基本组成部分。现在，细胞本身种类繁多，但我们对其中的一种特别感兴趣。这是一类特殊的细胞，被称为**神经细胞**，或**神经元**。为什么？事实证明，如果你取出大约 10 个神经元并把它们设置成特定的互补结构，你会得到一个能够发现火、农业和太空旅行的器官。然而，要了解这些神经元束是如何学习的，我们必须先了解单个神经元是如何工作的。正如你将看到的，正是我们大脑中由这些完全相同的神经元组成的重复结构，产生了我们(夸张地)称之为智能的更宏大的现象。

        

# 神经元的生理学

神经元是一种简单的电可兴奋细胞，通过电信号和化学信号接收、处理和传输信息。树突从神经元胞体延伸出来，接收来自其他神经元的信息。当我们说神经元*接收*或*发送*信息时，我们实际上指的是它们沿着轴突传递电脉冲。最后，神经元是*可兴奋的*。换句话说，提供给神经元的正确脉冲将产生电事件，称为**动作电位**。当一个神经元达到其动作电位(或*尖峰*)时，它会释放一种神经递质，这是一种化学物质，在到达其他神经元之前，它会穿过突触一小段距离。每当一个神经元出现尖峰信号时，数百个突触就会释放出神经递质，到达其他神经元的树突，这些神经元本身可能会也可能不会出现尖峰信号，这取决于脉冲的性质。正是这种行为方式让这些巨大的神经元网络能够进行交流、计算和合作，以解决我们人类每天面临的复杂任务:

![](Images/85e7d29f-354c-41af-8351-083135d85a75.png)

因此，一个神经元真正做的只是接受一些电输入，进行某种处理，然后如果结果是肯定的，就*激发*，或者如果处理的结果是否定的，就保持不活动。我们这里所说的结果是否是*积极的*是什么意思？为了理解这一点，有一点关于信息和知识在我们大脑中是如何表达的插入语是很有用的。

        

# 代表信息

考虑一个任务，你必须正确分类狗、猫和攻击直升机的图像。思考神经元学习系统的一种方式是，我们用几个神经元来代表存在于三个相应类别中的各种特征。换句话说，假设我们在这里为我们的分类任务使用了三个专家神经元。这些神经元中的每一个都是狗、猫和攻击直升机的专家。

他们怎么是专家？好吧，现在，我们可以认为我们的每个领域专家神经元都由他们自己的雇员内阁和支持人员支持，所有人都勤奋地为这些专家工作，分别收集和代表不同品种的狗、猫和攻击直升机。但是我们暂时不和他们的后勤人员打交道。目前，我们只是将任何图像呈现给我们的三个领域专家。如果图片是一只狗，我们的*狗专家*神经元立即识别出这个生物并开火，几乎就像它在说，*你好，我相信这是一只狗。相信我，我是专家*。同样，当我们向三位专家展示一张猫的照片时，我们的猫神经元会向我们发出信号，表明它们通过放电检测到了我们图像中的一只猫。虽然这并不完全是每个神经元如何代表真实世界的物体，如猫和狗，但它有助于我们获得对基于神经元的学习系统的功能性理解。希望你现在有足够的信息来介绍生物神经元的不太复杂的兄弟，人工神经元。

        

# 神经编码的奥秘

事实上，许多神经科学家认为，这种统一代表性神经元的想法，如我们的*猫专家*神经元，并不真正存在于我们的大脑中。他们指出，这种机制将需要我们的大脑拥有数千个神经元，专门用于我们熟悉的特定面孔，如我们的祖母、街角的面包师或唐纳德·特朗普。相反，他们假设了一个更加分布式的表示体系结构。这种分布式理论认为，一个特定的刺激，如一只猫的图片，由(并将触发)一种独特的放电神经元模式来表示，这种模式广泛分布在大脑中。换句话说，一只猫可能会被 100 个不同的神经元代表，每个神经元都致力于从图像中识别特定的类似猫的特征(如耳朵、尾巴、眼睛和一般的身体形状)。这里的直觉是，这些猫神经元中的一些可能会与其他神经元重组，以代表其他图像，这些图像中有*猫*的元素。例如，一只美洲虎或卡通猫*加菲猫*的图片，可以使用完全相同的猫神经元的子集，结合一些其他神经元来重建，这些神经元已经学习了更特定于美洲虎大小的属性，或者加菲猫著名的橙色和黑色条纹。

        

# 分布式表示和学习

在一些奇怪的医学案例中，头部受到身体创伤的患者在面对他们的亲人时，不仅没有与他们联系，甚至声称这些非常爱的人是骗子，只是伪装成他们的亲人！虽然这是一个奇怪的现象，但这种情况可能会给神经学习的确切机制带来更多的启示。很明显，患者认出了这个人，因为一些编码与他们所爱的人的特征(如脸和衣服)相对应的视觉模式的神经元被激活了。然而，由于他们有趣地报告了这种与这些相同的所爱的人的分离，尽管能够认出他们，这一定意味着所有通常在遇到这个所爱的人时会激活的神经元(包括编码我们的患者可能对此人的情感表达的神经元)在我们的患者遇到他们重要的熟人时没有激活。

这些类型的分布式表示可能会让我们的大脑在从非常少的数据中推断模式时具有多样性，正如我们观察自己能够做到的那样。例如，现代神经网络仍然需要你向它提供数百(如果不是数千)张图像，才能可靠地预测它是在看公交车还是烤面包机。另一方面，我三岁的侄女能够用大约三到五张公共汽车和烤面包机的图片来比较这种准确性。更令人着迷的是，在你的计算机上运行的神经网络有时会耗费数十亿瓦的能量来进行计算。我侄女只需要 12 瓦。她会从一些饼干中得到她需要的东西，或者她小心翼翼地从厨房偷偷拿走的一小块蛋糕。

        

# 数据科学的基础

让我们熟悉一些数据科学的基本术语和概念。我们将进入一些理论，然后继续理解一些复杂的术语，如熵和维度。

        

# 信息论

在深入探讨各种网络架构和一些实际操作示例之前，如果我们不详细阐述一下通过处理真实信号来获取信息这一关键概念，那将是很遗憾的。我们谈到量化信号中存在的信息量的科学，也称为信息论。虽然我们不希望在这个概念上提供深刻的数学概述，但从概率的角度了解一些学习的背景是有用的。

直觉上，得知一个不可能的事件已经发生比得知一个预期的事件已经发生更能提供信息。如果我告诉你，今天你可以在所有超市买到食物，我不会感到惊讶。为什么？嗯，我还没有真正告诉你一些超出你预期的事情。相反，如果我告诉你，你*今天不能*在所有超市购买食物，也许是因为一些总罢工，那么你会感到惊讶。您可能会感到惊讶，因为出现了一条不太可能的信息(在我们的例子中，这是单词*而不是*，出现在之前出现的配置中)。在信息论领域，这种直觉知识是我们试图编纂的。其他类似的概念包括:

*   发生可能性较低的事件应该具有较低的信息含量
*   发生可能性较高的事件应该具有较高的信息含量
*   保证发生的事件应该没有信息内容
*   具有独立发生可能性的事件应该具有附加信息内容

在数学上，我们实际上可以通过使用模拟事件自身信息的简单方程( *x* )来满足所有这些条件，如下所示:

![](Images/2e12687f-e26e-4842-8aab-7f75ea9f170b.png)

*l(x)* 用 *nat* 单位表示，量化观察一个概率事件所获得的信息量， *1/e* 。尽管前面的等式很好也很简洁，但它只允许我们处理单一的结果；这对于模拟真实世界的复杂依赖性没有太大的帮助。如果我们想量化事件的整个概率分布中的不确定性，会怎么样呢？然后，我们采用另一种度量，称为**香农熵**，如下面的等式 *:* 所示

![](Images/55ae7519-72f3-46cb-b253-dfcb9de84553.png)

        

# 熵

假设你是一名被困在敌后的士兵。你的目标是让你的盟友知道什么样的敌人正向他们走来。有时，敌人可能会派出坦克，但更多的时候，他们会派出巡逻队。现在，你能给你的朋友发信号的唯一方法是使用简单的二进制信号的无线电。你需要想出和盟友沟通的最佳方式，这样才不会浪费你宝贵的时间，被敌人发现。你是怎么做到的？首先，你绘制出许多二进制位序列，每个特定的序列对应一种特定类型的敌人(比如巡逻队或坦克)。稍微了解一下环境，就已经知道巡逻比坦克频繁多了。很明显，你可能会更多地使用二进制信号给*巡逻队*而不是*坦克*。因此，您将分配更少的二进制位来传达巡逻队的到来，因为您知道您将比其他人更频繁地发送该信号。你所做的是利用你对敌人类型分布的了解来减少你平均需要发送的比特数。事实上，如果你可以访问来袭巡逻队和坦克的总体分布，那么理论上你可以用最少的比特数最有效地与另一边的友军沟通。我们通过在每次传输中使用最佳比特数来做到这一点。代表信号的位数称为该数据的熵，可以用以下公式表示:

![](Images/6e57d53f-400b-4a7f-a19f-98a98b9d752a.png)

这里， *H(y)* 表示用概率分布 *y* 表示事件的最佳比特数的函数。 *y [i]*

*巡位* = *日志* ( *1* / *256pTank* )

=*log*(*1*/*ptank*)+*log*(*1*/(*2*^*8*))

= *坦克钻头* - *8*

        

# 交叉熵

交叉熵是另一个数学概念，它允许我们比较两个不同的概率分布，分别用 *p* 和 *q* 表示。事实上，正如您将在后面看到的，当处理分类特征时，我们经常在神经网络中使用基于熵的损失函数。本质上，在相同的基础事件集上，两个概率分布(【https://en.wikipedia.org/wiki/Probability_distribution】)、 *(p，q)* )之间的交叉熵测量在一个条件下，识别从一个集合中随机选取的事件所需的信息的平均数量；条件是所使用的编码方案对于预测的概率分布是优化的，而不是真正的*分布。我们将在后面的章节中重新审视这一概念，以澄清和实现我们的理解:*

![](Images/eb12840f-51f3-43cb-90f4-d093bb7a94f0.png)

        

# 数据处理的本质

之前，我们讨论了神经元如何利用化学反应电传播信息并与其他神经元通信。这些相同的神经元帮助我们确定一只猫或一只狗的样子。但是这些神经元从来没有真正看到猫的全貌。他们处理的只是化学和电脉冲。这些神经元网络能够执行它们的任务，只是因为其他感觉预处理器官，如我们的眼睛和视神经，已经以适当的格式准备了数据，供我们的神经元能够解释。我们的眼睛接收代表猫形象的电磁辐射(或光),并将其转化为通过电脉冲传递的有效表现形式。因此，人工神经元和生物神经元之间的主要区别与它们相互交流的媒介有关。正如我们所见，生物神经元使用化学物质和电脉冲作为交流的手段。类似地，人工神经元依靠数学的通用语言来表示来自数据的模式。事实上，为了知识提取的目的，围绕着用数学方法表示现实世界的现象的概念，存在着一个完整的学科。这个学科，正如你们许多人所熟悉的，被称为**数据科学**。

        

# 从数据科学到 ML

拿起任何一本关于数据科学的书；你很有可能会遇到一个详细的解释，涉及统计和计算机科学等领域的交叉，以及一些领域知识。当你快速翻阅页面时，你会注意到一些漂亮的视觉效果、图表、条形图——这些都是作品。将向您介绍统计模型、显著性测试、数据结构和算法，每一个都为一些演示用例提供了令人印象深刻的结果。这不是数据科学。这些确实是您作为一名成功的数据科学家将要使用的工具。然而，数据科学的本质可以用一种更简单的方式来概括:*数据科学是处理从原始数据中生成可操作知识的科学领域。这是通过反复观察现实世界的问题，量化不同维度或特征的整体现象，并预测未来的结果来实现预期目标。ML 只是教授机器数据科学的学科*。

虽然一些计算机科学家可能欣赏这种递归定义，但你们中的一些人可能会思考*量化一种现象意味着什么。*嗯，你看，现实世界中的大多数观察，无论是你吃的食物量，你看的节目种类，还是你喜欢的衣服颜色，都可以被定义为一些其他准依赖特征的(近似)函数。例如，你在某一天吃的食物量可以定义为其他因素的函数，如你前一餐吃了多少，你对某种食物的一般偏好，甚至你的体力消耗。

类似地，你喜欢看的节目类型可以通过你的个性特征、兴趣和你的时间表中的空闲时间来估算。简而言之，我们致力于量化和表示观察结果之间的差异(例如，人与人之间的观看习惯)，以推导出机器可以使用的功能预测规则。

我们通过将我们试图预测的可能结果(即，给定的人是喜欢喜剧还是恐怖片)定义为输入特征(即，此人在五大人格测试中的排名)的函数来归纳这些规则，这些输入特征是我们在观察普遍现象时收集的(例如，个性和人群的观看习惯):

![](Images/ca603c1f-d4a1-4da7-84fd-4be4ef2dfce5.png)

如果您选择了正确的特征集，您将能够导出一个能够可靠地预测您感兴趣的输出类的函数(在我们的例子中，这是查看者偏好)。我说的正确特征是什么意思？嗯，按理说，观看习惯和一个人的性格特征比旅行习惯更有关系。预测一个人是否倾向于恐怖电影，比如说，根据他们眼睛的颜色和实时 GPS 坐标，是没有用的，因为它们对我们试图预测的东西没有帮助。因此，我们总是选择相关的特征(通过领域知识或显著性测试)来简化地表示现实世界的现象。然后，我们简单地使用这个表示来预测我们感兴趣的未来结果。这种表示本身就是我们所说的预测模型。

        

# 在高维空间中建模数据

如您所见，我们可以通过将现实世界的观察结果重新定义为不同特征的函数来表示它们。例如，一个物体的速度是它在给定时间内行进距离的函数。同样，电视屏幕上像素的颜色实际上是组成该像素的红、绿、蓝亮度值的函数。这些元素就是数据科学家所说的数据的特征或维度。当我们有标注的维度时，我们处理的是监督学习任务，因为我们可以检查我们的模型相对于真实情况的学习。当我们有未标记的维度时，我们计算我们的观察点之间的距离，以在我们的数据中找到相似的组。这就是所谓的**无监督 ML** 。因此，以这种方式，我们可以开始建立一个现实世界现象的模型，通过简单地使用信息特征来表示它。

        

# 维度的诅咒

随之而来的自然问题是:我们究竟如何建立一个模型？长话短说，我们在观察结果时选择收集的特征都可以绘制在高维空间上。虽然这听起来可能很复杂，但它只是笛卡尔坐标系统的延伸，你可能从高中数学中熟悉它。让我们回忆一下如何用笛卡尔坐标系来表示图上的一个点。对于这个任务，我们需要两个值， *x* 和 *y* 。这是二维特征空间的例子，其中 *x* 和 *y* 轴每个都是表示空间中的维度。加一个 *z* 轴，我们得到一个三维特征空间。本质上，我们在一个 *n* 维特征空间中定义 ML 问题，其中 *n* 指的是我们试图预测的现象的特征数量。在我们之前预测观众偏好的案例中，如果我们单独使用五大个性测试分数作为输入特征，我们将基本上拥有一个五维特征空间，其中每个维度对应于一个人在五个个性维度之一上的分数。事实上，现代的 ML 问题可以有 100 到 100，000 个维度(有时甚至更多)。由于特征的可能配置的数量相对于不同特征的数量的增加呈指数增加，即使对于计算机来说，以这样的比例构思和计算也变得相当困难。ML 中的这个问题通常被称为*维数灾难*。

        

# 算法计算和预测模型

一旦我们有了相关数据的高维表示，我们就可以开始推导预测函数的任务。我们通过使用算法来实现这一点，算法本质上是一组预编程的递归指令，以某种方式对我们的高维数据表示进行分类和划分。这些算法(最常见的是聚类、分类和回归)递归地将我们在特征空间上的数据点(即，每个人的个性排名)分成更小的组，其中数据点相对更相似。以这种方式，我们使用算法迭代地将我们的高维特征空间分割成更小的区域，这将最终对应于我们的输出类(理想地)。因此，我们可以可靠地预测任何未来数据点的输出类，只需将它们放在我们的高维特征空间中，并将它们与对应于我们模型的预测输出类的区域进行比较。恭喜，我们有了一个预测模型！

        

# 将模型与用例相匹配

每当我们选择将一个观察定义为某些特征的函数时，我们就打开了一个半因果关联特征的潘多拉盒子，其中每个特征本身都可以被重新定义(或量化)为其他特征的函数。在这样做的时候，我们可能想后退一步，考虑一下我们到底想表达什么。我们的模型捕捉到相关的模式了吗？我们能依靠我们的数据吗？我们的资源，无论是算法还是计算能力，是否足以从我们拥有的数据中学习？

回想一下我们之前预测一个人每餐可能消耗的食物量的场景。我们讨论的特征，例如他们的体力消耗，可以被重新定义为他们的代谢和激素活动的函数。类似地，饮食偏好可以被重新定义为肠道细菌和粪便成分的函数。这些重新定义中的每一个都给我们的模型增加了新的特性，带来了额外的复杂性。

也许我们甚至可以更准确地预测你应该点多少外卖。这值得每天做胃活检吗？或者在你的厕所里安装最先进的电子显微镜？你们大多数人都会同意:不，不会的。我们是如何达成这一共识的？简单地通过评估我们的饮食预测用例，并选择与*足够相关的*特征，以可靠且与我们的情况成比例的方式预测我们想要预测的东西。由高质量硬件(如马桶传感器)补充的复杂模型对于饮食预测的用例是不必要的，也是不现实的。您可以根据容易获得的特征，如购买历史和先前的偏好，轻松实现功能预测模型。

这个故事的本质是，你可以以递归的方式将任何可观察到的现象定义为其他现象的函数，但聪明的数据科学家会通过选择合理适合你的用例的适当特征来知道何时停止；易于观察和验证；并积极处理所有相关情况。我们所需要的是近似一个可靠地预测我们的数据点的输出类的函数。对我们的现象进行过于复杂或简单的描述自然会导致我们的 ML 项目的失败。

        

# 功能表示

在我们开始理解、构建和掌握神经网络的旅程之前，我们必须至少刷新我们对一些基本 ML 概念的感知。例如，重要的是要明白，你永远不会完全模拟一个现象。你只是*在功能上*代表它的一部分。这有助于你直观地思考数据，形成大拼图中的一小块，由你试图理解的普遍现象来代表。这也有助于你认识到时代在变。要素的重要性以及周围的环境都会受到这种变化的影响，从而削弱模型的预测能力。这种直觉自然是通过实践和领域知识建立起来的。

在接下来的部分中，我们将通过一些简单的场景驱动的例子，用 ML 用例的一些经典陷阱来简单地刷新我们的记忆。这一点很重要，因为当我们开始理解并将神经网络应用于各种用例的主要旅程时，我们会注意到这些相同的问题再次出现。

        

# ML 的陷阱

考虑预测天气预报的问题。我们将通过进行一些特征选择来开始构建我们的预测模型。利用一些领域知识，我们最初将特征*空气压力*识别为相关的预测器。我们将在我们居住的夏威夷岛上记录不同日子里不同的 *Pa* 值(帕斯卡，气压的一种度量单位)。这些天有些是晴天，有些是雨天。

        

# 不平衡的阶级优先

在几个晴天之后，你的预测模型告诉你第二天很有可能也是晴天，但却下雨了。为什么？这仅仅是因为你的模型没有看到足够多的两种预测类别(晴天和雨天)的实例来准确评估下雨的可能性。在这种情况下，据说它具有不平衡的类别先验，这歪曲了整体天气模式。根据你的模型，只有晴天，因为到目前为止它只见过晴天。

        

# 欠拟合

您已经收集了大约两个月的气压数据，并平衡了每个输出类中的观测值数量。您的预测准确性稳步提高，但在次优水平(比如 61%)开始逐渐下降。突然，随着外面越来越冷，你的模型的精确度又开始下降。这里，我们面临拟合不足的问题，因为我们的简化模型无法捕捉我们数据的潜在模式，这是由冬季的季节性到来引起的。这种情况有一些简单的补救措施。最突出的是，我们可以简单地通过增加更多的预测功能来改进我们的模型，例如外部温度。这样做，我们在几天的数据收集后观察到，我们的准确性再次攀升，因为额外的功能为我们的模型添加了更多的信息，增加了它的预测能力。在其他拟合不足的情况下，我们可能会选择计算更密集的预测模型，添加更多数据并设计更好的功能，或者减少模型上的任何数学约束(如正则化的 lambda 超参数)。

        

# 过度拟合

在收集了大约几年的数据后，你自信地向你的农民朋友吹嘘说，你已经开发了一个稳健的预测模型，准确率达到 96%。你的朋友说，好消息，我能知道吗？你，作为一个利他主义者和慈善家，立即同意并把代码发给他。一天后，这位朋友从中国广东省的家中打来电话，愤怒地说你的模式不起作用，毁了他的庄稼收成。这里发生了什么？这仅仅是我们的模型过度适应夏威夷的热带气候的一个例子，它不能很好地概括这个样本之外的情况。我们的模型没有看到压力和温度的可能值中实际存在的足够多的变化，相应的标签为*晴天*和*雨天*，足以能够预测另一个大陆的天气。事实上，由于我们的模型只看到了夏威夷的温度和气压，它记住了数据中的琐碎模式(例如，从来没有连续两天下雨)，并使用这些模式作为进行预测的规则，而不是拾取更有信息的趋势。当然，一个简单的补救办法是在中国收集更多的天气数据，并根据当地的天气动态调整你的预测模型。在涉及过度拟合的其他类似情况下，您可以尝试选择一个更简单的模型，通过移除异常值和错误来对数据进行降噪，并使其相对于平均值居中。

        

# 错误数据

在向你亲爱的中国朋友(以下简称 Chan)解释了刚刚发生的计算错误后，你指示他安装传感器并开始收集当地的气压和温度，以构建一个标注了晴天和雨天的数据集，就像你在夏威夷所做的那样。Chan 努力地在他的屋顶和田地里放置传感器。不幸的是，Chan 的屋顶是由高导热率的强化金属合金制成的，这以不一致和不可靠的方式不稳定地夸大了来自屋顶的压力和温度传感器的读数。当这种被破坏的数据被输入到我们的预测模型中时，自然会产生次优的结果，因为被学习的线被噪声和错误的数据所扰乱。一个明确的补救办法是更换传感器，或者简单地丢弃错误的传感器读数。

        

# 不相关的功能和标签

最终，利用来自夏威夷、中国和世界其他一些地方的足够数据，我们注意到一个清晰的、全球通用的模式，我们可以用它来预测天气。所以，每个人都很高兴，直到有一天，你的预测模型告诉你这将是一个阳光明媚的日子，一场龙卷风来敲你的门。发生了什么事？我们哪里出错了？事实证明，当涉及到龙卷风时，我们的双特征二元分类模型没有纳入足够的关于我们问题的信息(这是龙卷风的动力学)，以允许我们近似一个可靠地预测这种特定灾难性结果的函数。到目前为止，我们的模型甚至没有试图预测龙卷风，我们只收集了晴天和雨天的数据。

这里的一位气候学家可能会说，*好吧，那么开始收集海拔、湿度、风速和方向的数据，并在你的数据中添加一些标注的龙卷风实例*，事实上，这将帮助我们抵御未来的龙卷风。也就是说，直到地震袭击大陆架并引发海啸。这个说明性的例子展示了无论您选择使用哪种模型，您都需要跟踪相关的特征，并为每个预测类别提供足够的数据(例如是晴天、雨天、龙卷风等等)来实现良好的预测准确性。拥有一个好的预测模型仅仅意味着你已经发现了一种机制，这种机制能够使用你迄今为止收集的数据，归纳出一组看似被遵守的预测规则。

        

# 摘要

在这一章中，我们获得了生物神经网络的功能概述，并对神经学习和分布式表示等概念进行了简短的介绍。我们还刷新了一些经典数据科学难题的记忆，这些难题与神经网络和其他 ML 技术同样相关。在下一章中，我们将最终深入到备受期待的学习机制中，这种学习机制大致是由我们的生物神经网络启发的，因为我们探索了人工神经网络的基本架构。我们友好地用这种方式描述人工神经网络，是因为尽管我们的目标是像它们的生物学对手一样有效地工作，但它们还没有完全达到目标。在下一章，你将回顾在设计人工神经网络中涉及的主要实施考虑，并逐步发现这种努力所包含的复杂性。

        

# 进一步阅读

*   **符号学习与联结主义学习**:【http://www.cogsci.rpi.edu/~rsun/sun.encyc01.pdf】T2
*   **人工智能历史**:[http://sitn . HMS . Harvard . edu/flash/2017/History-artificial-intelligence/](http://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/)
*   **人类大脑的历史**:【http://www.mybrain.co.uk/public/learn_history4.php】T2
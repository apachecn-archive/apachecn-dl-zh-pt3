# 1.构建TensorFlow输入管道

我们向您介绍带有 tf.data API 的 TensorFlow 输入管道，它使您能够从简单的、可重用的部分构建复杂的输入管道。输入管道是任何深度学习实验的生命线，因为学习模型期望数据以 TensorFlow 可消费的形式存在。使用 tf.data.Dataset 抽象(tf.data API 的一个组件)创建高性能管道非常容易，因为它以简单的格式表示数据集中的一系列元素。

尽管数据清理是输入管道的一个重要组成部分，但我们主要关注用清理后的数据构建管道。我们希望您专注于构建 TensorFlow 可消费管道，而不是数据清理。一个数据科学家可能会花费整个机器学习(ML)项目 80%以上的时间来清理数据。

我们从三个数据源构建输入管道。第一个数据源来自加载到内存中的数据。第二个来自外部文件。最后一个来自云存储。

章节的笔记本位于以下 URL:

[T2`https://github.com/paperd/deep-learning-models`](https://github.com/paperd/tensorflow)

## 什么是输入管道？

一个**机器学习(ML)** **输入管道**是一种对产生机器学习模型所需的工作流进行编码和自动化的方法。 *ML 工作流程*是在 ML 项目中实施的阶段。典型的阶段包括数据收集、数据预处理、构建数据集、模型训练和细化、评估以及部署到生产环境中。因此，输入管道的目标是自动化与 ML 问题解决相关的工作流程(或阶段)。一旦输入管道被自动化，当新数据被添加到 ML 项目中时，它可以被重用。它甚至可以被调整用于类似的 ML 项目。

任何输入管道的第一步都是数据预处理。在这一步中，原始数据被收集、清理并合并到一个单一的有组织的框架中。**数据清理**是识别和修复数据集任何问题的过程。数据清理的目标是修复任何不正确、不准确、不完整、格式不正确、重复或与 ML 项目目的无关的数据，以便清理的数据集是正确的、一致的、可靠的和可用的。

如果没有强大而准确的数据作为训练模型的输入，项目更有可能失败。一旦数据准备妥当，输入管道的重点就是编写和执行 ML 算法以获得 ML 模型。

## 为什么要建立输入管道？

为了理解输入管道的重要性，查看数据科学团队在构建 ML 模型时所经历的典型阶段是有益的。从头开始实现一个 ML 模型往往是非常面向问题的。因此，数据科学团队专注于创建一个模型来解决单一的业务问题。

### 手动工作流程

通常，团队从没有现有基础设施的*手动工作流*开始。数据收集、数据清理、模型训练和评估可能都写在一个笔记本上。笔记本在本地运行以产生一个模型，该模型被移交给一个工程师，该工程师的任务是将该模型转变为应用编程接口(API)端点。一个 **API 端点**是一个利用 ML 来解决特定项目中特定问题的远程工具。因此，工程师使用经过训练的模型来创建可以跨平台部署的 API 工具。

手动工作流通常是临时的，并且当团队开始加速其迭代周期时开始崩溃，因为手动过程很难重复和记录。单个笔记本格式的代码往往不适合协作。在手动工作流程场景中，**模型**就是产品。

### 自动化工作流程

一旦团队从偶尔更新单个模型的阶段发展到在生产中拥有多个频繁更新的模型，管道方法就变得至关重要。在这个场景中，我们不构建和维护模型。我们开发和维护渠道。所以**管道**就是产品。

自动化管道由组件和一个蓝图组成，该蓝图描述了如何集成组件以产生和更新最关键的组件——模型。借助自动化工作流，代码被拆分成更易于管理的组件，包括数据预处理、模型训练、模型评估和再训练触发器。当一个模型需要重新训练时，这样的触发器就会自动触发。

该系统提供了在整个管道环境中执行、迭代和监控单个组件的能力，就像在笔记本电脑上运行本地笔记本单元一样简单快速。它还让我们定义所需的输入和输出、库依赖关系和受监控的指标。

将问题解决分解成可重现的、预定义的和可执行的组件的能力迫使团队坚持联合的(或联合的)过程。一个联合的过程，反过来，在数据科学家和工程师之间创建一个定义良好的语言，最终导致一个自动化的设置，这是 ML 等价的持续集成(CI)。CI 是将来自多个参与者的代码变更自动集成到一个软件项目中的实践，这样最终产品就能够自动更新自己。

## 基本输入管道机制

*tf.data.Dataset* API 支持编写描述性的、高效的输入管道，它遵循一个通用的模式。首先，根据输入数据创建源数据集。其次，应用数据转换来预处理数据。第三，迭代数据集并处理元素。迭代以流的方式发生，因此整个数据集不需要适合内存。

创建数据源后，通过在 tf.data.Dataset 对象上链接方法调用，将其转换为新的数据集。dataset 对象是一个 Python iterable，可以通过 for 循环使用。

TensorFlow数据集通常以两种不同的方式创建。我们可以从存储在内存或一个或多个文件中的数据创建数据集。但是，如果需要，我们可以基于一个或多个 tf.data.Dataset 对象创建带有数据转换的数据集。

要从内存中创建 TensorFlow 数据集，请使用 *from_tensors()* 或 *from_tensor_slices()* 方法。要从以推荐的 TFRecord 格式存储在文件中的数据创建 TensorFlow 数据集，请使用 *TFRecordDataset()* 方法。

**from_tensors()** 方法组合来自数据源的输入张量，并返回包含单个元素的数据集。 **from_tensor_slices()** 方法为输入张量的每一行创建一个具有单独元素的数据集。一个**输入张量**是一个表示数据源的 n 维向量或矩阵。我们关注 *from_tensor_slices()* 方法，因为我们希望能够方便地检查和处理来自数据源的每个元素。

## 高性能管道

tf.data API 通过在当前步骤完成之前为下一步的训练提供数据，支持创建灵活高效的输入管道。我们关注构建高性能TensorFlow输入管道的三个最佳实践，即预取、缓存和混洗。当我们在本章后面构建输入管道时，我们将通过例子来讨论这些实践。

## 谷歌开发者代码实验室

即使在你完成了本书中的例子之后，你也可能想要通过探索额外的教程来增加你的深度学习应用知识。Google 开发人员 Codelabs 提供指导教程，强调动手编写代码的例子。大多数教程会引导您完成构建小型应用或向现有应用添加新功能的过程。它们涵盖了广泛的主题，如 Android Wear、Google 计算引擎、Project Tango 和 iOS 上的 Google APIs。

要阅读 Codelabs 网站，请访问

[T2`https://codelabs.developers.google.com/`](https://codelabs.developers.google.com/)

## 在 Colab 中创建新笔记本

在 Colab 环境中，很容易创建新的笔记本。在浏览器中打开 Google Colab(如果尚未打开)。在弹出的窗口中，点击*新建笔记本*。如果已经在 Colab 环境中，点击*下左上角菜单中的*文件*。从下拉菜单中点击*新建笔记本*。代码单元现在已经准备好执行 Python 代码了！点击 *+代码*或 *+文本*按钮，添加代码或文本单元格。更多选项，点击主菜单中的*插入*。*

有关 Colab 的介绍，请阅读

[T2`https://colab.research.google.com/`](https://colab.research.google.com/)

若要创建第一段代码，请在“代码”单元格中添加以下内容:

```py
10 * 5

```

要执行代码，单击左边的小箭头。代码单元的输出显示乘法的结果。

Tip

我们建议从网站上复制并粘贴代码。

## 导入 TensorFlow 库

在 TensorFlow 中做任何事情之前，我们必须导入适当的 Python 库。通常的做法是将 TensorFlow 库别名为 **tf** 。因此，继续在新的代码单元格中执行导入:

```py
import tensorflow as tf

```

## GPU 硬件加速器

要大幅加快处理速度，请使用 Google Colab 云服务提供的 GPU。Colab 提供了一个大约 12 GB RAM 的免费 Tesla K80 GPU(截至本文撰写时)。在 Colab 笔记本中启用 GPU 非常简单:

1.  点击左上角菜单中的*运行时*。

2.  从下拉菜单中点击*改变运行时间类型*。

3.  从*硬件加速器*下拉菜单中选择 *GPU* 。

4.  点击*保存*。

Note

必须在每个笔记本的*中启用 GPU。但它只需启用一次。*

验证 GPU 是否处于活动状态:

```py
tf.__version__, tf.test.gpu_device_name()

```

如果显示“/设备:GPU:0”，则 GPU 处于活动状态。如果显示“”，则常规 CPU 处于活动状态。

Tip

如果出现错误**名称‘TF’未定义**，请重新执行代码以导入 TensorFlow 库！出于某种原因，我们有时必须在 Colab 中重新执行 TensorFlow 库导入。我们不知道为什么会这样。

Colab 是使用 TensorFlow 的一个很棒的工具。然而，它也有其局限性。Colab 应用动态资源供应。为了能够免费提供计算资源，Colab 动态地调整使用限制和硬件可用性。因此，Colab 中的可用资源会随着时间的推移而变化，以适应需求的波动。简而言之，这意味着 Colab 可能并不总是可用！一个解决方案是每月支付少量费用，就可以使用 Colab Pro。截至本文撰写之时，费用为 9.99 美元/月。

Tip

对于严重的 TensorFlow 用户，我们建议转移到 Colab Pro。它不是免费的，但相当便宜。从我们的经验来看，它比免费版更强大，而且更容易获得。

## 创建TensorFlow数据集

创建一个包含三个张量的数据集，每个张量包含六个元素:

```py
data = [[8, 5, 7, 3, 9, 1],
        [0, 3, 1, 8, 5, 7],
        [9, 9, 9, 0, 0, 7]]

dataset = tf.data.Dataset.from_tensor_slices(data)
dataset

```

创建数据集。使用 from_tensor_slices()方法将其转换为 tf.data.Dataset 对象。数据集的形状是(6，)这意味着每行包含六个标量值。

Tip

我们强烈建议在代码单元中测试小段代码，以减少调试时间和工作量。

## 消费数据集

迭代数据集以显示张量信息:

```py
for i, row in enumerate(dataset):
  print ('row ' + str(i), ':', end=' ')
  print (row.numpy())

```

因为 tf.data.Dataset 对象是用 from_tensor_slices()创建的，所以它是一个 Python iterable，可以用 for 循环使用。对于 TensorFlow 数据集，使用 *numpy()* 方法将每个张量显式转换为 numpy 数组。

或者，我们可以使用 *take()* 方法迭代 TensorFlow 数据集:

```py
for i, e in enumerate(dataset.take(3)):
  print ('row ' + str(i), ':', end=' ')
  print (e.numpy())

```

我们在 take()方法中添加 *3* 作为参数来抓取三个例子。

另一个选择是创建一个 Python 迭代器:

```py
i = 0
it = iter(dataset)
print ('row ' + str(i), ':', end=' ')
print (next(it).numpy())
i += 1
print ('row ' + str(i), ':', end=' ')
print (next(it).numpy())
i += 1
print ('row ' + str(i), ':', end=' ')
print (next(it).numpy())

```

初始化计数器变量。使用 *iter()* 方法创建一个迭代器。用 *next()* 方法消耗迭代器并显示结果。

## 数据集结构

tf.data.Dataset 的 *element_spec* 属性允许检查数据集。属性返回 tf 的嵌套结构。匹配元素结构的 TypeSpec 对象。嵌套结构可以是单个组件、组件元组或组件嵌套元组。

检查数据集:

```py
dataset.element_spec

```

将显示形状和数据类型。

或者，我们可以只显示 tf.data.Dataset 对象:

```py
dataset

```

## 从内存中创建数据集

如果所有输入数据都适合内存，创建 TensorFlow 数据集的最简单方法是将其转换为 tf。使用 from_tensor_slices()方法创建张量对象。现在，我们要建一条管道。我们首先加载一个干净的数据集。我们继续缩放特征数据图像。缩放(或要素缩放)是一种用于归一化数据集的独立变量或要素范围的方法。缩放很重要，因为如果组成每个图像的像素尺寸较小，ML 模型往往会工作得更好。我们用代码和可视化来检查数据。接下来，我们为性能配置管道。我们以创建模型、训练模型和评估模型结束。

### 加载和检查数据

为了构建输入管道，我们需要一个数据集。因为重点是构建 TensorFlow 可消费管道，所以我们使用清理过的数据集。

将训练和测试数据加载到内存中:

```py
train, test = tf.keras.datasets.fashion_mnist.load_data()

```

将时尚 MNIST 数据下载到训练集和测试集中。我们使用训练数据来训练模型。我们使用测试数据来评估模型。时尚-MNIST 是一个数据集的扎隆多的文章图像。它包含 60，000 个训练和 10，000 个测试示例。该数据集旨在作为原始 MNIST 数据集的直接替代，用于机器学习算法的基准测试。

检查:

```py
type(train[0]), type(train[1])

```

训练集和测试集是元组，其中第一个元组元素包含特征图像，第二个元素包含相应的标签。两个数据集都是 NumPy 数组。

将图像和标签载入变量:

```py
train_img, train_lbl = train
test_img, test_lbl = test

```

通过从各自的数据集中分离图像和标签，我们可以更容易地根据需要处理图像和标签。

验证形状:

```py
print ('train:', train_img.shape, train_lbl.shape)
print ('test:', test_img.shape, test_lbl.shape)

```

训练数据由 60000 张 28 × 28 的特征图像和 60000 个标签组成。测试数据由 10000 张 28 × 28 的特征图像和 10000 个标签组成。

### 缩放并创建 tf.data.Dataset

扩展数据以实现高效处理，并创建训练集和测试集:

```py
train_image = train_img / 255.0
test_image = test_img / 255.0

train_ds = tf.data.Dataset.from_tensor_slices(
    (train_image, train_lbl))
test_ds = tf.data.Dataset.from_tensor_slices(
    (test_image, test_lbl))

```

用 *from_tensor_slices()* 以 tf.data.Dataset 对象的形式获取 NumPy 数组的切片。特征图像像素值通常是范围从 0 到 255 的整数。若要缩放，请将特征图像除以 255，以获得范围从 0 到 1 的像素值。

缩放图像是一个关键的预处理步骤，因为深度学习模型在较小的图像上训练更快。而且很多深度学习模型架构要求图像大小一致。但是原始图像的大小往往不同。

检查训练和测试张量:

```py
train_ds, test_ds

```

两个数据集都是 *TensorSliceDataset* 对象，这意味着它们是迭代器。一个**迭代器**是一个包含可计数数量的例子的对象，这些例子可以用 *next()* 方法遍历。

显示训练集中的第一个标签:

```py
next(train_ds.as_numpy_iterator())[1]

```

训练集中的每个示例都包含一个图像矩阵及其对应的标签。 *next()* 方法返回一个元组，其中第一个图像矩阵及其标签分别位于元组中的位置 0 和 1。

显示训练集中的十个标签:

```py
next(train_ds.batch(10).as_numpy_iterator())[1]

```

*batch()* 方法从数据集中获取 *n* 个例子。

显示训练集中的所有 60，000 个标签:

```py
labels = next(train_ds.batch(60_000).as_numpy_iterator())[1]
labels, len(labels)

```

显示训练集中的第一幅图像:

```py
next(train_ds.as_numpy_iterator())[0]

```

验证第一幅图像是一个 28 × 28 的矩阵:

```py
arrays = len(next(train_ds.as_numpy_iterator())[0])
pixels = len(next(train_ds.as_numpy_iterator())[0][0])
arrays, pixels

```

在 Python 中求矩阵的维度，高度(或行数)为 *len(矩阵)，*，宽度(或列数)为 *len(矩阵[0])* 。

### 验证缩放比例

显示训练集中的预缩放张量:

```py
train_img[0][3]

```

缩放后显示相同的张量:

```py
train_image[0][3]

```

瞧啊。像素在 0 和 1 之间缩放。

### 检查张量形状

检查形状:

```py
for img, lbl in train_ds.take(5):
  print ('image shape:', img.shape, end=' ')
  print ('label:', lbl.numpy())

```

时尚 MNIST 的图片大小相同。所以我们不必调整它们的大小！

### 检查张量

检查训练和测试张量:

```py
train_ds, test_ds

```

一切都好。

### 保持形状

为在模型中使用的特征图像形状分配一个变量:

```py
for img, _ in train_ds.take(1):
  img.shape

img_shape = img.shape
img_shape

```

### 设想

可视化训练集中的元素:

```py
import matplotlib.pyplot as plt

for feature, label in train_ds.take(1):
  plt.imshow(feature, cmap='ocean')
plt.axis('off')
plt.grid(b=None)

```

虽然时尚 MNIST 的图像是灰度的，但是我们可以使用 matplotlib 库中预定义的颜色映射来赋予它们生命。**颜色图**是一组颜色，用于将像素数据映射到实际颜色值。

有关 matplotlib 颜色映射的详细信息，请阅读以下 URL:

[T2`https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html`](https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html)

### 定义分类标签

根据我们与时尚 MNIST 合作的经验，我们知道相应的标签:

```py
class_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress',
                'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag',
                'Ankle boot']

```

### 将数字标签转换为类别标签

标签在我们刚刚加载的 tf.data.Dataset 中是数字的，但是我们可以用我们刚刚创建的 *class_labels* 列表显示相应的类名:

```py
for _, label in train_ds.take(1):
  print ('numerical label:', label.numpy())
print ('string label:', class_labels[label.numpy()])

```

举个例子，将标签显示为数值和字符串值。

### 从数据集中创建示例图

从训练集中获取一些图像和标签:

```py
num = 30
images, labels = [], []
for feature, label in train_ds.take(num):
  images.append(tf.squeeze(feature.numpy()))
  labels.append(label.numpy())

```

创建一个函数来显示如清单 [1-1](#PC30) 所示的示例网格。

```py
def display_grid(feature, target, n_rows, n_cols, cl):
  plt.figure(figsize=(n_cols * 1.5, n_rows * 1.5))
  for row in range(n_rows):
    for col in range(n_cols):
      index = n_cols * row + col
      plt.subplot(n_rows, n_cols, index + 1)
      plt.imshow(feature[index], cmap='twilight',
                 interpolation='nearest')
      plt.axis('off')
      plt.title(cl[target[index]], fontsize=12)
  plt.subplots_adjust(wspace=0.2, hspace=0.5)

Listing 1-1Function to Display a Grid of Examples

```

调用函数:

```py
rows, cols = 5, 6
display_grid(images, labels, rows, cols, class_labels)

```

检查数据集以查看它是否如我们所期望的那样总是一个好主意。

### 构建可消耗的输入管道

我们说*可消耗的输入管道*是因为实际的管道在数据被实际获取时开始。我们使用这个术语来强调将训练和测试数据集转换为用于TensorFlow模型消费的有效张量的重要性。我们看到一些例子将这一部分称为构建输入管道，但是输入管道包含了从原始数据到通用模型的整个工作流程。在后面的章节中，我们去掉了“消耗品”这个词

#### 配置数据集以提高性能

使用缓冲预取和缓存来提高 I/O 性能。混洗数据以提高模型性能。

**预取**是 tf.data API 中的一个函数，在训练时重叠数据预处理和模型执行，减少了模型的整体训练时间。要执行此操作，请添加 *tf。Dataset.prefetch* 到输入管道的转换。

将 *tf.data.Dataset.cache* 转换添加到管道中，以便在第一个时期将图像从磁盘中加载出来后将其保留在内存中，这可以确保数据集不会成为训练过程中的瓶颈。因此高速缓存避免了在每个时期执行操作(例如，文件打开、数据读取)。

**混洗**数据的目的是减少方差(确保模型保持通用)和减少过度拟合。洗牌的一个明显例子是当数据按类(或目标)排序时。我们进行洗牌，以确保训练集、测试集和验证集能够代表数据的总体分布。要执行此操作，请添加 *tf。Dataset.shuffle* 到管道的转换。

训练总是在成批的训练数据和标签上执行。这样做有助于算法收敛。**批处理**是指在一次迭代中使用所有数据集来计算梯度。**小批量**是指在一次迭代中使用数据集的子集来计算梯度。要执行此操作，请添加 *tf。Dataset.batch* 转换到流水线。

*批次维度*通常是数据张量的第一维度。所以一个形状为[100，192，192，3]的张量包含 100 个 192 × 192 像素的图像，每批中每个像素有三个值(RGB)。 **RGB 颜色模型**是一种加色模型，其中红色、绿色和蓝色光以各种方式相加，以再现各种颜色。

构建耗材输入管道:

```py
BATCH_SIZE = 128
SHUFFLE_SIZE = 5000

train_f = train_ds.shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE)
train_fm = train_f.cache().prefetch(1)

test_f = test_ds.batch(BATCH_SIZE)
test_fm = test_f.cache().prefetch(1)

```

洗牌训练数据。混洗使训练数据随机化，这确保了每个数据元素在每个训练时期都独立于其他数据元素。当暴露于独立采样的数据时，学习模型往往表现最佳。

批处理、缓存和预取训练和测试数据。添加 *cache()* 转换可以提高性能，因为数据在第一个时段内只被读写一次，而不是在每个时段内。添加*预取(1)* 转换是一个好主意，因为它增加了批处理过程的效率。也就是说，当我们的训练算法处理一批时，TensorFlow 正在并行处理数据集，以准备下一批。因此，这种转变可以极大地提高培训绩效。

与其他 tf.data.Dataset 方法一样，prefetch 对输入数据集的元素进行操作。它没有例子和批处理的概念。因此，预取两个带有 examples.prefetch(2)的示例，预取两个带有 examples.batch(20)的批处理，每个批处理有 20 个示例。预取(2)。

测试(或验证)集用于演示经过训练的模型在训练期间未见过的示例上工作得有多好。所以洗牌是不相关的。

我们基于反复试验来设置批量大小和洗牌大小。您可以通过调整批处理和随机播放大小来进行试验。

检查张量:

```py
train_fm, test_fm

```

### 建立模型

导入必需的库:

```py
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.losses import SparseCategoricalCrossentropy
import numpy as np

```

清除以前的模型，为结果的再现性提供依据:

```py
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

我们使用零作为种子值，但是任何数字都可以代替。

Tip

清除以前的模型不会*而不是*将当前模型重置为其初始状态。要重置模型，只需重新构建模型的输入管道！

创建模型:

```py
model = Sequential([
  Flatten(input_shape=img_shape),
  Dense(128, activation='relu'),
  Dropout(0.4),
  Dense(10, activation=None)
])

```

神经网络的基本构造块是层。图层从提供给它们的数据中提取表示。希望这些表示对手头的问题有意义。大多数深度学习都是由简单的层链在一起组成的。大多数层，比如*密集*，都有训练时学习到的参数。

这个网络中的第一层是 *Flatten* 层，它将图像的格式从二维数组(28 x 28 像素)转换为一维数组(28 * 28 = 784 像素)。可以把这一层想象成把图像中的一排排像素拆开并排列起来。该层没有要学习的参数，因为它只重新格式化数据。

在像素被展平之后，网络由两个密集层的序列组成。密集层是完全连接的神经层，这意味着一层中的所有神经元都连接到下一层中的所有神经元。

第一密集层有 128 个节点(或神经元)。我们在第一个密集层之后添加一个*下降*层，以减少过度拟合。第二层(也是最后一层)返回长度为 10 的 logits 数组。 **Logits** 是激活函数应用前一层神经元的输出。每个节点包含一个分数，该分数指示当前图像属于十个类别中的一个。

**Dropout** 是一种近似并行训练大量不同架构的神经网络的正则化方法。在训练期间，一些层输出被随机忽略或“丢弃”，这使得该层看起来像并且被视为与前一层具有不同数量的节点和连通性的层。实际上，训练期间对层的每一次更新都是用所配置层的不同“视图”来执行的。

检查模型:

```py
model.summary()

```

### 编译和训练模型

用*稀疏分类交叉熵*损失编译模型。当类别互斥时，稀疏分类交叉熵表现良好。也就是说，每个样本恰好属于一个类别。使用稀疏分类交叉熵的一个优点是，它节省了内存和计算时间，因为它对一个类使用单个整数，而不是整个向量。

*from_logits=True* 属性通知损失函数由模型生成的输出值未被归一化。也就是说，softmax 函数*没有*应用于它们以产生概率分布。

编译:

```py
model.compile(optimizer='adam',
  loss=SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])

```

训练模型:

```py
epochs = 10
history = model.fit(train_fm, epochs=epochs,
                    verbose=1, validation_data=test_fm)

```

该模型正在用十个纪元进行训练。**时期的数量**是学习算法在整个训练数据集中工作的次数。显示训练和测试数据的损失和准确性。训练损失和准确性基于模型在训练期间所学习的内容。测试损失和准确性基于模型尚未学习的新数据。因此，测试精度越接近训练精度，模型就越通用。当然，我们希望测试精度高，测试损耗低。

## 将 TensorFlow 数据集作为 NumPy 加载

上一节基于 Keras 数据集对时尚 MNIST 数据进行了建模。但是，我们可以将数据作为 TensorFlow 数据集(TFDS)加载，并将其转换为 NumPy 数组，以便于处理。我们将在下一章详细介绍 TFDS。

对于这个实验，我们加载 MNIST 数据集，而不是时尚 MNIST。我们这样做是因为我们在后面的章节中多次与时尚 MNIST 合作。所以我们只是想让你接触另一个数据集进行练习。一旦数据被加载并转换为 NumPy，输入管道阶段与上一节相同。

在单个批处理中将训练集创建为 NumPy 数组:

```py
import tensorflow_datasets as tfds

image_train, label_train = tfds.as_numpy(
    tfds.load(
        'mnist', split='train',
        batch_size=-1, as_supervised=True,
        try_gcs=True))

type(image_train), image_train.shape

```

通过使用 *batch_size=-1* ，整个数据集作为单个批处理加载。 *tfds.load()* 函数加载数据集。 *tfds.as_numpy()* 函数将数据集转换成 numpy 数组。

训练集包含 60，000 幅 28 × 28 的图像。 *1* 尺寸表示数据为灰度。一个**灰度**图像是其中唯一的颜色是灰色阴影。也就是说，图像只包含亮度(或明度)信息，不包含颜色信息。

创建相应的测试集:

```py
image_test, label_test = tfds.as_numpy(
    tfds.load(
        'mnist', split='test',
        batch_size=-1, as_supervised=True,
        try_gcs=True))

type(image_test), image_test.shape

```

### 检查形状和像素密度

获取训练形状:

```py
image_train.shape, label_train.shape

```

获取测试形状:

```py
image_test.shape, label_test.shape

```

创建一个函数，用清单 [1-2](#PC44) 中所示的像素亮度值找到第一个像素矢量。

```py
def find_intensity(m):
  for i, vector in enumerate(m):
    for j, pixels in enumerate(vector):
      if pixels > 0:
        print (vector)
        return i, j

Listing 1-2Function to Find Pixel Intensity

```

调用函数:

```py
M = image_train[0]
indx = find_intensity(M)
image_train[0][indx[0]][indx[1]]

```

非零值是像素强度。

显示强度大于零的第一个像素:

```py
image_train[0][indx[0]][indx[1]]

```

### 规模

因为 NumPy 数组值是浮点型的，所以将它们除以 255 来缩放图像像素:

```py
train_sc = image_train / 255.0
test_sc = image_test / 255.0

```

验证缩放是否有效:

```py
image_train[0][indx[0]][indx[1]], train_sc[0][indx[0]][indx[1]]

```

### 准备TensorFlow消耗的数据

将 NumPy 数组分割成 TensorFlow 数据集:

```py
train_mnds = tf.data.Dataset.from_tensor_slices(
    (image_train, label_train))
test_mnds = tf.data.Dataset.from_tensor_slices(
    (image_test, label_test))

```

检查:

```py
train_mnds, test_mnds

```

### 构建可消耗的输入管道

初始化参数、混洗训练数据以及批量和预取训练和测试数据:

```py
BATCH_SIZE = 100
SHUFFLE_SIZE = 10000

train_mnist = train_mnds.shuffle(SHUFFLE_SIZE).\
                         batch(BATCH_SIZE).prefetch(1)
test_mnist = train_mnds.batch(BATCH_SIZE).prefetch(1)

```

检查张量:

```py
train_mnist, test_mnist

```

### 建立模型

之前，我们导入了必需的库。由于它们已经在内存中，我们不需要再次导入它们(假设我们使用的是同一台笔记本)。

获取张量形状:

```py
np_shape = image_test.shape[1:]
np_shape

```

清除以前的模型，为结果的再现性提供依据:

```py
np.random.seed(0)
tf.random.set_seed(0)
tf.keras.backend.clear_session()

```

创建模型:

```py
model = Sequential([
  Flatten(input_shape=np_shape),
  Dense(512, activation='relu'),
  Dense(10, activation='softmax')
])

```

### 编译和训练模型

用稀疏分类交叉熵编译。注意，我们**没有**设置 *from_logits=True* ，因为我们在模型的输出层使用 *softmax* 激活来从 logits 产生概率分布。 **softmax** 激活函数作用于一个向量，以增加最大分量与所有其他分量之间的差值，并将该向量归一化为和为 1，以便将其解释为概率向量。它被用作分类器的最后一步:

```py
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

```

训练模型:

```py
epochs = 3
history = model.fit(train_mnist, epochs=epochs, verbose=1,
                     validation_data=test_mnist)

```

我们只训练三个纪元，因为 MNIST 很容易训练。

## 从文件创建数据集

使用 Keras 工具从文件创建 TensorFlow 数据集。我们使用 Keras 实用程序，因为它极大地简化了 flowers 数据集的处理。*花卉数据集*是公开的，成千上万的花卉照片被分成五类。就像时尚-MNIST 和 MNIST 的例子一样，我们按照相似的工作流程阶段构建输入管道。

### 下载并检查数据集

导入库进行可视化:

```py
import PIL.Image

```

数据集包含五个子目录中的数千张花的照片，每个类一张花的照片。目录结构如下:

```py
flowers_photos/
  daisy/
  dandelion/
  roses/
  sunflowers/
  tulips/

```

使用 tf.keras.utils.get_file 实用程序下载数据:

```py
import pathlib

url1 = 'https://storage.googleapis.com/download.tensorflow.org/'
url2 = 'example_images/flower_photos.tgz'
dataset_url = url1 + url2

data_dir = tf.keras.utils.get_file(origin=dataset_url,
                                   fname='flower_photos',
                                   untar=True)
data_dir = pathlib.Path(data_dir)

```

如果文件不在缓存中，那么 *tf.keras.utils.get_file* 实用程序会从 URL 下载文件。*号。Path* 函数提供了文件的具体路径。

统计 data_dir 中已下载和可用的花卉照片数量:

```py
image_count = len(list(data_dir.glob('*/*.jpg')))
print (image_count)

```

花卉图像有 3670 个文件。

*data_dir* 路径指向每个保存不同类型的花的目录。让我们看看目录:

```py
dirs = [item.name for item in data_dir.glob('*')\
        if item.name != 'LICENSE.txt']
dirs

```

每个目录都包含这种花的图片。

访问一些文件:

```py
files = tf.data.Dataset.list_files(str(data_dir/'*/*'))
fn = []
for f in files.take(4):
  print(f.numpy()), fn.append(str(f.numpy()))

```

显示每个文件的标签:

```py
from pathlib import Path

label = []
for i in range(4):
  parts = Path(fn[i]).parts
  label.append(parts[5])
  print (parts[5])

```

每个目录都包含这种花的图片。这是菊花目录中的第一朵花:

```py
daisy = list(data_dir.glob('daisy/*'))
parts = Path(daisy[0]).parts
print (parts[5])
PIL.Image.open(str(daisy[0]))

```

显示菊花图像的数量:

```py
len(daisy)

```

让我们显示几幅来自 *roses* 目录的图片。创建一个清单来存放玫瑰:

```py
roses = list(data_dir.glob('roses/*'))

```

从一些文件中抓取标签:

```py
label = []
for i in range(4):
  tup = Path(str(roses[i])).parts
  label.append(tup[5])

```

展示一些玫瑰，如清单 [1-3](#PC69) 所示。

```py
rows, cols = 2, 2
plt.figure(figsize=(10, 10))
for i in range(rows*cols):
  plt.subplot(rows, cols, i + 1)
  pix = np.array(PIL.Image.open(str(roses[i])))
  plt.imshow(pix)
  plt.title(label[i])
  plt.axis('off')

Listing 1-3Plot Rose Images

```

请注意，图像大小不同！

### 使用 tf.keras .预处理实用工具解析数据

*TF . keras . preprocessing . image _ dataset _ from _ directory*实用程序为从磁盘加载和解析图像提供了难以置信的便利！我们在“*创建训练和测试集”*小节中展示了该工具的便利性。

#### 设置参数

设置批量大小、图像高度和图像宽度:

```py
BATCH_SIZE = 32
img_height = 180
img_width = 180

```

我们最初将批处理大小设置为 32，因为对于我们处理的许多数据集来说，这是一个合适的大小。我们将图像的高度和宽度设置为 180，因为我们得到了很好的结果，并且模型训练非常快。请随意试验这些参数。

我们的检查显示图像大小不同。由于TensorFlow模型期望图像大小相同，因此我们必须调整它们的大小。

#### 创建训练集和测试集

*TF . keras . preprocessing . image _ dataset _ from _ directory*实用程序从目录中的图像文件生成一个 tf.data.Dataset。该实用程序非常有用，因为它允许我们方便地分割、播种、调整大小和批处理数据。让我们将数据分成 81%的训练集和 19%的测试集。我们根据大量实验设定了这种分割。当然，您可以通过自己的实验来调整尺寸。*验证 _ 分割*和*子集*参数的组合决定了训练和测试分割。

留出 81%用于训练数据:

```py
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.19,
  subset='training',
  seed=0,
  image_size=(img_height, img_width),
  batch_size=BATCH_SIZE)

```

留出 19%用于测试数据:

```py
test_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.19,
  subset='validation',
  seed=0,
  image_size=(img_height, img_width),
  batch_size=BATCH_SIZE)

```

#### 检查张量

检查:

```py
train_ds, test_ds

```

从训练集中取出第一批并保留形状:

```py
for img, lbl in train_ds.take(1):
  print (img.shape, lbl.shape)
flower_shape, just_img = img.shape[1:],\
                         img.shape[1:3]

```

我们取第一批来帮助我们检查数据集中的一批。我们保留批次的形状和批次大小，以便在模型中使用。批量大小为 32，图像大小调整为 180 × 180 × 3。 *3* 值表示图像有三个通道，这意味着它们是 RGB(彩色)。标签具有对应于 32 个标量图像的形状(32)。

#### 获取类名

我们已经从目录名中识别出了类。但是我们现在可以用 *class_names* 方法来访问它们:

```py
class_names = train_ds.class_names
class_names

```

#### 显示示例

从训练集中取出一批，并绘制一些图像，如清单 [1-4](#PC76) 所示。

```py
plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype('uint8'))
    plt.title(class_names[labels[i]])
    plt.axis('off')

Listing 1-4Plot Flower Images from the First Training Batch

```

#### 缩放数据

正如本章前面提到的，一个像素由 256 个值表示。因此 RGB 通道值在[0，255]范围内。由于神经网络在小值下工作得更好，数据通常被缩放到[0，1]范围内。

创建一个函数来缩放图像:

```py
def format_image(image, label):
  image = tf.image.resize(image, just_img) / 255.0
  return image, label

```

当我们配置输入管道时，会用到该函数。

#### 配置数据集以提高性能

使用缓冲预取从磁盘获取数据，以减轻 I/O 问题。缓存数据以在图像从磁盘上下载后将其保存在内存中。缓存避免了在每个时期执行文件打开和数据读取等操作。

#### 构建输入管道

缩放、混洗训练集，以及缓存和预取训练集和测试集:

```py
SHUFFLE_SIZE = 100

train_fds = train_ds.map(format_image).\
  shuffle(SHUFFLE_SIZE).cache().prefetch(1)
test_fds = test_ds.map(format_image).\
  cache().prefetch(1)

```

Note

由于训练和测试数据已经被实用程序批处理，因此在构建输入管道时，*不要*批处理！

#### 建立模型

由于我们正在处理大型彩色图像，我们需要建立一个卷积神经网络(CNN)模型来获得可观的性能，因为花朵图像是具有较高像素计数的彩色图像。

我们需要为 CNN 增加额外的库:

```py
from tensorflow.keras.layers import Conv2D, MaxPooling2D

```

获取模型中使用的类的数量:

```py
num_classes = len(class_names)
num_classes

```

清除任何以前的模型并生成一个随机种子:

```py
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建一个多层 CNN，如清单 [1-5](#PC82) 所示。

```py
flower_model = tf.keras.Sequential([
  Conv2D(32, 3, activation='relu',
         input_shape=flower_shape),
  MaxPooling2D(),
  Conv2D(32, 3, activation='relu'),
  MaxPooling2D(),
  Conv2D(32, 3, activation='relu'),
  MaxPooling2D(),
  Flatten(),
  Dense(128, activation='relu'),
  Dense(num_classes, activation='softmax')
])

Listing 1-5A Multilayer CNN

```

第一层缩放数据。第二层包含 32 个神经元，具有 3 × 3 卷积核(或滤波器)。激活是 *relu* 。第三层使用最大池，通过仅保留最大值来减小层的空间大小。因此，池层在不丢失重要特征或模式的情况下降低了图像维度。接下来的四层重复与第二层和第三层相同的模式。扁平化层将汇集的数据转换为单个列，因为密集层需要这种形式的数据。最终的密集层支持分类和预测。

#### 编译和训练模型

使用 SparseCategoricalCrossentropy()编译:

```py
flower_model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(),
  metrics=['accuracy'])

```

由于 *softmax* 应用于输出，我们**不**设置 *from_logits=True* 。

训练模型:

```py
history = flower_model.fit(
    train_fds,
    validation_data=test_fds,
    epochs=5)

```

该模型过度拟合，因为与训练精度相比，验证精度较低。但是我们还没有尝试调整这个模型。在下一章中，我们将探索一种强有力的技术来减轻过度拟合。

### 从谷歌云存储中获取鲜花

我们演示了来自内存和文件的数据的输入管道。我们还可以从云存储中传输数据。Flowers 数据存放在 Google 云存储(GCS)的一个公共存储桶中。这样我们就可以从 GCS 获取花卉档案。我们可以将花读取为 JPEG 文件或 TFRecord 文件。对于数据建模，我们使用 TFRecord 文件。为了获得最佳性能，我们一次读取多个 TFRecord 文件。 **TFRecord 格式**是一种用于存储二进制记录序列的简单格式。TFRecord 文件包含一系列记录，这些记录只能按顺序读取。

#### 将花读取为 JPEG 文件，并执行简单的处理

基于 GCS 模式读取 JPEG 文件:

```py
GCS_PATTERN = 'gs://flowers-public/*/*.jpg'
filenames = tf.io.gfile.glob(GCS_PATTERN)

```

GCS_PATTERN 是一个支持“*”和“？”的*全局模式*通配符。**glob**(也称为 glob patterns)是可以将通配符模式扩展为匹配给定模式的路径名列表的模式。

获取 JPEG 图像的数量:

```py
num_images = len(filenames)
print ('Pattern matches {} images.'.format(num_images))

```

从 GCS_PATTERN 创建一个文件名数据集，并仔细阅读其内容:

```py
filenames_ds = tf.data.Dataset.list_files(GCS_PATTERN)
for filename in filenames_ds.take(5):
  print (filename.numpy().decode('utf-8'))

```

我们需要(图像，标签)元组中的数据来独立地处理图像和标签。因此创建一个函数来返回(image，label)元组的数据集，如清单 [1-6](#PC88) 所示。

```py
def decode_jpeg_and_label(filename):
  bits = tf.io.read_file(filename)
  image = tf.image.decode_jpeg(bits)
  label = tf.strings.split(
      tf.expand_dims(filename, axis=-1), sep='/')
  label = label.values[-2]
  return image, label

Listing 1-6Function That Returns a Dataset of (image, label) Tuples

```

将函数映射到每个文件名，以创建(图像，标签)元组的数据集:

```py
ds = filenames_ds.map(decode_jpeg_and_label)

```

仔细阅读:

```py
for image, label in ds.take(5):
  print (image.numpy().shape,
         label.numpy().decode('utf-8'))

```

显示图像:

```py
for img, lbl  in ds.take(1):
  plt.axis('off')
  plt.title(lbl.numpy().decode('utf-8'))
  fig = plt.imshow(img)

```

尽管我们没有使用这个数据集进行训练，但是让我们看看如何将文本标签转换成编码标签，如清单 [1-7](#PC92) 所示。

```py
for img, lbl  in ds.take(1):
  label = lbl.numpy().decode('utf-8')

matches = tf.stack([tf.equal(label, s)\
                    for s in class_names], axis=-1)
one_hot = tf.cast(matches, tf.float32)
print (matches.numpy(), one_hot.numpy())
new_label = tf.math.argmax(one_hot)
new_label.numpy()

Listing 1-7Convert Text Labels to Encoded Labels

```

拿个标签。将它与类名列表进行比较，以找到它在列表中的位置。创建一个热点向量。将独热向量转换成标签张量。我们不用这个数据集进行训练，因为它不是从 GCS 中建模复杂数据的方法。但这是加载和检查数据的简单方法。

### 将 Flowers 作为 TFRecord 文件读取和处理

从 GCS 对复杂数据建模的最佳方式是 TFRecord 文件。TFRecord 文件将数据存储为二进制字符串序列。处理二进制字符串非常有效。

#### 读取 TFRecord 文件

基于 GCS 模式读取 TFRecord 文件:

```py
piece1 = 'gs://flowers-public/'
piece2 = 'tfrecords-jpeg-192x192-2/*.tfrec'
TFR_GCS_PATTERN = piece1 + piece2
tfr_filenames = tf.io.gfile.glob(TFR_GCS_PATTERN)

```

获取桶的数量:

```py
num_images = len(tfr_filenames)
print ('Pattern matches {} image buckets.'.format(num_images))

```

我们抓了 16 桶。由于有 3670 个花文件，15 个桶包含 230 个图像(15×230 = 3450)，最终桶包含 220 个图像。220 加 3450 得 3670。

显示文件:

```py
filenames_tfrds = tf.data.Dataset.list_files(TFR_GCS_PATTERN)
for filename in filenames_tfrds.take(1):
  print (filename.numpy())

```

#### 设置训练参数

设置图像大小调整、流水线和时期数的参数:

```py
IMAGE_SIZE = [192, 192]
AUTO = tf.data.experimental.AUTOTUNE
BATCH_SIZE = 64
SHUFFLE_SIZE = 100
EPOCHS = 5

```

使用*自动调优*来提示 tf.data 运行时，它会在运行时动态调优该值。

Note

自动调优是实验性的，这意味着操作在将来可能会改变。

设置验证拆分和分类标签:

```py
VALIDATION_SPLIT = 0.19
CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']

```

创建数据分割、验证步骤和每个时期的步骤，如清单 [1-8](#PC98) 所示。

```py
split = int(len(tfr_filenames) * VALIDATION_SPLIT)
training_filenames = tfr_filenames[split:]
validation_filenames = tfr_filenames[:split]
print ('Splitting dataset into {} training files and {}'
        ' validation files'.format(
            len(tfr_filenames), len(training_filenames),
            len(validation_filenames)), end = ' ')
print ('with a batch size of {}.'.format(BATCH_SIZE))
validation_steps = int(3670 // len(tfr_filenames) *\
                       len(validation_filenames)) // BATCH_SIZE
steps_per_epoch = int(3670 // len(tfr_filenames) *\
                      len(training_filenames)) // BATCH_SIZE
print ('There are {} batches per training epoch and {} '\
       'batches per validation run.'\

       .format(BATCH_SIZE, steps_per_epoch, validation_steps))

Listing 1-8Create Training Splits and Steps

```

#### 创建函数来加载和处理 TFRecord 文件

创建一个函数来解析 TFRecord 文件，如清单 [1-9](#PC99) 所示。

```py
def read_tfrecord(example):
  features = {
      'image': tf.io.FixedLenFeature([], tf.string),
      'class': tf.io.FixedLenFeature([], tf.int64)
  }
  example = tf.io.parse_single_example(example, features)
  image = tf.image.decode_jpeg(example['image'], channels=3)
  image = tf.cast(image, tf.float32) / 255.0
  image = tf.reshape(image, [*IMAGE_SIZE, 3])
  class_label = example['class']
  return image, class_label

Listing 1-9Function to Parse a TFRecord

```

该函数接受一个 TFRecord 文件。字典保存 TFRecords 通用的数据类型。tf.string 数据类型将图像转换为字节字符串(字节列表)。tf.int64 将类标签转换为 64 位整数标量值。TFRecord 文件被解析成(图像，标签)元组。图像元素是 JPEG 编码的图像，被解码成 uint8 图像张量。图像张量被缩放到[0，1]范围，以便更快地训练。然后，它被重塑为模型消费的标准尺寸。class label 元素被转换为标量。

创建一个函数以 tf.data.Dataset 的形式加载 TFRecord 文件，如清单 [1-10](#PC100) 所示。

```py
def load_dataset(filenames):
  option_no_order = tf.data.Options()
  option_no_order.experimental_deterministic = False
  dataset = tf.data.TFRecordDataset(
      filenames, num_parallel_reads=AUTO)
  dataset = dataset.with_options(option_no_order)
  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)
  return dataset

Listing 1-10Function to Create a tf.data.Dataset from TFRecord Files

```

该函数接受 TFRecord 文件。为了获得最佳性能，包含了一次读取多个 TFRecord 文件的代码。options 设置允许顺序改变优化。这样， *n* 个文件被并行读取，为了提高读取速度，数据顺序被忽略。

创建一个函数，从 TFRecord 文件构建一个输入管道，如清单 [1-11](#PC101) 所示。

```py
def get_batched_dataset(filenames, train=False):
  dataset = load_dataset(filenames)
  dataset = dataset.cache()
  if train:
    dataset = dataset.repeat()
    dataset = dataset.shuffle(SHUFFLE_SIZE)
  dataset = dataset.batch(BATCH_SIZE)
  dataset = dataset.prefetch(AUTO)
  return dataset

Listing 1-11Function to Build an Input Pipeline from TFRecord Files

```

该函数接受 TFRecord 文件并调用 *load_dataset* 函数。该函数继续通过缓存、重复、混排、批处理和预取数据集来构建输入管道。重复和混排仅映射到训练数据，以遵循 Keras 数据集的最佳实践。

#### 创建训练集和测试集

实例化数据集:

```py
training_dataset = get_batched_dataset(
    training_filenames, train=True)
validation_dataset = get_batched_dataset(
    validation_filenames, train=False)
training_dataset, validation_dataset

```

显示图像并保留模型的形状:

```py
for img, lbl in training_dataset.take(1):
  plt.axis('off')
  plt.title(CLASSES[lbl[0].numpy()])
  fig = plt.imshow(img[0])
  tfr_flower_shape = img.shape[1:]

```

#### 模型数据

清除和播种:

```py
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建如清单 [1-12](#PC105) 所示的模型。

```py
tfr_model = Sequential([
  Conv2D(32, (3, 3), activation = 'relu',
         input_shape=tfr_flower_shape),
  MaxPooling2D(2, 2),
  Conv2D(64, (3, 3), activation='relu'),
  MaxPooling2D(2, 2),
  Conv2D(128, (3, 3), activation='relu'),
  MaxPooling2D(2),
  Conv2D(128, (3, 3), activation='relu'),
  MaxPooling2D(2, 2),
  Flatten(),
  Dense(512, activation='relu'),
  Dense(num_classes, activation='sigmoid')
])

Listing 1-12Create the Model

```

检查:

```py
tfr_model.summary()

```

编译:

```py
loss = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=True)

tfr_model.compile(optimizer='adam',
              loss=loss,
              metrics=['accuracy'])

```

火车:

```py
history = tfr_model.fit(training_dataset, epochs=EPOCHS,
                    verbose=1, steps_per_epoch=steps_per_epoch,
                    validation_steps=validation_steps,
                    validation_data=validation_dataset)

```

## 摘要

我们从三种类型的数据构建了 ML 输入管道示例。第一个实验从加载到内存中的数据构建管道。然后，我们从外部文件构建了一个管道。最后的实验从云存储中构建了一个管道。
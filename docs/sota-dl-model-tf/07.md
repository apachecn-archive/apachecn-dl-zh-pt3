# 7.高级迁移学习

我们通过基于几种迁移学习架构的代码示例来介绍高级迁移学习。代码示例使用这些体系结构训练学习模型。

章节的笔记本位于以下 URL:

[T2`https://github.com/paperd/deep-learning-models`](https://github.com/paperd/deep-learning-models)

## 迁移学习

迁移学习是基于这样一种想法，即网络为一个问题学习的特征可以在各种其他任务中重复使用。在 ML 和模式识别中，**特征**是正在观察的现象的单个可测量属性或特征。因此，有效的学习算法能够从数据中收集信息丰富、有鉴别能力和独立的特征。

迁移学习模型是惊人的，因为它们可以重用他们在新数据上学习的功能！利用迁移学习可以节省创建新模型、测试新模型和调整新模型直到得到预期结果的时间。此外，迁移学习模型是由经验丰富的数据科学家创建的，他们花了数年时间来调整和完善可用的迁移学习模型。

与从零开始训练的模型相比，迁移学习模型可以提高准确性，而无需花费太多时间来收敛。但这并不意味着一个预先训练好的模型明显优于一个从零开始创建的模型。当 ML 模型在训练期间达到一种状态，其中损失稳定在最终值附近的误差范围内时，ML 模型达到收敛。所以当额外的训练不能改善模型时，模型就会收敛。

在最近与一位数据科学家的交谈中，他告诉我们他从头开始创建了一些自己的模型。在当前的项目中，他正在使用一个现有的(预训练的)模型。对于其他项目，他建立自己的模型。只是看任务了。他还让我们知道，他不像关注收敛那样关注速度。请记住，此人拥有数据科学博士学位和多年的行业经验。

如果预先训练的神经网络是有效的，它学习的特征可以用于其他任务。当人类学习如何执行一项新任务时，我们很少从头开始。我们把我们一生中所学的东西都拿来快速学习新东西。我们常常可以从一个单一的训练例子中学习。但其他时候，它实际上阻碍了我们的发展。当然，婴儿不会这样学习，因为他们没有同等水平的先验知识。

我们在前一章中演示了迁移学习可以用在它从未见过的数据集上。在这一章，我们提出了一个新的预训练模型，以显示它如何与不同的数据集。我们还将向您展示如何在不使用 TensorFlow Hub 库的情况下直接实现迁移学习。正如我们通过实验证明的那样，直接实施迁移学习提供了更大的灵活性。

我们提出了四个迁移学习实验。我们从豆子实验开始。我们继续斯坦福的狗、花和石头剪刀布实验。我们坚信熟能生巧。每个实验的代码往往是相似的，但是每个数据集被不同地对待。

通过我们所有的实验，我们建立了 Colab 生态系统。所以从导入主 TensorFlow 库和实例化 GPU 开始。

## 导入 TensorFlow 库

导入库并将其别名为 **tf** :

```
import tensorflow as tf

```

将 TensorFlow 库别名为 tf 是常见的做法。

## GPU 硬件加速器

为了方便起见，我们提供了在 Colab 笔记本中启用 GPU 的步骤:

1.  点击左上角菜单中的*运行时*。

2.  从下拉菜单中点击*改变运行时间类型*。

3.  从*硬件加速器*下拉菜单中选择 *GPU* 。

4.  点击*保存*。

验证 GPU 是否处于活动状态:

```
tf.__version__, tf.test.gpu_device_name()

```

如果显示“/设备:GPU:0”，则 GPU 处于活动状态。如果'..'显示时，常规 CPU 处于活动状态。

Note

如果得到错误**名称****'****TF****'****未定义**，重新执行代码导入 TensorFlow 库！

## 豆子实验

*Beans* 是一个 TensorFlow 数据集(TFDS ),由智能手机相机在田间拍摄的豆类植物图像组成。它包括三类(豆锈病、角斑病、叶斑病、健康病)。三类中的两类是*角斑病*和*豆锈病*，这是可以降临到豆类植物上的疾病。第三类是*健康*。因此，这个数据集中的豆类植物要么是健康的，要么患有这两种疾病中的一种。乌干达国家作物资源研究所的专家对数据进行了注释，数据由 Makerere AI 研究实验室收集。

我们使用两个预训练模型对 beans 数据进行训练。其中一个模型对您来说是新的，另一个是在前一章中演示的 Inception。我们展示两者是为了对比。即使其中一个在这个数据集上比另一个更好，也不能保证它在另一个数据集上也是如此！但是，一旦你习惯了使用预先训练好的模型，使用它们就非常简单了。所以尝试不同的可能是一个好策略。

### 加载 Beans

从谷歌云服务(GCS)加载 beans 作为 TFDS:

```
import tensorflow_datasets as tfds

beans, beans_info = tfds.load(
    'beans', with_info=True, as_supervised=True,
    try_gcs=True)

```

虽然不是必需的，但我们建议从 GCS 加载 TFDS。

### 探索数据

显示元数据:

```
beans_info

```

为简单起见，将拆分分配给变量:

```
train = beans['train']
valid = beans['validation']
test = beans['test']

```

从元数据中，我们知道训练数据有 1，034 个示例，验证数据有 133 个示例，测试数据有 128 个示例。

获取标签和类别数量:

```
class_labels = beans_info.features['label'].names
num_classes = beans_info.features['label'].num_classes
class_labels, num_classes

```

检查图像尺寸:

```
for img, lbl in train.take(10):
  print (img.shape)

```

从样本来看，似乎所有图像都是 500 × 500 × 3。

### 设想

用 *show_examples* 可视化:

```
fig = tfds.show_examples(train, beans_info)

```

### 重新格式化图像

为异常模型调整大小和处理图像:

```
def preprocess(image, label):
  resized_image = tf.image.resize(image, [224, 224])
  final_image = tf.keras.applications.xception.\
                preprocess_input(resized_image)
  return final_image, label

```

我们将图像的大小调整为 224 × 224，这是异常图像的预期大小。我们使用 Xception 预处理 API 对调整大小的图像进行预处理，并返回最终的图像和标签。该函数将在下一节中使用。

### 构建输入管道

将培训、验证和测试数据转换为 TensorFlow 耗材对象:

```
BATCH_SIZE = 32
shuffle = 250

train_ds = train.shuffle(shuffle).\
  map(preprocess).batch(BATCH_SIZE).prefetch(1)
valid_ds = valid.map(preprocess).batch(BATCH_SIZE).prefetch(1)
test_ds = test.map(preprocess).batch(BATCH_SIZE).prefetch(1)

```

如清单 [7-1](#PC11) 所示可视化。

```
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 12))
for img, lbl in train_ds.take(1):
  for index in range(9):
    plt.subplot(3, 3, index + 1)
    plt.imshow(img[index] / 2 + 0.5)
    plt.title(class_labels[lbl[index]])
    plt.axis('off')

Listing 7-1Visualize

Training Examples

```

我们为手头的任务提供不同的可视化代码。请随意创建自己的可视化代码，以获得 Python 数据科学任务的经验。

### 异常模型

我们引入了 Xception 预训练模型来拓宽您的体验。此外，Xception 是最近向公众介绍的一个。

Xception 是在 ImageNet 数据集上预先训练的六个最先进的图像分类器之一。另外五个是 MobileNet、VGG16、VGG19、ResNet50 和 Inception-v3。在 ImageNet 数据集上，Xception 略优于 Inception-v3，在具有 17，000 个类(或更多)的更大图像分类数据集上，xception 远远优于 Inception-v3。最重要的是，它与 Inception 具有相同数量的模型参数，这意味着更高的计算效率。VGG16 和 VGG19 的卷积层数较少，但训练时间比 Xception 长得多。ResNet 模型大小相当，但 Xception 训练速度更快，产生的训练结果更好。

Xception 模型是 Francois Chollet 在 2017 年提出的。例外是 Inception 架构的扩展，它用深度方向可分离的卷积代替了标准的 Inception 模块。例外是在 ImageNet 上预先训练的。Xception 通常优于 VGGNet、ResNet 和 Inception-v3 模型。作为旁注，Chollet 也是 Keras 的作者。

#### 创建模型

清除和播种:

```
import numpy as np

tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建带有例外的基础模型:

```
Xception = tf.keras.applications.xception.Xception
xception_model = Xception(
    weights='imagenet', include_top=False)

```

通过设置 *include_top=False* 排除网络的顶层。因此，全局平均池层和密集输出层被排除在外，这意味着我们必须在分类头中包括这两个层。

为了训练得更快，我们排除了顶层。然而，所有层的训练可能会增加学习。我们将在本章的后面向您展示如何做到这一点。

探索基础模型层:

```
tf.keras.utils.plot_model(
    xception_model,
    show_shapes=True,
    show_layer_names=True)

```

tf.keras.utils.plot_model API 提供了异常模型的详细图形描述。

获取层数:

```
len(xception_model.layers)

```

例外有 132 层。

导入库:

```
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout,\
                                    GlobalAveragePooling2D

```

建立最终模型(分类头):

```
x_model = tf.keras.Sequential([
  xception_model,
  GlobalAveragePooling2D(),
  Dropout(0.5),
  Dense(num_classes, activation='softmax')])

```

我们排除了预训练网络的顶层，它有一个全局平均池层和一个密集输出层。因此，我们必须添加我们自己的全局平均池层和一个具有三个类和 softmax 激活的密集输出层。

获得最终模型的布局:

```
tf.keras.utils.plot_model(
    x_model,
    show_shapes=True,
    show_layer_names=True)

```

请注意我们最终模型的简单性！

#### 对数据建模

冻结预训练层的权重:

```
for layer in xception_model.layers:
  layer.trainable = False

```

我们添加前面的步骤来通知编译器我们冻结顶层的意图。

编译:

```
optimizer = tf.keras.optimizers.SGD(
    lr=0.2, momentum=0.9, decay=0.01)

x_model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer=optimizer,
    metrics=['accuracy'])

```

火车:

```
history = x_model.fit(
    train_ds, validation_data=valid_ds, epochs=10)

```

请注意，培训时间很少。

创建一个可视化训练表现的函数，如清单 [7-2](#PC22) 所示。

```
def visualize(span):
  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  epochs_range = span
  plt.figure(figsize=(8, 8))
  plt.subplot(1, 2, 1)
  plt.plot(epochs_range, acc, label='Training Accuracy')
  plt.plot(epochs_range, val_acc, label='Validation Accuracy')
  plt.legend(loc='lower right')
  plt.title('Training and Validation Accuracy')
  plt.subplot(1, 2, 2)
  plt.plot(epochs_range, loss, label='Training Loss')
  plt.plot(epochs_range, val_loss, label='Validation Loss')
  plt.legend(loc='upper right')
  plt.title('Training and Validation Loss')
  plt.show()

Listing 7-2Visualization Function

```

调用:

```
visualize(range(10))

```

Note

请确保为 visualize 函数提供一个范围，该范围等于模型接受训练的历元数。

我们设定了非常积极的学习率，但仍然取得了令人尊敬的成绩。尝试学习率，看看你是否能提高性能。

Note

将学习速率设置为较高的值通常可以使模型学习得更快。然而，成本可能是次优的最终权重集。将学习率设置为较低的值可以允许模型学习一组更优甚至全局最优的权重，但是训练时间可能会长得多。

#### 使用未冻结的图层对训练数据建模

验证准确性相当好，但是没有变得更好。所以最高层训练有素。也就是说，精确度达到了一个稳定水平。

现在我们已经准备好解冻所有层并继续训练，如清单 [7-3](#PC24) 所示。

```
for layer in xception_model.layers:
  layer.trainable = True

optimizer = tf.keras.optimizers.SGD(
    learning_rate=0.01, momentum=0.9,
    nesterov=True, decay=0.001)

x_model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer=optimizer, metrics=['accuracy'])

history = x_model.fit(
    train_ds, validation_data=valid_ds, epochs=10)

Listing 7-3Continue Training with All Layers Unfrozen

```

最初，一个好的策略是为了速度而冻结顶层训练。设定一个高的学习率可以进一步提高训练速度。一旦验证准确性达到稳定水平，我们就知道顶层是经过训练的。然后，我们可以通过解冻顶层并设置较低的学习速率来继续训练。我们使用一个较低的学习速率来避免损坏预训练的权重。

我们仍然在相同的模型上训练，直到我们清除模型会议。这就是为什么我们在训练新模型之前清除模型会话。

视觉化:

```
visualize(range(10))

```

### 具有 Inception 的模型 Beans

让我们来看看《盗梦空间》和《例外》相比如何。在本节中，我们将展示互换预先训练好的模型是多么容易。

*Inception-v3* 是一个预先训练好的卷积神经网络模型，深度为 48 层。这是一个已经在来自 ImageNet 数据库的 100 多万张图像上训练过的网络版本。预先训练的网络可以将图像分类为 1000 个对象类别，如键盘、鼠标、铅笔和许多动物。

#### 创建模型

清除和播种:

```
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建基础模型:

```
inception_v3 = tf.keras.applications.InceptionV3
inception_model = inception_v3(
    include_top=False, weights='imagenet',
    input_shape=(224, 224, 3))

```

探索基础模型层:

```
tf.keras.utils.plot_model(
    inception_model,
    show_shapes=True,
    show_layer_names=True)

```

获取层数:

```
len(inception_model.layers)

```

咻！《盗梦空间》极其庞大(311 层)和复杂！

创建最终模型:

```
i_model = tf.keras.Sequential([
  inception_model,
  GlobalAveragePooling2D(),
  Dropout(0.5),
  Dense(num_classes, activation='softmax')])

```

我们可以使用 shape (224，224，3)，因为 include_top 为 False。否则，对于初始状态，输入形状必须是(299，299，3)。

#### 对数据建模

冻结预训练层的权重:

```
for layer in inception_model.layers:
  layer.trainable = False

```

编译:

```
optimizer = tf.keras.optimizers.RMSprop(lr=0.1)

i_model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer=optimizer, metrics=['accuracy'])

```

火车:

```
history = i_model.fit(
    train_ds, validation_data=valid_ds, epochs=10)

```

视觉化:

```
visualize(range(10))

```

#### 使用未冻结的图层对训练数据建模

解冻所有层并继续训练，如清单 [7-4](#PC35) 所示。

```
for layer in inception_model.layers:
  layer.trainable = True

optimizer = tf.keras.optimizers.RMSprop(lr=0.0001)

i_model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer=optimizer, metrics=['accuracy'])

history = i_model.fit(
    train_ds, validation_data=valid_ds, epochs=10)

Listing 7-4Continue Training with All Layers Unfrozen

```

Note

Adagrad、Adadelta、RMSprop 和 Adam 等自适应梯度下降算法为经典 SGD 算法提供了替代方案。自适应算法提供了一种自动调整超参数的启发式方法，这避免了手动调整学习速率表的超参数所固有的昂贵工作。

视觉化:

```
visualize(range(10))

```

#### 对看不见的数据进行归纳

对未知的测试数据集进行归纳，以发现异常:

```
x_model.evaluate(test_ds)

```

对未见过的测试数据集进行归纳，以用于 Inception:

```
i_model.evaluate(test_ds)

```

## 斯坦福狗实验

我们已经演示了大型数据集实验，但是它们都不包含大量的类标签。斯坦福狗数据集包含了来自世界各地的 120 种狗的图片。数据集由 ImageNet 中的图像和注释构建，用于细粒度的图像分类任务。斯坦福狗包含 20，580 幅图像，分为 12，000 幅训练图像和 8，580 幅测试图像。为所有 12，000 幅图像提供了类别标签和边界框注释。

### 用 MobileNet 模拟斯坦福狗

*MobileNets* 是小型、低延迟、低功耗的型号，其参数化设计可满足各种用例的资源限制。预训练模型被认为是低功率模型，因为它们消耗少量的计算机资源。原因是他们已经受过训练了。初始训练确实会消耗大量的计算机资源。但是一旦经过训练，它们消耗的计算机资源非常少。它们可以用于分类、检测、嵌入和分割，类似于其他流行的大规模模型(如 Inception)的操作。

MobileNet-v2 型号是由谷歌开发的。它在 ImageNet 数据集上进行了预训练，ImageNet 数据集是一个由 140 万幅图像和 1000 个类组成的大型数据集。 *ImageNet* 是一个研究训练数据集，有各种各样的类别，如菠萝蜜和注射器。它的基础知识帮助我们从特定的数据集中对狗进行分类。

### 加载数据

从斯坦福狗训练数据加载训练集(训练分割):

```
train_pups, dogs_info = tfds.load(
    'stanford_dogs', with_info=True,
    as_supervised=True, try_gcs=True,
    split='train')

```

加载验证和测试集，每个测试集具有来自斯坦福狗测试数据的 50%分割(测试分割):

```
(validation_pups, test_pups) = tfds.load(
    'stanford_dogs',
    split=['test[:50%]', 'test[50%:]'],
    as_supervised=True, try_gcs=True)

```

### [计]元数据

显示元数据:

```
dogs_info

```

### 可视化示例

创建一个函数，从整数标签中获取名为的*标签:*

```
get_name = dogs_info.features['label'].int2str

```

通过反复试验，我们得到了所有的整数标签，并将它们转换为命名标签:

```
lbls = []
for image, label in train_pups.take(464):
  lbls.append(get_name(label))
set_lbl = set(lbls)
len(set_lbl)

```

变量 *set_lbl* 保存数据集的类标签。

从元数据中我们知道斯坦福狗有 120 节课。所以我们(通过反复试验)调整了样本的数量，直到我们得到了 120 个独特的标签！

抓取一些图像和标签进行可视化:

```
img, lbl = [], []
for image, label in train_pups.take(9):
  img.append(image)
  lbl.append(get_name(label)[10:])

```

显示第一个:

```
lbl[0]

```

显示一些例子，如清单 [7-5](#PC46) 所示。

```
plt.figure(figsize=(12, 12))
for index in range(9):
  plt.subplot(3, 3, index + 1)
  plt.imshow(img[index])
  plt.title(lbl[index])
  plt.axis('off')

Listing 7-5Display Examples

```

以简单的方式展示示例:

```
fig = tfds.show_examples(train_pups, dogs_info)

```

### 检查图像形状

举一些例子并展示图像形状:

```
for img, lbl in train_pups.take(10):
  print (img.shape)

```

由于图像大小不同，我们必须调整它们的大小:

### 构建输入管道

获取类别数:

```
num_classes = dogs_info.features['label'].num_classes
num_classes

```

我们已经知道了类的数量，但是我们将向您展示如何用一行代码获得这个数量。

创建管道变量:

```
IMG_LEN = 224
IMG_SHAPE = (IMG_LEN,IMG_LEN,3)
N_BREEDS = num_classes

```

创建一个预处理函数，如清单 [7-6](#PC51) 所示。

```
def preprocess(img, lbl):
  resized_image = tf.image.resize(img, [IMG_LEN, IMG_LEN])
  final_image = tf.keras.applications.mobilenet.preprocess_input(
      resized_image)
  label = tf.one_hot(lbl, N_BREEDS)
  return final_image, label

Listing 7-6Preprocessing Function

```

创建一个函数来构建输入管道，如清单 [7-7](#PC52) 所示。

```
def prepare(dataset, batch_size=None, shuffle_size=None):
  ds = dataset.map(preprocess, num_parallel_calls=4)
  ds = ds.shuffle(buffer_size=1000)
  if batch_size:
    ds = ds.batch(batch_size)
  if shuffle_size:
    ds = ds.shuffle(shuffle_size)
  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
  return ds

Listing 7-7Function to Build the Input Pipeline

```

构建管道:

```
BATCH_SIZE = 32
SHUFFLE_SIZE = 1000

train_dogs = prepare(train_pups, batch_size=BATCH_SIZE,
                     shuffle_size=SHUFFLE_SIZE)
validation_dogs = prepare(validation_pups, batch_size=32)
test_dogs = prepare(test_pups, batch_size=32)

```

### 创建模型

创建基础模型:

```
mobile_v2 = tf.keras.applications.MobileNetV2
mobile_model = mobile_v2(
    input_shape=IMG_SHAPE, include_top=False,
    weights='imagenet')

```

探索基础模型层:

```
tf.keras.utils.plot_model(
    mobile_model,
    show_shapes=True,
    show_layer_names=True)

```

获取层数:

```
len(mobile_model.layers)

```

清除和播种:

```
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建模型(冻结顶层):

```
mobile_model.trainable = False

sd_model = tf.keras.Sequential([
  mobile_model,
  GlobalAveragePooling2D(),
  Dropout(0.5),
  Dense(num_classes, activation='softmax')
])

```

### 编译和训练

编译并训练模型，如清单 [7-8](#PC59) 所示。

```
EPOCHS = 5

sd_model.compile(
    optimizer=tf.keras.optimizers.Adamax(learning_rate=0.005),
    loss='categorical_crossentropy',
    metrics=['accuracy', 'top_k_categorical_accuracy'])

history = sd_model.fit(
    train_dogs, epochs=EPOCHS, validation_data=validation_dogs)

Listing 7-8Compile and Train

```

因为我们要训练更多的图像和更多的类，所以训练时间要长得多。所以要有耐心。如果你的电脑崩溃了，不要担心。这不是一个错误。需要更多的内存。我们使用 Colab Pro，似乎没有问题。

Tip

如果您想要对真实世界的数据进行建模，您可能需要每月花费几美元来迁移到 Colab Pro。

视觉化:

```
visualize(range(EPOCHS))

```

可视化清单 [7-9](#PC61) 中显示的前五个预测。

```
acc = history.history['top_k_categorical_accuracy']
val_acc = history.history['val_top_k_categorical_accuracy']

epochs_range = range(EPOCHS)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Top 5 Training and Validation Accuracy')
plt.grid(b=None)

Listing 7-9Top Five Predictions

```

还不错！我们的品种检测准确率超过 80%。如果我们看看前五个预测，猜对品种的几率跃升至 97%以上！由于数据集庞大而复杂，我们展示了使用预训练模型可以有真实世界的用例。同样令人惊讶的是，我们只用几行代码就可以构建一个如此强大的模型！

### 使用未冻结的图层对训练数据建模

解冻所有层并继续训练，如清单 [7-10](#PC62) 所示。

```
mobile_model.trainable = True

sd_model.compile(
    optimizer=tf.keras.optimizers.Adamax(0.00001),
    loss='categorical_crossentropy',
    metrics=['accuracy', 'top_k_categorical_accuracy'])

history = sd_model.fit(
    train_dogs, epochs=3,
    validation_data=validation_dogs)

Listing 7-10Unfreeze All Layers and Continue Training

```

我们使用*低得多的学习速率*来避免损坏预先训练的权重。我们只跑三个纪元，因为训练时间太长了。

Note

为真实世界的用例设置低得多的学习率，就像我们对斯坦福狗所做的那样。

视觉化:

```
visualize(range(3))

```

### 推广

从看不见的数据中归纳:

```
sd_model.evaluate(test_dogs)

```

## 花卉实验

让我们使用存储为 TFRecords 的数据集。我们坚信用各种数据集练习有助于学习。

因为我们在前面的章节中使用了 flowers，所以在这一节中我们将不描述数据集。我们将 flowers 加载为 TFRecords，并使用预先训练好的模型进行学习。

### 将花读为 TFRecords

从 GCS 读取 TFRecord 文件:

```
piece1 = 'gs://flowers-public/'
piece2 = 'tfrecords-jpeg-192x192-2/*.tfrec'
TFR_GCS_PATTERN = piece1 + piece2
tfr_filenames = tf.io.gfile.glob(TFR_GCS_PATTERN)

```

### 创建数据拆分

设置管道和培训参数:

```
IMAGE_SIZE = [192, 192]
AUTO = tf.data.experimental.AUTOTUNE
BATCH_SIZE = 64
SHUFFLE_SIZE = 100
EPOCHS = 5
VALIDATION_SPLIT = 0.19
CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']

```

创建如清单 [7-11](#PC67) 所示的分割。

```
split = int(len(tfr_filenames) * VALIDATION_SPLIT)
training_filenames = tfr_filenames[split:]
validation_filenames = tfr_filenames[:split]
print ('Splitting dataset into {} training files and {}'
       'validation files'.\
       format(
           len(tfr_filenames), len(training_filenames),
           len(validation_filenames)), end = ' ')
print ('with a batch size of {}.'.format(BATCH_SIZE))

validation_steps = int(3670 // len(tfr_filenames) *\
                       len(validation_filenames)) // BATCH_SIZE
steps_per_epoch = int(3670 // len(tfr_filenames) *\
                      len(training_filenames)) // BATCH_SIZE
print ('There are {} batches per training epoch and {} '\
       'batches per validation run.'\
       .format(BATCH_SIZE, steps_per_epoch, validation_steps))

Listing 7-11Create Splits

```

### 创建函数来加载和处理 TFRecord 文件

演示如清单 [7-12](#PC68) 所示的单热编码。

```
named_lbl = 'sunflowers'
indx = CLASSES.index(named_lbl)
encode = tf.one_hot([indx], 5)
one_hot = encode[0].numpy()
print ('encoded label:', one_hot)
pos = tf.math.argmax(one_hot).numpy()
print ('integer label:', pos)

Listing 7-12Demonstrate One-Hot Encoding

```

使用 tf.one_hot() API 对命名标签进行编码。使用 tf.math.argmax() API 将独热编码标签转换为整数标签。

创建一个函数来解析 TFRecord 文件，如清单 [7-13](#PC69) 所示。

```
def read_tfrecord(example):
  features = {
      'image': tf.io.FixedLenFeature([], tf.string),
      'class': tf.io.FixedLenFeature([], tf.int64)
  }
  example = tf.io.parse_single_example(example, features)
  image = tf.image.decode_jpeg(example['image'], channels=3)
  image = tf.cast(image, tf.float32) / 255.0
  image = tf.reshape(image, [*IMAGE_SIZE, 3])
  class_label = example['class']
  one_hot = tf.one_hot(class_label, 5)
  return image, one_hot

Listing 7-13Function to Parse a TFRecord File

```

创建一个函数以 tf.data.Dataset 的形式加载 TFRecord 文件，如清单 [7-14](#PC70) 所示。

```
def load_dataset(filenames):
  option_no_order = tf.data.Options()
  option_no_order.experimental_deterministic = False
  dataset = tf.data.TFRecordDataset(
      filenames, num_parallel_reads=AUTO)
  dataset = dataset.with_options(option_no_order)
  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)
  return dataset

Listing 7-14Function to Load TFRecords as a tf.data.Dataset

```

创建一个函数，从 TFRecord 文件构建一个输入管道，如清单 [7-15](#PC71) 所示。

```
def get_batched_dataset(filenames, train=False):
  dataset = load_dataset(filenames)
  dataset = dataset.cache()
  if train:
    dataset = dataset.repeat()
    dataset = dataset.shuffle(SHUFFLE_SIZE)
  dataset = dataset.batch(BATCH_SIZE)
  dataset = dataset.prefetch(AUTO)
  return dataset

Listing 7-15Function to Build an Input Pipeline from TFRecord Files

```

### 创建训练集和测试集

实例化数据集:

```
training_dataset = get_batched_dataset(
    training_filenames, train=True)
validation_dataset = get_batched_dataset(
    validation_filenames, train=False)
training_dataset, validation_dataset

```

显示如清单 [7-16](#PC73) 所示的图像。

```
for img, lbl in training_dataset.take(1):
  plt.axis('off')
  label = tf.math.argmax(lbl[0]).numpy()
  plt.title(CLASSES[label])
  fig = plt.imshow(img[0])
  tfr_flower_shape = img.shape[1:]

Listing 7-16Display an Image

```

### 创建模型

创建预训练模型列表:

```
ptm =\
  [tf.keras.applications.MobileNetV2,
   tf.keras.applications.VGG16,
   tf.keras.applications.MobileNet,
   tf.keras.applications.xception.Xception,
   tf.keras.applications.InceptionV3,
   tf.keras.applications.ResNet50]

```

通过索引选择任何预训练的模型。我们使用异常创建一个基础模型:

```
pre_trained_model = ptm[3](
    weights='imagenet', include_top=False,
    input_shape=[*IMAGE_SIZE, 3])

```

清除和播种:

```
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建最终模型:

```
pre_trained_model.trainable = True

flower_model = tf.keras.Sequential([
  pre_trained_model,
  GlobalAveragePooling2D(),
  Dense(5, activation='softmax')])

```

我们使用异常预训练模型。我们删除特定于 ImageNet 的顶层，用 *include_top=false* 和一个 max pooling 和一个 softmax 层来预测五个 flower 类。请注意，我们还解冻了所有的顶层！不要试图用更大的数据集预先解冻所有图层！

### 编译和训练

编译:

```
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)

flower_model.compile(
    optimizer=optimizer,
    loss = 'categorical_crossentropy',
    metrics=['accuracy'])

```

初始学习率通常是唯一最重要的超参数。如果只能调整一个超参数，那么学习率就是值得调整的参数。方便的是，我们可以使用 *Adam* 优化器来自动调整学习速率！但是我们仍然必须设定初始学习率。

我们设置一个非常低的学习率，以便模型(有希望)学习到一个更优甚至全局最优的权重集。但是训练需要更长的时间。我们将学习率设置为一个较低的值，以确保梯度下降不会增加训练误差。最初，我们希望允许神经网络随机调整其权重。较低的学习率增加了随机性。更高的学习率减少了随机化。

火车:

```
history = flower_model.fit(
    training_dataset, epochs=EPOCHS,
    verbose=1, steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    validation_data=validation_dataset)

```

### 设想

可视化培训表现:

```
visualize(range(EPOCHS))

```

### 推广

我们对验证集进行归纳，因为我们没有分离出一个测试集:

```
flower_model.evaluate(validation_dataset)

```

## 石头剪刀布实验

最后的实验是用*石头剪刀布*数据集。数据集改编自石头剪子布游戏。该数据包含玩石头剪刀布游戏的手的图像。

石头剪子布是一种通常在两个人之间玩的手游戏，每个人同时伸出一只手形成三种形状中的一种。可能的形状有石头、布和剪刀。规则很简单。石头打败剪刀。纸打败了石头。剪刀打败了纸。比喻石头砸剪刀，纸盖石头，剪刀剪纸。

### 加载数据

加载训练集:

```
train_digits, rps_info = tfds.load(
    'rock_paper_scissors', with_info=True,
    split='train', as_supervised=True,
    try_gcs=True)

```

加载测试集:

```
test_digits = tfds.load(
    'rock_paper_scissors',  try_gcs=True,
    as_supervised=True, split='test')

```

检查张量:

```
for image, label in train_digits.take(5):
  print (image.shape, label.numpy())

```

显示元数据:

```
rps_info

```

### 设想

展示一些例子:

```
fig = tfds.show_examples(train_digits, rps_info)

```

### 构建输入管道

创建一个函数来处理图像和标签，如清单 [7-17](#PC87) 所示。

```
def process_digits(image, label):
  resized_image = tf.image.resize(image, [224, 224])
  final_image = tf.keras.applications.xception.\
                preprocess_input(resized_image)
  one_hot = tf.one_hot(label, 3)
  return final_image, one_hot

Listing 7-17Function to Process Data

```

标签应该是一次性编码的对象。

构建管道:

```
BATCH_SIZE = 64
shuffle = 250

train_fingers = train_digits.shuffle(shuffle).\
  map(process_digits).batch(BATCH_SIZE).prefetch(1)
test_fingers = test_digits.map(process_digits).\
  batch(BATCH_SIZE).prefetch(1)

```

### 创建模型

创建基础模型:

```
Xception = tf.keras.applications.xception.Xception
xception_model = Xception(
    weights='imagenet', include_top=False)

```

清除和播种:

```
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建最终模型:

```
pre_trained_model.trainable = True

fingers_model = tf.keras.Sequential([
  xception_model,
  GlobalAveragePooling2D(),
  Dense(3, activation='softmax')])

```

解冻所有层！

### 编译和训练

编译:

```
optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)

fingers_model.compile(
    optimizer=optimizer,
    loss = 'categorical_crossentropy',
    metrics=['accuracy'])

```

因为我们解冻了所有层，所以设置一个非常低的学习速率，以允许网络在早期训练时期随机平衡神经元权重。

火车:

```
history = fingers_model.fit(
    train_fingers, epochs=10,
    validation_data=test_fingers)

```

还不错！

### 设想

可视化培训表现:

```
visualize(range(10))

```

### 推广

对测试数据进行归纳:

```
fingers_model.evaluate(test_fingers)

```

## 提示和概念

有关调整迁移学习模型的其他技巧，请阅读

[T2`https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b`](https://medium.com/%2540kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b)

对于这个主题的全面(但可读的)理解，请阅读

[T2`https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a`](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)
# 四、利用 TensorFlow 数据集的深度学习

在前一章中，我们演示了如何使用 TFDS 对象。在这一章中，我们使用大型复杂的 TFDS 对象进行了两个端到端的深度学习实验。时尚 MNIST 和豆子数据集很小，包含简单的图像。

第一个实验使用了包含猫和狗的复杂图像的大型数据集。第二种方法处理包含人手复杂图像的数据集。人手数据集没有第一个实验中的大。两个实验都包括数据扩充以提高性能。我们的目标是帮助您使用更大、更复杂的数据集完成端到端的学习实验。

章节的笔记本位于以下 URL:

[T2`https://github.com/paperd/deep-learning-models`](https://github.com/paperd/tensorflow)

## 用猫和狗做的实验

我们用 *cats_vs_dogs* 数据集演示了一个端到端的例子。该数据集包含 23，262 个猫和狗的大图像示例。这个实验的目的是为你提供训练大型复杂 TFDS 的经验。我们鼓励您通过许多数据集来获得更多深度学习的经验。数据是关键！使用各种数据集会提供不同的体验，因为每个数据集都是唯一的。

Note

处理大型图像文件需要大量内存。因此，如果你的电脑崩溃，你可能需要投资更多内存或订阅谷歌的 Colab Pro 服务。在我们的电脑上，这个数据集有时会出现内存崩溃。但自从我们升级到 Colab Pro 后，我们就没有遇到任何问题。

## 导入 TensorFlow 库

导入库并将其别名为 **tf** :

```py
import tensorflow as tf

```

将 TensorFlow 库别名为 tf 是常见的做法。

## GPU 硬件加速器

为了方便起见，我们提供了在 Colab 笔记本中启用 GPU 的步骤:

1.  点击左上角菜单中的*运行时*。

2.  从下拉菜单中点击*改变运行时间类型*。

3.  从*硬件加速器*下拉菜单中选择 *GPU* 。

4.  点击*保存*。

验证 GPU 是否处于活动状态:

```py
tf.__version__, tf.test.gpu_device_name()

```

如果显示“/设备:GPU:0”，则 GPU 处于活动状态。如果'..'显示时，常规 CPU 处于活动状态。

Note

如果出现错误**名称‘TF’未定义**，请重新执行代码以导入 TensorFlow 库！

## 开始实验

使用新数据集时，最好浏览其元数据。然后，我们可以就如何分割做出明智的决定。

### 加载 TFDS 对象

使用简单参数加载数据集以获取其元数据:

```py
import tensorflow_datasets as tfds

data, info = tfds.load(name='cats_vs_dogs', with_info=True,
                       try_gcs=True)

```

因为数据集包含 20，000 多幅大图像，所以加载数据集的时间会稍长一些。但是一旦数据集被加载到内存中，重新加载数据集是非常快的。损坏的图像会被自动跳过。

### [计]元数据

显示信息对象的内容:

```py
info

```

这个对象包含了很多信息。但是我们只需要从中获取一些信息。虽然您可能不需要对象中包含的大量信息，但显示它并通读可用的内容并无大碍。

获取类别标签和类别数量:

```py
class_labels = info.features['label'].names
num_classes = info.features['label'].num_classes
class_labels, num_classes

```

从元数据中，我们看到数据集是*而不是*预分割的。所以我们必须自己拆分数据。我们选择将 80%用于定型集，10%用于验证集，10%用于测试集。如果你愿意，你可以选择不同的分割方式。

显示分割信息:

```py
num_train_img = info.splits['train[0%:80%]'].num_examples
num_validation_img = info.splits['train[80%:90%]'].num_examples
num_test_img = info.splits['train[90%:100%]'].num_examples
print ('train images:', num_train_img)
print ('validation images:', num_validation_img)
print ('test images:', num_test_img)

```

使用我们的分割方案(80:10:10)，我们应该有 18，610 个样本用于训练，2，326 个样本用于验证，2，326 个样本用于测试。将数据分为训练、验证和测试部分的动机是从训练数据中学习，从验证数据中调整，从测试数据中归纳。

Note

我们实际上并没有拆分这一部分的数据。我们只是向您展示在我们的拆分方案中，每次拆分会有多少个示例。

虽然常见的情况是将数据分为训练和测试两部分，但再添加一个部分以保留模型从未涉及的一些数据是有利的。通过三次拆分，训练数据用于学习，验证数据用于调整和优化，测试数据用于评估可推广性。仅仅通过训练和测试，我们就必须从测试集中进行调优和归纳。由于模型触及了测试集，所以它并不完全是新数据！

验证分割百分比:

```py
train_num = num_train_img /23262
validation_num = num_validation_img /23262
test_num = num_test_img /23262

'{0:.0%}'.format(train_num), '{0:.0%}'.format(validation_num),\
'{0:.0%}'.format(test_num)

```

由于数据集包含 23，262 幅图像，我们通过除以该数字来验证每组中的图像数。

### 拆分数据

我们可以将数据加载到一个容器中，并手动执行所需的拆分。或者，我们可以在 split 参数中包含拆分信息，如下所示:

```py
(training_set, validation_set, test_set), info = tfds.load(
    'cats_vs_dogs', with_info=True,
    split=['train[:80%]', 'train[80%:90%]',
           'train[90%:]'], shuffle_files=True,
    as_supervised=True, try_gcs=True)

```

该代码在一个步骤中将 80%的数据加载到定型集中，10%的数据加载到验证集中，10%的数据加载到测试集中。之前，我们演示了如何一步加载训练集和测试集。

手动验证每个分割中的样本数量:

```py
len(list(training_set)), len(list(validation_set)),\
len(list(test_set))

```

列表操作需要一些时间，因为每个张量例子都被处理成一个列表。所以我们**不**建议对非常大的数据集执行这个操作！

### 设想

让我们想象一下训练集中的一些例子，看看图像和标签是什么样子的。我们可以想象三种方式。

用 show_examples 显示示例:

```py
fig = tfds.show_examples(training_set, info)

```

将示例显示为数据帧:

```py
tfds.as_dataframe(training_set.take(4), info)

```

为了最大限度地控制，请手动显示示例。首先举几个例子:

```py
images, labels = [], []
for img, lbl in training_set.take(4):
  img = tf.squeeze(img)
  images.append(img), labels.append(lbl)

```

继续可视化清单 [4-1](#PC13) 中所示的示例。

```py
import matplotlib.pyplot as plt

rows, cols = 2, 2
plt.figure(figsize=(10, 10))
for i in range(rows*cols):
  plt.subplot(rows, cols, i + 1)
  plt.imshow(images[i], cmap='bone')
  t = class_labels[labels[i]] + ' (' +\
      str(labels[i].numpy()) + ')'
  plt.title(t)
  plt.axis('off')

Listing 4-1Visualize Examples

```

现在，我们对数据集中的例子有了一个概念。

### 检查示例

举一些例子，并将它们转换成 NumPy 数组，如清单 [4-2](#PC14) 所示。

```py
features, labels = [], []
for img, lbl in training_set.take(4):
  img = tfds.as_numpy(img)
  lbl = tfds.as_numpy(lbl)
  features.append(img)
  labels.append(lbl)

Listing 4-2Add NumPy Examples to Lists

```

在可视化示例时，使用 NumPy 数组更容易。

如清单 [4-3](#PC15) 所示可视化。

```py
rows, cols = 2, 2
plt.figure(figsize=(10, 10))
for i in range(rows*cols):
  c = class_labels[labels[i]]
  s = str(features[i].shape)
  title = c + ' ' + s
  plt.subplot(rows, cols, i + 1)
  plt.title(title)
  plt.imshow(features[i], cmap='binary')
  plt.axis('off')

Listing 4-3Visualize Inspected Examples

```

### 重新格式化图像

创建一个调整图像大小和缩放图像的函数:

```py
def format_image(image, label):
  image = tf.image.resize(image, (150, 150))/255.0
  return image, label

```

使用较小的图像训练模型会更快。所以把图片尺寸调整到 150 × 150 像素。缩放图像以提高训练效果。

Note

将图像调整到较小的尺寸时，一些信息会丢失。但是 tf.image.resize 很好地保留了尽可能多的信息。我们将图像大小调整为 150 × 150，以保留大部分信息，同时提高学习速度。尝试不同的大小，看看对性能的影响。

下一节将使用该函数来帮助构建输入流水线。

### 构建输入流水线

通过为学习模型准备训练、验证和测试集来构建输入流水线。

设定批处理和随机播放参数:

```py
BATCH_SIZE = 200
SHUFFLE_SIZE = 500

```

Tip

试验批量和随机大小，看看学习成绩是如何受到影响的。

转换数据以获得最佳性能:

```py
train_batches = training_set.shuffle(SHUFFLE_SIZE).\
map(format_image).batch(BATCH_SIZE).cache().prefetch(1)

validation_batches = validation_set.\
map(format_image).batch(BATCH_SIZE).cache().prefetch(1)

test_batches = test_set.\
map(format_image).batch(BATCH_SIZE).cache().prefetch(1)

```

通过批处理，减少了训练时间。通过混洗，准确度通常会提高。缓存有助于更好地管理内存，预取应该可以减少训练时间。

检查张量:

```py
train_batches, validation_batches, test_batches

```

### 可视化并检查批次中的样品

参加第一批培训:

```py
for img, lbl in train_batches.take(1):
  print (img.shape)

```

检查该批次的第一个样品:

```py
img[0].shape, class_labels[lbl[0].numpy()]

```

该示例包含一个 150 × 150 × 3 的“狗”或“猫”图像。因为随机效应，我们无法知道是哪一个。

将四个示例提取到列表中:

```py
images, labels = [], []
for i in range(4):
  tf.squeeze(img[i])
  images.append(img[i]), labels.append(lbl[i])

```

挤出 *1* 维度，因为 *imshow()* 函数需要一个 2D 矩阵。

可视化如清单 [4-4](#PC23) 所示的图像。

```py
rows, cols = 2, 2
plt.figure(figsize=(10, 10))
for i in range(rows*cols):
  plt.subplot(rows, cols, i + 1)
  plt.imshow(images[i], cmap='bone')
  t = class_labels[labels[i]] + ' (' +\
      str(labels[i].numpy()) + ') ' +\
      str(images[i].shape)
  plt.title(t)
  plt.axis('off')

Listing 4-4Visualize Batched Examples

```

### 建立模型

获取输入形状:

```py
for img, lbl in train_batches.take(1):
  in_shape = img.shape[1:]
in_shape

```

导入库:

```py
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D,\
Dense, Flatten, Dropout

```

清除和播种:

```py
import numpy as np

tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建一个函数来构建模型，如清单 [4-5](#PC27) 所示。

```py
def build_model():
  model = \
  Sequential([
  Conv2D(32, (3, 3), activation = 'relu',
         input_shape=in_shape, strides=1,
         kernel_regularizer='l1_l2'),
  MaxPooling2D(2, 2),
  Conv2D(64, (3, 3), activation='relu'),
  MaxPooling2D(2, 2),
  Conv2D(128, (3, 3), activation='relu'),
  MaxPooling2D(2),
  Conv2D(128, (3, 3), activation='relu'),
  MaxPooling2D(2, 2),
  Flatten(),
  Dense(512, activation='relu'),
  Dense(num_classes, activation='sigmoid')])
  return model

Listing 4-5Multilayered CNN Model

```

我们创建了一个函数来保存这个实验的模型。我们这样做是为了向您展示如何使用函数来实现这一点。

该模型从四个 Conv2D 层和四个相关的 MaxPooling2D 层开始。一个 *Conv2D* 层计算给定输入和 4D 滤波张量的 2D 卷积。在我们的例子中，张量的维数是(200，150，150，3)。输入张量是一批 200 幅 150 × 150 的彩色图像。*最大池 2D* 图层对 2D 空间数据执行最大池操作。因此，每个 max pooling 操作都会减少从每个 Conv2D 图层接收的 2D 空间数据的维数。我们使用 2 × 2 的池大小，因为我们在这个大小下体验到了良好的性能。

*卷积层*对原始图像或其他特征图应用滤镜。最重要的参数是颗粒的数量和大小。*池化层*执行最大池化或平均池化以降低网络的维度。我们在每个卷积层之后使用一个池层来减少卷积层产生的维数。最大池取筛选区域中的最大值，而平均池取筛选区域中的平均值。

第一个 Conv2D 层接受内核数量、内核大小、输入形状、步幅和正则化。我们使用 3 × 3 的内核大小，因为在这个大小下我们体验到了良好的性能。我们添加了 l1 和 l2 正则化来减少过拟合。*内核*是用于从图像中提取特征的过滤器。具体来说，核是一个矩阵，它在输入数据上移动，与输入数据的子区域执行点积，并获得作为点积矩阵(或特征图)的输出。一个*特征图*捕获将过滤器(或内核)应用于输入图像的结果。

可视化特定输入图像的特征地图的原因是试图获得对我们的 CNN 检测到什么特征的一些理解。我们对数据应用几个卷积层，因为我们希望每一层都产生特征图，帮助我们检测越来越清晰的特征。

剩余的 Conv2D 层增加了内核大小，以提高模型性能。在每个 Conv2D 层之后是 MaxPooling2D，以减少卷积带来的维数。每个 Conv2D 层使用整流线性单元(ReLU)激活，以解决 sigmoid 分布中出现的梯度消失问题。

平坦层为密集层准备来自卷积层的输出。密集图层需要一个长特征向量作为输入。包括两个完全连接的密集层用于输出的分类。

创建模型:

```py
cat_dog_model = build_model()

```

检查模型:

```py
cat_dog_model.summary()

```

要获得将正则化应用于学习模型的大量资源，请阅读

[T2`www.machinecurve.com/index.php/2020/01/23/how-to-use-l1-l2-and-elastic-net-regularization-with-keras/`](http://www.machinecurve.com/index.php/2020/01/23/how-to-use-l1-l2-and-elastic-net-regularization-with-keras/)

### 编译和训练模型

编译:

```py
loss = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=True)

cat_dog_model.compile(optimizer='adam',
              loss=loss,
              metrics=['accuracy'])

```

由于模型输出 logit，因此设置*from _ logit = True*。模型输出 logits，因为我们在模型的输出层使用了 sigmoid 激活函数。

火车:

```py
epochs = 10
history = cat_dog_model.fit(
    train_batches, epochs=epochs, verbose=1,
    validation_data=validation_batches)

```

模型从训练集学习，并用验证集进行验证。模型永远不会触及测试集。

### 评估模型的可推广性

对测试批次使用评估方法:

```py
metrics = cat_dog_model.evaluate(test_batches)

```

*evaluate()* 方法返回损失值和精度值。我们使用 *test_batches* 来评估可推广性，因为模型从未见过这个数据集。**泛化**是一个学习模型恰当地适应新的、以前未见过的数据的能力，这些数据来自与用于创建模型的分布相同的分布。

### 可视化性能

创建一个可视化函数，如清单 [4-6](#PC33) 所示。

```py
def viz(hd):
  acc = hd['accuracy']
  val_acc = hd['val_accuracy']
  loss = hd['loss']
  val_loss = hd['val_loss']
  plt.figure(figsize=(8, 8))
  plt.subplot(1, 2, 1)
  plt.plot(acc, label='Training Accuracy')
  plt.plot(val_acc, label='Validation Accuracy')
  plt.legend(loc='lower right')
  plt.title('Training and Validation Accuracy')
  plt.subplot(1, 2, 2)
  plt.plot(loss, label='Training Loss')
  plt.plot(val_loss, label='Validation Loss')
  plt.legend(loc='upper right')
  plt.title('Training and Validation Loss')
  plt.show()

Listing 4-6Plot Model Performance

```

调用函数:

```py
viz(history.history)

```

该模型是过度拟合的，因为测试精度与训练精度不是非常一致。

## 增加预处理层

为了减轻过度拟合并提高模型性能，我们对数据扩充进行了实验。应用随机水平翻转、随机旋转和随机缩放，如清单 [4-7](#PC35) 所示。

```py
from tensorflow.keras import layers

data_augmentation = tf.keras.Sequential(
  [
    layers.experimental.preprocessing.RandomFlip('horizontal'),
    layers.experimental.preprocessing.RandomRotation(0.1),
    layers.experimental.preprocessing.RandomZoom(0.1),
  ]
)

Listing 4-7Keras Preprocessing Layers

for Transformation

```

我们基于反复试验选择使用这些层。随意试验其他层。

Note

这种转换操作是实验性的，这意味着它可能会在未来发生变化。

显示如清单 [4-8](#PC36) 所示的增强图像。

```py
plt.figure(figsize=(10, 10))
for images, _ in train_batches.take(1):
  for i in range(9):
    augmented_images = data_augmentation(images)
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(augmented_images[0])
    plt.axis('off')

Listing 4-8Display an Augmented Image

```

该可视化显示了多次应用于同一图像的数据扩充。在 *plt.imshow* 代码语句中，将索引从 0(在 *augmented_images[0]* 中)更改为 1 到 199(批量大小 200)之间，以查看不同的图像。

### 建立模型

通过清除以前的会话、生成种子并为实验创建模型来构建模型。

清除和播种:

```py
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建如清单 [4-9](#PC38) 所示的模型。

```py
cat_dog_layers = Sequential([
  data_augmentation,
  Conv2D(32, (3, 3), activation = 'relu',
         input_shape=in_shape, strides=1,
         kernel_regularizer='l1_l2'),
  MaxPooling2D(2, 2),
  Conv2D(64, (3, 3), activation='relu'),
  MaxPooling2D(2, 2),
  Conv2D(128, (3, 3), activation='relu'),
  MaxPooling2D(2),
  Conv2D(128, (3, 3), activation='relu'),
  MaxPooling2D(2, 2),
  Flatten(),
  Dense(512, activation='relu'),
  Dense(num_classes, activation='sigmoid')
])

Listing 4-9Model with Augmentation Layer

```

请注意，第一层是我们创建的增强！因此，该模型从第一层获得增强，并像其他卷积模型一样从该点向前继续。

### 编译和训练模型

编译:

```py
cat_dog_layers.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(
        from_logits=True),
    metrics=['accuracy'])

```

火车:

```py
epochs = 10
history = cat_dog_layers.fit(
    train_batches, epochs=epochs, verbose=1,
    validation_data=validation_batches)

```

### 评估模型的可推广性

评估:

```py
metrics = cat_dog_layers.evaluate(test_batches)

```

数据扩充并不能保证更好的性能。这只是一种可以用于那个目的的技术。此外，我们只运行这个模型十个时期。因此，可能需要更多的纪元才能看到更好的性能。

### 可视化性能

可视化培训表现:

```py
viz(history.history)

```

过度拟合有所缓解。试着多运行几次实验，看看会发生什么。

## 对图像应用数据增强

通过直接在图像上执行变换来应用数据扩充。

创建函数来放大图像，如清单 [4-10](#PC43) 所示。

```py
def random_crop(image):
    shape = tf.shape(image)
    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100
    return tf.image.random_crop(image, [min_dim, min_dim, 3])

def preprocess(image, label):
  cropped_image = random_crop(image)
  cropped_image = tf.image.random_flip_left_right(cropped_image)
  resized_image = tf.image.resize(cropped_image, [150, 150])
  final_image = tf.keras.applications.xception.preprocess_input(
      resized_image)
  return final_image, label

Listing 4-10Functions That Apply Augmentations on Images

```

*random_crop* 功能随机裁剪图像。*预处理*函数调用 random_crop，从左到右随机翻转图像，并调整它们的大小。*TF . keras . applications . xception . preprocess _ input*实用程序通过对一批图像进行编码来预处理张量(或 NumPy 数组)。通过研究和实验，我们发现这些增强提高了性能并减轻了过度拟合。尝试不同的增强，看看会发生什么。

### 构建输入流水线

导入*部分*包:

```py
from functools import partial

```

部分包允许我们创建部分函数。部分函数允许我们固定一个函数的一定数量的参数，并生成一个新的函数。

设定批处理和随机播放大小参数:

```py
BATCH_SIZE = 200
SHUFFLE_SIZE = 500

```

Tip

试验批量和随机大小，看看学习成绩是如何受到影响的。

构建流水线:

```py
train_shuffle = training_set.shuffle(1000)
train_batches = train_shuffle.map(partial(preprocess)).\
  batch(BATCH_SIZE).prefetch(1)
validation_batches = validation_set.map(preprocess).\
  batch(BATCH_SIZE).prefetch(1)
test_batches = test_set.map(preprocess).\
  batch(BATCH_SIZE).prefetch(1)

```

在预处理函数上设置 partial 可以固定它的参数，这样我们就可以只对来自训练集的图像*应用变换！我们不需要增加其他数据集，因为模型只从训练集中学习。*

### 显示增强图像

下面是清单 [4-11](#PC47) 中显示的图像增强效果。

```py
plt.figure(figsize=(10, 10))
for images, _ in train_batches.take(1):
  for i in range(9):
    augmented_images = data_augmentation(images)
    Images = np.clip(augmented_images, 0, 1)
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(Images[0])
    plt.axis('off')

Listing 4-11Visualize Augmentations on an Image

```

我们在该批次的第一幅图像上显示放大图像。尝试使用索引号来查看该批 200 幅图像中任意一幅的放大。一定要选择 0 到 199 之间的索引，因为批量大小是 200！

### 建立模型

清除和播种:

```py
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建模型:

```py
cat_dog_images = build_model()

```

### 编译和训练模型

编译:

```py
cat_dog_images.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(
        from_logits=True),
    metrics=['accuracy'])

```

火车:

```py
epochs = 5
history = cat_dog_images.fit(
    train_batches, epochs=epochs,
    verbose=1, validation_data=validation_batches)

```

我们只训练几个时期，因为训练时间随着我们应用于图像的增强而显著增加。试验一下历元的数量，看看会发生什么。

### 评估模型的可推广性

评估:

```py
cat_dog_images.evaluate(test_batches)

```

我们使用测试集，因为它从未被模型看到过。

Note

准确性可能看起来更低，但实际上并非如此。原因是我们可能需要运行模型更多的时期。这就是为什么我们鼓励你去试验纪元的数量。

### 可视化性能

可视化培训表现:

```py
viz(history.history)

```

验证精度轨迹好得多！也就是说，训练值和测试值更加一致。

### 预言

为了完成这个实验，让我们看看这个模型从测试集中预测的有多好。我们可以对整个测试数据集或数据集中的一批数据进行预测。

首先对整个测试数据集进行预测，并显示第一个示例的预测数组:

```py
predictions =cat_dog_images.predict(test_batches)
list(predictions[0])

```

在 *test_batches* 上预测，因为它从未被模型看到过。 *predict()* 方法返回 NumPy 个预测数组。对于分类实验，预测数组中的每个元素代表一个类别标签。由于我们的实验中有两个类(猫和狗)，每个预测数组包含两个元素。猫的预测是数组中的第一个值，狗的预测是第二个值。每个值都是预测的概率。概率的大小表示该元素是预测类的可能性。因此，预测数组中两个元素之间的较高概率代表预测。例如，预测数组[0.33，0.778]意味着预测是狗，因为它具有更高的概率。

返回第一个示例的预测:

```py
first_prediction = tf.math.argmax(predictions[0])
class_labels[first_prediction.numpy()]

```

*tf.math.argmax()* API 返回张量轴上最大值的索引。简单地说，它返回预测数组中具有最高值的索引。

我们还可以对单个批次进行预测:

```py
first_batch = test_batches.take(1)
predict_batch = cat_dog_images.predict(first_batch)

```

取第一批，对其进行预测。

获取批处理中第一个示例的预测:

```py
first_batch_prediction = tf.math.argmax(predict_batch[0])
class_labels[first_batch_prediction.numpy()]

```

获取第一个实际标签:

```py
for image, label in first_batch:
  print ('batch size:', image.shape[0])
class_labels[label[0].numpy()]

```

从第一批中抓取实际图像和标签。显示第一个实际图像形状及其相应的标签。如果预测与实际标签相符，则预测正确！

手动检查预测精度，如清单 [4-12](#PC59) 所示。

```py
cnt = 0
for i in range(image.shape[0]):
  pred = tf.math.argmax(predict_batch[i]).numpy()
  actual = label[i].numpy()
  if actual == pred:
    cnt += 1
acc = cnt / image.shape[0]
'{percent:.2%}'.format(percent=acc) + ' accuracy'

Listing 4-12Check Prediction Accuracy

```

该代码计算测试数据的预测准确性，并将其显示为百分比。

### 可视化预测

从测试集中获取第一批图像和标签:

```py
for img, lbl in test_batches.take(1):
  print (img.shape)

```

每批包含 200 张 150 × 150 的彩色图像。

检查第一批中的第一张图像:

```py
img[0].shape, class_labels[lbl[0].numpy()]

```

形象化:

```py
Image= np.clip(img[0], 0, 1)
fig = plt.imshow(Image)
fig = plt.axis('off')

```

我们使用*TF . keras . applications . xception . preprocess _ input*实用程序对图像进行预处理(参见清单 [4-10](#PC43) 中的预处理函数)。该实用程序实例化了 Xception 体系结构，以获得最佳性能。但是，它不能缩放图像。因此，我们必须将图像像素转换为 0 到 1 之间的值，以便适当地显示它们。

处理一些例子:

```py
images, labels = [], []
for i in range(20):
  tf.squeeze(img[i])
  images.append(img[i]), labels.append(lbl[i])

```

创建一个函数来显示一组图像和标签。该函数确定预测是正确还是不正确。正确预测的标题正常显示，但错误预测的标题以红色文本显示。

创建如清单 [4-13](#PC64) 所示的函数。

```py
def display_test(feature, target, num_images,
                 n_rows, n_cols, cl, p):
  for i in range(num_images):
    plt.subplot(n_rows, 2*n_cols, 2*i+1)
    Image= np.clip(feature[i], 0, 1)
    plt.imshow(Image)
    pred = cl[tf.math.argmax(p[i]).numpy()]
    actual = cl[target[i]]
    title_obj = plt.title(actual + ' (' +\
                          pred + ') ')
    if pred == actual:
      title_obj
    else:
      plt.getp(title_obj, 'text')
      plt.setp(title_obj, color='r')
    plt.tight_layout()
    plt.axis('off')

Listing 4-13Function to Display Predictions Against Actual Labels

```

调用函数:

```py
num_rows, num_cols = 5, 4
num_images = num_rows*num_cols
plt.figure(figsize=(20, 20))
display_test(images, labels, num_images, num_rows,
             num_cols, class_labels, predictions)

```

图像显示时带有标题。每个标题都显示了实际的标签，括号中是预测。如果预测不正确，标题显示为红色。

Note

虽然我们应用的学习模型对深度学习的新手爱好者来说可能看起来很复杂，但它们真的非常简单。随着您获得学习模型的经验，您将获得构建更复杂模型或迁移到迁移学习模型的信心。我们将在本书中讨论迁移学习模型。

## 石头剪刀布的实验

虽然我们刚刚完成了一个大型复杂数据集的实验，但我们认为，在多个数据集上练习深度学习对于成为一名合格的从业者至关重要。在我们的研讨会上，我们发现当参与者能够将他们所学的应用到另一个环境中时，他们会学得更快。在这种情况下，它是一个新的数据集。实验在石头剪刀布数据集上进行，该数据集包含 2892 张玩石头剪刀布游戏的手的图像。

### 配置张量板

**TensorBoard** 是一个在机器学习工作流程中提供测量和可视化的工具。它跟踪损失、准确性、模型图可视化以及将投影嵌入到低维空间等指标。在这个实验中，我们向您展示 TensorBoard，以提供对另一个可视化工具的访问。

对于一个好的教程，请仔细阅读

[T2`www.tensorflow.org/tensorboard/get_started`](http://www.tensorflow.org/tensorboard/get_started)

加载 TensorBoard 笔记本扩展:

```py
%load_ext tensorboard

```

导入我们在实验中使用的必备库:

```py
import datetime

```

清除以前运行的日志:

```py
!rm -rf ./logs/

```

### 加载数据

加载训练集和测试集:

```py
(train_digits, test_digits), rps_info = tfds.load(
    'rock_paper_scissors', with_info=True,
    data_dir='tmp', as_supervised=True,
    split=['train', 'test'])

```

### 检查数据

我们认为探索一个新的数据集以了解其配置是一个好主意。因此，我们获得元数据对象，可视化一些示例，并获得训练和测试示例的数量、示例形状和标签名称。我们需要知道所有这些信息来进行实验。

获取元数据:

```py
rps_info

```

视觉化:

```py
fig = tfds.show_examples(train_digits, rps_info)

```

获取标签的示例和数量:

```py
train_examples = rps_info.splits['train'].num_examples
test_examples = rps_info.splits['test'].num_examples
num_labels = rps_info.features['label'].num_classes
train_examples, test_examples, num_labels

```

获取形状:

```py
rps_info.features['image'].shape,\
rps_info.features['label'].shape

```

获取标签名称:

```py
label_name = rps_info.features['label'].int2str
for lbl in range(num_labels):
  print (label_name(lbl), end=' ')

```

检查图像形状:

```py
for image, label in train_digits.take(5):
  print (image.shape)

```

### 预处理数据

下一步是预处理数据，供学习模型使用。我们首先获取当前图像一半大小的值。我们用这个来重塑图像。我们选择这个尺寸是为了减少训练时间。通过选择这个大小，我们发现该模型仍然表现良好。我们鼓励你尝试不同的图像尺寸，看看学习是如何受到影响的。我们也缩放和调整图像大小。请记住，学习模型在较小的像素尺寸下效果更好。缩放是在不影响学习的情况下缩小图像大小的最佳方式。

创建图像大小减半的形状:

```py
new_pixels = rps_info.features['image'].shape[0] // 2
new_pixels

```

创建预处理函数:

```py
def format_digits(image, label):
  image = tf.cast(image, tf.float32) / 255.
  image = tf.image.resize(image, [new_pixels, new_pixels])
  return image, label

```

预处理训练集和测试集:

```py
train_original = train_digits.map(format_digits)
test_original = test_digits.map(format_digits)

```

探索一个例子:

```py
for image, label in train_original.take(1):
  finger_img_shape = image.shape
  print (image.shape, image[0][0].numpy(), label.numpy())

```

我们总是在预处理后探索至少一个例子，看看它看起来怎么样。

### 可视化处理后的数据

创建一个可视化函数，如清单 [4-14](#PC80) 所示。

```py
def preview_dataset(dataset):
  plt.figure(figsize = (12, 12))
  plot_index = 0
  for image, label in dataset.take(12):
    plot_index += 1
    plt.subplot(3, 4, plot_index)
    plt.axis('Off')
    label = label_name(label.numpy())
    plt.title(label)
    plt.imshow(image.numpy())

Listing 4-14Visualization Function

```

调用函数:

```py
preview_dataset(train_original)

```

### 扩充训练数据

我们包括数据增强以改善学习。我们选择了基于实验的增强。为了灵活起见，我们将不同的扩充分成不同的函数。我们使用所有的增强功能进行实验，但是您可以使用一个或多个功能进行新的实验。您甚至可以跳过增强步骤来查看模型在未增强的训练数据下的学习效果。

增强是一门艺术。我们还没有发现任何关于如何系统地增强给定数据集的应用深度学习研究。深度学习算法已经存在很多年了，但它们的应用却是最近的事情。一个很大的原因是计算能力远不及现在。而且便宜很多！另一个原因是 TensorFlow 作为开源产品才出现了几年。

#### 创建数据增强功能

我们现在创建翻转、着色、旋转、反转和缩放图像的函数。

创建一个函数来随机翻转图像:

```py
def flip(image: tf.Tensor) -> tf.Tensor:
  image = tf.image.random_flip_left_right(image)
  image = tf.image.random_flip_up_down(image)
  return image

```

Note

用 *tf 将图像转换成张量。张量* API。

创建一个随机增加颜色的函数，如清单 [4-15](#PC83) 所示。

```py
def paint(image: tf.Tensor) -> tf.Tensor:
  image = tf.image.random_hue(image, max_delta=0.2)
  image = tf.image.random_saturation(image, lower=0.7, upper=1.3)
  image = tf.image.random_brightness(image, 0.05)
  image = tf.image.random_contrast(image, lower=0.8, upper=1)
  image = tf.clip_by_value(image, clip_value_min=0,
                           clip_value_max=1)
  return image

Listing 4-15Randomly Augment Image Color

```

创建一个随机旋转图像的函数:

```py
def rotate(image: tf.Tensor) -> tf.Tensor:
  return tf.image.rot90(
      image,
      tf.random.uniform(
          shape=[], minval=0,
          maxval=4, dtype=tf.int32))

```

创建一个函数来随机反转图像:

```py
def invert(image: tf.Tensor) -> tf.Tensor:
  random = tf.random.uniform(shape=[], minval=0, maxval=1)
  if random > 0.5:
    image = tf.math.multiply(image, -1)
    image = tf.math.add(image, 1)
  return image

```

创建一个函数来缩放图像，如清单 [4-16](#PC86) 所示。

```py
def zoom(
    image: tf.Tensor, min_zoom=0.8, max_zoom=1.0) -> tf.Tensor:
  image_width, image_height, image_colors = image.shape
  crop_size = (image_width, image_height)
  scales = list(np.arange(min_zoom, max_zoom, 0.01))
  boxes = np.zeros((len(scales), 4))
  for i, scale in enumerate(scales):
    x1 = y1 = 0.5 - (0.5 * scale)
    x2 = y2 = 0.5 + (0.5 * scale)
    boxes[i] = [x1, y1, x2, y2]
  def random_crop(img):
    crops = tf.image.crop_and_resize(
        [img], boxes=boxes,
        box_indices=np.zeros(len(scales)),
        crop_size=crop_size)
    return crops[tf.random.uniform(
        shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]
  choice = tf.random.uniform(
      shape=[], minval=0., maxval=1., dtype=tf.float32)
  return tf.cond(
      choice < 0.5, lambda: image, lambda: random_crop(image))

Listing 4-16Zoom Augmentation

```

缩放功能生成 1%至 20%范围内的裁剪设置。然后，它创建边界框来保存裁剪后的图像。调整返回的裁剪图像的大小，以保持用于训练的大小一致。裁剪只在 50%的时间里执行。

创建一个增强函数:

```py
def augment_data(image, label):
  image = flip(image)
  image = paint(image)
  image = rotate(image)
  image = invert(image)
  image = zoom(image)
  return image, label

```

要进行实验，请通过注释掉函数来删除一个或多个增强。

### 扩充训练数据

将增强映射到训练数据:

```py
train_augmented = train_original.map(augment_data)

```

可视化培训示例扩展:

```py
preview_dataset(train_augmented)

```

可视化原始测试集:

```py
preview_dataset(test_original)

```

### 构建输入流水线

完成流水线:

```py
BATCH_SIZE = 32

train_fingers = train_augmented.shuffle(train_examples).cache().\
  batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)

test_fingers = test_original.batch(BATCH_SIZE)

```

预取 API 使输入流水线能够在模型定型时异步获取批处理。

### 创建模型

清除和播种:

```py
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

验证图像形状:

```py
finger_img_shape

```

如清单 [4-17](#PC94) 所示构建模型。

```py
finger_model = Sequential([
  Conv2D(64, 3, activation='relu',
         input_shape=finger_img_shape,
         kernel_regularizer='l1_l2'),
  MaxPooling2D(2, 2),
  Conv2D(64, 3, activation='relu'),
  MaxPooling2D(2, 2),
  Conv2D(128, 3, activation='relu'),
  MaxPooling2D(2, 2),
  Conv2D(128, 3, activation='relu'),
  MaxPooling2D(2, 2),
  Flatten(),
  Dense(512, activation='relu'),
  Dense(num_labels, activation='softmax')])

Listing 4-17Create the Model

```

检查模型:

```py
tf.keras.utils.plot_model(
    finger_model,
    show_shapes=True,
    show_layer_names=True)

```

我们引入了另一个工具来检查模型作为替代。我们试图让你有尽可能多的选择。但是我们不想压倒。所以我们在实验中加入一些新的东西。我们发现，在某些情况下，学习像 TensorFlow 这样的复杂软件要快得多。

### 编译和训练

编译:

```py
optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)

finger_model.compile(
    optimizer=optimizer,
    loss=tf.keras.losses.sparse_categorical_crossentropy,
    metrics=['accuracy'])

```

建立培训参数:

```py
steps_per_epoch = train_examples // BATCH_SIZE
validation_steps = test_examples // BATCH_SIZE
print('steps_per_epoch:', steps_per_epoch)
print('validation_steps:', validation_steps)

```

删除日志和检查点以清除以前的模型会话:

```py
!rm -rf tmp/checkpoints
!rm -rf logs

```

准备 TensorBoard 回电:

```py
log_dir = 'logs/fit/' +\
  datetime.datetime.now().strftime('%Y%m%d-%H%M%S')
tensorboard_callback = tf.keras.callbacks.TensorBoard(
    log_dir=log_dir, histogram_freq=1)

```

火车:

```py
training_history = finger_model.fit(
    train_fingers.repeat(),
    validation_data=test_fingers.repeat(),
    epochs=10,
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=[tensorboard_callback])

```

### 可视化性能

创建一个如清单 [4-18](#PC101) 所示的函数。

```py
def viz_history(training_history):
  loss = training_history.history['loss']
  val_loss = training_history.history['val_loss']
  accuracy = training_history.history['accuracy']
  val_accuracy = training_history.history['val_accuracy']
  plt.figure(figsize=(14, 4))
  plt.subplot(1, 2, 1)
  plt.title('Loss')
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.plot(loss, label='Training set')
  plt.plot(val_loss, label='Test set', linestyle='--')
  plt.legend()
  plt.grid(linestyle='--', linewidth=1, alpha=0.5)
  plt.subplot(1, 2, 2)
  plt.title('Accuracy')
  plt.xlabel('Epoch')
  plt.ylabel('Accuracy')
  plt.plot(accuracy, label='Training set')
  plt.plot(val_accuracy, label='Test set', linestyle='--')
  plt.legend()
  plt.grid(linestyle='--', linewidth=1, alpha=0.5)
  plt.show()

Listing 4-18Visualization Function

```

调用函数:

```py
viz_history(training_history)

```

启动 TensorBoard:

```py
%tensorboard --logdir logs/fit

```

同样，我们向你展示如何在实验环境中使用 TensorBoard 来加快你的学习。我们不经常使用 TensorBoard，因为我们可以像以前一样只用几行代码就能看到模型性能。但是我们认为向您展示产品是一个好主意。你可能更喜欢它，而不是我们视觉化学习表现的方式。

### 关闭 TensorBoard 服务器

使用全局正则表达式打印(grep)命令获取正在运行的 TensorBoard 进程的详细信息:

```py
!ps -ef | grep tensorboard

```

输出如下所示:

```py
root       10757    4202 26 19:13 ?        00:00:04 python3 /usr/local/bin/tensorboard --logdir logs/fit
root       10794    4202  0 19:13 ?        00:00:00 /bin/bash -c ps -ef | grep tensorboard
root       10796   10794  0 19:13 ?        00:00:00 grep tensorboard

```

第一个数字 10757 是 TensorFlow 的当前进程标识符(pid)。

使用 pid 终止进程:

```py
!kill 10757

```

Note

每次 TensorBoard 被激活时，pid 都会改变。
# 9.卷积和变分自动编码器

自动编码器通常不能很好地处理图像，除非它们非常小。但是卷积和变分自动编码器比带有大彩色图像的前馈密集编码器要好得多。

**A** **变分自动编码器(VAE)** 是一种用于学习潜在表示的深度学习技术。他们运用学到的潜在空间表征来绘制图像，并在句子之间进行插值。VAE 的工作方式是将输入压缩成潜在空间表示，然后从该表示中重构输出。**潜在空间**是压缩数据的数学表示。

VAE 通过使编码器返回潜在空间上的高斯分布而不是单个点，并在返回的分布上的损失函数中添加正则化来解决潜在空间不规则的问题。在深度学习中，可以压缩数据，以更好地管理计算资源。但是潜在空间必须分布在高斯分布上，以便为了模型消耗而对其进行归一化。

VAE 的一个主要优点是，它以高斯概率的方式描述了(潜在空间中的)观察结果，以更好地模拟自然现象。因此，VAE 不是构建一个输出单个值来描述每个潜在状态属性的编码器，而是构建一个编码器来描述每个潜在属性的概率分布。结果是生成质量高得多的图像。

章节的笔记本位于以下 URL:

[T2`https://github.com/paperd/deep-learning-models`](https://github.com/paperd/deep-learning-models)

我们用代码示例演示卷积和变分自动编码器。我们从卷积自动编码器实验开始。我们继续进行 VAE 实验。我们以一个张量流概率(TFP)层的 VAE 实验结束。这三个实验通过产生原始图像的更清晰的再现，显示了它们相对于基本堆叠自动编码器的优越性。

通过导入主 TensorFlow 库并实例化 GPU，开始设置 Colab 生态系统。

## 导入 TensorFlow 库

导入库并将其别名为 **tf** :

```py
import tensorflow as tf

```

将 TensorFlow 库别名为 tf 是常见的做法。

## GPU 硬件加速器

为了方便起见，我们在 Colab 笔记本中包含了启用 GPU 的步骤:

1.  点击左上角菜单中的*运行时*。

2.  从下拉菜单中点击*改变运行时间类型*。

3.  从*硬件加速器*下拉菜单中选择 *GPU* 。

4.  点击*保存。*

验证 GPU 是否处于活动状态:

```py
tf.__version__, tf.test.gpu_device_name()

```

如果显示“/设备:GPU:0”，则 GPU 处于活动状态。如果'..'显示时，常规 CPU 处于活动状态。

Note

如果得到错误**名称****'****TF****'****未定义**，重新执行代码导入 TensorFlow 库！

## 卷积编码器实验

*卷积自动编码器*是卷积神经网络的变体，用于卷积滤波器的无监督学习。卷积自动编码器通过在图像重建期间学习最佳滤波器来最小化重建误差。在实验中，卷积自动编码器学习如何根据数据集的输入特征生成新图像。

### 加载数据

我们在这个实验中使用了*马或人类*数据集。horses_or_humans 数据集包含 1，283 幅马和人的图像。

将数据集作为 TFDS 对象加载以进行检查:

```py
import tensorflow_datasets as tfds

data, hh_info = tfds.load(
    'horses_or_humans', with_info=True,
    split='train', try_gcs=True)

```

### 检查日期

获取元数据:

```py
hh_info

```

获取标签和类别数量:

```py
class_labels = hh_info.features['label'].names
num_classes = hh_info.features['label'].num_classes
class_labels, num_classes

```

### 显示示例

展示一些 tfds API 的例子:

```py
fig = tfds.show_examples(data, hh_info)

```

将示例显示为熊猫数据框:

```py
tfds.as_dataframe(data.take(4), hh_info)

```

手动显示图像:

```py
import matplotlib.pyplot as plt

for element in data.take(1):
  plt.imshow(element['image'])
  plt.axis('off')

```

手动显示示例网格，如清单 [9-1](#PC9) 所示。

```py
img, lbl = [], []
for element in data.take(9):
  img.append(element['image'])
  lbl.append(element['label'].numpy())
fig=plt.figure(figsize=(8, 8))
columns = 3
rows = 3
for i in range(1, columns*rows+1):
  fig.add_subplot(rows, columns, i)
  plt.imshow(img[i-1])
  plt.title(class_labels[lbl[i-1]])
  plt.axis('off')
plt.show()

Listing 9-1Grid of Examples

```

创建一组图像和标签。在网格中绘制图像和标签。

### 获取培训数据

从元数据中，我们知道数据拆分:

```py
(x_train_img, _), (x_test_img, _) = tfds.as_numpy(
    tfds.load(
        'horses_or_humans', split=['train','test'],
        batch_size=-1, as_supervised=True,
        try_gcs=True))

```

由于自动编码器是无监督的模型，我们不需要标签。

获取培训和测试元素的数量:

```py
len(x_train_img), len(x_test_img)

```

### 检查形状

检查列车并测试形状:

```py
x_train_img.shape, x_test_img.shape

```

检查图像尺寸:

```py
for element in range(10):
  print (x_train_img.shape)

```

由于图像是相同的形状，我们不必为了训练而调整它们的大小。

### 预处理图像数据

缩放图像:

```py
import numpy as np

x_train, x_test = x_train_img.astype(np.float32) / 255,\
                  x_test_img.astype(np.float32) / 255

```

在缩放之前和之后检查来自训练图像的向量:

```py
x_train_img[0][0][0], x_train[0][0][0]

```

### 创建卷积自动编码器

清除和播种:

```py
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

获取输入形状:

```py
hh_shape = hh_info.features['image'].shape
hh_shape

```

导入库:

```py
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D,\
  Dense, Flatten, Input, Conv2DTranspose, Reshape
from tensorflow.keras.models import Model

```

创建一个编码器，如清单 [9-2](#PC19) 所示。

```py
conv_encoder = Sequential([
  Input(shape=hh_shape),
  Conv2D(16, kernel_size=3, padding='SAME', activation='selu'),
  MaxPool2D(pool_size=2),
  Conv2D(32, kernel_size=3, padding='SAME', activation='selu'),
  MaxPool2D(pool_size=2),
  Conv2D(64, kernel_size=3, padding='SAME', activation='selu'),
  MaxPool2D(pool_size=2)
])

Listing 9-2Encoder

for a Convolutional Autoencoder

```

编码器由卷积层和池层组成。编码器减少了输入的空间维度(高度和宽度)，同时增加了深度(特征图的数量)。

创建如清单 [9-3](#PC20) 所示的解码器。

```py
conv_decoder = Sequential([
  Conv2DTranspose(32, kernel_size=3, strides=2, padding='VALID',
                  activation='selu'),
  Conv2DTranspose(16, kernel_size=3, strides=2, padding='SAME',
                  activation='selu'),
  Conv2DTranspose(3, kernel_size=3, strides=2, padding='SAME',
                  activation='sigmoid')
])

Listing 9-3Decoder for a Convolutional Autoencoder

```

解码器的工作与编码器相反，它放大图像并将图像深度还原到原始尺寸。conv 2d 转置层用于此目的。

创建卷积自动编码器:

```py
conv_ae = Sequential([conv_encoder, conv_decoder])

```

### 编译和训练

为精确度指标创建一个函数:

```py
def rounded_accuracy(y_true, y_pred):
    return tf.keras.metrics.binary_accuracy(
        tf.round(y_true), tf.round(y_pred))

```

编译:

```py
conv_ae.compile(
    loss='binary_crossentropy',
    optimizer=tf.keras.optimizers.SGD(lr=1.0),
    metrics=[rounded_accuracy])

```

火车:

```py
cae_history = conv_ae.fit(
    x_train, x_train, epochs=5,
    validation_data=(x_test, x_test))

```

### 可视化培训表现

创建一个可视化函数，如清单 [9-4](#PC25) 所示。

```py
def viz_history(training_history):
  loss = training_history.history['loss']
  val_loss = training_history.history['val_loss']
  accuracy = training_history.history['rounded_accuracy']
  val_accuracy = training_history.history['val_rounded_accuracy']
  plt.figure(figsize=(14, 4))
  plt.subplot(1, 2, 1)
  plt.title('Loss')
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.plot(loss, label='Training set')
  plt.plot(val_loss, label='Test set', linestyle='--')
  plt.legend()
  plt.grid(linestyle='--', linewidth=1, alpha=0.5)
  plt.subplot(1, 2, 2)
  plt.title('Accuracy')
  plt.xlabel('Epoch')
  plt.ylabel('Accuracy')
  plt.plot(accuracy, label='Training set')
  plt.plot(val_accuracy, label='Test set', linestyle='--')
  plt.legend()
  plt.grid(linestyle='--', linewidth=1, alpha=0.5)
  plt.show()

Listing 9-4Performance Visualization Function

```

调用可视化功能:

```py
viz_history(cae_history)

```

### 可视化重建

创建如清单 [9-5](#PC27) 所示的重建可视化功能。

```py
def show_reconstructions(model, images, n_images, reshape=False):
  reconstructions = model.predict(images[:n_images])
  if reshape:
    reconstructions = tf.squeeze(reconstructions)
  fig = plt.figure(figsize=(n_images * 1.5, 3))
  for image_index in range(n_images):
    plt.subplot(2, n_images, 1 + image_index)
    plot_image(images[image_index])
    plt.subplot(2, n_images, 1 + n_images + image_index)
    plot_image(reconstructions[image_index])

Listing 9-5Reconstruction Visualization Function

```

该函数根据图像预测生成重建。

创建一个函数来显示图像:

```py
def plot_image(image):
  plt.imshow(image, cmap='binary')
  plt.axis('off')

```

显示原始图像和重建图像:

```py
show_reconstructions(conv_ae, x_test, 5)

```

## 变分自动编码器实验

一种**变分自动编码器** (VAE)是一种无监督的 ML 技术，它以概率方式学习高效的数据编码。VAE 训练是有规律的，以减轻过度拟合，并确保潜在空间有效地产生类似的输出时，比较培训投入。VAE 与其他自动编码器非常不同，因为它将输入编码为潜在空间上的分布，而不是单点。

最初，输入被编码为潜在空间上的分布。然后从潜在空间中的一个点对分布进行采样。对采样点进行解码，并计算重建误差。然后，重构误差通过网络反向传播。

实际上，编码的分布是*正态，*因此编码器可以被训练来返回描述高斯分布的均值和协方差矩阵。将输入编码为分布而不是单点的原因是因为潜在空间正则化可以非常自然地表示为高斯分布。编码器返回的分布被 VAE 模型强制接近标准正态分布。

关于 VAE 建模的精彩讨论，请阅读

[T2`https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73`](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)

### 加载数据

将时尚-MNIST 训练和测试图像作为一批 NumPy 阵列加载:

```py
(x_train_fm, _), (x_test_fm, _) = tfds.as_numpy(
    tfds.load('fashion_mnist', split=['train','test'],
              batch_size=-1, as_supervised=True,
              try_gcs=True))

```

### 检查日期

获取训练和测试张量形状:

```py
x_train_fm.shape, x_test_fm.shape

```

获取编码器的输入形状:

```py
fmnist_shape = x_train_fm.shape[1:]
fmnist_shape

```

### 规模

通过除以每个图像中的像素数来缩放特征图像:

```py
x_train_fds, x_test_fds = x_train_fm.astype(np.float32) / 255,\
                          x_test_fm.astype(np.float32) / 255

```

### 创建自定义图层以对编码进行采样

编码器的采样层接受两个输入，即均值μ和对数方差γ。它使用 tf.random.normal API 从均值为零(μ=0)、标准差为 1 (σ=1)的正态分布中采样一个与γ形状相同的随机向量，将该随机向量乘以 exp(γ/2)，加上μ，然后返回结果。

创建如清单 [9-6](#PC34) 所示的采样类。

```py
class Sampling(tf.keras.layers.Layer):
  def call(self, inputs):
    mean, log_var = inputs
    return tf.random.normal(tf.shape(log_var)) *\
           tf.math.exp(log_var / 2) + mean

Listing 9-6Sampling Class for the Encoder

```

### 创建 VAE 模式

清除和播种:

```py
tf.keras.backend.clear_session()
np.random.seed(0)
tf.random.set_seed(0)

```

创建如清单 [9-7](#PC36) 所示的编码器。

```py
codings_size = 10

inputs = Input(shape=fmnist_shape)
z = Flatten()(inputs)
z = Dense(128, activation='relu')(z)
z = Dense(64, activation='relu')(z)
z = Dense(32, activation='relu')(z)
codings_mean = Dense(codings_size)(z)
codings_log_var = Dense(codings_size)(z)
codings = Sampling()([codings_mean, codings_log_var])
variational_encoder = Model(
    inputs=[inputs],
    outputs=[codings_mean, codings_log_var, codings])

Listing 9-7VAE Encoder

```

我们使用函数式 API，因为模型不完全是顺序的。密集层输出具有相同输入(即，第二密集层的输出)的 codings_mean μ和 codings_log_var γ。然后将 codings_mean 和 codings_log_var 传递给采样层。变分编码器有三个输出，即编码平均值、编码对数变量和编码。但是我们只使用编码输出。

创建如清单 [9-8](#PC37) 所示的解码器。

```py
decoder_inputs = Input(shape=[codings_size])
x = Dense(32, activation='relu')(decoder_inputs)
x = Dense(64, activation='relu')(x)
x = Dense(128, activation='relu')(x)
x = Dense(28 * 28, activation='sigmoid')(x)
outputs = Reshape(fmnist_shape)(x)
variational_decoder = Model(
    inputs=[decoder_inputs], outputs=[outputs])

Listing 9-8VAE Decoder

```

我们可以使用顺序 API 代替函数 API，因为它实际上只是一个简单的层堆栈。但我们以这种方式创建了 VAE 解码器，以匹配 VAE 编码器的结构。

建立 VAE 模式:

```py
_, _, codings = variational_encoder(inputs)
reconstructions = variational_decoder(codings)
variational_ae = Model(
    inputs=[inputs], outputs=[reconstructions])

```

忽略前两个输出，因为我们只需要编码。

### 编译和训练

#### 在模型中加入潜在损失和重建损失

将潜在损失计算为 1 加上 codings_log_var 减去 codings_log_var 的指数减去 codings_mean 的平方(1+codings _ log _ var e<sup>codings _ log _ var</sup>—codings _ mean<sup>2</sup>)。将这个结果乘以-0.5。将重建损失计算为该批次中所有实例的平均损失除以 784，以确保适当的比例。我们除以 784，因为图像是 28 × 28 像素。

回顾一下，自动编码器是接收图像并通过从图像中学习输入特征来重建图像的神经网络。编码器从图像中创建潜在向量。*潜在向量*是图像的压缩表示。潜在向量被馈送到解码器，解码器从潜在向量重建输入图像的传真。

VAE 还从图像的学习输入特征中重建新图像。但是编码器基于高斯分布创建潜在向量的样本。解码器从编码器创建的分布中随机抽取潜在向量，以创建新的传真图像。新图像质量更好，因为它们是基于从高斯分布中提取的随机潜在表示。

我们用潜在损失来限制 VAE。*潜在损失*测量编码器生成的高斯分布中潜在向量的损失。因此，潜在损失基于潜在向量离单位高斯分布有多近或多远来惩罚网络。还测量实际的图像损失，以查看传真图像与输入图像的匹配程度。当结合这两个损失度量时，网络必须在低潜在损失(潜在向量的单位高斯分布)和低图像损失(输入和传真输出图像之间的高相似性)之间找到最佳折衷。只有当均值为 0 且标准差为 1(单位高斯)时，潜在损失才评估为零(完美)。

创建受限 VAE，如清单 [9-9](#PC39) 所示。

```py
latent_loss = -0.5 * tf.math.reduce_sum(
    1 + codings_log_var - tf.math.exp(codings_log_var) -\
    tf.math.square(codings_mean), axis=-1)

variational_ae.add_loss(
    tf.math.reduce_mean(latent_loss) / 784.)

Listing 9-9Restricted VAE

```

编译:

```py
variational_ae.compile(
    loss='binary_crossentropy', optimizer='rmsprop',
    metrics=[rounded_accuracy])

```

火车:

```py
vae_history = variational_ae.fit(
    x_train_fds, x_train_fds, epochs=10,
    batch_size=128,
    validation_data=(x_test_fds, x_test_fds))

```

可视化培训表现:

```py
viz_history(vae_history)

```

### 可视化重建

检查测试装置的形状:

```py
x_test_fds.shape

```

移除 *1* 尺寸以便绘图:

```py
x_test_fds_imgs = tf.squeeze(x_test_fds)
x_test_fds_imgs.shape

```

视觉化:

```py
show_reconstructions(
    variational_ae, x_test_fds_imgs, 5, reshape=True)

```

### 生成新图像

创建一个绘图函数，如清单 [9-10](#PC46) 所示。

```py
def plot_multiple_images(images, n_cols=None):
  n_cols = n_cols or len(images)
  n_rows = (len(images) - 1) // n_cols + 1
  if images.shape[-1] == 1:
    images = np.squeeze(images, axis=-1)
  plt.figure(figsize=(n_cols, n_rows))
  for index, image in enumerate(images):
    plt.subplot(n_rows, n_cols, index + 1)
    plt.imshow(image, cmap='binary')
    plt.axis('off')

Listing 9-10Plotting Function for New Images

```

我们不是从图像预测中生成重建，而是创建一组随机高斯编码，并直接从解码器中重建图像。

生成一些随机编码，解码它们，并绘制出结果图像:

```py
tf.random.set_seed(0)

codings = tf.random.normal(shape=[12, codings_size])
images = variational_decoder(codings).numpy()
plot_multiple_images(images, 4)

```

创建 12 个随机编码，用解码器解码，用绘图功能绘图。

在图像之间执行语义插值，如清单 [9-11](#PC48) 所示。

```py
tf.random.set_seed(0)
np.random.seed(0)

codings_grid = tf.reshape(codings, [1, 3, 4, codings_size])
larger_grid = tf.image.resize(codings_grid, size=[5, 7])
interpolated_codings = tf.reshape(
    larger_grid, [-1, codings_size])
images = variational_decoder(interpolated_codings).numpy()
images.shape

Listing 9-11Semantic Interpolation Between the Codings

```

对于像 VAE 这样的隐式模型，我们在潜在空间的采样点之间进行插值。我们这样做是为了使代码向量的分布假设与内插路径的几何形状相匹配。否则，关于编码点之间的质量和语义的典型假设可能是不合理的。

移除 *1* 尺寸以便绘图:

```py
images = tf.squeeze(images)

```

如清单 [9-12](#PC50) 所示可视化。

```py
plt.figure(figsize=(7, 5))
for index, image in enumerate(images):
  plt.subplot(5, 7, index + 1)
  if index%7%2==0 and index//7%2==0:
    plt.gca().get_xaxis().set_visible(False)
    plt.gca().get_yaxis().set_visible(False)
  else:
    plt.axis('off')
  plt.imshow(image, cmap='binary')

Listing 9-12Visualize Interpolated Codings

```

## 全要素生产率实验

在本实验中，我们使用张量流概率层来拟合 VAE。*TensorFlow Probability(TFP)*是 tensor flow 中用于概率推理和统计分析的库。作为 TensorFlow 生态系统的一部分，TFP 提供了概率方法与深度网络的集成、使用自动微分的基于梯度的推理，以及通过硬件加速(如 GPU)和分布式计算对大型数据集和模型的可扩展性。

TFP 使得在现代硬件(如 TPU、GPU)上结合概率模型和深度学习变得很容易。TFP 是为数据科学家、统计学家、ML 研究人员和希望对领域知识进行编码以理解数据和做出预测的从业者而设计的。

TFP 包括广泛的概率分布和双投影选择。Bijector API 为构建一大类概率分布提供了模块化的构建模块。双投影器封装了概率密度的变量变化。所以它们可以用来把一个张量分布转换成另一种分布。简单地说，他们把一个随机结果变成另一个来自不同分布的随机结果。

由于 TFP 继承了 TensorFlow 的优点，我们可以在模型探索和生产的整个生命周期中使用单一语言构建、调整和部署模型。TFP 是开源的，可以在 GitHub 上获得。

加载时尚-MNIST 数据:

```py
fmnist, fmnist_info = tfds.load(
    name='fashion_mnist', try_gcs=True,
    with_info=True, as_supervised=False)

```

创建预处理数据的函数:

```py
def _preprocess(sample):
  image = tf.cast(sample['image'], tf.float32) / 255.
  image = image < tf.random.uniform(tf.shape(image))
  return image, image

```

投射图像以浮动和缩放。继续随机将图像像素转换为二进制形式，作为*真*或*假*值。tf.random.uniform API 从均匀分布中输出随机值。请注意，该函数返回*图像，图像*，而不仅仅是图像，因为 Keras 旨在用于具有*(示例，标签)*输入格式的区别性模型。由于 VAE 的目标是从 x 本身恢复输入 x，因此数据对是*(示例，范例)*。

为输入管道建立参数:

```py
auto = tf.data.experimental.AUTOTUNE
BATCH_SIZE, SHUFFLE_SIZE = 256, int(10e3)

```

创建列车组:

```py
train_tpl = (fmnist['train']
             .map(_preprocess)
             .batch(BATCH_SIZE)
             .prefetch(auto)
             .shuffle(SHUFFLE_SIZE))

```

创建测试集:

```py
test_tpl = (fmnist['test']
            .map(_preprocess)
            .batch(BATCH_SIZE)
            .prefetch(auto))

```

检查一批图像的切片:

```py
for example in train_tpl.take(1):
  print (example[0][0][0])
  print (example[0].shape)

```

请注意，像素现在不是布尔真就是布尔假！

检查训练批次的形状:

```py
for row in train_tpl.take(1):
  print (row[0].shape)

```

### 创建一个全要素生产率 VAE 模型

创建一个无学习参数的 TFP 独立高斯分布。潜在变量 z(编码大小)被分配 16 个维度。如清单 [9-13](#PC58) 所示，将分布分配给 prior。

```py
import tensorflow_probability as tfp

tfd = tfp.distributions
encoded_size = 16
prior = tfd.Independent(
    tfd.Normal(
        loc=tf.zeros(encoded_size), scale=1),
        reinterpreted_batch_ndims=1)

Listing 9-13TFP Independent Gaussian Distribution

```

请注意，prior 是独立规范化的。一个**先验**是我们对世界的一个潜在假设。一个常见的先验是，我们假设一个硬币是公平的(50%正面和 50%反面)。普遍的看法是，先验并不总是正确的，但大多数时候是正确的。

获取输入形状并分配深度:

```py
input_shape = fmnist_info.features['image'].shape
base_depth = 32
input_shape

```

基础深度是神经元的基础数量。

为方便起见，请指定别名:

```py
tfpl = tfp.layers
tfd = tfp.distributions
leaky = tf.nn.leaky_relu

```

#### TFP VAE 编码器

创建具有全协方差高斯分布的编码器，该分布具有由神经网络的输出参数化的均值和协方差矩阵。TFP 层能够以简单的格式构建这种复杂的编码器。

创建如清单 [9-14](#PC61) 所示的编码器。

```py
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

from tensorflow.keras.layers import InputLayer, Lambda

encoder = Sequential([
  InputLayer(input_shape=input_shape),
  Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),
  Conv2D(base_depth, 5, strides=1, padding='same',
         activation=leaky),
  Conv2D(base_depth, 5, strides=2, padding='same',
         activation=leaky),
  Conv2D(base_depth * 2, 5, strides=1,
         padding='same', activation=leaky),
  Conv2D(base_depth * 2, 5, strides=2, padding='same',
         activation=leaky),
  Conv2D(4 * encoded_size, 7, strides=1, padding='valid',
         activation=leaky),
  Flatten(),
  Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),
        activation=None),
  tfpl.MultivariateNormalTriL(
      encoded_size,
      activity_regularizer=tfpl.KLDivergenceRegularizer(
          prior, weight=1.0))
])

Listing 9-14TFP VAE Encoder

```

编码器是具有卷积和密集层的正常 Keras 序列模型。但是输出被传递到 TFP 层(MultivariateNormalTril())，该层透明地将来自最终密集层的激活分割成指定均值和下三角协方差矩阵所需的部分。我们使用 tfpl 助手 multivariatenormaltril . params _ size(encoded _ size)来使密集层输出正确的激活次数。我们还为最终损失贡献了一个正则项，以减轻过拟合。具体来说，我们在编码器和丢失之前增加了 Kullback-Leibler (KL)散度正则化。

#### TFP VAE 解码器

将解码器创建为独立于像素的伯努利分布，如清单 [9-15](#PC62) 所示。

```py
decoder = Sequential([
  InputLayer(input_shape=[encoded_size]),
  Reshape([1, 1, encoded_size]),
  Conv2DTranspose(2 * base_depth, 7, strides=1,
                  padding='valid', activation=leaky),
  Conv2DTranspose(2 * base_depth, 5, strides=1,
                  padding='same', activation=leaky),
  Conv2DTranspose(2 * base_depth, 5, strides=2,
                  padding='same', activation=leaky),
  Conv2DTranspose(base_depth, 5, strides=1,
                  padding='same', activation=leaky),
  Conv2DTranspose(base_depth, 5, strides=2,
                  padding='same', activation=leaky),
  Conv2DTranspose(base_depth, 5, strides=1,
                  padding='same', activation=leaky),
  Conv2D(filters=1, kernel_size=5, strides=1,
         padding='same', activation=None),
  Flatten(),
  tfpl.IndependentBernoulli(
      input_shape, tfd.Bernoulli.logits)
])

Listing 9-15TFP VAE Decoder

```

这里的形式与编码器基本相同，但我们使用转置卷积将 16 维向量的潜在表示转换回 28 × 28 × 1 张量。最后一层参数化独立于像素的伯努利分布。

#### 构建全要素生产率 VAE 模型

构建模型:

```py
from tensorflow.keras import Model

tpl_vae = Model(inputs=encoder.inputs,
                outputs=decoder(encoder.outputs[0]))

```

检查输入是否符合预期:

```py
encoder.inputs

```

### 编译和训练

设定学习率:

```py
lr = 1e-3
lr

```

我们根据反复试验来设定这个学习率。随意尝试不同的学习速度。

编译:

```py
negloglik = lambda x, rv_x: -rv_x.log_prob(x)

tpl_vae.compile(
    optimizer=tf.optimizers.Adam(learning_rate=lr),
    loss=negloglik)

```

我们的模型只是一个 Keras 模型，其中输出被定义为编码器和解码器的组合。由于编码器已经将 Kullback-Leibler (KL)散度项添加到损失中，我们只需要指定重建损失(ELBO 的第一项)。KL 散度是衡量一个概率分布与另一个概率分布的不同之处。也叫相对熵。

ELBO(证据下限)是 log p(x)(或观察数据点的对数概率)上的下限。ELBO 方程中的第一个积分是重建项。它问我们有多大可能从图像 x 开始，将其编码为 z，解码，然后得到原始的 x。第二项是 KL 散度项。它测量我们的编码器与我们分配给前一个变量的值有多接近。我们可以认为这个术语只是为了保持我们的编码器诚实。如果我们的编码器生成 z 个样本，而这些样本在给定我们的先验值的情况下是不太可能的，那么目标就比它生成 z 个样本更能代表先验值的情况差。因此，只有当这样做的成本被重建项的收益超过时，编码器才应该不同于先前的值。

火车:

```py
_ = tpl_vae.fit(train_tpl, epochs=15,
                validation_data=test_tpl)

```

### 功效测试

检查十个随机数字:

```py
x = next(iter(test_tpl))[0][:10]
xhat = tpl_vae(x)
assert isinstance(xhat, tfd.Distribution)

```

创建一个函数来显示随机图像，如清单 [9-16](#PC69) 所示。

```py
def display_imgs(x, y=None):
  if not isinstance(x, (np.ndarray, np.generic)):
    x = np.array(x)
  plt.ioff()
  n = x.shape[0]
  fig, axs = plt.subplots(1, n, figsize=(n, 1))
  if y is not None:
    fig.suptitle(np.argmax(y, axis=1))
  for i in range(n):
    axs.flat[i].imshow(x[i].squeeze(),
                       interpolation='none',
                       cmap='gray')
    axs.flat[i].axis('off')
  plt.show()
  plt.close()

Listing 9-16Plotting Function for Random Images

```

视觉化:

```py
print('Originals:')
display_imgs(x)

print('Decoded Random Samples:')
display_imgs(xhat.sample())

print('Decoded Modes:')
display_imgs(xhat.mode())

print('Decoded Means:')
display_imgs(xhat.mean())

```

Python sample()方法返回从序列中选择的特定长度的项目列表。它用于无替换的随机抽样。Python mode()方法适用于名义(非数值)数据。请记住，我们将像素图像数据转换为布尔值 True 或 False。它用于定位数值或名义数据的集中趋势。Python mean()方法计算给定数字列表的算术平均值。为了获得更清晰的重建图像，运行模型更多的时期(以减少损失)。

## 摘要

在本章中，我们演示了三个最先进的自动编码器实验。这些自动编码器中的每一个都比基本的堆叠式自动编码器产生更真实的输入图像渲染。
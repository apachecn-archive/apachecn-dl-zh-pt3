# 1.深入喀拉斯

> 想象力比知识更重要。因为知识是有限的，而想象力却包含了整个世界。
> 
> —阿尔伯特·爱因斯坦<sup>[1](#Fn1)T3】</sup>

这本书的一个关键目标是探索深度学习作为一种分析艺术的概念——计算环境是你的画布，深度学习设计是你的画笔。对分析性创造力和想象力的深刻理解是理解本能的、本能的深度学习所不可或缺的。本书旨在为你提供这种理解。随着深度学习的世界不断变化，那些只将他们的深度学习知识与今天的工具联系在一起的人会发现，当新的语法和库被引入时，他们很难与深度学习一起工作。然而，对游戏性、智力自由和好奇心的直观感受，可以让我们更接近于密切地、个人地、成功地与深度学习合作，超越对任何一个特定模型架构或框架的相互依赖。

当然，相互依赖是一个崇高的理想；然而，作为对爱因斯坦名言的回应，想象力和创造力必须植根于某些具体的知识体系中才能存在。能够探索和理解深度学习的分析艺术首先需要建立实现的框架，就像为房子打地基一样。这些知识——从概念到代码——将允许我们在后面的章节中探索深度学习中更抽象和复杂的想法。

本章将深入探讨 Keras，它是理解如何构建和实现我们将要开发的概念所选择的框架。本章涵盖的内容并不是要取代易于访问的在线语法文档，Keras 和 TensorFlow API 文档是实现这些目的的最佳选择。相反，它既是对 Keras 的关键构建模块的快速介绍，以构建我们稍后将使用的更复杂的结构，也是一个概念参考指南，可能对以后的参考很有价值。除了涵盖 Keras 的语法——正如大多数在线代码教程或 API 文档所做的那样——我们将深入框架，了解技巧、诀窍和概念，以确保高效和熟练地使用 Keras 和思考过程。

## 为什么很难？

在希腊语中，Keras (κέρας)的意思是“号角”，指的是*奥德赛*。它最初是为 project ONEIROS(开放式神经电子智能机器人操作系统)开发的，但由于广泛的应用和背景，它在现代深度学习社区中变得非常受欢迎。

有许多深度学习框架可用，但 Keras 在简单性和多功能性方面尤为突出。Keras 将自己标榜为“人类的深度学习”，但它的用户友好性不言自明。Keras 的设计最大限度地减少了沟通想法和实施所需的时间和精力。

2019 年的一项调查询问了 Kaggle 比赛中得分最高的团队使用了哪些机器学习框架，发现 Keras 排名第一。Keras 的创造者 Francis Chollet 在一篇 Quora 帖子中写下了他对这一现象的看法:

> 开发好的模型需要对你最初的想法进行多次迭代，直到截止日期；您总是可以进一步改进您的模型… Keras 旨在快速构建许多不同模型的原型，重点是尽可能减少从有想法到实验结果所需的时间。
> 
> ——弗朗西斯·乔列特[【3】](#Fn3)

Keras 的开发速度和多功能性也使其成为网飞和 Instacart 等公司、研究人员以及 CERN 和 NASA 等科学组织的热门选择。截至 2021 年初，Keras 拥有超过 40 万用户。 <sup>[4](#Fn4)</sup>

这不是一本关于 Keras 的书，而是一本关于现代深度学习设计的书。然而，如前所述，设计的一个组成部分是实现。Keras 将是一个有价值的媒介，通过它我们可以构建和实现我们讨论的想法。有了 Keras，我们可以更自由地探索深度学习的可能性，而不会被束缚在艰巨而漫长的实现中。

## 安装和导入 Keras

Keras 可以通过`pip`作为`pip install keras`自行安装，也可以作为`import keras`导入。这个(以及以后的所有部分)可以直接安装在命令提示符界面中，或者在 Jupyter Notebook 中添加一个感叹号(！)在命令之前。然而，Keras 已经成为 TensorFlow 的一部分，tensor flow 是谷歌的一个深度学习框架，允许更多的底层控制。由于这次合并，Keras 用户可以利用 Keras 的用户友好性和 TensorFlow 的低级定制能力。

由于 TensorFlow 包含了 Keras，所以单独安装 Keras 是多余的。因此，通常只安装 TensorFlow，Keras 从 TensorFlow 导入(清单 [1-1](#PC1) )。

```
!pip install tensorflow       # only install TF
import tensorflow as tf       # import TF
from tensorflow import keras # import keras from TF

Listing 1-1Installing and importing TensorFlow and Keras

```

如果您还没有工作空间，请考虑以下事项:

*   Jupyter Notebook:Jupyter Notebook 在数据科学领域特别受欢迎，因为它基于单元的输入输出结构允许快速实验和整洁的组织。通过 Anaconda 安装会自动安装重要的数据科学库。

*   Kaggle 是一个在线数据科学平台，提供竞赛、数据集、数据科学论坛和代码笔记本。Kaggle 笔记本支持 Jupyter 笔记本和 Python 或 R 脚本。虽然 Kaggle 不能处理高度计算或内存密集型操作，因为它是基于 web 的，但它提供了易于访问的 GPU 和 TPU。此外，Kaggle 允许您在笔记本电脑自己的服务器上轻松运行几个小时，这是设置虚拟机或其他计算工作流的简单替代方法。截至 2021 年，Kaggle 通常将 GPU 的使用限制在每周 30 到 42 小时(每周不同)，将 TPU 的使用限制在每周 30 小时。

*   Google Colab : Google Colab 还允许使用 GPU 和 TPU，这在技术上是没有限制的，但当可用的计算资源无法满足需求，并且您已经消耗了相当长一段时间的资源时，就可以停止使用。Google Colab 有利于分享和高性能计算的快速实验。

## 简单的 Keras 工作流程

用 Keras 构建任何模型时，深度学习工作流程一般有三个步骤:定义架构、编译、拟合分析(图 [1-1](#Fig1) )。从最简单到最复杂的模型都遵循这个工作流程。在本节中，我们将详细回顾工作流中的每个步骤。

![../images/516104_1_En_1_Chapter/516104_1_En_1_Fig1_HTML.jpg](../images/516104_1_En_1_Chapter/516104_1_En_1_Fig1_HTML.jpg)

图 1-1

神经网络的输入-主体-输出模型

### 步骤 1:定义架构

神经网络的架构有三个关键部分(图 [1-2](#Fig2) )。

![../images/516104_1_En_1_Chapter/516104_1_En_1_Fig2_HTML.jpg](../images/516104_1_En_1_Chapter/516104_1_En_1_Fig2_HTML.jpg)

图 1-2

神经网络的输入-主体-输出模型

*   *输入*:该部分定义并接收神经网络用于预测基础的输入数据的格式。

*   *Body* :该部分对输入执行一系列操作，将其转换为输出。身体由神经网络的各层组成。

*   *输出*:该部分定义了神经网络输出结果的格式。

Note

在本节中，我们将使用顺序 Keras API 来说明 Keras 工作流。顺序模型允许用户通过线性或顺序堆叠层来构建模型。对于较简单的架构来说，这已经足够了，但是更复杂的设计需要函数式 API，这将在后面讨论。

让我们考虑一个非常简单的数据集来定义神经网络的架构(表 [1-1](#Tab1) )。这个样本数据集包含三个二元特征——*A*、 *B* 和*C*——以及两个二元标签。仅当任何特征为 1 时，标签 1 为 1，并且仅当至少两个特征的值为 1 时，标签 2 为 1。

表 1-1

具有三个要素和两个标注的样本虚拟数据集

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
| 

A

 | 

B

 | 

C

 | 

标签 1

 | 

标签 2

 |
| --- | --- | --- | --- | --- |
| Zero | Zero | Zero | Zero | Zero |
| one | Zero | Zero | one | Zero |
| Zero | one | Zero | one | Zero |
| Zero | one | one | one | one |
| one | one | Zero | one | one |
| one | one | one | one | one |

该数据集有三个要素，这意味着输入是三维的。让我们从导入 Keras、顺序模型和输入层开始；我们可以创建一个模型并定义输入(清单 [1-2](#PC2) )。

```
import keras
from keras.models import Sequential
from keras.layers import Input

model = Sequential() # initializes sequential model
model.add(Input((3,)))

Listing 1-2Building the input component of a Sequential model

```

Note

如果模型要处理图像，那么对于 128x128 像素的彩色图像，输入形状可能类似于`Input((128,128,3))`，其中每个像素保存对应于一种颜色的三个值。图像形状的细节，比如形状`(3,)`和`(3,1)`之间的差异，取决于你处理数据的方式。您可以随时使用`x_data[0].shape`来查找数据的具体形状。在后面演示基于图像的深度学习方法的章节中，你会看到更多这样的例子。

现在我们已经指定了输入的形状，我们可以开始添加层来形成神经网络的主体。这个简单的神经网络将只有`Dense`层，它们是规则的密集连接的神经网络层(列出 [1-3](#PC3) )。一般来说，使用`Dense`层时会提供两个参数——层中的单元(神经元、节点)数量和激活函数。

```
from keras.layers import Dense

# layer with 10 nodes and ReLU activation
model.add(Dense(10, activation='relu'))

# layer with 5 nodes and ReLU activation
model.add(Dense(5, activation='relu'))

Listing 1-3Building the body component of a Sequential model

```

Note

`Dense`层的激活功能范围有限。要使用高级激活函数，不要在标准的密集连接层中提供激活函数(默认情况下不会应用激活函数),并在其后跟随一个`Activation`类层，如`model.add(keras.layers.LeakyReLU())`。

这两层构成了神经网络的主体——它们承担了学习关系的重任，以理解输入和输出之间的映射。在这种情况下，数据相对简单，因此这个小物体就足够了，但更困难的问题将需要更大和更复杂的物体。在接下来的章节中，我们将熟悉更复杂的神经网络结构的设计。

Note

可以在神经网络的第一层将`input_shape=(...)`作为参数传递，以避免使用`Input`层。虽然风格的选择因人而异，但通常使用`Input`层比`input_shape=(...)`层更好，因为它在代码组织方面更清晰。此外，`Input`层提供了更多处理数据的选项(参见 Keras 文档)。

你可能会发现这些其他层通常有助于添加到神经网络体系结构，而不管具体的应用，以增加更多的复杂性或稳定性；这些层的添加通常会提高网络性能(表 [1-2](#Tab2) )。

表 1-2

有用的正则化和规范化图层表。卷积层将在后面讨论

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

层

 | 

履行

 | 

描述

 |
| --- | --- | --- |
| 拒绝传统社会的人 | `keras.layers.Dropout(rate=0.1)` | 丢弃层随机丢弃丢弃前一层和后一层之间的某些百分比的连接。该百分比可通过`rate`参数指定。尽管简单，但放弃是防止大型神经网络过度拟合的最有效的正则化方法之一。 |
| 批量标准化 | `keras.layers.BatchNormalization()` | 批量归一化将输出归一化到其前一层，使平均值为 0，标准差为 1。它最初是为了解决一种称为内部协变量转移的现象，在这种现象中，随着模型参数的更新，深层神经网络中隐藏层的输入分布发生不规则的变化。然而，内部协变量变化已被证明不会对模型性能产生太大影响。然而，批处理规范化显著地平滑了损失情况(优化器必须导航以最小化损失的情况)，这似乎是它如此有助于模型性能的原因。许多现代神经网络采用批处理规范化，因为它在大多数问题中对大多数模型有很大的促进作用。 |
| 高斯噪声 | `keras.layers.GaussianNoise(stddev=1)` | 高斯噪声层将零中心高斯噪声添加到它前面的层的输出中。像 dropout 一样，高斯噪声层添加了噪声元素，以防止神经网络过拟合。然而，高斯噪声层提供了一种不同形式的噪声。一般来说，将噪声层放置在输入附近可以使神经网络对噪声数据更加鲁棒。我们将在第 [2](2.html) 章中探讨如何在自我监督学习的环境中有效地使用这一层和类似的层。 |

既然已经构建了输入和主体，我们就可以构造输出了。该模型应该输出与虚拟数据集中的目标相对应的两个数字，*标签 1* 和*标签 2* 。此外，这两个数字应该介于 0 和 1 之间，这意味着我们应该将 sigmoid 函数应用于其输出。sigmoid 函数允许输出介于 0 和 1 之间，表示输入具有标签 *1* 的概率。最后一个`Dense`层允许我们定义两个输出和一个 sigmoid 激活函数:model.add(Dense(2，activation='sigmoid ')。

这样，我们完整的小神经网络如下(列表 [1-4](#PC4) )。

```
import keras
from keras.models import Sequential
from keras.layers import Input, Dense
model=Sequential()
model.add(Input((3,)))
model.add(Dense(10, activation='relu'))
model.add(Dense(5, activation='relu'))
model.add(Dense(2, activation='sigmoid'))

Listing 1-4Building the complete Sequential neural network

```

应该注意的是，不同的人可能会发现，根据他们的编码风格，有许多不同的导入方式。例如，在前面的例子中，层被导入为`from keras.layers import a, b, ...`。然而，当构造需要许多不同层的大型神经网络时，没有必要导入单独的层。在这种情况下，可以使用`import keras.layers as L`并将每一层称为`L.layer_name`。使用这种方法，可以重新编写神经网络，而不需要在开始时按名称导入每一层，如下所示(清单 [1-5](#PC5) )。

```
import keras
from keras.models import Sequential
import keras.layers as L
model=Sequential()
model.add(L.Input((3,)))
model.add(L.Dense(10, activation='relu'))
model.add(L.Dense(5, activation='relu'))
model.add(L.Dense(2, activation='sigmoid'))

Listing 1-5Rewriting method of imports to avoid needing to import all layers explicitly

```

请注意，本书将在大多数情况下使用 L.Layer 格式，除非有必要单独呈现每个层来解释它们的用途，其中使用了 from keras.layers import a，b 语法(这主要出现在前面的章节中)。

既然我们已经用输入-主体-输出框架定义了模型的体系结构，我们需要在模型适合数据之前提供模型的其他方面的信息。

### 第二步:编译

既然我们已经用输入-主体-输出框架定义了模型的架构，我们需要提供关于模型其他方面的信息。

Keras 模型的`.compile()`方法需要三个关键参数:

*   *损失函数*:损失函数是一个数学函数，它接受真实标签和预测标签，并输出相应的误差。损失函数量化了错误的“特征”——例如，它是否不成比例地惩罚了某些类型的错误。

*   *优化器*:优化器确定神经网络如何改变其权重以最小化损失函数。不同的优化器更适合不同的损失情况；一些优化器可能更好，例如，在光滑和平坦的损失景观。其他人可能会在更曲折的道路上取得成功。

*   *metrics(s)*:此参数不影响神经网络的训练方式，但它让 Keras 知道您想要使用哪些指标来监控神经网络的性能。默认情况下，Keras 将记录并提供有关丢失的信息(以及验证丢失，如果您提供了验证数据集)。但是，它也可以提供其他的误差度量，以提供对神经网络性能的更全面的理解。

例如，一个简单的模型可以使用均方误差作为损失函数，Adam 优化器(Adam 通常用作默认优化器)，并且还提供关于平均绝对误差和准确度的信息:model . compile(loss = ' binary _ cross entropy '，optimizer='adam '，metrics=['mae '，' accuracy'])。

理解编制步骤的一个好方法是理解这三个参数中的每一个与损失情况的关系。损失情况是模型的每个参数与具有这些参数的模型将获得的相应损失之间的关系。

例如，考虑以下损失情况。神经网络的目标是在损失图中找到损失值最小的位置。

![../images/516104_1_En_1_Chapter/516104_1_En_1_Fig3_HTML.jpg](../images/516104_1_En_1_Chapter/516104_1_En_1_Fig3_HTML.jpg)

图 1-3

标有全局最小值的损失情况示例

有几个在大多数损失场景中常见的属性需要注意:

*   存在大范围的可行参数。超出此范围的参数会有巨大的损失，这可以通过损失急剧增加的大斜坡来证明。在这种情况下，可行的范围大约在–4.0 到 11.0 之间。这意味着此范围内的参数值会产生一个模型，该模型会针对数据集产生合理的行为。

*   有一个全局最优/最小值标有叉号。这是最小化损失函数和优化性能的参数。在这个示例损失函数中，优化假设模型性能的参数大约是 7.5。

*   在从-2.5 到 0.0 的参数范围附近有一个局部最小值/平台。在这个区域中，向任一方向移动要么增加误差，要么不增加误差。神经网络可能难以导航这些区域，因为曲线在该点的斜率没有给出全局最小值驻留在哪里的指示。

这些特征在损失场景中很常见，尽管在具有数百万或数十亿参数的现代神经网络中，这些场景比本例中的场景更高维，更难以解释/可视化。

让我们更好地理解与损失景观概念相关的编译 Keras 模型的每一个元素。

#### 损失函数

损失函数对于确定神经网络如何达到其最优解是至关重要的。它通过接受模型预测和真实标签，然后返回一个数字来量化模型预测的“良好程度”,来定义损失情况的形状。

设计损失函数的目标是在计算上或数学上最好地表示“最佳”、“较好”和“较差”模型的特征。一个好的损失函数应该在模型最好的地方最低。如果一组模型参数较好，损失应该较低，如果模型较差，损失应该较高。此外，损失的减少和增加应该与模型的“更好”或“更坏”成比例。例如，如果我们认为某些行为比其他行为对模型性能的损害更大，我们的损失函数应该不成比例地惩罚该行为，以反映我们对孰优孰劣的感觉。

例如，计算预测标签和真实标签之间的平均平方差的均方误差(MSE)损失背后的逻辑是，大误差比小误差更具破坏性。平方机制迫使任何较大的误差变得特别突出，模型必须在关注较小的误差之前解决这些较大的误差，以最大程度地减少损失。

在许多情况下，在不同的损失函数上优化模型导致不同的解决方案(即，最终神经网络在训练后具有的参数集)。有几个通用损失函数，一般足以解决大多数问题，并可用于开始。这些组织在表 [1-3](#Tab3) 中。

应该注意的是，一些默认的损失函数可以通过将一个字符串作为参数传递给`.compile()`方法，像`.compile(loss='mse')`或`.compile(loss='mae')`来通过名字显式地提及。但是，如果您想使用带有特定参数的更复杂的损失，请将一个`keras.losses`对象传递给`loss`参数，而不是一个字符串。例如，如果想对二进制交叉熵损失使用标签平滑(一种防止过度自信的方法)，模型将编译如下(清单 [1-6](#PC6) )。

```
import keras.losses as L
model.compile(loss=L.BinaryCrossEntropy(l_smoothing=0.1),
              ...)

Listing 1-6Example of passing a keras.losses object rather than a string as an argument when compiling. The parameter label_smoothing is abbreviated as l_smoothing for length

```

然而，即使 TensorFlow/Keras 的违约损失也是有限的。TensorFlow Addons 是一个社区贡献的代码集合，可与 TensorFlow/Keras 一起使用，并基于其功能进行构建。TensorFlow 插件支持许多更复杂的损失，通常用于某些类型的问题。TensorFlow 插件可以通过`pip install tensorflow-addons`安装，并作为`import tensorflow_addons as tfa`导入。

表 [1-3](#Tab3) 中的`Implementation Name`列解释了有用的损失函数和用例，包含一个字符串(`'loss_name'`)、一个`keras.losses`对象(`keras.losses.loss_name()`)或一个`tfa.losses`对象(`tfa.losses.loss_name()`)。这些可以传递到`.compile`命令的`loss`参数中。当不需要`keras.losses`对象时，只提供一个字符串，因为没有用户可以提供的参数。

表 1-3

回归和分类问题的常见损失函数列表

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
| 

损失函数

 | 

问题类型

 | 

实现名称

 | 

描述

 |
| --- | --- | --- | --- |
| 均方误差 | 回归 | `'mse'` | 均方误差是预测标签和真实标签之间的平均平方差。MSE 具有不成比例地惩罚较大误差的优势。例如，如果模型预测输出为 1，而真实标签为 3，则 MSE 将为 4。如果模型将其预测值增加一个单位，达到 2 而不是 1，则 MSE 将为 1。将模型的预测值增加一个单位会导致误差减少四分之三。随着模型的预测变得越来越接近真实预测，MSE 将减少得越来越少。 |
| 绝对平均误差 | 回归 | `'mae'` | 平均绝对误差可能是最简单的损失函数——它就是预测值与实际值之间的平均距离。由于这种简单性，它几乎从未用于深度学习，尽管它可能足以满足某些更简单的任务和架构。 |
| 胡伯损失 | 回归 | `'huber'`(默认增量值为 1.0)`keras.losses.huber(y_true, y_pred, delta=1.0)` | Huber 损失设计为 MSE 和 MAE 的组合，使用 delta 参数。当δ参数等于 0 时，Huber 损耗等于 MAE 当它等于无穷大时，Huber 损失等于 MSE。当数据变化很大且有许多异常值时，使用低增量值；当数据变化不大时，使用较高的增量值。 |
| 均方对数误差 | 回归 | `'msle'` | 均方对数误差是真实值的对数和预测值的对数之间的均方差值。它与真实值和预测值之间的比率有关；它测量目标和预测之间的百分比差异。MSLE 特别惩罚低估多于高估。 |
| 余弦相似性 | 回归 | `'cosine_similarity'` | 余弦相似度计算两个向量之间角度的余弦，即真实的 *y* 值和预测的 *y* 值。Keras 中的余弦相似性损失是这样实现的，余弦相似性损失 1 表示两个向量彼此直接相反(最不相似)，损失–1 表示两个向量指向完全相同的方向(最相似)，损失 0 表示两个向量彼此正交或垂直。当预测的向量表示的方向比其幅度更重要时，使用余弦相似性损失。 |
| 交叉熵损失/负对数似然 | 分类 | `keras.losses.BinaryCrossentropy(y_true, y_pred)`用于二进制分类`keras.losses.CategoricalCrossentropy(y_true, y_pred)`用于带有两个以上标签的分类。标签是一次性编码的。`keras.losses.SparseCategoricalCrossentropy(y_true, y_pred)`用于带有两个以上标签的分类。标签是整数。 | 交叉熵损失是分类中最流行和默认的损失之一。它是校正概率对数的负平均值。也就是说，首先找到校正后的概率，简单地说，如果预测是正确的，就意味着 *p* ，如果预测是错误的，就意味着 1-*p*。校正概率越高，性能越好。取这些概率的负对数允许低校正概率比高校正概率具有不成比例的高误差。这些对数的平均值是交叉熵的结果。利用概率和对数也与信息论和熵有关，熵是对分布不确定性的一种度量。 |
| 焦点损失 | 分类 | `tfa.losses.SigmoidFocalCrossEntropy()` | 焦点损失最常用于对高度不平衡的数据集进行分类。这是交叉熵的一种变化形式，它对不太常见的例子给予较高的权重，而对更常见的例子给予较低的权重。焦点丢失是为密集对象检测任务设计的，在这种情况下，特定类别和其他类别之间存在非常大的不平衡，但它还有许多其他使用案例。 |

此表中没有包括许多其他损失，这些损失可能对某些问题子集有用。它们可以在 Keras/tensor flow/tensor flow-Addons 文档中找到。

然而，即使是 Keras 和 TensorFlow/Tensorflow 插件也受到损失函数选择的限制。您可以创建*自定义损失函数*来使用尚未实现的函数，或者以现有方法无法实现的方式更改现有损失函数以达到您的目的。

创建一个定制损失函数通常采用以下形式(清单 [1-7](#PC7) )。我们将在后面的章节中使用自定义损失函数来解决需要当前已有损失函数之外的专门损失函数的问题。

```
import keras.backend as K
def custom_loss(y_true, y_pred):
    result = do_something(y_true, y_pred)
    return result

Listing 1-7The general form of a custom loss function

```

注意，因为损失函数处理的是 Keras 张量，所以使用 Keras 后端或`tf.math`函数来执行数学运算是最简单的，比如`K.sum()`或`K.square()`。例如，考虑以下均方误差的自定义实现(清单 [1-8](#PC8) )。

```
import keras.backend as K
def custom_mse(y_true, y_pred):
    return K.mean(K.square(y_pred-y_true))

Listing 1-8Example of writing the mean squared error loss as a custom loss function

```

但是，如果损失函数更复杂，那么很难只用后端函数编写损失函数。在这种情况下，TensorFlow 的`.py_function()`允许将 Python 函数写成 TensorFlow 图，可以用作神经网络中的损失函数。例如，我们可以在我们的损失函数中编写`if/else`关系，否则需要用像`tf.cond()`这样的张量流函数来编写，这允许条件语句，但很难使用并且不直观(清单 [1-9](#PC9) )。

使用 TensorFlow 的`.py_function()`将 Python 操作写入损失函数至少涉及两个函数:

*   处理 Python 操作的 Python 函数，如 if/else/elif、for 循环等。它必须接受一列`tf.Tensor`输入，并输出一列张量。

*   一个形式上作为“真实”损失函数的函数，传递给编译的`loss`参数。该函数完全使用 TensorFlow/Keras 对象和操作进行操作。

```
def py_func(y_true, y_pred):
    if condition():
        return something(y_true, y_pred)
    else:
        return something_else(y_true, y_pred)

def custom_loss(y_true, y_pred):
    result = tf.py_function(func=py_func,
                            inp=[y_true, y_pred],
                            Tout=tf.float32)
    return result

Listing 1-9One example of the structure of writing Python functions as TensorFlow operations capable of functioning as a loss

```

py_function 中的 Tout 参数有助于指定 Python 函数的输出类型。一般来说，定义自定义损失与类型错误有关；这些问题通常可以通过在函数的开头放置 var = tf.cast(var，tf.float32)(或其他一些数据类型，如 tf.float64)来解决，这样该函数的所有输入参数都符合特定的数据类型。

此外，您的自定义损失函数需要能够处理批量数据。容纳批处理的一种方法是使用下面的结构:`[func(batch) for batch in y_true]`。这将对每个批次应用一个操作。

还值得注意的是，损失函数不能涉及来自外部库的函数，除非它们被转换成 Keras/TensorFlow 可适应的函数，因为损失函数需要可微，而非 Keras/TensorFlow 函数不可微。您的代码可能仍会运行，但是模型将无法访问有意义的渐变，并且性能很差。

一般来说，大多数定制损失函数设计都非常简单，值得编写一个定制损失函数，并获得更好的性能。损失函数最直接地决定了你的损失景观的形状，它控制神经网络收敛到哪个解。针对您的特定问题选择和/或调整损失函数对于高性能尤为重要。

#### 优化者

虽然损失函数决定了损失图的形状，但是优化器的选择决定了神经网络如何更新其权重来遍历损失图以找到其最小值。哪个优化器工作得最好取决于损耗图的形状，正如前面提到的，损耗图最直接地由损耗函数决定，但也受包括网络架构在内的各种其他因素的影响。

像损失函数一样，在编译时，优化器可以作为字符串名传递，如`'adam'`，它初始化默认的优化器对象或 TensorFlow/Keras 优化器对象，如`keras.optimizers.Adam()`。TensorFlow Addons 也有许多在核心 TensorFlow/Keras 库中没有实现的优化器，它们可能比默认的可用优化器更适合特定的问题。

几乎所有现代神经网络优化器都是基于梯度的，这意味着它们依赖于损失函数在某一点的导数或斜率来判断它应该向哪个方向移动。这样，优化器可以“向下”移动，有希望达到全局最小值。

基于梯度的方法的主要问题是复杂数据集和模型的损失景观有许多局部最小值，优化器可能会“陷入”其中。一般来说，优化者的区别在于他们如何处理局部最小值和平台。处理这些问题的一些方法包括

*   *动量*:把优化器想象成一个滚落在丘陵地带的球，试图找到海拔最低的区域。极小值位于两座山之间的空间。一旦球达到最小值，它不会立即停下来，因为它有从山上滚下来的动量——这种动量将允许它继续向下一座山滚一点点。如果下一个山丘太高，球会滚下来并振荡，直到它达到最小值。如果下一个山不太高，球的动量可能允许它滚过下一个山进入潜在的更低的最小值。内斯特罗夫加速梯度(NAG)和其他基于动量的优化策略使用这种逻辑来“跳出”局部最小值。

*   *更新的波动性*:拟合的每一步，模型都会对损失函数进行评估，决定往哪个方向介入。如果每次更新都是高度不稳定的——它变化不定且显著——优化器可以简单地因为这种高度活跃的行为而“跳出”局部最小值。然而，这也意味着它有跳出好的局部极小值到更差的解的风险。

*   *调整学习率*:当导数告诉优化器向哪个方向前进时，学习率决定了该前进多远。高学习率导致大的步长，这可以跨越低学习率难以摆脱的局部最小值。然而，应该注意的是，如果模型已经找到了真正的全局最小值，则设置高学习率会冒跳出该全局最小值的风险。

参见以下常见优化器及其在 Keras 模型中的实现(表 [1-4](#Tab4) )。

表 1-4

常见的 less 优化器列表

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

【计算机】优化程序

 | 

Keras 实施

 | 

**描述**

 |
| --- | --- | --- |
| 随机梯度下降 | `'sgd'``keras.optimizers.SGD()` | 随机梯度下降对每个训练示例的权重进行更新，因此它比“普通”(标准)梯度下降更快。因为 SGD 经常更新权重，所以训练可能会不稳定。这意味着 SGD 可以跳跃并发现新的局部极小值，但是它很难收敛到一个解。具有内斯特罗夫加速梯度的 SGD 在浅层网络中表现良好。 |
| 阿达格拉德 | `'adagrad'``keras.optimizers.Adagrad()` | Adagrad 自动调整学习率，以较小的学习率更新频繁出现的特征(更加小心),以较大的学习率更新不太频繁出现的特征。由于这种自动学习速率调整，Adagrad 非常适合稀疏数据。然而，随着时间的推移，学习率稳步下降，直到它在功能上等于 0，在这种情况下，没有新的东西可以学习。 |
| 均方根传播(RMSProp) | `'rmsprop'``keras.optimizers.RMSProp()` | RMSProp 通过降低学习速度衰减的速率来缓解 Adagrad 的学习速度持续衰减的问题。RMSProp 是深度神经网络的常见选择，因为它的学习速率衰减方法在大多数损失情况下都是有效的。 |
| 自适应矩估计 | `'adam'``keras.optimizers.Adam()`稀疏数据见`tfa.optimizers.LazyAdam()`。参见`tfa.optimizers.RectifiedAdam() ()`解决(纠正)自适应学习率的高变化。 | Adam 以类似于 RMSProp 的方式解决 Adagrad 的激进学习率问题。然而，Adam 考虑梯度更新历史，这意味着更新不仅基于当前梯度，而且基于先前的更新。我们不需要依赖当前的梯度，但是可以基于几个步骤通知更新行为。Adam 常用于深度网络。 |

选择适当的损失函数进行优化对于良好的模型性能至关重要。

#### 韵律学

指标不涉及改变或导航亏损状况。相反，它们有助于更全面地理解模型的优点。虽然度量和损失在结构上是相似的，因为它们接受预测标签和真实标签，并输出一个数字来量化误差，但它们的设计应该是不同的。损失的目的是引导优化器找到最佳解决方案，而度量的目的是作为一个人来理解一个模型是否好。

因此，在设计损失函数时，强调移动(即，引导优化器向理想的解决方案移动)，这可能以可解释性为代价。也就是说，我们更关心的是指导网络，而不是实际解释它在训练期间的表现。另一方面，在深度学习的背景下，一个好的*指标*除了适合你的问题(问题和数据集类型——分类/回归、平衡/不平衡等)的前提条件之外。)，必须易于解读。理想情况下，度量可以提供一组更丰富的数据，以支持人们对模型应该做什么的决策。例如，如果模型达到一个非常低的损失值*和*，其他几个有意义的不同指标证实了模型的高性能，你可以相信模型不仅仅在*损失函数*方面是好的，而且通常在几个指标上也是好的。在损失和度量方面都表现良好的模型很可能成功地对数据集代表的现象建模，而不仅仅是数据集本身(即过度拟合)。

如果模型在损失方面表现良好，但在其他指标方面表现不佳，则有两种可能性需要考虑:

*   损失函数代表“好的解决方案”吗？如果损失函数构造得不好，它可能会引导神经网络找到使损失最小化的解决方案，但对于其他度量来说表现不好。

*   *这些指标与问题相关吗？*某些指标可能与神经网络试图建模的现象无关。如果您认为是这种情况，您可以选择与问题更相关的其他指标。

将度量指标与模型性能进行比较，可以获得关于模型性能的重要见解。请记住，深度学习和机器学习通常涉及对*现象*或数据来源进行建模，而不是实际的数据集本身(尽管我们必须对数据集进行建模才能对现象进行建模)。也就是说，我们想要一个模型来分离猫和狗的图像，而不是——作为其最终目标——记住一个图像数据集，即使为了这样做，模型需要学习图像数据集中的表示。度量允许我们更广泛、更丰富地考虑模型的性能和行为，而不仅仅是损失。

您可以将前面讨论的许多损失作为度量传递，如均方误差或交叉熵。然而，有一些额外的指标不能、不应该或很难用作损失函数，但作为监测网络性能的指标却很有价值(如表 [1-5](#Tab5) 所示)。

像损失函数和优化器一样，在 Keras 中，度量可以作为字符串、`keras.metrics`对象或`tfa.metrics`对象传递给编译的`metrics`参数。

表 1-5

分类中使用的通用指标的示例列表。或多或少，回归的所有损失函数都可以用作度量

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

公制的

 | 

硬名称

 | 

描述

 |
| --- | --- | --- |
| 准确 | `keras.metrics.BinaryAccuracy()`对于二进制标签`keras.metrics.CategoricalAccuracy()`对于分类一热标签 | 准确度是最基本的指标之一，计算方法是正确预测的标签数除以标签总数。 |
| 曲线下面积 | `keras.metrics.AUC()` | AUC(或 AUROC，或受试者工作曲线下面积)是一种用于二元分类的度量，范围从 0 到 1。AUC 表示正绘制的均匀随机具有比负绘制的均匀随机更高的模型输出的概率。 |
| F1 分数 | `tfa.metrics.F1Score` | F1 分数是精确度和召回率的调和平均值，范围从 0 到 1。在功能上，它类似于平衡模型的正确性和不正确性的准确性，但在不平衡的数据集上效果更好。 |

也可以使用与创建定制损失函数相同的方法来创建定制度量。构建自定义指标来适应您的特定问题是很好的，因为通用指标通常有弱点，可能会误导具有某些属性的数据集，如不平衡或有许多异常值。但是，要确保自定义指标是可解释的。

### 第三步:适应和评估

既然已经定义了模型架构，并且已经编译了模型，那么模型就可以适合数据了。拟合一般采用以下形式:model.fit(x=x_data，y=y_data，epochs=30，callback =[callback 1，callback2])。

在这种情况下，提供`x_data`和`y_data`来拟合模型。这些可以采用`numpy`数组或`pandas`数据帧的形式。然而，对于许多大型数据集，例如图像，使用这些显式方法通常会导致内存问题。其他更有效的数据流方法将在后面讨论。

`epochs`参数是指模型将在整个提供的数据集上循环的次数。例如，如果 epochs=5，模型将在整个数据集上运行五次。

尽管拟合模型并不需要回调，但是使用回调是一种很好的做法。回调是在每个时期之后执行的操作，因此允许在其训练期间记录或改变模型。通常使用三种回调方法——保存模型权重、提前停止和在平稳状态下减慢学习速度。

`ModelCheckpoint`回调(清单 [1-10](#PC10) )将每个历元后的模型权重保存到指定的`filepath`；如果`save_best_only`被设置为`True`，只有最佳的模型权重集被存储到该位置。哪些权重是最佳的可以通过`monitor`和`mode`的参数来指定，前者指定要监控的度量或损失，后者指定最佳模型是否是最小化或最大化度量或损失的模型。例如，如果`monitor`被设置为`'accuracy'`(并且准确性是编译期间提供的度量标准)，`mode`应该是`'max'`。

```
import keras.callbacks as C
mc = C.ModelCheckpoint(filepath='output/folder',
                       save_weights_only=True,
                       monitor='val_loss',
                       mode='min',
                       save_best_only=True)

Listing 1-10Model checkpoint callback syntax

```

`ModelCheckpoint`回调允许模型一旦停止改进就停止训练。这有助于节省计算资源。`monitor`参数指定将被监控以进行改进的指标或损失。监控指标的变化或损失小于`min_delta`将被视为无改善。默认情况下，`min_delta`会被算作`0`。最后，`patience`确定模型停止训练需要多少个没有改进的时期。在 Keras 中可以这样使用:es = C . early stopping(monitor = " val _ loss "，min_delta=0，patience=3)。

`ReduceLROnPlateau`回调还检查模型是否停止改进(它达到了一个“平稳期”)，但是降低了学习率，而不是停止训练，就像`EarlyStopping`所做的那样。`monitor`和`patience`参数的作用与`EarlyStopping`相同；`ReduceLROnPlateau`回调还有另一个参数`factor`，它决定了每次确定模型停止改进时，学习率所乘以的因子。在 Keras 中可以这样使用:RP = C . ReduceLROnPlateau(monitor = " val _ loss "，patience=3，factor=0.1)。

在虚拟数据集上运行该神经网络的`.fit()`方法 1000 个历元，产生如图所示的进度输出。损失函数和指标的值显示在进度输出中(列表 [1-11](#PC11) )。

```
Epoch 1/1000
1/1 [==============================] - 1s 610ms/step - loss: 0.6230 - mae: 0.4616 - accuracy: 1.0000
Epoch 2/1000
1/1 [==============================] - 0s 4ms/step - loss: 0.6209 - mae: 0.4604 - accuracy: 1.0000
Epoch 3/1000
1/1 [==============================] - 0s 2ms/step - loss: 0.6188 - mae: 0.4592 - accuracy: 1.0000

Listing 1-11Example output for a neural network on the sample dataset when the model is fitted. Note the decreasing loss just in the first three epochs. Additionally, because our dummy dataset is so small, it is counted only as one batch. Batches are groups of data that are processed simultaneously to better inform gradient updates. With larger datasets, the progress bar will indicate how many batches have been processed in the current epoch

```

虽然这些是模型性能的良好指标，但是可以通过将 model.fit()的输出分配给一个变量来存储进度，以便进行分析和可视化，如下所示:history = model.fit(...).

`history.history`是一个字典，其中每个键是一个损失或指标的名称，如`'loss'`、`'mae'`和`'accuracy'`，对应的值是每个时期的这些值的数组。例如，损失可以可视化如下(列表 [1-12](#PC12) ，图 [1-4](#Fig4) )。

![../images/516104_1_En_1_Chapter/516104_1_En_1_Fig4_HTML.jpg](../images/516104_1_En_1_Chapter/516104_1_En_1_Fig4_HTML.jpg)

图 1-4

示例模型在不同时期的训练性能

```
import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

Listing 1-12Plotting the history

```

可视化可以洞察训练行为，以及未来的训练决策。该模型似乎下降损失相当稳定和一致，虽然它是在速度下降。因此，很可能多几个时期的训练可以导致损失的轻微减少。你可以再次调用`model.fit(...)`，模型将从之前拟合终止的地方继续拟合。

模型预测可以用`model.predict(X_sample)`计算，模型对验证数据的性能可以用`model.evaluate(X_test, y_ test)`计算。评估为所提供的数据集计算在编译步骤中传递的损失和度量。

基于训练的结果，可以调整编译步骤中指定的模型架构和训练参数，以优化性能。第 5 章将讨论自动优化的方法。

## 可视化模型架构

大型复杂的神经网络架构在构建时可能难以概念化。Keras 提供了一个有用的工具来可视化模型的体系结构，这在构建神经网络时是无价的。我们可以从绘制我们刚刚构建的模型的架构开始(列表 [1-13](#PC13) ，图 [1-5](#Fig5) )。

![../images/516104_1_En_1_Chapter/516104_1_En_1_Fig5_HTML.jpg](../images/516104_1_En_1_Chapter/516104_1_En_1_Fig5_HTML.jpg)

图 1-5

默认`plot_model`命令的输出

```
from keras.utils import plot_model
plot_model(model)

Listing 1-13Plotting an example model with Keras

```

Keras 将每一层可视化为一个矩形；每个图层都以“名称:图层类型”的形式进行注释如果用户需要引用特定的层，Keras 会自动将每个层与名称相关联。然而，我们可以通过使 Keras 显示每个层的形状转换和数据类型来获得关于模型的更多信息:plot_model(model，show_shapes=True，show_dtype=True)。输出如图 [1-6](#Fig6) 所示。

![../images/516104_1_En_1_Chapter/516104_1_En_1_Fig6_HTML.jpg](../images/516104_1_En_1_Chapter/516104_1_En_1_Fig6_HTML.jpg)

图 1-6

显示数据类型和形状的`plot_model`命令输出

本例中所有四层的数据类型都是`float32`。了解数据类型可以让您调试在更复杂的数据类型和流中可能遇到的任何数据类型问题。

了解每一层如何转换数据的形状特别有价值，尤其是在处理像图像或文本这样需要复杂转换的高维数据时。例如，通过查看图表，我们可以看到“`dense_1`”层接收形状为`(None, 10)`的数据，输出形状为`(None, 5)`的数据。于是，这一层将十维数据投射到五维空间。

Note

“维度”这个词在深度学习中意味着很多东西。在传统意义上，具有五个特征的数据集被认为是“五维的”然而，在图像数据中，例如，通常有三个*空间*维度，因为每个图像具有类似于`(a, b, 3)`的形状。尽管数据有三个空间维度，但神经网络在技术上是在`a*b*3`维空间中运行的。术语“维度”单独指的是每个数据实例中元素的数量，而不考虑它们是如何组织的，而术语“空间维度”指的是每个数据实例的元素沿着其组织的轴的数量。

我们将看到一些例子，在这些例子中，可视化模型对于非线性拓扑和第 [3](3.html) 章中的自动编码器设计都很有帮助。

最后，如果您需要高分辨率的架构图，例如，在非常大的架构使得查看特定组件更加困难的情况下，请使用 to_file='path/image.png '和 dpi 参数。后者控制每英寸点数；200 到 400 通常有助于获得清晰的图像。

## 功能 API

`Sequential`模型通过`.add()`方法依次添加层。然而，这种类型的模型在许多方面受到限制，更复杂的神经网络结构使用函数式 API。

在函数式 API 中，各个层被定义为前一层的函数(清单 [1-14](#PC14) )。

```
import keras.layers as L
input_layer = L.Input(shape)
second_layer = L.Layer_Name(params)(input_layer)
third_layer = L.Layer_Name(params)(second_layer)
output_layer = L.Layer_Name(params)(third_layer)

Listing 1-14General syntax of the Functional API

```

每一层都以它自己的变量开始，每一层都相对于另一层进行初始化(除了第一个输入层)，这与`Sequential`模型不同，在`Sequential`模型中，层是在代码中定义的，与`keras.models`对象直接相关。需要注意的是，这个“双括号符号”是由两部分组成的——第一组括号是 Python 符号的一部分，用于初始化 layer 对象，第二组括号用于将前一层传递给这个初始化的 layer 对象。您不必一起执行这两个操作(有时您不能这样做，因为实现需要分离，但通常将它们链接在一起更容易)；例如，您可以编写 curr_layer = L.Layer_Name(params)在一行中初始化某个当前层，并编写 curr _ Layer = curr _ Layer(prev _ Layer)将其与前一层连接起来。

一旦从功能上定义了每一层，就需要将它们聚集成一个模型对象:model = keras。模型(输入=输入层，输出=输出层)。

将每个层分配给一个唯一且适当命名的变量的好处是，以后可以单独引用它们。然而，如果不需要这样做，通常每次都用类似`x`的变量重新定义层。这在功能上构建了神经网络，就像先前的方法一样，但是没有引用单个层的能力(列表 [1-15](#PC15) )。

```
import keras.layers as L
input_layer = L.Input(shape)
x = L.Layer_Name(params)(input_layer)
x = L.Layer_Name(params)(x)
x = L.Layer_Name(params)(x)
model = keras.Model(inputs=input_layer, outputs=x)

Listing 1-15Defining architectures functionally with repeated variable assignment for simplicity

```

这种变量重定义符号可能会令人困惑。我们来分解一下:在清单 [1-15](#PC15) 的第 3 行，x 被定义为连接到输入层的层。在第 4 行中，x 被定义为连接到 x 的层；但是，在第 4 行的变量 x 实际赋值之前，对象 L.Layer_Name(params)(x)被初始化和连接。因此，当对象被初始化时，x 保存第 3 行中定义的前一层。在对象初始化并连接到先前定义的层之后，对象本身被定义为 x，在第 5 行中，连接到在第 4 行中定义的这个层的新层被重新定义为 x，以此类推。在第 6 行中，x 持有架构的最后一层，因此持有输出；除了输入层之外的所有其他中间层都被赋值给了一个变量(我们可以通过名称来检索它们；图层命名将在本章中讨论，非可变图层检索方法将在第 [2](2.html) 章中讨论，在那里更相关)。

一旦创建了模型对象，基于函数 API 的模型的训练、预测和评估过程与`Sequential`模型是相同的。您可以将这个功能定义的模型可视化，并将其与顺序定义的模型的架构进行比较，以验证它们的等价性。

在接下来的章节中，我们将会看到更多函数式 API 变得非常有用的例子。

### 将序列模型转换为功能模型

之前，我们按顺序构建了以下模型(清单 [1-16](#PC16) )。

```
from keras.models import Sequential
import keras.layers as L
model = Sequential()
model.add(L.Input((3,)))
model.add(L.Dense(10, activation='relu'))
model.add(L.Dense(5, activation='relu'))
model.add(L.Dense(2, activation='sigmoid'))

Listing 1-16Previous Sequential model

```

现在，我们可以在不使用`Sequential`模型使用的`.add()`方法的情况下功能性地构建模型(清单 [1-17](#PC17) )。

```
import keras.layers as L

# define all layers
input_layer = L.Input((3,))
dense_1 = L.Dense(10, activation='relu')(input_layer)
dense_2 = L.Dense(5, activation='relu')(dense_1)
output_layer = L.Dense(2, activation='sigmoid')(dense_2)

# aggregate into model
model = keras.Model(inputs=input_layer, outputs=output_layer)

Listing 1-17Rewriting the Sequential model functionally

```

我们也可以通过使用变量重定义方法来编写顺序定义模型的架构(清单 [1-18](#PC18) )。请注意，因为将层聚合到模型中的第二步需要输入和输出层，所以我们不能将输入层定义为 x。

```
import keras.layers as L

# define all layers
input_layer = L.Input((3,))
x = L.Dense(10, activation='relu')(input_layer)
x = L.Dense(5, activation='relu')(x)
x = L.Dense(2, activation='sigmoid')(x)

# aggregate into model
model = keras.Model(inputs=input_layer, outputs=x)

Listing 1-18Rewriting the Sequential model functionally with repeated variable assignment

```

### 构建非线性拓扑

在前面的部分中，我们将顺序定义的模型转换/重写为功能定义的模型。不过，对于非线性拓扑来说，函数式 API 尤其有价值，因为非线性拓扑是一种神经网络架构，没有也不能顺序定义。非线性拓扑使用*复制*，其中一层的输出被复制并发送到两个或更多单独的层，以及*串联*或其他形式的合并，其中一层的输入是其之前多个层的聚合。与线性、顺序定义的拓扑形成对比，在线性、顺序定义的拓扑中，每层的输入只是一层的输出，一层的输出只传递给一层的输入。

非线性拓扑是有价值的，因为它们允许更复杂和不同的数据表示。例如，假设我们想训练一个神经网络来分类一张图片是猫还是狗。如果我们训练了一个顺序构建的卷积神经网络，图像将通过一组过滤器，从一种形式的过滤器中提取的特征将被传递到下一层。也就是说，每一层都受到一组参数的限制，这些参数决定了先前的字符如何提取信息。您可以在第 [6](6.html) 章中找到关于架构非线性的更详细的技术讨论。

在本例中，利用非线性拓扑，我们可以将输入通过三个独立的滤波器，以提取图像的三种不同的有意义的表示和提取:

*   小尺寸滤镜:这一层捕捉更小的细节，比如鼻子的形状。

*   中等大小滤镜:这一层捕捉更大的细节，比如毛发或面部结构的纹理。

*   *大尺寸滤镜*:这一层捕捉宏观尺度的图案，比如动物身体的形状。

尽管顺序构建的模型据说经历了这些相同的步骤(即，可以开发它们自己的“大”、“中”和“小”过滤器内部表示)，但是它们更多地受到它们的拓扑的限制和约束。几乎所有现代深度神经网络设计都使用某种非线性拓扑。

用函数式 API 构建非线性拓扑非常直观。让我们反向工作，从一个拓扑的可视化开始(图 [1-7](#Fig7) )并使用函数 API 编写代码来创建模型。

![../images/516104_1_En_1_Chapter/516104_1_En_1_Fig7_HTML.jpg](../images/516104_1_En_1_Chapter/516104_1_En_1_Fig7_HTML.jpg)

图 1-7

要重建的非线性拓扑的示例图

应注意，该图遵循命名程序:

*   `b` (branch):这是复制后合并前的图层系列。因此，“`b1`”表示“`branch1`”

*   `l`(层):由此，“`l1`”表示“`layer1`”

*   `m`(合并):这是分支合并期间和之后的一系列层。

当然，这种命名过程是任意的，不能处理更复杂的体系结构，比如有多个合并站点的情况。在为组织使用非线性拓扑时，最好建立一个命名程序。

让我们从定义输入层开始(列表 [1-19](#PC19) )。虽然 Keras 会自动为您命名层，但是在复杂的拓扑中实现您自己的命名过程是一个很好的实践，这可以通过将`name='name'`传递到每一层来完成。还可以在层初始化后通过调用`layer._name = 'name'`来更改名称。

```
import keras.layers as L
input_layer = L.Input((3,), name='input')

Listing 1-19Defining the input of a nonlinear functional model and specifying the name of layers

```

第一个分支可以这样构造(清单 [1-20](#PC20) )。

```
b1_l1 = L.Dense(10, name='b1_l1')(input_layer)
b1_l2 = L.Dense(10, name='b1_l2')(b1_l1)
b1_l3 = L.Dense(10, name='b1_l3')(b1_l2)

Listing 1-20Defining one branch of a nonlinear functional model

```

第二个分支可以类似地构建(清单 [1-21](#PC21) )。

```
b2_l1 = L.Dense(3, name='b2_l1')(input_layer)
b2_l2 = L.Dense(3, name='b2_l2')(b2_l1)
b2_l3 = L.Dense(3, name='b2_l3')(b2_l2)

Listing 1-21Defining another branch of a nonlinear functional model

```

既然已经创建了两个分支，我们需要实现一个合并。合并层采用`merging_layer()([l1,l2,...])`的形式，其中`l1`、`l2`等是其输出被合并的在先层。

Keras 提供了许多合并方法:

*   `Concatenate()`:前几层的输出相互连接。例如，如果一个层输出`[0,1]`而另一个层输出`[2,3,4]`，连接将产生`[0,1,2,3,4]`。

*   `Average()`:对前几层的输出进行平均。例如，如果一层输出`[0,1]`而另一层输出`[2,3]`，平均将得到`[1,2]`。与级联不同，在求平均值时，所有输出的长度必须相同。

*   `Maximum()`:返回上一层输出中每个对应元素的最大值。例如，如果一层输出`[0,5]`，另一层输出`[4,2]`，取最大值将得到`[4,5]`。像求平均值一样，在取最大值时，所有输出的长度必须相同。

Keras 也有类似的`Minimum()`、`Add()`、`Subtract()`、`Multiply()`、`Dot()`层。一般来说，使用`Concatenate()`层是因为它可以处理不同长度的先前层，还因为它保留了它们的所有元素。网络可以被训练成在级联之后自动执行其自己的聚合。但是，如果您非常清楚希望某些分支或合并站点扮演什么角色，那么使用其他合并方法可能会比信任模型通过串联自己发现这种关系更成功。

Note

如果处理影像数据，请确保要合并的所有要素地图都是相同的维度(例如，不能将输出形状为(100，100)的卷积图层与输出形状为(105，105)的卷积图层合并)。对于图像数据的串联式合并，Keras 默认执行深度方式的串联，其中特征贴图沿深度/过滤器/通道轴堆叠。如果使用默认参数将具有 shape (100，100，32)的要素地图连接到具有 shape (100，100，64)的要素地图，则连接的输出具有 shape (100，100，96)。

该图显示了该网络的合并方法是级联。在分支合并之后，我们可以完成网络的剩余部分(清单 [1-22](#PC22) )。

```
m1_l1 = L.Concatenate(name='m1_l1')([b1_l3, b2_l3])
m1_l2 = L.Dense(5, name='m1_l2')(m1_l1)
output_layer = L.Dense(2, name='output')(m1_l2)

Listing 1-22Merging and completing the nonlinear model

```

完成的模型可以聚合成一个`Model`对象:model = keras。模型(输入=输入层，输出=输出层)。

在本书中，我们将使用类似的逻辑，首先概念化网络架构，然后使用功能 API 来实现它。函数式 API 的简单设计允许用 for 循环和条件来构建复杂的非线性拓扑。我们将在后面的章节中看到这方面的演示。

## 处理数据

前面提到过，用`x_data`和`y_data`作为`numpy`数组或`pandas`数据帧进行训练是可能的，但对于需要深度学习应用的大多数数据类型来说，通常效率太低。有几个关键的迹象或原因可以说明为什么人们想要利用替代数据流来强力加载显式数据:

*   通过显式强力方法加载数据需要太多时间。

*   原始数据的形式非常复杂，以至于编写一个脚本将它转换成所需的格式非常困难，而且还有更简单的替代方法。

*   模型遇到了 OOM(内存不足)错误。

*   原始数据集在物理上无法容纳在分配的内存中。

因为大多数深度学习应用程序至少会涉及这些问题中的一个，所以通常最好的做法是使用替代数据流来显式加载数据。虽然有许多数据流方法，但选择一种适合您的特定问题的方法是很重要的。没有适用于所有问题的通用最佳解决方案，选择不适合您的特定问题的专用数据流方法可能比只编写显式脚本更糟糕。

Note

术语“显式”用于指非常显式地加载数据的方法，而没有任何适合于数据结构的特殊格式化或压缩以提高效率。有时，显式方法是最好的解决方案，尤其是对于较小的数据集，在这种情况下，建立数据流可能需要更多的时间投入，而不是回报。

### 加载数据中的张量流数据集

如果您已经将数据集加载到内存中，有一个简单的解决方案可以将数据放入 TensorFlow 数据集的形式中。这使得数据的处理比原始形式更有效。它可以解决使用原始数据训练模型时可能遇到的 OOM 错误。

注意，我们需要在这里导入 TensorFlow，以利用它的后端功能。

比方说，你有两个`numpy`数组，`X_train`和`y_train`；您可以使用`from_tensor_slices`函数将这两个`numpy`数组转换成一个 TensorFlow 数据集(清单 [1-23](#PC23) )。

```
import tensorflow as tf
from tf.data import Dataset as d
train_data = d.from_tensor_slices((X_train, y_train))

Listing 1-23Constructing a TensorFlow dataset from already loaded arrays

```

请注意， *x* 和 *y* 数据被组合成一个数据集。将 TensorFlow dataset 对象传递到 Keras 模型进行定型时，只能使用一个，而不能使用两个。

用`train_data.shuffle(l)`混洗数据集是一个很好的做法，其中`l`是数据集的长度。这意味着网络查看数据的顺序——这可能会影响它的学习——不受您加载数据的方式的影响。例如，如果对猫/狗分类数据集进行组织，使得前 50%的数据集项目都是猫的图像，后 50%的项目都是狗的图像，则网络的学习效果将会很差，因为如果这两个类不彼此靠近，它就不能直接区分狗和猫的图像。另外，在训练之前，用`train_data.batch(n)`对数据集进行批处理，其中每批有`n`个数据实例。这不是一个可选择的步骤，否则会导致安装错误。

在拟合 Keras 模型时，可以通过传入 dataset: model.fit(train_data，epochs=10，...).

将数据从数组直接加载到 TensorFlow 数据集的方法有很多，比如组织在目录中的文本文件或图像文件，这将在接下来讨论。

### 来自图像文件的张量流数据集

如果您正在使用影像数据集，它可能会被安排在一个目录中。不需要手动使用另一个库如`cv2`或`matplotlib`来将图像加载到存储器中，然后用现有方法将它们转换成张量流数据集格式。TensorFlow 允许我们使用`.map`一步到位地自动读取图像并将其转换为 TensorFlow 数据集的元素，这允许我们对数据集的每个元素应用一个函数。

这个想法是有一个数据集，其中 *x* 是图像的文件名， *y* 是真正的标签。然后，将对数据集应用解析函数，使得每个文件名被其对应的图像替换:un parsed _ data = d . from _ tensor _ slices((文件名，标签))。

让我们定义一个函数，它接收文件名并输出它们的图像。它遵循以下步骤:

1.  读取文件的内容。

2.  解码文件格式(jpeg，png 等。).

3.  转换为浮点值。

4.  将图像调整到所需的大小。

幸运的是，TensorFlow 实现了所有这些操作(清单 [1-24](#PC24) )。

```
def parse_files(filename, label):
    raw_image = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(raw_image, channels=3)
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.image.resize(image, [512,512])
    return image, label

Listing 1-24Creating a function to parse a TensorFlow dataset with filenames and labels

```

关于此功能的几点注意事项:

*   对于特定的图像格式，您可以使用`decode_png`或其他解码功能来代替`decode_jpeg`。

*   注意，`label`参数被原封不动地传入和传出函数。我们仍然需要包含此参数，因为数据集包含标签，这需要在映射整个数据集的函数中加以考虑。

*   在调整大小之后和返回图像和标签之前，您还可以添加许多`tf.image`函数中的几个来执行图像预处理，如添加随机变化、翻转、裁剪、调整饱和度、亮度和色调等。

这个函数可以映射到未解析的数据集，然后进行批处理、混洗，用于训练:parsed _ data = un parsed _ data . map(parse _ files)。

您可以使用将函数映射到 TensorFlow 数据集的逻辑来加载和组织图像之外的其他数据。使用映射函数允许在将数据组织成某种期望的格式时进行高级别的控制。

TensorFlow 数据集通常用于所有类型的复杂数据，因为它们高效且易于使用。

### 来自目录的自动影像数据集

Keras 提供了一个有用的函数`.image_dataset_from_directory`，它根据组织在一个目录中的数据自动构造一个`tf.data.Dataset`，在这个目录中，图像被放入相应类的文件夹中(参见清单 [1-25](#PC25) )。您可以使用像`os`和`cv2`这样的 Python 库来自动将数据重新排列成这种格式，如果它还不是的话。

```
data/
... class_1/
...... img_01.png
...... img_02.png
... class_2/
...... img_50.png
...... img_51.png

Listing 1-25Directory structure for Keras’ automated creation of a TensorFlow dataset from a directory

```

下面的代码可以用来快速地将目录转换成图像数据集(清单 [1-26](#PC26) )。`directory`参数传递一个字符串，该字符串带有直接包含对应于每个类的子文件夹的目录名。

```
from keras.preprocessing import image_dataset_from_directory
train_data = image_dataset_from_directory(
    directory='data',
    batch_size=32,
    image_size=(256, 256)
)

Listing 1-26Creating an image TensorFlow dataset from a directory

```

然后，可以像使用任何标准 TensorFlow 数据集一样使用该数据集。然而，由于数据和标签已经压缩在一起，为了应用转换，数据集需要解压缩。

### 图片生成器

TensorFlow 数据集格式的一个流行替代方案是`ImageDataGenerator`对象，它以张量形式生成图像数据，并实时扩充它们，而不是先加载所有数据并生成图像数据。因此，`ImageDataGenerator`(列表 [1-27](#PC27) )很受欢迎，因为它可以有效地处理大型数据集，还因为它不断提供新的随机增强来源。虽然 TensorFlow 数据集也可以有效地处理大数据，但它不能在训练过程中给数据添加随机性。

要使用生成器，首先要初始化一个`ImageDataGenerator`对象。当初始化对象时，向它提供关于图像的增强或预处理的信息。例如，`rotation_range`接受一个度数范围，从中选择一个随机度数并用于旋转图像。`width_shift_range`和`height_shift_range`随机将图像上下移动一定数量的像素。`horizontal_flip`随机水平翻转图像。还有许多其他参数可用于通过增亮、标准化、剪切、缩放等来增强图像，您可以在 Keras 文档中找到具体信息。如果这些可用的转换不够或者不符合您的目的，您可以向`preprocessing_function`传递一个自定义函数。

```
from keras.preprocessing.image import ImageDataGenerator
data_gen = ImageDataGenerator(rotation_range = 20,
                              width_shift_range = 30,
                              height_shift_range = 30,
                              horizontal_flip = True,
                              preprocessing_function = func)

Listing 1-27Setting up an Image Data Generator

```

生成器的作用就像一个模子，通过它数据被转换并形成所需的形式。请注意，图像数据生成器实际上并不会通过增加数据集的大小来生成新数据，它的作用就像是在每次训练之前对数据运行的自动转换。从技术上讲，它不断产生新的数据，但不是以占用更多空间的方式；这使得它成为大型数据集问题中一种流行的扩充形式。

既然您已经指定了应该如何更改数据的框架，那么有三种方法可以将数据提供给生成器。

如果您的数据已经被加载到数组格式中，但是您想要利用`ImageDataGenerator`的实时随机扩充功能，您可以使用`.flow()`方法，该方法接受一个 *x* 数据集和一个 *y* 数据集，并通过数据生成器的指定参数传递它。拟合模型时，数据生成器的作用相当于一个数据集:model . fit(data _ gen . flow(x _ train，y_train)，...).

如果图像的目录路径及其相应的标签在数据帧中，您可以使用`.flow_from_dataframe`方法在将数据作为参数传递到 fitting 之前用数据源“填充”数据(清单 [1-28](#PC28) )。

```
data_gen_filled = data_gen.flow_from_dataframe(
    dataframe,
    x_col = 'filenames',
    y_col = 'label'
)
model.fit(data_gen_filled, ...)

Listing 1-28Using the image data generator with data from a DataFrame to fit the model

```

如果图像被组织到一个目录中，其中每个子文件夹包含一个类的所有图像(就像前面讨论的 TensorFlow 数据集的格式)，您可以使用`.flow_from_directory`方法(清单 [1-29](#PC29) )。

```
data_gen_filled = data_gen.flow_from_directory(
    directory='data'
)
model.fit(data_gen_filled, ...)

Listing 1-29Using the image data generator with data from a directory to fit the model

```

## 要点

在本章中，我们讨论了使用 Keras 实现神经网络的概念和代码:

*   Keras 入门简单，功能极其丰富。

*   Keras 工作流程有三个步骤:定义模型架构、编译和拟合。
    *   在顺序模型中，通过将神经网络层相互堆叠来定义模型架构。输入和输出的设计必须适应数据的形状。

    *   编译步骤至少需要三个参数:损失函数、优化器和度量。这些参数中的每一个都与理解与损失前景相关的模型有关。对于这些参数中的每一个，您都可以传入一个字符串、一个 Keras 损耗/优化器/度量对象或一个 TensorFlow 插件损耗/优化器/度量对象。

    *   拟合模型时，提供数据、回调和要训练的时期数。您可以收集并可视化模型性能，以确定未来的步骤。

*   Keras 提供了可视化模型架构的工具，这在构建层之间的复杂关系和/或分析数据在神经网络中传递时形状如何变化时很有价值。

*   函数式 API 允许您定义非线性拓扑，这鼓励神经网络开发更复杂的数据表示。

*   虽然您可以将数据作为 numpy 数组或 pandas 数据帧传递到神经网络中，但您可以使用两种更有效的格式:TensorFlow 数据集和 Keras 图像数据生成器(用于图像数据)。

在下一章中，我们将基于我们对 Keras 如何工作的了解，讨论如何利用预训练作为一种更容易、更快速地构建复杂、强大和成功的模型的方法。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

[`https://store.doverpublications.com/0486470105.html`](https://store.doverpublications.com/0486470105.html) 。

  [2](#Fn2_source)

[`https://keras.io/why_keras/`](https://keras.io/why_keras/) 。

  [3](#Fn3_source)

[`www.quora.com/Why-has-Keras-been-so-successful-lately-at-Kaggle-competitions`](http://www.quora.com/Why-has-Keras-been-so-successful-lately-at-Kaggle-competitions) 。

  [4](#Fn4_source)

[`https://keras.io/why_keras/`](https://keras.io/why_keras/) 。

 </aside>
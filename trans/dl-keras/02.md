

# 二、Keras 安装和 API

在前一章中，我们讨论了神经网络的基本原理，并提供了几个能够识别 MNIST 手写数字的网络示例。

本章说明如何安装 Keras、Theano 和 TensorFlow。一步一步，我们将看看如何让环境工作，并在很短的时间内从直觉转向工作网络。然后，我们将讨论如何在基于容器的 dockerized 基础设施上安装，以及如何在 Google GCP、Amazon AWS 和 Microsoft Azure 的云中安装。除此之外，我们将介绍 Keras APIs 的概述，以及一些常用的操作，如加载和保存神经网络的架构和权重，早期停止，历史保存，检查点，以及与 TensorBoard 和颤的交互。我们开始吧。

在本章结束时，我们将已经涵盖了以下主题:

*   安装和配置 Keras
*   喀拉斯建筑



# 安装 Keras

在接下来的小节中，我们将展示如何在多个平台上安装 Keras。



# 步骤 1 —安装一些有用的依赖项

首先，我们安装`numpy`包，它提供了对大型多维数组和矩阵以及高级数学函数的支持。然后我们安装`scipy`，一个用于科学计算的库。之后，安装`scikit-learn`可能是合适的，这是一个被认为是用于机器学习的 Python 瑞士军刀的包。在这种情况下，我们将使用它进行数据探索。可选地，安装`pillow`，一个对图像处理有用的库，和`h5py`，一个对 Keras 用于模型保存的数据序列化有用的库。一个命令行就足以安装所需的东西。或者，你可以安装 Anaconda Python，它将自动安装科学计算所需的`numpy`、`scipy`、`scikit-learn`、`h5py`、`pillow`和许多其他库(有关更多信息，请参考:S. Ioffe 和 C. Szegedy 著的*批处理规范化:通过减少内部协变量移位加速深度网络训练*、[arXiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)，2015)。你可以在 https://docs.continuum.io/anaconda/pkg-docs[的 Anaconda Python 中找到可用的包。下面的截图显示了如何为我们的工作安装软件包:](https://docs.continuum.io/anaconda/pkg-docs)

![](assets/image_02_001.png)

# 步骤 2 —安装

我们可以使用`pip`来安装 Theano，如下截图所示:

![](assets/image_02_002.png)

# Step 3 — install TensorFlow

现在，我们可以使用 TensorFlow 网站上的说明安装 TensorFlow，网址为[https://www . tensor flow . org/versions/r 0.11/get _ started/OS _ setup . html # pip-installation](https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#pip-installation)。同样，我们简单地使用`pip`来安装正确的包，如下面的截图所示。例如，如果我们需要使用 GPU，选择合适的包很重要:

![](assets/image_02_003.png)

# Step 4 — install Keras

现在我们可以简单地安装 Keras 并开始测试安装的环境。相当简单；我们再来用一下`pip`，如这张截图所示:

![](assets/image_02_004.png)

# 步骤 5 —测试 Theano、TensorFlow 和 Keras

现在我们来测试一下环境。首先，让我们看看如何定义的函数。如你所见，这很简单；我们只需写出数学公式，并在矩阵上按元素计算函数。只需运行 Python Shell 并编写如下截图所示的代码即可获得结果:

![](assets/image_02_005.png)

所以，Theano 起作用了。让我们通过简单地导入 MNIST 数据集来测试 TensorFlow，如下图所示。我们已经在[第 1 章](c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml)、*神经网络基础*中看到了 Keras 网络的几个工作示例:

![](assets/image_02_006.png)

# 配置 Keras

Keras 有一个非常简单的配置文件。让我们用一个`vi`会话来装载它。参数非常简单:

| **参数** | **值** |
| `image_dim_ordering` | 可以是TensorFlow图像排序的`tf`或TensorFlow图像排序的`th` |
| `epsilon` | 计算过程中使用的`epsilon`值 |
| `floatx` | 可以是`float32`或`float64` |
| `backend` | 可以是`tensorflow`或`theano` |

`th`值的`image_dim_ordering`给你一个有点不直观的图像尺寸排序(深度、宽度和高度)，而不是`tf`的(宽度、高度和深度)。以下是我的机器的默认参数:

![](assets/image_02_007.png)

如果您安装了支持 GPU 的 TensorFlow 版本，那么当 TensorFlow 被选为后端时，Keras 将自动使用您配置的 GPU。



# 在 Docker 上安装 Keras

开始使用 TensorFlow 和 Keras 的最简单方法之一是在 Docker 容器中运行。一个方便的解决方案是使用社区创建的预定义 Docker 映像进行深度学习，该映像包含所有流行的 DL 框架(TensorFlow、Theano、Torch、Caffe 等等)。代码文件请参考位于 https://github.com/saiprashanths/dl-docker 的 GitHub 库。假设你已经安装并运行了 Docker(更多信息，请参考 https://www.docker.com/products/overview 的，安装它非常简单，如下所示:

![](assets/image_02_008.png)

下面的截图是这样的，从 Git 获得图像后，我们构建 Docker 图像:

![](assets/image_02_009.png)

在这个屏幕截图中，我们看到了如何运行它:

![](assets/image_02_010.png)

在容器内，可以激活对 Jupyter 笔记本的支持(更多信息，请参考[http://jupyter.org/](http://jupyter.org/)):

![](assets/image_02_011.png)

从主机的端口直接访问它:

![](assets/image_02_012.png)

还可以借助下面截图中的命令访问 TensorBoard(有关更多信息，请参考[https://www . tensor flow . org/how _ tos/summaries _ and _ tensor board/](https://www.tensorflow.org/how_tos/summaries_and_tensorboard/))，这将在下一节中讨论:

![](assets/image_02_013.png)

运行上述命令后，您将被重定向到以下页面:

![](assets/image_02_014.png)



# 在 Google Cloud ML 上安装 Keras

在 Google Cloud 上安装 Keras 非常简单。首先，我们可以安装 Google Cloud(可下载文件参考[https://cloud.google.com/sdk/](https://cloud.google.com/sdk/))*，*一个 Google Cloud 平台的命令行界面；然后，我们可以使用 CloudML，这是一种托管服务，使我们能够轻松地使用 TensorFlow 构建机器学习模型。在使用 Keras 之前，让我们使用 Google Cloud 和 TensorFlow 来训练 GitHub 上的一个 MNIST 示例。代码是本地的，训练在云中进行:

![](assets/image_02_015.png)

在下面的屏幕截图中，您可以看到如何运行培训课程:

![](assets/image_02_016.png)

我们可以使用 TensorBoard 来展示交叉熵如何在迭代中减少:

![](assets/image_02_017.png)

在下一张截图中，我们可以看到交叉熵图:

![](assets/image_02_018.png)

现在，如果我们想在 TensorFlow 上使用 Keras，我们只需从 PyPI 下载 Keras 源代码(有关可下载文件，请参考[https://pypi.Python.org/pypi/Keras/1.2.0](https://pypi.Python.org/pypi/Keras/1.2.0)或更高版本),然后直接使用 Keras 作为 CloudML 包解决方案，如下例所示:

![](assets/image_02_019.png)

这里，`trainer.task2.py`是一个示例脚本:

```

from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
import numpy as np

# pre-built and pre-trained deep learning VGG16 model
base_model = VGG16(weights='imagenet', include_top=True)
for i, layer in enumerate(base_model.layers):
  print (i, layer.name, layer.output_shape)

```



# 在 Amazon AWS 上安装 Keras

在亚马逊上安装 TensorFlow 和 Keras 非常简单。事实上，可以使用一个名为`TFAMI.v3`的预建 AMI，它是开放和免费的(更多信息，请参考[https://github.com/ritchieng/tensorflow-aws-ami](https://github.com/ritchieng/tensorflow-aws-ami))，如下所示:

![](assets/image_02_020.png)

这个 AMI 运行 TensorFlow 不到五分钟，支持 TensorFlow，Keras，OpenAI Gym，以及所有依赖项。截至 2017 年 1 月，它支持以下内容:

*   TensorFlow 0.12
*   Keras 1.1.0
*   张量层 1.2.7
*   CUDA 8.0
*   CuDNN 5.1
*   Python 2.7
*   Ubuntu 16.04

此外，`TFAMI.v3`在 P2 计算实例上工作(更多信息，请参考[https://aws.amazon.com/ec2/instance-types/#p2](https://aws.amazon.com/ec2/instance-types/#p2))，如以下截图所示:

![](assets/image_02_021.png)

P2 实例的一些特征如下:

*   英特尔至强 E5-2686v4 (Broadwell)处理器
*   NVIDIA K80 GPUs，每个都有 2，496 个并行内核和 12 GB 的 GPU 内存
*   支持点对点 GPU 通信
*   提供增强的网络(有关更多信息，请参考[https://AWS . Amazon . com/ec2/FAQs/# What _ networking _ capabilities _ are _ included _ in _ this _ feature](https://aws.amazon.com/ec2/faqs/#What_networking_capabilities_are_included_in_this_feature))和 20 Gbps 的聚合网络带宽

`TFAMI.v3`也适用于 G2 计算实例(更多信息，请参考[https://aws.amazon.com/ec2/instance-types/#g2](https://aws.amazon.com/ec2/instance-types/#g2))。G2 实例的一些特性如下:

*   英特尔至强 E5-2670 (Sandy Bridge)处理器
*   NVIDIA GPUs，每个都有 1，536 个 CUDA 内核和 4 GB 视频内存



# 在 Microsoft Azure 上安装 Keras

在 Azure 上安装 Keras 的一种方法是安装对 Docker 的支持，然后获得 TensorFlow plus Keras 的容器化版本。在网上，也可以找到一组关于如何使用 Docker 安装 Keras 和 TensorFlow 的详细说明，但这基本上是我们在上一节中已经看到的内容(有关更多信息，请参考[https://blogs . msdn . Microsoft . com/uk _ faculty _ connection/2016/09/26/tensor flow-on-Docker-with-Microsoft-azure/](https://blogs.msdn.microsoft.com/uk_faculty_connection/2016/09/26/tensorflow-on-docker-with-microsoft-azure/))。

如果你使用 Theano 作为唯一的后端，那么 Keras 只需点击一下，加载 Cortana Intelligence Gallery 上的预建包即可运行(更多信息，请参考[https://Gallery . Cortana Intelligence . com/Experiment/the ano-Keras-1](https://gallery.cortanaintelligence.com/Experiment/Theano-Keras-1))。
以下示例显示了如何将 Theano 和 Keras 作为 ZIP 文件直接导入 Azure ML，并在执行 Python 脚本模块中使用它们。这个例子是海宁的(更多信息，请参考 https://goo.gl/VLR25o 的)，它本质上是在`azureml_main()`方法中运行 Keras 代码:

```

# The script MUST contain a function named azureml_main
# which is the entry point for this module.

# imports up here can be used to
import pandas as pd
import theano
import theano.tensor as T
from theano import function
from keras.models import Sequential
from keras.layers import Dense, Activation
import numpy as np
# The entry point function can contain up to two input arguments:
#   Param<dataframe1>: a pandas.DataFrame
#   Param<dataframe2>: a pandas.DataFrame
def azureml_main(dataframe1 = None, dataframe2 = None):
    # Execution logic goes here
    # print('Input pandas.DataFrame #1:rnrn{0}'.format(dataframe1))

    # If a zip file is connected to the third input port is connected,
    # it is unzipped under ".Script Bundle". This directory is added
    # to sys.path. Therefore, if your zip file contains a Python file
    # mymodule.py you can import it using:
    # import mymodule
    model = Sequential()
    model.add(Dense(1, input_dim=784, activation="relu"))
    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
    data = np.random.random((1000,784))
    labels = np.random.randint(2, size=(1000,1))
    model.fit(data, labels, nb_epoch=10, batch_size=32)
    model.evaluate(data, labels)

    return dataframe1,

```

在此屏幕截图中，您可以看到使用 Microsoft Azure ML 运行 Theano 和 Keras 的示例:

![](assets/image_02_022.png)

# Keras API

Keras 有一个模块化，极简，易于扩展的架构。《Keras》的作者 Francois Chollet 说:

该库的开发重点是支持快速实验。能够以尽可能少的延迟从想法到结果是做好研究的关键。

Keras 定义了运行在 TensorFlow(更多信息，请参考[https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow))或 Theano(更多信息，请参考【https://github.com/Theano/Theano】T2)之上的高级神经网络。详细来说:

*   模块性:模型是独立模块的序列或图形，可以像构建神经网络的乐高积木一样组合在一起。也就是说，该库预定义了大量实现不同类型的神经层、成本函数、优化器、初始化方案、激活函数和正则化方案的模块。
*   极简主义:这个库是用 Python 实现的，每个模块都保持简短和自描述。
*   **易扩展性**:库可以扩展新的功能，我们将在[第七章](9384823c-eb58-4a0f-91e7-1a5508eeb520.xhtml)、*附加深度学习模型*中描述。



# Keras 架构入门

在本节中，我们将回顾用于定义神经网络的最重要的 Keras 组件。首先，我们定义张量是什么，然后我们讨论组成预定义模块的不同方法，最后我们概述最常用的方法。



# 什么是张量？

Keras 使用 Theano 或 TensorFlow 对张量执行非常高效的计算。但是张量到底是什么呢？张量只不过是一个多维数组或矩阵。两个后端都能够在张量上进行有效的符号计算，张量是创建神经网络的基本构件。



# 在 Keras 中构建模型

Keras 中有两种组成模型的方法。它们如下:

*   顺序合成
*   操作组合

让我们详细看看每一个。



# 顺序合成

第一种是顺序组合，其中不同的预定义模型以类似于堆栈或队列的层的线性管道堆叠在一起。在[第 1 章](c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml)、*神经网络基础*中，我们看到了一些顺序流水线的例子。例如:

```

model = Sequential()
model.add(Dense(N_HIDDEN, input_shape=(784,)))
model.add(Activation('relu'))
model.add(Dropout(DROPOUT))
model.add(Dense(N_HIDDEN))
model.add(Activation('relu'))
model.add(Dropout(DROPOUT))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))
model.summary()

```



# 操作组合

组成模块的第二种方式是通过函数式 API，在这里可以定义复杂的模型，比如有向无环图、具有共享层的模型或者多输出模型。我们将在[第七章](9384823c-eb58-4a0f-91e7-1a5508eeb520.xhtml)、*附加深度学习模型*中看到这样的例子。



# 预定义神经网络层概述

Keras 有许多预构建的层。让我们回顾一下最常用的层，并强调在哪一章中最常用到这些层。



# 规则密集

密集模型是完全连接的神经网络层。我们已经在[第 1 章](c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml)、*神经网络基础*中看到了使用示例。以下是带有参数定义的原型:

```

keras.layers.core.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)

```



# 循环神经网络——简单、LSTM 和 GRU

循环神经网络是一类利用其输入的顺序性质的神经网络。这种输入可以是文本、语音、时间序列以及序列中某个元素的出现依赖于它之前出现的元素的任何其他内容。我们将在第六章、*循环神经网络— RNN* 中讨论简单、LSTM 和 GRU 循环神经网络。在这里，您可以看到一些带有参数定义的原型:

```

keras.layers.recurrent.Recurrent(return_sequences=False, go_backwards=False, stateful=False, unroll=False, implementation=0)

keras.layers.recurrent.SimpleRNN(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)

keras.layers.recurrent.GRU(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)

keras.layers.recurrent.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)

```



# 卷积层和池层

ConvNets 是一类使用卷积和池操作的神经网络，用于基于渐进的抽象级别渐进地学习相当复杂的模型。这种通过渐进抽象的学习类似于在人脑中进化了数百万年的视觉模型。几年前人们称之为 3-5 层的*深*，现在已经涨到 100-200 了。我们将在[第三章](4be2a04a-4545-4051-bcd9-32764d21f0f2.xhtml)、*用 ConvNets 进行深度学习*中讨论卷积神经网络。以下是一些带有参数定义的原型:

```

keras.layers.convolutional.Conv1D(filters, kernel_size, strides=1, padding='valid', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)

keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)

keras.layers.pooling.MaxPooling1D(pool_size=2, strides=None, padding='valid')

keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)

```



# 正规化

正则化是防止过度拟合的一种方法。我们已经在[第 1 章](c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml)、*神经网络基础*中看到了使用示例。多个图层具有用于正则化的参数。以下是通常用于密集和卷积模块的正则化参数列表:

*   `kernel_regularizer`:应用于权重矩阵的正则化函数
*   `bias_regularizer`:应用于偏置向量的正则化函数
*   `activity_regularizer`:应用于层输出的正则化函数(其激活)

此外，有可能使用辍学正规化，这往往是一个非常有效的选择

```

keras.layers.core.Dropout(rate, noise_shape=None, seed=None)

```

其中:

*   `rate`:介于 0 和 1 之间的浮点数，表示要丢弃的输入单位的分数
*   `noise_shape`:1D 整数张量，表示将与输入相乘的二进制删除掩码的形状
*   `seed`:用作随机种子的整数



# 批量标准化

批量归一化(更多信息请参考[https://www . col wiz . com/cite-in-Google-docs/cid = f 20 f 9683 AAF 69 ce](https://www.colwiz.com/cite-in-google-docs/cid=f20f9683aaf69ce))是一种加速学习的方法，一般可以达到更好的准确率。当我们讨论 gan 时，我们将在[第 4 章](a67ea944-b1a6-48a3-b8aa-4e698166c0eb.xhtml)、*生成对抗网络和 WaveNet* 中查看用法示例。以下是带有参数定义的原型:

```

keras.layers.normalization.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)

```



# 预定义激活功能概述

激活包括常用的函数，如 sigmoid、线性、双曲正切和 ReLU。我们已经在[第 1 章](c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml)、*神经网络基础*中看到了一些激活函数的例子，更多的例子将在接下来的章节中介绍。下图是 sigmoid、线性、双曲正切和 ReLU 激活函数的示例:

| **乙状结肠**![](assets/image_02_023.png) | **线性**![](assets/image_02_024.png) |
| **双曲正切**![](assets/image_02_025.png) | 继电器![](assets/image_02_026.png) |



# 损失函数概述

损失函数(或目标函数，或优化得分函数；欲了解更多信息，请参考https://keras.io/losses/可分为四类:

*   用于分类问题的精确度。有多个选择:`binary_accuracy`(二分类问题所有预测的平均准确率)`categorical_accuracy`(多类分类问题所有预测的平均准确率)`sparse_categorical_accuracy`(对稀疏目标有用)`top_k_categorical_accuracy`(目标类在提供的`top_k`预测内时成功)。
*   误差损失，衡量预测值和实际观察值之间的差异。有多种选择:`mse`(预测值与目标值的均方误差)`rmse`(预测值与目标值的均方根误差)`mae`(预测值与目标值的平均绝对误差)`mape`(预测值与目标值的平均百分比误差)`msle`(预测值与目标值的均方对数误差)。
*   铰链损失，一般用于训练分类器。有两个版本:*铰链*定义为![](assets/image_02_027.png)和*平方铰链*定义为铰链损耗的平方值。
*   类别损失用于计算分类问题的交叉熵。有多个版本，包括二元交叉熵(更多信息，请参考[https://en.wikipedia.org/wiki/Cross_entropy](https://en.wikipedia.org/wiki/Cross_entropy))和分类交叉熵。

我们已经在[第 1 章](c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml)、*神经网络基础*中看到了一些目标函数的例子，更多的例子将在接下来的章节中给出。



# 指标概述

度量函数(更多信息，请参考[https://keras.io/metrics/](https://keras.io/metrics/))类似于目标函数。唯一的区别是，在训练模型时不使用评估指标的结果。我们已经在[第 1 章](c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml)、*神经网络基础*中看到了一些度量的例子，更多的例子将在接下来的章节中呈现。



# 优化器概述

优化器包括 SGD、RMSprop 和 Adam。我们已经在[第 1 章](c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml)、*神经网络基础*中看到了一些优化器的例子，以及更多的例子(Adagrad 和 Adadelta 更多信息，请参见 https://keras.io/optimizers/[将在下一章节中介绍。](https://keras.io/optimizers/)



# 一些有用的操作

这里我们报告一些可以用 Keras APIs 执行的实用程序操作。目标是促进网络的创建、训练过程和中间结果的保存。



# 保存和加载模型的权重和架构

模型架构可以很容易地保存和加载，如下所示:

```

# save as JSON json_string = model.to_json()
# save as YAML yaml_string = model.to_yaml() 
# model reconstruction from JSON: from keras.models import model_from_json model = model_from_json(json_string) # model reconstruction from YAML model = model_from_yaml(yaml_string)

```

模型参数(权重)可以轻松保存和加载，如下所示:

```

from keras.models import load_model model.save('my_model.h5')
# creates a HDF5 file 'my_model.h5' del model
# deletes the existing model
# returns a compiled model
# identical to the previous one model = load_model('my_model.h5')

```



# 定制培训流程的回访

当指标停止改善时，可以使用适当的`callback`停止训练过程:

```

keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,  
patience=0, verbose=0, mode='auto')

```

可以通过定义如下的`callback`来保存损耗历史:

```

class LossHistory(keras.callbacks.Callback):     def on_train_begin(self, logs={}):         self.losses = []     def on_batch_end(self, batch, logs={}):         self.losses.append(logs.get('loss')) model = Sequential() model.add(Dense(10, input_dim=784, init='uniform')) model.add(Activation('softmax')) model.compile(loss='categorical_crossentropy', optimizer='rmsprop') history = LossHistory() model.fit(X_train,Y_train, batch_size=128, nb_epoch=20,  
verbose=0, callbacks=[history]) print history.losses

```



# 检查点

检查点是一个定期保存应用状态快照的过程，因此在出现故障时，应用可以从上次保存的状态重新启动。这在深度学习模型的训练期间是有用的，这通常是一项耗时的任务。一个深度学习模型在任一时间点的状态就是该模型在该时间点的权重。Keras 以 HDF5 格式保存这些权重(更多信息，请参考[https://www.hdfgroup.org/](https://www.hdfgroup.org/))，并使用其回调 API 提供检查点。

检查点可能有用的一些情况包括:

*   如果您希望在 AWS Spot 实例(有关更多信息，请参考[http://docs . AWS . Amazon . com/AWS sec 2/latest/user guide/how-Spot-instances-work . html](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-work.html))或 Google preemptible 虚拟机(有关更多信息，请参考【https://cloud.google.com/compute/docs/instances/preemptible】T3)意外终止后，能够从您的最后一个检查点重新启动
*   如果您想要停止训练，也许是为了在测试数据上测试您的模型，然后从最后一个检查点继续训练
*   如果您希望在多个时期训练时保留最佳版本(通过一些度量标准，如验证损失)

第一种和第二种情况可以通过在每个时期后保存一个检查点来处理，这是通过默认使用`ModelCheckpoint`回调来处理的。以下代码说明了如何在 Keras 中训练深度学习模型的过程中添加检查点:

```

from __future__ import division, print_function 
from keras.callbacks import ModelCheckpoint 
from keras.datasets import mnist 
from keras.models import Sequential 
from keras.layers.core import Dense, Dropout 
from keras.utils import np_utils 
import numpy as np 
import os 

BATCH_SIZE = 128 
NUM_EPOCHS = 20 
MODEL_DIR = "/tmp" 

(Xtrain, ytrain), (Xtest, ytest) = mnist.load_data() 
Xtrain = Xtrain.reshape(60000, 784).astype("float32") / 255 
Xtest = Xtest.reshape(10000, 784).astype("float32") / 255 
Ytrain = np_utils.to_categorical(ytrain, 10) 
Ytest = np_utils.to_categorical(ytest, 10) 
print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape) 

model = Sequential() 
model.add(Dense(512, input_shape=(784,), activation="relu")) 
model.add(Dropout(0.2)) 
model.add(Dense(512, activation="relu")) 
model.add(Dropout(0.2)) 
model.add(Dense(10, activation="softmax")) 

model.compile(optimizer="rmsprop", loss="categorical_crossentropy", 
              metrics=["accuracy"]) 

# save best model 
checkpoint = ModelCheckpoint( 
    filepath=os.path.join(MODEL_DIR, "model-{epoch:02d}.h5")) 
model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE, nb_epoch=NUM_EPOCHS, 
          validation_split=0.1, callbacks=[checkpoint])

```

第三个场景涉及监控指标，例如验证准确性或损失，并且仅在当前指标优于先前保存的检查点时才保存检查点。Keras 提供了一个额外的参数`save_best_only`，为了支持这个功能，在实例化 checkpoint 对象时需要将这个参数设置为`true`。



# 使用 TensorBoard 和 Keras

Keras 提供了一个回调函数，用于保存您的训练和测试指标，以及您的模型中不同层的激活直方图:

```

keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0,  
write_graph=True, write_images=False)

```

然后，可以通过在命令行启动 TensorBoad 来可视化保存的数据:

```

tensorboard --logdir=/full_path_to_your_logs

```



# 使用箭筒和 Keras

在[第三章](4be2a04a-4545-4051-bcd9-32764d21f0f2.xhtml)、*用 ConvNets 进行深度学习*中，我们将讨论 ConvNets，这是一种处理图像的高级深度学习技术。在这里，我们给出了一个颤的预览(更多信息，请参考 https://github.com/jakebian/quiver[)，这是一个以交互方式可视化 ConvNets 功能的有用工具。安装非常简单，之后只需一行代码就可以使用箭筒:](https://github.com/jakebian/quiver)

```

pip install quiver_engine 

from quiver_engine import server     server.launch(model)

```

这将在`localhost:5000`启动可视化。“颤动”允许您直观地检查神经网络，如下例所示:

![](assets/image_02_028.png)

# 摘要

在本章中，我们讨论了如何在以下系统上安装 Theano、TensorFlow 和 Keras:

*   您的本地机器
*   基于容器的码头化基础设施
*   在云中使用谷歌 GCP、亚马逊 AWS 和微软 Azure

除此之外，我们还看了一些定义 Keras APIs 和一些常用操作的模块，例如加载和保存神经网络的架构和权重、提前停止、历史保存、检查点、与 TensorBoard 的交互以及与颤的交互。

在下一章中，我们将介绍卷积网络的概念，这是深度学习中的一项基本创新，已成功用于多个领域，从文本到视频，再到语音，远远超出了最初设想的图像处理领域。
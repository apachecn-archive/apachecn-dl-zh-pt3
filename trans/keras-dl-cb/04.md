

# 卷积神经网络

卷积网络(参考文献*le Cun【1】*，2013)，也称为**卷积** **神经网络**
或**CNN**，是一种特殊类型的神经网络，以网格状拓扑结构处理数据。示例包括时间序列数据，可以将其视为以固定时间间隔采样的 1D 网格，或者是像素的 2D 网格的图像数据。卷积神经网络的名称意味着该网络采用一种称为**卷积**的数学运算。卷积是一种特殊的线性运算。卷积网络是在至少一层中使用卷积(一种数学运算)代替一般矩阵乘法的神经网络。

首先，我们将描述卷积的数学运算。然后，我们将讨论池的概念，以及它如何帮助 CNN。我们还将了解 TensorFlow 中卷积网络的实现。

在本章的末尾，我们将使用 TensorFlow 的 CNN 实现对斯坦福数据集的狗和猫进行分类。

lecun[1]:t0[http://yann . lecun . com/exdb/lenet/]t1]

我们将在本章中讨论以下主题:

*   CNN 的概况和直觉
*   卷积运算
*   联营
*   基于卷积网络的图像分类



# CNN 的概况和直觉

CNN 由多层卷积、轮询和最终全连接层组成。这比我们在[第二章](99346436-65d0-4059-81eb-e29091747df3.xhtml)、*中讨论的纯前馈网络*要高效得多。

![](Images/df7b7f21-ff98-4900-9eed-778fde9122d9.png)

上图通过**卷积层** | **最大池** | **卷积** | **最大池** | **全连接层**这是 CNN 架构



# 单 Conv 层计算

让我们首先讨论一下 conv 层直观地计算什么。Conv 层的参数由一组可学习的过滤器组成(也称为**张量**)。每个过滤器在空间上很小(深度、宽度和高度)，但是延伸通过输入体积(图像)的整个深度。ConvNet 第一层上的滤镜大小通常为 5 x 5 x 3(即五个像素的宽度和高度，三个像素的深度，因为图像的颜色通道有三个深度)。在正向传递过程中，过滤器在输入体积的宽度和高度上滑动(或**卷积**),并计算过滤器的条目和任意点的输入之间的点积。当滤光器在输入体积的宽度和高度上滑动时，它产生 2D 激活，给出该滤光器在每个空间位置的响应。网络将学习过滤器，当它们看到某种视觉特征时就会激活，例如第一层上某个方向的边缘或某个颜色的斑点，或者它可能会检测到网络更高层上的整个蜂窝或轮状图案。一旦我们在每个 conv 层中有了一整套过滤器(例如，12 个过滤器)，它们中的每一个都会产生一个单独的 2D 激活图。我们沿着深度维度堆叠这些激活图，并产生输出体积。

![](Images/ee47f9f9-11ab-48ab-beb6-551faa50bb8d.jpg)

由 5 x 5 过滤器卷积的 32 x 32 像素的图像

上图显示了一个 32 x 32 x 3 的图像，在该图像上应用了 5 x 5 x 3 的滤镜。

![](Images/2d72b474-77a0-422b-82a5-4fb0c91002c1.jpg)

过滤器和图像块之间的每个点积产生一个数字

接下来，让我们卷积在整个图像上创建的滤镜，一次移动一个像素。最终输出的大小将为 28 x 28 x 1。这被称为**激活图**。

![](Images/3bac5eb6-fd65-4de5-85f9-7c8b79337c3b.jpg)

通过在图像上应用滤镜生成的激活图

考虑一个接一个地使用两个过滤器；这将产生两个大小为 28 x 28 x 1 的激活图。

![](Images/9eb97f4c-5cb4-46c7-9260-87f46e754008.jpg)

在单个图像上应用两个滤镜会产生两个激活图

如果我们使用六个这样的过滤器，我们将得到一个大小为 28×28×3 的新图像。ConvNet 是一系列这样的卷积层，其中散布着激活功能，如 **Relu** 。

![](Images/1629fe0d-d370-4f34-bb9d-3bce9ec47bfe.jpg)

在图像上应用 6 个 5×5×3 的过滤器的结果产生 28×28×6 的激活图

让我们根据张量流的说法正式定义 CNN。

**定义**:CNN 是一个至少有一层(`tf.nn.conv2d`)的神经网络，在其输入和生成该层输出的可配置内核之间进行卷积。卷积将内核(过滤器)应用于输入层(张量)中的每个点。它通过在输入张量上滑动核来产生滤波输出。

**用例**:以下示例是使用卷积对输入图像应用的边缘检测滤波器

![](Images/49356c6c-9b70-48f9-9701-5a61b24f70b9.jpg)

通过在输入图像上应用核进行边缘检测

CNN 遵循一个匹配信息的过程，该过程类似于在猫的纹状皮层的细胞布局中发现的结构。当信号通过猫的纹状皮层传递时，当视觉模式被突出显示时，某些层会发出信号。例如，当一条水平线穿过一层细胞时，该层细胞被激活(增加其输出信号)。CNN 也会表现出类似的行为，神经元簇根据从训练中学习到的模式激活。在基于预先标记的数据进行训练之后，CNN 将具有当水平/垂直线穿过它时激活的某些层。

匹配水平/垂直线将是一个有用的神经网络架构，但 CNN 将多个简单模式分层以匹配复杂模式。这些模式被称为**过滤器**或**内核**。训练的目标是调整这些核权重以最小化损失函数。训练这些滤波器是通过组合多层和使用梯度下降或其他优化技术学习权重来完成的。



# CNN in TensorFlow

CNN 由卷积层(由`tf.nn.conv2d`定义)、非线性层(`tf.nn.relu`)、最大池(`tf.nn.max_pool`)和全连接层(`tf.matmul`)组成。下图显示了典型的 CNN 图层及其在 TensorFlow 中的相应实现:

![](Images/d7949c19-8b34-4a86-b6e7-5aa9746d84a4.jpg)

将 CNN 层映射到张量流函数



# TensorFlow 中的图像加载

现在让我们看看 TensorFlow 是如何加载图像的。让我们用三个图像的小数组定义一个常量，并将它们加载到一个会话中:

```
sess = tf.InteractiveSession()
image_batch = tf.constant([
   [ # First Image
     [[255, 0, 0], [255, 0, 0], [0, 255, 0]],
     [[255, 0, 0], [255, 0, 0], [0, 255, 0]]
   ],
   [ # Second Image
     [[0, 0, 0], [0, 255, 0], [0, 255, 0]],
     [[0, 0, 0], [0, 255, 0], [0, 255, 0]]
   ],
   [ # Third Image
     [[0, 0, 255], [0, 0, 255], [0, 0, 255]],
     [[0, 0, 255], [0, 0, 255], [0, 0, 255]]
   ]
 ])
 print(image_batch.get_shape())
 print(sess.run(image_batch)[1][0][0])
```

前面清单的输出显示了张量的形状和第一幅图像的第一个像素。在此示例代码中，创建了一个包含三个图像的图像数组。每个图像具有两个像素的高度和三个像素的宽度，具有 RGB 颜色空间。示例代码的输出将图像的数量显示为第一组维度 Dimension(1)的大小。每个图像的高度是第二个集合的大小，维度(2)，每个图像的宽度包括第三个集合，维度(3)，颜色通道的数组大小是最后一个集合，维度(3):

```
(3, 2, 3, 3)
[255 0 0]
```



# 卷积运算

卷积运算是 CNN 的关键组成部分；这些操作使用输入张量和过滤器来计算输出。关键是决定可用于调整它们的参数。

假设我们正在跟踪一个物体的位置。它的输出是一个单一的 *x(t)* ，是物体在时间 *t* 的位置。 *x* 和 *t* 都是实值，也就是说，我们可以在任意时刻获得不同的读数。假设我们的测量有噪声。为了获得物体位置的噪声较小的估计，我们希望将测量值平均在一起。最近的测量对我们更有意义；我们希望这是一个加权平均值，给予最近的测量更高的权重。我们可以使用加权函数 *w(a)* 来计算这一点，其中 *a* 是测量的年龄(进行测量的时间)
如果我们在每一时刻应用加权平均运算，我们将获得一个新的函数，该函数提供对象位置的平滑估计:

![](Images/136f8c61-0fbb-4ab6-ad49-73cef018deee.png)

这个操作叫做**卷积**。卷积运算用星号表示:

![](Images/b4e11c31-065e-44d8-869c-7b8993d9072c.png)

这里，

*   *w* 是内核
*   *x* 是输入
*   *s* 是输出，也称为**特征图**



# 图像上的卷积

如果我们使用一个 2D 图像作为我们的输入，我们可能也想使用一个 2D 内核。前面的等式将如下所示:

![](Images/2c8fcc55-c730-4e45-9931-07a02f67d6d7.png)

由于卷积函数是可交换的，我们可以将前面的等式写成如下:

![](Images/5f2da051-543d-4049-81b0-4b8a86ce60a0.png)

将 *i - m* 和 *j -n* 改变为加法被称为互相关，因为这是由 TensorFlow 实现的:

![](Images/a918398f-37c2-4aa0-bdef-076bd0417146.png)

让我们定义一个简单的输入和一个内核，并在 TensorFlow 中运行`conv2d`操作。让我们来看看一个简单的图像输入和一个内核输入。下图显示了一个基本图像、一个内核以及应用卷积运算后的预期输出:

![](Images/5c93289c-7713-40b6-8a5f-2bd2d8ac2efb.jpg)

基本图像和应用于它的内核的例子

现在让我们看看如何以 1，1，1，1:

![](Images/be47e774-a84e-4442-9085-9f259093ba78.jpg)

通过对输入应用核来计算输出

接下来，我们将在 TensorFlow 中实现相同的功能:

```
i = tf.constant([
                 [1.0, 1.0, 1.0, 0.0, 0.0],
                 [0.0, 0.0, 1.0, 1.0, 1.0],
                 [0.0, 0.0, 1.0, 1.0, 0.0],
                 [0.0, 0.0, 1.0, 0.0, 0.0]], dtype=tf.float32)
k = tf.constant([
                [1.0, 0.0, 1.0],
                [0.0, 1.0, 0.0],
                [1.0, 0.0, 1.0]
        ], dtype=tf.float32),
kernel = tf.reshape(k, [3, 3, 1, 1], name='kernel')
image = tf.reshape(i, [1, 4, 5, 1], name='image')
res = tf.squeeze(tf.nn.conv2d(image, kernel, strides=[1, 1, 1, 1], padding="VALID"))
# VALID means no padding
with tf.Session() as sess:
    print sess.run(res)
```

前面清单的输出如下——这与我们手工计算的结果相同:

```
[[ 3\. 3\. 3.]
 [ 2\. 2\. 4.]]
```



# 大步

卷积的主要目的是降低图像的维度(宽度、高度和通道数)。图像越大，所需的处理时间就越长。

`strides`参数使内核跳过图像中的像素，并且不将它们包含在输出中。当使用更大的图像和更复杂的内核时，`strides`参数决定卷积运算如何与内核一起工作。当卷积在输入上滑动内核时，它使用`strides`参数来确定它如何遍历输入，而不是遍历输入的每个元素。

让我们来看看下面的例子，我们以 1，3，3，1 的步幅在 6 x 6 x 1 的映像上移动一个 3 x 3 x 1 的内核:

![](Images/88babb37-5210-499f-8ed8-267661d6b995.png)

步骤 1，内核以 1，3，3，1 的步幅滑动

在步骤 3 和 4 中，内核跨越了以下元素:

![](Images/d37b361e-768b-4670-a7c8-a5dc10beef9e.png)

内核跨越输入的第 3 步和第 4 步

让我们在 TensorFlow 中实现这个；输出将是一个 4 x 4 x 1 张量:

```
import tensorflow as tf

def main():
  session = tf.InteractiveSession()
  input_batch = tf.constant([
    [ # First Input (6x6x1)
      [[0.0], [1.0], [2.0], [3.0], [4.0], [5.0]],
      [[0.1], [1.1], [2.1], [3.1], [4.1], [5.1]],
      [[0.2], [1.2], [2.2], [3.2], [4.2], [5.2]],
      [[0.3], [1.3], [2.3], [3.3], [4.3], [5.3]],
      [[0.4], [1.4], [2.4], [3.4], [4.4], [5.4]],
      [[0.5], [1.5], [2.5], [3.5], [4.5], [5.5]],
  ],
 ])
kernel = tf.constant([ # Kernel (3x3x1)
  [[[0.0]], [[0.5]], [[0.0]]],
  [[[0.0]], [[0.5]], [[0.0]]],
  [[[0.0]], [[0.5]], [[0.0]]]
])

# NOTE: the change in the size of the strides parameter.
conv2d = tf.nn.conv2d(input_batch, kernel, strides=[1, 3, 3, 1], padding='SAME')
conv2d_output = session.run(conv2d)
print(conv2d_output)
if __name__ == '__main__':
main()
```

输出类似于下面的列表，其中前面图像中四个红框的 1，3，3，1 步幅前导与内核相乘:

```
[[[[ 1.64999998][ 6.1500001 ]]
  [[ 2.0999999 ][ 6.60000038]]]]
```



# 联营

池层有助于过度拟合，并通过减小输入张量的大小来提高性能。通常，它们用于缩小输入，保留重要信息。与`tf.nn.conv2d`相比，池化是一种更快的减少输入大小的机制。

TensorFlow 支持以下池机制:

*   平均的
*   最大
*   带 argMax 的 max

每个池操作使用大小为`ksize`的矩形窗口，由偏移量`strides`分隔。如果`strides`都是 1(1，1，1，1)，则使用每个窗口；如果`strides`都是二(1，2，2，1)，则每隔一个窗口使用一个维度；诸如此类。



# 最大池

以下定义的函数为输入 4D 张量`tf.nn.max_pool`提供最大汇集:

```
max_pool(
  value, ksize, strides, padding, data_format='NHWC', name=None
)
```

前面的参数解释如下:

*   `value`:这是形状为【批次，高度，宽度，通道】，类型为`tf.float32`的 4D 张量，需要在其上进行最大汇集。
*   `ksize`:这是有`length >= 4`的 int 的列表。输入张量每个维度的窗口大小。
*   `strides`:这是 int，`length >= 4`的列表。输入张量的每个维度的滑动窗口的跨度。
*   `padding`:这是一个字符串，不是`VALID`就是`SAME`。填充算法。以下部分解释了`VALID`和`SAME`填充。

![](Images/12b26b0d-fafe-45c2-92ff-4701475b58a5.png)

参考:[https://stack overflow . com/questions/37674306/what-is-the-difference-betting-in-TF-nn-max-pool-of-t](https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t)

*   这是一个字符串。支持`NHWC`和`NCHW`。
*   `name`:该操作的可选名称。



# 示例代码

以下代码演示了使用`VALID`填充方案的张量上的最大池化:

```
import tensorflow as tf

batch_size=1
input_height = 3
input_width = 3
input_channels = 1

def main():
  sess = tf.InteractiveSession()
  layer_input = tf.constant([
    [
     [[1.0], [0.2], [2.0]],
     [[0.1], [1.2], [1.4]],
     [[1.1], [0.4], [0.4]]
    ] 
  ])

# The strides will look at the entire input by using the image_height and image_width
kernel = [batch_size, input_height, input_width, input_channels]
max_pool = tf.nn.max_pool(layer_input, kernel, [1, 1, 1, 1], "VALID")
print(sess.run(max_pool))

if __name__ == '__main__':
  main()
```

上述清单的输出将给出窗口 3 x 3 x 1 中的最大值:

```
[[[[ 2.]]]]
```

下图解释了最大池逻辑的工作原理:

![](Images/f500a11c-b10d-4cd6-b4bf-38f16e45446f.png)

可以看出，max pool 基于 1，1，1 的步幅从窗口中选择了最大值。



# 平均池

它对输入张量执行平均汇集。输出中的每个条目都是相应大小的`ksize`窗口的平均值。使用`tf.nn.avg_pool`方法定义:

```
avg_pool( value, ksize, strides, padding, data_format='NHWC', name=None)
```

让我们看看在简单的 2D 张量中使用`avg_pool`的代码示例:

```
import tensorflow as tf

batch_size=1
input_height = 3
input_width = 3
input_channels = 1

def main():
  sess = tf.InteractiveSession()
  layer_input = tf.constant([
    [
      [[1.0], [0.2], [2.0]],
      [[0.1], [1.2], [1.4]],
      [[1.1], [0.4], [0.4]]
    ]
  ])

  # The strides will look at the entire input by using the image_height and image_width
  kernel = [batch_size, input_height, input_width, input_channels]
  avg_pool = tf.nn.avg_pool(layer_input, kernel, [1, 1, 1, 1], "VALID")
  print(sess.run(avg_pool))

if __name__ == '__main__': 
    main()
```

前面清单的输出是张量中所有值的平均值。

*平均值=(1.0+0.2+2.0+0.1+1.2+1.4+1.1+0.4+0。4) / 9 = 0.86666*

```
[[[[ 0.86666667]]]]
```



# 基于卷积网络的图像分类

让我们看一个使用 CNN 的更现实的案例；我们将使用斯坦福大学的狗和猫的数据集。这个数据集有 100 多张狗和猫的图片。

您可以从以下位置下载该数据集(每组 100 张图片): [https://S3 . amazonaws . com/neural-networking-book/ch04/dogs _ vs _ cats . tar . gz](https://s3.amazonaws.com/neural-networking-book/ch04/dogs_vs_cats.tar.gz)

1.  导入相关函数和 Python 类:

```
import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix
import time
from datetime import timedelta
import math
import dataset
import random
```

2.  我们将定义卷积层的参数。有三个具有以下参数的卷积层:

| **层数** | **图层类型** | **过滤器/神经元的数量** |
| one | 盘旋 | 32 个过滤器 |
| Two | 盘旋 | 32 个过滤器 |
| three | 盘旋 | 64 个过滤器 |
| four | 完全连接 | 128 个神经元 |

网络拓扑可以表示为下图所示:

![](Images/04579c56-ba76-4fc4-9c9d-c1282aa91ac6.png)

以下代码应该有助于理解这些参数:

```
# Convolutional Layer 1.
filter_size1 = 3 
num_filters1 = 32

# Convolutional Layer 2.
filter_size2 = 3
num_filters2 = 32

# Convolutional Layer 3.
filter_size3 = 3
num_filters3 = 64

# Fully-connected layer.
# Number of neurons in fully-connected layer.
fc_size = 128

# Number of color channels for the images: 1 channel for gray-scale.
num_channels = 3

# image dimensions (only squares for now)
img_size = 128

# Size of image when flattened to a single dimension
img_size_flat = img_size * img_size * num_channels

# Tuple with height and width of images used to reshape arrays.
img_shape = (img_size, img_size)
```

3.  为类的数量(在本例中是两个)和其他变量定义常量。为了更容易处理，我们将斯坦福数据集缩减为 100 张狗和猫的图片:

```
# class info
classes = ['dogs', 'cats']
num_classes = len(classes)

# batch size
batch_size = 2

# validation split
validation_size = .2
total_iterations = 0
early_stopping = None  # use None if you don't want to implement early stoping
home = '/home/ubuntu/Downloads/dogs_vs_cats'
train_path = home + '/train-cat-dog-100/'
test_path = home + '/test-cat-dog-100/'
checkpoint_dir = home + "/models/"
```

让我们先把数据集读入张量。读取逻辑在`dataset`类中定义:

```
data = dataset.read_train_sets(train_path, img_size, classes, validation_size=validation_size)
```

这里定义了`train_path`、`image_size`、`classes`和`validation_size`。让我们来看看`read_train_sets(..)`的实现:

```
def read_train_sets(train_path, image_size, classes, validation_size=0):
  class DataSets(object):
    pass
  data_sets = DataSets()

  images, labels, ids, cls = load_train(train_path, image_size, classes)
  images, labels, ids, cls = shuffle(images, labels, ids, cls)  # shuffle the data

  if isinstance(validation_size, float):
    validation_size = int(validation_size * images.shape[0])

  validation_images = images[:validation_size]
  validation_labels = labels[:validation_size]
  validation_ids = ids[:validation_size]
  validation_cls = cls[:validation_size]

  train_images = images[validation_size:]
  train_labels = labels[validation_size:]
  train_ids = ids[validation_size:]
  train_cls = cls[validation_size:]

  data_sets.train = DataSet(train_images, train_labels, train_ids, train_cls)
  data_sets.valid = DataSet(validation_images, validation_labels, validation_ids, 
   validation_cls)

  return data_sets
```

这个方法又调用`load_train(...)`返回数据类型的`numpy.array`:

```
def load_train(train_path, image_size, classes) :
 images = labels = []
 ids = cls = []
 # load data into arrays
 images = np.array(images) 
 labels = np.array(labels) 
 ids = np.array(ids) 
 cls =  np.array(cls)   
 return images, labels, ids, cls
```

加载到训练中的数据是`validation_set`的函数；它是根据图像数组的第一维计算的:

![](Images/19940b2c-a831-4b0e-a3e1-515a1fb652d6.png)

我们计算的`validation_size as`显示在下面的代码中:

```
validation_size = int(validation_size * images.shape[0])
```

由于我们将验证大小保持为`0.2`，因此得出的`58.2`四舍五入为`58`:

![](Images/4686ba14-d906-429d-a911-2c5841fedc0d.png)

类似地，我们创建测试数据集，`test_images`和`test_ids`:

```
test_images, test_ids = dataset.read_test_set(test_path, img_size)
```

这里，`read_test_set(...)`是内部调用的函数:

```
def read_test_set(test_path, image_size):
  images, ids  = load_test(test_path, image_size)
  return images, ids
```

`read_test_set(test_path, image_size)`依次调用`load_test(test_path, image_size)`，其清单如下:

```
def load_test(test_path, image_size):
  path = os.path.join(test_path, '*g')
  files = sorted(glob.glob(path))

  X_test = []
  X_test_id = []
  print("Reading test images")
  for fl in files:
      flbase = os.path.basename(fl)
      img = cv2.imread(fl)
      img = cv2.resize(img, (image_size, image_size), fx=0.5, fy=0.5,
        interpolation=cv2.INTER_LINEAR)

      #img = cv2.resize(img, (image_size, image_size), cv2.INTER_LINEAR)
      X_test.append(img)
      X_test_id.append(flbase)

  ### because we're not creating a DataSet object for the test images, 
  ### normalization happens here
  X_test = np.array(X_test, dtype=np.uint8)
  X_test = X_test.astype('float32')
  X_test = X_test / 255

  return X_test, X_test_id
```

4.  让我们看看创建的各种`numpy`数组的大小:

```
print("Size of:")
print("- Training-set:\t\t{}".format(len(data.train.labels)))
print("- Test-set:\t\t{}".format(len(test_images)))
print("- Validation-set:\t{}".format(len(data.valid.labels)))
```

```
Size of:Size of:
- Training-set: 233
- Test-set: 100
- Validation-set: 58
```

5.  用适当的类别在 3 x 3 的网格中绘制 9 个随机图像:

```
 images, cls_true = data.train.images, data.train.cls
 plot_images(images=images, cls_true=cls_true
```

这里，`plot_images`函数在下面的代码块中定义:

```
def plot_images(images, cls_true, cls_pred=None):

    if len(images) == 0:
        print("no images to show")
        return 
    else:
        random_indices = random.sample(range(len(images)), min(len(images), 9))

    images, cls_true  = zip(*[(images[i], cls_true[i]) for i in random_indices])

    # Create figure with 3x3 sub-plots.
    fig, axes = plt.subplots(3, 3)
    fig.subplots_adjust(hspace=0.3, wspace=0.3)

    for i, ax in enumerate(axes.flat):
        # Plot image.
        print(images[i])
        ax.imshow(images[i].reshape(img_size, img_size, num_channels))
        print(images[i].size)
        print(img_size)
        print(num_channels)
        # Show true and predicted classes.
        if cls_pred is None:
            xlabel = "True: {0}".format(cls_true[i])
        else:
            xlabel = "True: {0}, Pred: {1}".format(cls_true[i], cls_pred[i])

        # Show the classes as the label on the x-axis.
        ax.set_xlabel(xlabel)

        # Remove ticks from the plot.
        ax.set_xticks([])
        ax.set_yticks([])

    # Ensure the plot is shown correctly with multiple plots
    # in a single Notebook cell.
    plt.show()
```

以下是我们代码的输出:

![](Images/0baca6e1-e7d0-4d90-8a99-54c0f13843d1.png)

数据集中的九张随机图像



# 为输入图像和第一卷积层定义张量

接下来，我们将为输入图像和第一个卷积层定义一个张量。



# 输入张量

用`shape[None, img_size_flat]`创建一个占位符，并将其重新整形为`[-1, img_size, img_size, num_channels]`:

```
x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')
x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])
```

这里，参数`img_size`和`num_channels`具有以下值:

*   `img_size` = 128
*   `num_channels` = 3



# 第一卷积层

将输入张量整形为`x_image`后，我们将创建第一个卷积层:

```

layer_conv1, weights_conv1 = new_conv_layer(input=x_image,
                                            num_input_channels=num_channels,
                                            filter_size=filter_size1,
                                            num_filters=num_filters1,
                                            use_pooling=True)
print(layer_conv1)
```

这里定义了`new_conv_layer(...)`功能。让我们看看发送给这个函数的每个变量的值:

![](Images/b8b1af64-88cf-40e5-aba0-c1b7f4704291.png)

```
def new_conv_layer(input,              # The previous layer.
                   num_input_channels, # Num. channels in prev. layer.
                   filter_size,        # Width and height of each filter.
                   num_filters,        # Number of filters.
                   use_pooling=True):  # Use 2x2 max-pooling.

    # Shape of the filter-weights for the convolution.
    # This format is determined by the TensorFlow API.
    shape = [filter_size, filter_size, num_input_channels, num_filters]

    # Create new weights aka. filters with the given shape.
    weights = new_weights(shape=shape)

    # Create new biases, one for each filter.
    biases = new_biases(length=num_filters)

    # Create the TensorFlow operation for convolution.
    # Note the strides are set to 1 in all dimensions.
    # The first and last stride must always be 1,
    # because the first is for the image-number and
    # the last is for the input-channel.
    # But e.g. strides=[1, 2, 2, 1] would mean that the filter
    # is moved 2 pixels across the x- and y-axis of the image.
    # The padding is set to 'SAME' which means the input image
    # is padded with zeroes so the size of the output is the same.
    layer = tf.nn.conv2d(input=input,
                         filter=weights,
                         strides=[1, 1, 1, 1],
                         padding='SAME')

    # Add the biases to the results of the convolution.
    # A bias-value is added to each filter-channel.
    layer += biases

    # Use pooling to down-sample the image resolution?
    if use_pooling:
        # This is 2x2 max-pooling, which means that we
        # consider 2x2 windows and select the largest value
        # in each window. Then we move 2 pixels to the next window.
        layer = tf.nn.max_pool(value=layer,
                               ksize=[1, 2, 2, 1],
                               strides=[1, 2, 2, 1],
                               padding='SAME')

    # Rectified Linear Unit (ReLU).
    # It calculates max(x, 0) for each input pixel x.
    # This adds some non-linearity to the formula and allows us
    # to learn more complicated functions.
    layer = tf.nn.relu(layer)

    # Note that ReLU is normally executed before the pooling,
    # but since relu(max_pool(x)) == max_pool(relu(x)) we can
    # save 75% of the relu-operations by max-pooling first.

    # We return both the resulting layer and the filter-weights
    # because we will plot the weights later.
    return layer, weights
```

这些变量在运行时具有以下值:

![](Images/94fc1581-7e56-4eea-8f6a-462173e18a4c.png)![](Images/b86f9480-4130-4e9b-a42c-56e921259837.png)

如果我们运行这个，`print(..)`语句的输出将如下所示:

```
Tensor("Relu:0", shape=(?, 64, 64, 32), dtype=float32)
```

输出显示了来自输入层 1 的输出张量的形状。



# 第二卷积层

在第二个卷积层中，我们从第一个层的输出作为输入开始，并使用以下参数构建一个新层:

![](Images/fe16178f-69ae-4b98-a2cd-c6db7d000c1f.png)

首先，我们为 real `y`和 real `y`的类(类的标签)定义一个占位符:

```
y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')

y_true_cls = tf.argmax(y_true, dimension=1)
```

这两个变量的形状如下:

![](Images/21d8c384-836d-44e2-84ea-c905f32cf6a3.png)

```

layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1,
                                            num_input_channels=num_filters1,filter_size=filter_size2,num_filters=num_filters2,use_pooling=True)
```

其中，以下是值:

*   `num_input_channels` = 3
*   `filter_size` = 3
*   `num_filters` = 32

这是打印输出的结果:

```
Tensor("Relu_1:0", shape=(?, 32, 32, 32), dtype=float32)
```



# 第三卷积层

这一层将第二层的输出作为输入。让我们来看看创建这一层的输入:

![](Images/2d0e1178-13c2-41d2-b055-3e003015ed40.png)

```
shape = [filter_size, filter_size, num_input_channels, num_filters] weights = new_weights(shape=shape)
```

```
layer_conv3, weights_conv3 = new_conv_layer(input=layer_conv2,
                                            num_input_channels=num_filters2,filter_size=filter_size3,num_filters=num_filters3,use_pooling=True) 
```

```
print(layer_conv3)
```

`layer_conv3`的形状如下:

```
Tensor("Relu_2:0", shape=(?, 16, 16, 64), dtype=float32)
```



# 展平图层

接下来，我们将图层展平到图像的`num`和特征的`num`，在本例中为 16，384。如果您注意到最后一层的输出，我们已经用以下逻辑将其展平，16 x 16 x 64 = 16，384:

```
layer_flat, num_features = flatten_layer(layer_conv3)
```

如果我们打印这些值，您将看到以下输出:

```
Tensor("Reshape_1:0", shape=(?, 16384), dtype=float32)
16384
```



# 完全连接的层

在第四层和第五层中，我们定义完全连接的层:

```
layer_fc1 = new_fc_layer(input=layer_flat,
                         num_inputs=num_features,
                         num_outputs=fc_size,
                         use_relu=True)
```

在哪里

*   `layer_flat`:最后一层展平
*   `num_features`:特征数量
*   `fc_size`:输出数量

下图显示了传递给`new_fc_layer()`的值:

![](Images/dd3e30ec-b8fb-4c02-ac90-428f32e4a762.png)

```
print(layer_fc1)
```

印刷品的价值如下:

```
Tensor("Relu_3:0", shape=(?, 128), dtype=float32)
```

接下来是完全连接的第 2 层，该函数采用以下参数:

*   `layer_fc1`:第一个全连接层的输出
*   `num_inputs` : 128
*   `num_inputs` : `num_classes`，本例中为 2
*   `use_relu`:布尔函数，指定是否使用`relu`；`False`在这种情况下

```
layer_fc2 = new_fc_layer(input=layer_fc1,
                         num_inputs=fc_size,
                         num_outputs=num_classes,
                         use_relu=False)
```

让我们看看第二个全连接层的输出:

```
print(layer_fc2)
```

```
Tensor("add_4:0", shape=(?, 2), dtype=float32)
```



# 定义成本和优化器

对`layer_fc2`(完全连接的第二层)的输出应用 Softmax。

在数学中，`softmax`函数，或标准化的指数函数，^(:198)是对[逻辑函数](https://en.wikipedia.org/wiki/Logistic_function)的推广，即*将任意实值的 K 维向量 Z 挤压为在范围[ *0* ， *1* ]内的 K 维向量σ(Z)*加起来等于 *1 该函数由以下公式给出:***

![](Images/be5e10c9-6ffd-4ff8-bcf3-35b80c8c2454.png)

```
y_pred = tf.nn.softmax(layer_fc2)
y_pred_cls = tf.argmax(y_pred, dimension=1)
```

计算交叉熵:

```
cross_entropy = tf.nn.softmax_cross_entropy_with_logits(
  logits=layer_fc2,
  labels=y_true)
cost = tf.reduce_mean(cross_entropy)
```



# 【计算机】优化程序

接下来，我们定义优化器，它基于 Adam 优化器。

Adam 不同于随机梯度下降算法。随机梯度下降为所有权重更新保持单一学习率(称为**α**),学习率在训练期间不变。

该算法为每个网络权重(参数)保持一个学习速率，并随着学习的展开而单独调整。它根据梯度的一阶和二阶矩的估计来计算不同参数的个体自适应学习率。

Adam 结合了随机梯度下降的两个其他扩展的优点。

**自适应梯度算法** ( **AdaGrad** )保持了每参数学习率，提高了具有稀疏梯度的 ML 问题(例如，自然语言和计算机视觉问题)的性能。**均方根传播** ( **RMSProp** )保持每个参数的学习率；这些是基于权重的梯度的最近值的平均值(它变化得有多快)来调整的。

```
optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)
```

我们还计算了`correct_prediction`和`accuracy`的变量:

```
correct_prediction = tf.equal(y_pred_cls, y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
```



# 第一纪元

初始化会话并调用`num_iterations=1`的`optimize()`函数:

```
session = tf.Session()
session.run(tf.global_variables_initializer())
batch_size = 2
train_batch_size = batch_size
optimize(num_iterations = 1, data=data, train_batch_size=train_batch_size, x=x, y_true=y_true,
session=session, optimizer=optimizer, cost=cost, accuracy=accuracy)
```

这里，`optimize()`函数在下面的块中定义:

```
def optimize(num_iterations, data, train_batch_size, x, y_true, session, optimizer, cost, accuracy):
    # Ensure we update the global variable rather than a local copy.
    global total_iterations

    # Start-time used for printing time-usage below.
    start_time = time.time()

    best_val_loss = float("inf")
    patience = 0

    for i in range(total_iterations,
                   total_iterations + num_iterations):

        # Get a batch of training examples.
        # x_batch now holds a batch of images and
        # y_true_batch are the true labels for those images.
        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(train_batch_size)
        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(train_batch_size)

        # Convert shape from [num examples, rows, columns, depth]
        # to [num examples, flattened image shape]

        x_batch = x_batch.reshape(train_batch_size, img_size_flat)
        x_valid_batch = x_valid_batch.reshape(train_batch_size, img_size_flat)

        # Put the batch into a dict with the proper names
        # for placeholder variables in the TensorFlow graph.
        feed_dict_train = {x: x_batch,
                           y_true: y_true_batch}

        feed_dict_validate = {x: x_valid_batch,
                              y_true: y_valid_batch}

        # Run the optimizer using this batch of training data.
        # TensorFlow assigns the variables in feed_dict_train
        # to the placeholder variables and then runs the optimizer.
        session.run(optimizer, feed_dict=feed_dict_train)

        # Print status at end of each epoch (defined as full pass through 
        # training dataset).
        if i % int(data.train.num_examples/batch_size) == 0: 
            val_loss = session.run(cost, feed_dict=feed_dict_validate)
            epoch = int(i / int(data.train.num_examples/batch_size))

            #print_progress(epoch, feed_dict_train, feed_dict_validate, val_loss)
            print_progress(session, accuracy, epoch, feed_dict_train, feed_dict_validate,
              val_loss)

            if early_stopping:    
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    patience = 0
                else:
                    patience += 1

                if patience == early_stopping:
                    break

    # Update the total number of iterations performed.
    total_iterations += num_iterations

    # Ending time.
    end_time = time.time()

    # Difference between start and end-times.
    time_dif = end_time - start_time

    # Print the time-usage.
    print("Time elapsed: " + str(timedelta(seconds=int(round(time_dif)))))
```

此处列出了打印培训、认证准确性和认证损失的输出:

```
Epoch 1 --- Training Accuracy: 100.0%, Validation Accuracy: 50.0%, Validation Loss: 0.705
```

打印`Test-Set`的精度:

```
print_validation_accuracy(x, y_true, y_pred_cls, session, data, show_example_errors=True, show_confusion_matrix=False)
Epoch 2 --- Training Accuracy: 50.0%, Validation Accuracy: 100.0%, Validation Loss: 0.320
Accuracy on Test-Set: 43.1% (25 / 58)
```

接下来，让我们为`100`迭代优化模型:

```
optimize(num_iterations=100, data=data, train_batch_size=train_batch_size, x=x, y_true=y_true,session=session, optimizer=optimizer, cost=cost, accuracy=accuracy)

print_validation_accuracy(x, y_true, y_pred_cls, session, data, show_example_errors=True,
                              show_confusion_matrix=False)
Accuracy on Test-Set: 62.1% (36 / 58)
```

输出还显示误报:

![](Images/0701d3e7-93a0-4d1f-a3a1-b60938860ec7.png)

显示误报的输出



# 绘制滤镜及其对图像的影响

让我们将两个图层中的滤镜应用到两个测试图像中，看看它们会受到怎样的影响:

```
image1 = test_images[0] 
plot_image(image1)
```

下图显示了`plot_image(image1)`功能的输出:

![](Images/e73c27ed-677f-4ced-a229-e7ae1b1f0828.png)

```
image2 = test_images[13]
plot_image(image2)
```

应用了过滤器的`image2`的输出如下所示:

![](Images/7a69fdcd-2edf-412c-8c87-2f3e61a606f0.png)

**卷积层 1** :下面是层 1 的权重图:

![](Images/148d381d-ae2f-431f-9f59-c5777a7ffdd3.png)

第 1 层的滤镜应用于图像 1:

```
plot_conv_layer(layer=layer_conv1, image=image1, session=session, x=x)
```

![](Images/0a7fcbe4-27aa-4810-8426-3dcfc2b29895.png)

图层 1 中的滤镜应用于图像 2:

```
plot_conv_layer(layer=layer_conv1, image=image2, session=session, x=x)
```

![](Images/c87f3e63-b355-43f2-a591-73c5adbff0c9.png)

**卷积层 2** :现在绘制第二个卷积层的滤波器权重。第一 conv 层有 16 个输出通道，这意味着第二 conv 层有 16 个输入通道。第二 Conv 层对于其每个输入通道具有一组滤波器权重。我们首先绘制第一通道的滤波器权重。

第二层重量:

```
plot_conv_weights(weights=weights_conv1, session=session)
```

![](Images/1fef67e7-1d91-4d12-8472-88ba49458be4.png)

Conv2 输入通道 0 的权重。正重量为红色，负重量为蓝色

第二卷积层有 16 个输入通道，因此我们可以像这样绘制另外 15 个滤波器权重图。我们只是用第二通道的滤波器权重再做一个:

```
plot_conv_weights(weights=weights_conv2, session=session, input_channel=1)
```

![](Images/3940424f-1b26-4655-a8e6-33b1f835132c.png)

正重量为红色，负重量为蓝色

使用卷积层 2 的过滤器绘制图像 1 和 2:

```
plot_conv_layer(layer=layer_conv2, image=image1, session=session, x=x)
plot_conv_layer(layer=layer_conv2, image=image2, session=session, x=x)
```

![](Images/32a3fb47-36fc-4c28-a134-dbe122e429f9.png)

conv2 输入通道 1 的权重。显示通过第 2 层过滤器过滤的图像 1 的图像

![](Images/cf75f4f8-7094-42de-93ae-a53ef5def00c.png)

显示通过第 2 层过滤器过滤的图像 2 的图像

**卷积第三层**:我们来打印第三层权重；这一层有 64 个过滤器。这是图像 1 和 2 通过这些滤镜后的样子:

```
plot_conv_weights(weights=weights_conv3, session=session, input_channel=0)
```

![](Images/75b0fedd-b2fc-4fd5-b618-1bfad5389d36.png)

Conv2 输入通道 0 的权重，正权重为红色，负权重为蓝色

```
plot_conv_weights(weights=weights_conv3, session=session, input_channel=1)
```

![](Images/ee6baebb-0628-4681-b538-6049633ac2e8.png)

Conv2 输入通道 1 的权重。正权重为红色，负权重为蓝色。

**绘制通过第三层滤波器的图像**:执行以下语句，绘制通过卷积第三层 64 个滤波器的图像 1 和 2:

```
plot_conv_layer(layer=layer_conv3, image=image1, session=session, x=x)
plot_conv_layer(layer=layer_conv3, image=image2, session=session, x=x)
```

![](Images/0c6fbc09-09e5-4a7d-ae8b-9f7c14c9a579.png)

图 1，使用 conv3 的卷积滤波器绘制

以下是 conv3 卷积滤波器的图像:

![](Images/a8b2d685-5888-4864-b36a-f979f377d1ec.png)

图 2，使用 conv3 的卷积滤波器绘制

这样，我们就完成了对猫和狗数据集的分析，其中我们使用了一个具有三个隐藏层和两个完全连接层的五层 CNN 来构建我们的模型。



# 摘要

在本章中，您学习了卷积的基础知识，以及为什么它是图像标签预测的有效机制。您学习了基本概念，如`strides`和填充。接下来是一个基于斯坦福猫对狗数据集的例子。我们使用三个卷积层来构建神经网络，并使用两个完全连接的层来展示它如何用于对图像进行分类。我们还绘制了三个图层的权重，并看到了滤镜如何修改图像。我们还研究了图像池等概念，以及它如何帮助 CNN 提高效率。

在下一章中，我们来看一种不同的神经网络，称为**递归神经网络** ( **RNN** )，它处理时间序列数据或者用于**自然语言处理** ( **NLP** )来预测序列中的下一个单词


# 自编码器

自编码器是一种神经网络，它被训练为尝试将其输入复制到其输出。它有一个隐藏层(姑且称之为 *h* )，描述了用来表示输入的代码。该网络可被视为由两部分组成:

*   **编码器功能** : *h = f (x)*
*   **产生重建的解码器** : *r = g(h)*

下图显示了具有输入 *n* 的基本自编码器和具有神经元 *m* 的隐藏层:

![](Images/af478e87-a284-4b89-95bd-027cbdca7a02.png)

自编码器的基本表示

自编码器被设计成不能学习完美地复制。它们受到限制，只能大致复制，并且只能复制类似于训练数据的输入。当模型被迫优先考虑输入的哪些方面应该被复制时，它经常学习数据的有用属性。

本章将涵盖以下主题:

*   自编码器算法
*   不完整的自编码器
*   基本自编码器
*   附加高斯噪声自编码器
*   稀疏自编码器



# 自编码器算法

以下符号中，`x`为输入，`y`为编码数据，`z`为解码数据，`σ`为非线性激活函数(通常为 sigmoid 或双曲线正切)，`f(x;θ)`表示由`θ`参数化的`x`的函数。

该模型可总结如下:

输入数据被映射到隐藏层(编码)。映射通常是仿射的(允许或保持平行关系)。)变换，随后是非线性:

```py
y = f(x;θ) = σ(Wx+b)y = f(x;θ) =σ(Wx+b)
```

隐藏层映射到输出层，也叫**解码**。该映射是仿射变换(仿射变换是一种保持点、直线和平面的线性映射方法),可选地后跟非线性。下面的等式解释了这一点:

```py
z = g(y;θ′) = g(f(x;θ);θ′) = σ(W′y+b′)
```

为了减小模型的规模，可以使用捆绑权重，这意味着解码器权重矩阵是受约束的，并且可以是编码器权重矩阵的转置，*θ’=θ^T*。

隐藏层可以具有比输入/输出层更低或更高的维度。

在较低维度的情况下，解码器从原始输入的较低维度表示(也称为**不完全表示**)重建原始输入。为了使整个算法能够工作，编码器应该学会提供一种低维表示，这种表示可以捕捉数据的本质(即分布中变化的主要因素)。它被迫找到一个很好的方法来总结数据。

参考:[http://black echo . github . io/blog/machine-learning/2016/02/29/降噪-auto encoder-tensor flow . html](http://blackecho.github.io/blog/machine-learning/2016/02/29/denoising-autoencoder-tensorflow.html)。



# 不完整的自编码器

从自编码器获得有用特征的方法之一是通过约束 *h* 使其尺寸小于输入`x`来实现。代码维数小于输入维数的自编码器称为欠完整编码器。

学习不完整的表示迫使自编码器捕捉训练数据的最显著特征。

学习过程被描述为最小化损失函数`L(x, g(f(x)))`、
，其中`L`是因与`x`不同而惩罚`g(f (x))`的损失函数，例如均方误差。



# 资料组

我们计划使用`idx3`格式的 MNIST 数据集作为输入来训练我们的自编码器。我们将在前 100 张图像上测试自编码器。让我们首先绘制原始图像:

```py

from tensorflow.examples.tutorials.mnist import input_data
import matplotlib.pyplot as plt

mnist = input_data.read_data_sets('MNIST_data', one_hot = True)

class OriginalImages:

    def __init__(self):
        pass

    def main(self):
        X_train, X_test = self.standard_scale(mnist.train.images, mnist.test.images)

        original_imgs = X_test[:100]
        plt.figure(1, figsize=(10, 10))

        for i in range(0, 100):
            im = original_imgs[i].reshape((28, 28))
            ax = plt.subplot(10, 10, i + 1)
            for label in (ax.get_xticklabels() + ax.get_yticklabels()):
                label.set_fontsize(8)

            plt.imshow(im, cmap="gray", clim=(0.0, 1.0))
        plt.suptitle(' Original Images', fontsize=15, y=0.95)
        plt.savefig('figures/original_images.png')
        plt.show()

def main():
    auto = OriginalImages()
    auto.main()

if __name__ == '__main__':
    main()
```

前面的输出如下图所示:

![](Images/3ea4bce8-c710-41bb-9eed-3ba8deac2dde.png)

MNIST 原图



# 基本自编码器

让我们看一个自编码器的基本例子，它也是一个基本的自编码器。首先，我们将创建一个`AutoEncoder`类，并用传递给`__init__()`的以下参数初始化它:

*   `num_input`:输入样本数
*   `num_hidden`:隐藏层中神经元的数量
*   `transfer_function=tf.nn.softplus`:传递函数
*   `optimizer = tf.train.AdamOptimizer()`:优化器

您可以传递自定义的`transfer_function`和`optimizer`或者使用指定的默认设置。在我们的例子中，我们使用 softplus 作为默认的`transfer_function`(也称为**激活功能** ): `f(x)=ln(1+e^x)`。



# 自编码器初始化

首先，我们初始化类变量和权重:

```py
 self.num_input = num_input
 self.num_hidden = num_hidden
 self.transfer = transfer_function
 network_weights = self._initialize_weights()
 self.weights = network_weights
```

这里，`_initialize_weigths()`函数是一个本地函数，它初始化`weights`字典的值:

*   `w1`是一个形状为`num_input X num_hidden`的 2D 张量
*   `b1`是一个形状为`num_hidden`的 1D 张量
*   `w2`是一个形状为`num_hidden X num_input`的 2D 张量
*   `b2`是一个形状为`num_input`的 2D 张量

以下代码显示了如何将权重初始化为两个隐藏层的 TensorFlow 变量的字典:

```py
def _initialize_weights(self):
    weights = dict()
    weights['w1'] = tf.get_variable("w1", shape=[self.num_input, self.num_hidden],
                      initializer=tf.contrib.layers.xavier_initializer())
    weights['b1'] = tf.Variable(tf.zeros([self.num_hidden], dtype=tf.float32))
    weights['w2'] = tf.Variable(tf.zeros([self.num_hidden, self.num_input],
      dtype=tf.float32))
    weights['b2'] = tf.Variable(tf.zeros([self.num_input], dtype=tf.float32))
    return weights
```

接下来，我们定义`x_var`、`hidden_layer`和`reconstruction layer`:

```py
 self.x_var = tf.placeholder(tf.float32, [None, self.num_input])
 self.hidden_layer = self.transfer(tf.add(tf.matmul(self.x_var, 
   self.weights['w1']), self.weights['b1']))
 self.reconstruction = tf.add(tf.matmul(self.hidden_layer, 
   self.weights['w2']), self.weights['b2'])
```

```py
This is followed by the cost function and the Optimizer
# cost function
self.cost = 0.5 * tf.reduce_sum(
   tf.pow(tf.subtract(self.reconstruction, self.x_var), 2.0))
self.optimizer = optimizer.minimize(self.cost)
```

![](Images/65f7a30e-20da-4026-b85e-8536e42987f3.jpg)

价值函数

实例化全局变量初始化器并将其传递给 TensorFlow 会话。

```py
initializer = tf.global_variables_initializer()
self.session = tf.Session()
self.session.run(initializer)
```



# 自编码器类

下面的代码显示了`AutoEncoder`类。在接下来的几节中，将为示例实例化该类以创建自编码器:

```py
import tensorflow as tf

class AutoEncoder:

    def __init__(self, num_input, num_hidden, 
      transfer_function=tf.nn.softplus, 
      optimizer = tf.train.AdamOptimizer()):
        self.num_input = num_input
        self.num_hidden = num_hidden
        self.transfer = transfer_function

        network_weights = self._initialize_weights()
        self.weights = network_weights

        # model for reconstruction of the image
        self.x_var = tf.placeholder(tf.float32, [None, self.num_input])
        self.hidden_layer = self.transfer(tf.add(tf.matmul(self.x_var, 
          self.weights['w1']), self.weights['b1']))
        self.reconstruction = tf.add(tf.matmul(self.hidden_layer, 
          self.weights['w2']), self.weights['b2'])

        # cost function
        self.cost = 
          0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction,
          self.x_var), 2.0))
        self.optimizer = optimizer.minimize(self.cost)

        initializer = tf.global_variables_initializer()
        self.session = tf.Session()
        self.session.run(initializer)

    def _initialize_weights(self):
        weights = dict()
        weights['w1'] = tf.get_variable("w1", 
                          shape=[self.num_input, 
                          self.num_hidden],
                          initializer=
                            tf.contrib.layers.xavier_initializer())
        weights['b1'] = tf.Variable(tf.zeros([self.num_hidden], 
                                    dtype=tf.float32))
        weights['w2'] = tf.Variable(
          tf.zeros([self.num_hidden, self.num_input],
          dtype=tf.float32))
        weights['b2'] = tf.Variable(tf.zeros(
                          [self.num_input], dtype=tf.float32))
        return weights

    def partial_fit(self, X):
        cost, opt = self.session.run((self.cost, self.optimizer), 
          feed_dict={self.x_var: X})
        return cost

    def calculate_total_cost(self, X):
        return self.session.run(self.cost, feed_dict = {self.x_var: X})

    def transform(self, X):
        return self.session.run(self.hidden_layer, 
          feed_dict={self.x_var: X})

    def generate(self, hidden = None):
        if hidden is None:
            hidden = self.session.run(
              tf.random_normal([1, self.num_hidden]))
        return self.session.run(self.reconstruction, 
               feed_dict={self.hidden_layer: hidden})

    def reconstruct(self, X):
        return self.session.run(self.reconstruction, 
                                feed_dict={self.x_var: X})

    def get_weights(self):
        return self.session.run(self.weights['w1'])

    def get_biases(self):
        return self.session.run(self.weights['b1'])
```



# 带 MNIST 数据的基本自编码器

让我们使用 MNIST 数据的自编码器:`mnist = input_data.read_data_sets('MNIST_data', one_hot = True)`。

使用 Scikit Learn 的`sklearn.` `preprocessing`模块中的标准标量提取`testmnist.test.images`和训练图像`mnist.train.images`:

```py
X_train, X_test = self.standard_scale(mnist.train.images, mnist.test.images).
```

预处理模块提供了一个实用程序类`StandardScaler`，它实现了 Transformer API。这将计算并转换训练集的平均值和标准偏差。它将相同的转换重新应用于测试集。默认情况下，标量使平均值居中，并使方差为 1。
通过将`with_mean=False`或`with_std=False`传递给 StandardScaler 的构造函数，可以禁用居中或缩放。

接下来，我们定义前面列出的 AutoEncoder 类的实例:

```py
 n_samples = int(mnist.train.num_examples)
 training_epochs = 5
 batch_size = 128
 display_step = 1

 autoencoder = AutoEncoder(n_input = 784,
   n_hidden = 200,
   transfer_function = tf.nn.softplus,
   optimizer = tf.train.AdamOptimizer(learning_rate = 0.001))
```

请注意，自编码器包括以下内容:

*   输入神经元的数量为`784`
*   隐藏层中的神经元数量为`200`
*   激活功能是`tf.nn.softplus`
*   优化器是`tf.train.AdamOptimizer`

接下来，我们迭代训练数据并显示成本函数:

```py
for epoch in range(training_epochs):
    avg_cost = 0.
    total_batch = int(n_samples / batch_size)
    # Loop over all batches
    for i in range(total_batch):
        batch_xs = self.get_random_block_from_data(X_train, batch_size)

        # Fit training using batch data
        cost = autoencoder.partial_fit(batch_xs)
        # Compute average loss
        avg_cost += cost / n_samples * batch_size

    # Display logs per epoch step
    if epoch % display_step == 0:
        print("Epoch:", '%04d' % (epoch + 1), "cost=", "{:.9f}".format(avg_cost))
```

打印总成本:

```py
print("Total cost: " + str(autoencoder.calc_total_cost(X_test)))
```

历元的输出如下所示:正如所料，成本随着每次迭代而收敛:

```py
('Epoch:', '0001', 'cost=', '20432.278386364')
('Epoch:', '0002', 'cost=', '13542.435997727')
('Epoch:', '0003', 'cost=', '10630.662196023')
('Epoch:', '0004', 'cost=', '10717.897946591')
('Epoch:', '0005', 'cost=', '9354.191921023')
Total cost: 824850.0
```



# 重量的基本自编码器图

训练完成后，使用 Matplotlib 库通过代码清单显示权重图:

```py
print("Total cost: " + str(autoencoder.calc_total_cost(X_test)))
wts = autoencoder.getWeights()
dim = math.ceil(math.sqrt(autoencoder.n_hidden))
plt.figure(1, figsize=(dim, dim))

for i in range(0, autoencoder.n_hidden):
    im = wts.flatten()[i::autoencoder.n_hidden].reshape((28, 28))
    ax = plt.subplot(dim, dim, i + 1)
    for label in (ax.get_xticklabels() + ax.get_yticklabels()):
        label.set_fontname('Arial')
        label.set_fontsize(8)
    # plt.title('Feature Weights ' + str(i))
    plt.imshow(im, cmap="gray", clim=(-1.0, 1.0))
plt.suptitle('Basic AutoEncoder Weights', fontsize=15, y=0.95)
#plt.title("Test Title", y=1.05)
plt.savefig('figures/basic_autoencoder_weights.png')
plt.show()
```

![](Images/8f561398-b0db-4d6f-b0eb-622b94e61396.png)

基本自编码器权重图

在下一节中，我们将了解如何使用前面图像中显示的权重来重新创建图像。



# 基本自编码器重新创建图像图

重新创建图像后，让我们绘制它们，感受一下它们的样子。首先，我们将使用之前创建的`autoencoder`实例重建图像:

```py
predicted_imgs = autoencoder.reconstruct(X_test[:100])

plt.figure(1, figsize=(10, 10))

for i in range(0, 100):
    im = predicted_imgs[i].reshape((28, 28))
    ax = plt.subplot(10, 10, i + 1)
    for label in (ax.get_xticklabels() + ax.get_yticklabels()):
                label.set_fontname('Arial')
                label.set_fontsize(8)

    plt.imshow(im, cmap="gray", clim=(0.0, 1.0))
plt.suptitle('Basic AutoEncoder Images', fontsize=15, y=0.95)
plt.savefig('figures/basic_autoencoder_images.png')
plt.show()
```

让我们看看从神经网络创建的图像:

![](Images/fcaccfd9-080c-4775-a79e-3f0756e2c92b.png)

输出图像的基本自编码器图



# 基本自编码器完整代码清单

完整的代码清单可以在这里找到，也可以从 GitHub-[https://GitHub . com/rajdeepd/neural network-programming/blob/ed1/ch07/basic _ auto encoder _ example . py](https://github.com/rajdeepd/neuralnetwork-programming/blob/ed1/ch07/basic_autoencoder_example.py)下载:

```py
import numpy as np

import sklearn.preprocessing as prep
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
from autencoder_models.auto_encoder import AutoEncoder
import math
import matplotlib.pyplot as plt

mnist = input_data.read_data_sets('MNIST_data', one_hot = True)

class BasicAutoEncoder:

    def __init__(self):
        pass

    def standard_scale(self,X_train, X_test):
        preprocessor = prep.StandardScaler().fit(X_train)
        X_train = preprocessor.transform(X_train)
        X_test = preprocessor.transform(X_test)
        return X_train, X_test

    def get_random_block_from_data(self,data, batch_size):
        start_index = np.random.randint(0, len(data) - batch_size)
        return data[start_index:(start_index + batch_size)]

    def main(self):
        X_train, X_test = self.standard_scale(mnist.train.images, mnist.test.images)

        n_samples = int(mnist.train.num_examples)
        training_epochs = 5
        batch_size = 128
        display_step = 1

        autoencoder = AutoEncoder(n_input = 784,
                                  n_hidden = 200,
                                  transfer_function = tf.nn.softplus,
                                  optimizer = tf.train.AdamOptimizer(
                                    learning_rate = 0.001))

        for epoch in range(training_epochs):
            avg_cost = 0.
            total_batch = int(n_samples / batch_size)
            # Loop over all batches
            for i in range(total_batch):
                batch_xs = self.get_random_block_from_data(X_train, batch_size)

                # Fit training using batch data
                cost = autoencoder.partial_fit(batch_xs)
                # Compute average loss
                avg_cost += cost / n_samples * batch_size

            # Display logs per epoch step
            if epoch % display_step == 0:
                print("Epoch:", '%04d' % (epoch + 1), "cost=", "{:.9f}".format(avg_cost))

        print("Total cost: " + str(autoencoder.calc_total_cost(X_test)))

        wts = autoencoder.getWeights()
        dim = math.ceil(math.sqrt(autoencoder.n_hidden))
        plt.figure(1, figsize=(dim, dim))

        for i in range(0, autoencoder.n_hidden):
            im = wts.flatten()[i::autoencoder.n_hidden].reshape((28, 28))
            ax = plt.subplot(dim, dim, i + 1)
            for label in (ax.get_xticklabels() + ax.get_yticklabels()):
                label.set_fontname('Arial')
                label.set_fontsize(8)
            # plt.title('Feature Weights ' + str(i))
            plt.imshow(im, cmap="gray", clim=(-1.0, 1.0))
        plt.suptitle('Basic AutoEncoder Weights', fontsize=15, y=0.95)
        #plt.title("Test Title", y=1.05)
        plt.savefig('figures/basic_autoencoder_weights.png')
        plt.show()

        predicted_imgs = autoencoder.reconstruct(X_test[:100])

        plt.figure(1, figsize=(10, 10))

        for i in range(0, 100):
            im = predicted_imgs[i].reshape((28, 28))
            ax = plt.subplot(10, 10, i + 1)
            for label in (ax.get_xticklabels() + ax.get_yticklabels()):
                        label.set_fontname('Arial')
                        label.set_fontsize(8)

            plt.imshow(im, cmap="gray", clim=(0.0, 1.0))
        plt.suptitle('Basic AutoEncoder Images', fontsize=15, y=0.95)
        plt.savefig('figures/basic_autoencoder_images.png')
        plt.show()

def main():
    auto = BasicAutoEncoder()
    auto.main()

if __name__ == '__main__':
    main()
```



# 基本自编码器摘要

autoencoder 使用 200 个神经元隐藏层创建了 MNSIT 图像的基本近似值。下图显示了九幅图像，以及如何使用基本的自编码器将它们转换为近似值:

![](Images/f98d20e7-7c2e-4a37-8e18-5fc0bc23ab87.png)

基本自编码器输入和输出表示

在下一节中，我们将看看一个更高级的自编码器，一个**加性高斯噪声自编码器**。



# 加性高斯噪声自编码器

什么是去噪自编码器？它们非常类似于我们在前面章节中看到的基本模型，不同之处在于，输入在被传递到网络之前被破坏。通过在训练时将原始版本(不是被破坏的版本)与重建进行匹配，该自编码器被训练来从被破坏的图像重建原始输入图像。从损坏的图像重建原始图像的能力使得 autoencoder 非常智能。

加性噪声自编码器使用下面的等式来增加输入数据的损坏:

*x[corr]= x+scale * random _ normal(n)*

以下是对上述等式的详细描述:

*   *x* 是原始图像
*   *scale* 是从 *n* 生成的随机正常数的乘数
*   *n* 为训练样本数
*   *x[corr]是损坏的输出*



# 自编码器类

我们通过传递以下参数来初始化`class AdditiveGaussianNoiseAutoEncoder`中定义的自编码器:

*   `num_input`:输入样本数
*   `num_hidden`:隐藏层中神经元的数量
*   `transfer_function=tf.nn.sigmoid`:传递函数
*   `optimizer = tf.train.AdamOptimizer()`:优化器
*   `scale=0.1`:图像损坏的比例

```py
def __init__(self, num_input, num_hidden, 
                 transfer_function=tf.nn.sigmoid, 
                 optimizer=tf.train.AdamOptimizer(),
                 scale=0.1):
```

将传递的参数分配给实例变量:

```py
        self.num_input = num_input
        self.num_hidden = num_hidden
        self.transfer = transfer_function
        self.scale = tf.placeholder(tf.float32)
        self.training_scale = scale
        n_weights = self._initialize_weights()
        self.weights = n_weights
```

初始化隐藏层`hidden_layer`和重建层`reconstruction`:

```py
self.x = tf.placeholder(tf.float32, [None, self.num_input])
self.hidden_layer = self.transfer(
            tf.add(tf.matmul(
                      self.x + scale * tf.random_normal((n_input,)),
                      self.weights['w1']),
                      self.weights['b1']))
self.reconstruction = tf.add(
                        tf.matmul(self.hidden_layer, self.weights['w2']),    
                        self.weights['b2'])
```

定义成本函数和优化器:

```py
self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(
                           self.reconstruction, self.x), 2.0))
self.optimizer = optimizer.minimize(self.cost)
```

成本函数与基本的自编码器保持相同

![](Images/594dd7ad-8b38-4948-9df7-edea73778020.jpg)

加性高斯自编码器的代价函数

最后，我们初始化全局变量，创建一个 TensorFlow 会话，并运行它来执行`init`图:

```py
init = tf.global_variables_initializer()
self.session = tf.Session()
self.session.run(init)

```

在下一节中，我们将了解如何使用这个自编码器来编码 MNIST 数据。



# 基于 MNIST 数据集的加性高斯自编码器

首先，我们加载训练和测试数据集，`X_train`和`X_test`:

```py
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)

def get_random_block_from_data(data, batch_size):
    start_index = np.random.randint(0, len(data) - batch_size)
    return data[start_index:(start_index + batch_size)]

X_train = mnist.train.images
X_test = mnist.test.images

```

为训练的每次迭代定义样本数量的变量`n_samples`、`training_epoch`和`batch_size`以及`display_step`:

```py
n_samples = int(mnist.train.num_examples)
training_epochs = 2
batch_size = 128
display_step = 1
```

实例化自编码器和优化器。自编码器有 200 个隐藏单元，使用 sigmoid 作为`transfer_function`:

```py
autoencoder = AdditiveGaussianNoiseAutoEncoder(n_input=784,
                                               n_hidden=200,
                                               transfer_function=tf.nn.sigmoid,
                                               optimizer=tf.train.AdamOptimizer(learning_rate=0.001),
                                               scale=0.01)
```



# 训练模型

一旦定义了神经网络层，我们就通过调用方法来训练模型

`autoencoder.partial_fit(batch_xs)`对于每批数据:

```py
for epoch in range(training_epochs):
    avg_cost = 0.
    total_batch = int(n_samples / batch_size)
    # Loop over all batches
    for i in range(total_batch):
        batch_xs = get_random_block_from_data(X_train, batch_size)

        # Fit training using batch data
        cost = autoencoder.partial_fit(batch_xs)
        # Compute average loss
        avg_cost += cost / n_samples * batch_size

    # Display logs per epoch step
    if epoch % display_step == 0:
        print("Epoch:", '%04d' % (epoch + 1), "cost=", avg_cost)

print("Total cost: " + str(autoencoder.calc_total_cost(X_test)))
```

打印每个时期的成本:

```py
('Epoch:', '0001', 'cost=', 1759.873304261363)
('Epoch:', '0002', 'cost=', 686.85984829545475)
('Epoch:', '0003', 'cost=', 460.52834446022746)
('Epoch:', '0004', 'cost=', 355.10590241477308)
('Epoch:', '0005', 'cost=', 297.99104825994351)
```

培训的总费用如下:

```py
Total cost: 21755.4
```



# 绘制重量图

让我们直观地绘制权重，并使用 Matplotlib 进行绘制:

```py
wts = autoencoder.get_weights()
dim = math.ceil(math.sqrt(autoencoder.num_hidden))
plt.figure(1, figsize=(dim, dim))
for i in range(0, autoencoder.num_hidden):
    im = wts.flatten()[i::autoencoder.num_hidden].reshape((28, 28))
    ax = plt.subplot(dim, dim, i + 1)
    for label in (ax.get_xticklabels() + ax.get_yticklabels()):
        label.set_fontsize(8)
    #plt.title('Feature Weights ' + str(i))

    plt.imshow(im, cmap="gray", clim=(-1.0, 1.0))
plt.suptitle('Additive Gaussian Noise AutoEncoder Weights', fontsize=15, y=0.95)
plt.savefig('figures/additive_gaussian_weights.png')
plt.show()
```

![](Images/02034b23-6d96-47a1-bd02-38459aaecc86.png)

加性高斯自编码器隐层神经元的权值



# 绘制重建的图像

最后一步是打印重建图像，为我们提供编码器如何根据权重重建图像的直观证据:

```py
predicted_imgs = autoencoder.reconstruct(X_test[:100])

# plot the reconstructed images
plt.figure(1, figsize=(10, 10))
plt.title('Autoencoded Images')
for i in range(0, 100):
    im = predicted_imgs[i].reshape((28, 28))
    ax = plt.subplot(10, 10, i + 1)
    for label in (ax.get_xticklabels() + ax.get_yticklabels()):
        label.set_fontname('Arial')
        label.set_fontsize(8)

    plt.imshow(im, cmap="gray", clim=(0.0, 1.0))
plt.suptitle('Additive Gaussian Noise AutoEncoder Images', fontsize=15, y=0.95)
plt.savefig('figures/additive_gaussian_images.png')
plt.show()
```

![](Images/29d01b60-b0b1-4d30-b2f5-cdd4801808d6.png)

利用加性高斯自编码器重建图像



# 加法高斯自编码器完整的源代码清单

以下是附加高斯自编码器的代码:

```py
import numpy as np
import tensorflow as tf
def xavier_init(fan_in, fan_out, constant = 1):
    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))
    high = constant * np.sqrt(6.0 / (fan_in + fan_out))
    return tf.random_uniform((fan_in, fan_out), minval = low, maxval = high, dtype = tf.float32)

class AdditiveGaussianNoiseAutoEncoder(object):
    def __init__(self, num_input, num_hidden, 
                 transfer_function=tf.nn.sigmoid, 
                 optimizer=tf.train.AdamOptimizer(),
                 scale=0.1):
        self.num_input = num_input
        self.num_hidden = num_hidden
        self.transfer = transfer_function
        self.scale = tf.placeholder(tf.float32)
        self.training_scale = scale
        n_weights = self._initialize_weights()
        self.weights = n_weights
      # model
</span>        self.x = tf.placeholder(tf.float32, [None, self.num_input])
        self.hidden_layer = self.transfer(
            tf.add(tf.matmul(
                      self.x + scale * tf.random_normal((n_input,)),
                      self.weights['w1']),
                      self.weights['b1']))
        self.reconstruction = tf.add(
                                tf.matmul(self.hidden_layer, self.weights['w2']),    
                                self.weights['b2'])

        # cost
        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(
                           self.reconstruction, self.x), 2.0))

        self.optimizer = optimizer.minimize(self.cost)

        init = tf.global_variables_initializer()
        self.session = tf.Session()
        self.session.run(init)

    def _initialize_weights(self):
        weights = dict()
        weights['w1'] = tf.Variable(xavier_init(self.num_input, self.num_hidden))
        weights['b1'] = tf.Variable(tf.zeros([self.num_hidden], dtype=tf.float32))
        weights['w2'] = tf.Variable(tf.zeros([self.num_hidden, self.num_input],
          dtype=tf.float32))
        weights['b2'] = tf.Variable(tf.zeros([self.num_input], dtype=tf.float32))
        return weights

    def partial_fit(self, X):
        cost, opt = self.session.run((self.cost, self.optimizer), 
            feed_dict={self.x: X,self.scale: self.training_scale})
        return cost

    def kl_divergence(self, p, p_hat):
        return tf.reduce_mean(
          p * tf.log(p) - p * tf.log(p_hat) + (1 - p) * tf.log(1 - p) - (1 - p) *        tf.log(1 - p_hat))

    def calculate_total_cost(self, X):
        return self.session.run(self.cost, feed_dict={self.x: X,
                                                      self.scale: self.training_scale
                                                      })

    def transform(self, X):
        return self.session.run(
          self.hidden_layer, 
          feed_dict = {self.x: X, self.scale: self.training_scale})

    def generate_value(self, _hidden=None):
        if _hidden is None:
            _hidden = np.random.normal(size=self.weights["b1"])
        return self.session.run(self.reconstruction, 
            feed_dict={self.hidden_layer: _hidden})

    def reconstruct(self, X):
        return self.session.run(self.reconstruction, 
          feed_dict={self.x: X,self.scale: self.training_scale })

    def get_weights(self):
        return self.session.run(self.weights['w1'])

    def get_biases(self):
        return self.session.run(self.weights['b1'])
```



# 基本编码器成本与加性高斯噪声自编码器成本的比较

下图显示了每个时期两种算法的成本。可以推断出，与附加高斯噪声自编码器相比，基本自编码器要昂贵得多:

![](Images/5ce1b147-0a74-4a1d-a216-df06b6355f71.png)

成本比较:基本与附加高斯噪声自编码器



# 加性高斯噪声自编码器摘要

您了解了如何创建带有高斯噪声的自编码器，与基本的自编码器相比，这有助于大幅提高模型的准确性。



# 稀疏自编码器

在这一节中，我们将看看在成本函数中增加稀疏度如何有助于降低训练成本。大部分代码保持不变，但主要的变化是成本函数的计算方式。



# KL 散度

我们先来试着理解一下 KL 散度，它是用来给代价函数增加稀疏度的。

如果神经元的输出值接近 1，我们可以认为神经元是活跃的(或*触发*),如果其输出值接近 0，我们可以认为*是不活跃的*。我们希望限制神经元在大部分时间不活动。这个讨论假设了一个 sigmoid 激活函数。
回想一下 *a ^((2)) [j]* 表示自编码器中隐藏单元 *j* 的激活。这个符号并没有明确说明导致这个激活的输入 *x* 是什么。我们将写*a^((2))[j](x)*来表示当网络被给定一个特定的输入 *x* 时隐藏单元的激活。此外，假设![](Images/10147870-75b0-464d-b1cf-2edc0807e4d2.jpg)是隐藏单元 *j* 的平均激活(在训练集上平均)。我们希望(近似地)实施约束![](Images/9971f609-c670-4c63-a7d8-381212c5620c.png)，其中 [![](Images/82da78e8-7a12-4a56-8037-b83b98326850.png)] 是一个稀疏参数，通常是一个接近于零的小值(比如说，= *0.05* )。我们的目标是每个隐藏神经元 *j* 的平均激活接近 *0.05* (作为一个例子)。为了满足前面的约束，隐藏单元的激活必须大部分接近于零。

为了实现这一点，一个额外的惩罚项被添加到优化目标中，对其进行惩罚，显著偏离 [![](Images/82da78e8-7a12-4a56-8037-b83b98326850.png)] :

![](Images/6088760a-c222-4657-b2d1-7fcf511893dd.jpg)

让我们看看 KL 散度如何作为平均激活的函数而变化:

![](Images/16a1258c-7aef-41ae-95dd-00965d51e402.png)

平均激活度对 KL 散度图



# TensorFlow 中的 KL 散度

在我们的稀疏编码器实现中，我们在`SparseEncoder`类的`kl_divergence`函数中定义了 KL 散度，它只不过是前面公式的一个实现:

```py
def kl_divergence(self, p, p_hat):
    return tf.reduce_mean(
           p*(tf.log(p)/tf.log(p_hat)) + 
           (1-p)*(tf.log(1-p)/tf.log(1-p_hat)))
```



# 基于 KL 散度的稀疏自编码器的代价

与本章中讨论的先前编码器相比，成本函数用两个新参数`sparse_reg`和`kl_divergence`重新定义:

```py
self.cost = 0.5 * tf.reduce_sum(
  tf.pow(tf.subtract(self.reconstruction, self.x), 2.0)) + 
    self.sparse_reg * self.kl_divergence(self.sparsity_level, self.hidden_layer)
```



# 稀疏自编码器的完整代码清单

作为参考，我们在这里给出了`SparseAutoEncoder`的代码清单，以及前面讨论过的`kl_divergence`和`cost`:

```py
class SparseAutoencoder(object):
    def __init__(self, num_input, num_hidden, 
                 transfer_function=tf.nn.softplus, 
                 optimizer=tf.train.AdamOptimizer(),
                 scale=0.1):
        self.num_input = num_input
        self.num_hidden = num_hidden
        self.transfer = transfer_function
        self.scale = tf.placeholder(tf.float32)
        self.training_scale = scale
        network_weights = self._initialize_weights()
        self.weights = network_weights
        self.sparsity_level = np.repeat([0.05], 
           self.num_hidden).astype(np.float32)
        self.sparse_reg = 0.0

        # model
        self.x = tf.placeholder(tf.float32, [None, self.num_input])
        self.hidden_layer = self.transfer(tf.add(tf.matmul(
            self.x + scale * tf.random_normal((num_input,)), 
                                               self.weights['w1']),
                                               self.weights['b1']))
        self.reconstruction = tf.add(tf.matmul(self.hidden_layer, 
            self.weights['w2']), self.weights['b2'])

        # cost
        self.cost = 0.5 * tf.reduce_sum(
            tf.pow(tf.subtract(self.reconstruction, self.x), 2.0)) + 
            self.sparse_reg * self.kl_divergence(
                self.sparsity_level, self.hidden_layer)

        self.optimizer = optimizer.minimize(self.cost)

        init = tf.global_variables_initializer()
        self.session = tf.Session()
        self.session.run(init)

    def _initialize_weights(self):
        all_weights = dict()
        all_weights['w1'] = tf.Variable(xavier_init(self.num_input, 
           self.num_hidden))
        all_weights['b1'] = tf.Variable(tf.zeros([self.num_hidden], 
           dtype = tf.float32))
        all_weights['w2'] = tf.Variable(tf.zeros([self.num_hidden, 
                            self.num_input], 
                            dtype = tf.float32))
        all_weights['b2'] = tf.Variable(tf.zeros([self.num_input], 
            dtype = tf.float32))
        return all_weights

    def partial_fit(self, X):
        cost, opt = self.session.run((self.cost, self.optimizer), 
                    feed_dict = {self.x: X,
                                 self.scale: self.training_scale})
        return cost

     def kl_divergence(self, p, p_hat):
         return tf.reduce_mean(p*(tf.log(p)/tf.log(p_hat)) + 
             (1-p)*(tf.log(1-p)/tf.log(1-p_hat)))

     def calculate_total_cost(self, X):
         return self.session.run(self.cost, feed_dict = {
             self.x: X,
             self.scale: self.training_scale
         })

     def transform(self, X):
         return self.session.run(self.hidden_layer, 
             feed_dict = {self.x: X, self.scale: self.training_scale})

     def generate(self, hidden = None):
         if hidden is None:
             hidden = np.random.normal(size = self.weights["b1"])
             return self.session.run(self.reconstruction, 
                 feed_dict = {self.hidden_layer: hidden})

     def reconstruct(self, X):
         return self.session.run(self.reconstruction, 
             feed_dict = {self.x: X, self.scale: self.training_scale})

     def get_weights(self):
         return self.session.run(self.weights['w1'])

     def get_biases(self):
         return self.session.run(self.weights['b1'])

```

在下一节中，我们将研究应用于特定数据集的稀疏自编码器。



# MNIST 数据的稀疏自编码器

让我们在其他示例中使用的相同数据集上运行此编码器，并比较结果:

```py
class SparseAutoEncoderExample:
    def main(self):
        mnist = input_data.read_data_sets('MNIST_data', one_hot = True)

        def get_random_block_from_data(data, batch_size):
            start_index = np.random.randint(0, len(data) - batch_size)
            return data[start_index:(start_index + batch_size)]

        X_train = mnist.train.images
        X_test = mnist.test.images

        n_samples = int(mnist.train.num_examples)
        training_epochs = 5
        batch_size = 128
        display_step = 1

        autoencoder =SparseAutoencoder(num_input=784,
                                       num_hidden = 200,
                                       transfer_function = tf.nn.sigmoid,
                                       optimizer = tf.train.AdamOptimizer(
                                           learning_rate = 0.001),
                                       scale = 0.01)

        for epoch in range(training_epochs):
            avg_cost = 0.
            total_batch = int(n_samples / batch_size)
            # Loop over all batches
            for i in range(total_batch):
                batch_xs = get_random_block_from_data(X_train, batch_size)

                # Fit training using batch data
                cost = autoencoder.partial_fit(batch_xs)
                # Compute average loss
                avg_cost += cost / n_samples * batch_size

            # Display logs per epoch step
            if epoch % display_step == 0:
                print("Epoch:", '%04d' % (epoch + 1), "cost=", avg_cost)

        print("Total cost: " + 
            str(autoencoder.calculate_total_cost(X_test)))

        # input weights
        wts = autoencoder.get_weights()
        dim = math.ceil(math.sqrt(autoencoder.num_hidden))
        plt.figure(1, figsize=(dim, dim))
        for i in range(0, autoencoder.num_hidden):
            im = wts.flatten()[i::autoencoder.num_hidden].reshape((28, 28))
            ax = plt.subplot(dim, dim, i + 1)
            for label in (ax.get_xticklabels() + ax.get_yticklabels()):
                label.set_fontsize(6)
            plt.subplot(dim, dim, i+1)
            plt.imshow(im, cmap="gray", clim=(-1.0, 1.0))
        plt.suptitle('Sparse AutoEncoder Weights', fontsize=15, y=0.95)
        plt.savefig('figures/sparse_autoencoder_weights.png')
        plt.show()

        predicted_imgs = autoencoder.reconstruct(X_test[:100])

        # plot the reconstructed images
        plt.figure(1, figsize=(10, 10))
        plt.title('Sparse Autoencoded Images')
        for i in range(0,100):
            im = predicted_imgs[i].reshape((28,28))
            ax = plt.subplot(10, 10, i + 1)
            for label in (ax.get_xticklabels() + ax.get_yticklabels()):
                label.set_fontsize(6)

            plt.subplot(10, 10, i+1)
            plt.imshow(im, cmap="gray", clim=(0.0, 1.0))
        plt.suptitle('Sparse AutoEncoder Images', fontsize=15, y=0.95)
        plt.savefig('figures/sparse_autoencoder_images.png')
        plt.show()

def main():
    auto = SparseAutoEncoderExample()
    auto.main()

if __name__ == '__main__':
    main()
```

上述代码的输出如下:

```py
('Epoch:', '0001', 'cost=', 1697.039439488638)
('Epoch:', '0002', 'cost=', 667.23002088068188)
('Epoch:', '0003', 'cost=', 450.02947024147767)
('Epoch:', '0004', 'cost=', 351.54360497159115)
('Epoch:', '0005', 'cost=', 293.73473448153396)
Total cost: 21025.2
```

可以看出，成本比其他编码器低，因此 KL 散度和稀疏度肯定有帮助。



# 稀疏编码器与加性高斯噪声编码器的比较

下图显示了加性高斯噪声自编码器和稀疏自编码器的成本比较:

![](Images/7bafe3e7-94b6-4a06-96e7-8422a114d7ab.png)

MNIST 数据集上五个历元的两种自编码器的成本比较



# 摘要

在本章中，您学习了三种不同类型的自编码器:基本、加性高斯噪声和稀疏。我们了解它们有用的用例。我们在 MNIST 数据集上运行了它们，并比较了三种自编码器的成本。我们还画出了重量和大概的产量。
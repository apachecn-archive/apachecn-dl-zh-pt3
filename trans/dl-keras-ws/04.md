

# 四、使用 Keras 包装器通过交叉验证评估您的模型

概观

本章向您介绍用 scikit-learn 构建 Keras 包装器。您将学习应用交叉验证来评估深度学习模型，并创建用户定义的函数来实现深度学习模型和交叉验证。到本章结束时，你将能够构建稳健的模型，这些模型在新的、看不见的数据上的表现与在训练数据上的表现一样好。

# 简介

在前一章中，我们试验了不同的神经网络结构。我们能够通过观察训练过程中的损失和准确性来评估不同模型的性能。这有助于我们确定模型何时欠拟合或过拟合训练数据，以及如何使用早期停止等技术来防止过拟合。

在本章中，你将学习交叉验证。与我们在前面章节中讨论的模型评估方法相比，这是一种重采样技术，可以对模型的性能进行非常准确和稳健的估计。

本章首先深入讨论了为什么我们需要在模型评估中使用交叉验证，交叉验证的基础知识，它的变化，以及它们之间的比较。接下来，我们将在 Keras 深度学习模型上实现交叉验证。我们还将在 scikit-learn 中使用 Keras 包装器，以允许将 Keras 模型视为 scikit-learn 工作流中的估计器。然后，您将了解如何在 scikit-learn 中实现交叉验证，最后将所有这些整合在一起，并使用 scikit-learn 在 Keras 深度学习模型上执行交叉验证。

最后，您将了解如何使用交叉验证来执行不仅仅是模型评估，以及如何使用模型性能的交叉验证评估来比较不同的模型，并选择在特定数据集上产生最佳性能的模型。您还将使用交叉验证，通过为给定模型找到最佳的超参数集来提高该模型的性能。我们将在三个活动中实现我们将在本章中学习的概念，每个活动都涉及一个真实的数据集。

# 交叉验证

`Resampling techniques`是统计数据分析中的一组重要技术。它们涉及到从数据集中反复抽取样本来创建训练集和测试集。在每次重复时，他们使用从该重复的训练集和测试集的数据集中提取的样本来拟合和评估模型。

使用这些技术可以为我们提供关于模型的信息，否则通过使用一个训练集和一个测试集仅拟合和评估模型一次是无法获得这些信息的。由于重采样方法需要多次将模型拟合到训练数据，因此计算量很大。因此，当涉及到深度学习时，我们只在数据集和网络相对较小的情况下实现它们，并且可用的计算能力允许我们这样做。

在本节中，您将了解一种非常重要的叫做`cross-validation`的重采样方法。交叉验证是最重要和最常用的重采样方法之一。当给定有限的数据集时，它根据新的、看不见的示例计算模型性能的最佳估计。我们还将探索交叉验证的基础，它的两种变体，以及它们之间的比较。

## 仅分割一次数据集的缺点

在前一章中，我们提到在用于训练模型的相同数据集上评估模型是一个方法错误。由于该模型已被训练以减少该特定示例集上的错误，因此它在其上的性能是高度有偏差的。这就是为什么训练数据的错误率总是低估新样本的错误率。我们了解到，解决这个问题的一种方法是随机拿出一部分数据作为评估的测试集，并在其余数据上拟合模型，这称为训练集。下图展示了这种方法:

![Figure 4.1: Overview of training set/test set split
](image/B15777_04_01.jpg)

图 4.1:训练集/测试集分割概述

正如我们前面提到的，将数据分配给训练集或测试集是完全随机的。这意味着，如果我们重复这个过程，每次都会将不同的数据分配给测试集和训练集。这种方法报告的测试错误率可能会有很大差异，这取决于哪些示例在测试集中，哪些示例在训练集中。

**例子**

让我们看一个例子。在这里，我们为您在*活动 3.02* 、*用神经网络进行高级纤维化诊断*、*第三章*、*深度学习用 Keras* 中看到的丙肝数据集构建了单层神经网络。我们使用训练集/测试集方法来计算与该模型相关的测试误差。如果我们将数据分割成五个独立的数据集并重复这个过程五次，而不是只分割和训练一次，我们可能会得到五个不同的测试错误率图。

这五个实验中每个实验的测试误差率可以在下图中看到:

![Figure 4.2: Plot of test error rates with five different training set/test set splits on an example dataset
](image/B15777_04_02.jpg)

图 4.2:一个示例数据集上五个不同训练集/测试集分割的测试错误率图

如你所见，每次实验的测试错误率都有很大不同。模型评估结果中的这种变化表明，将数据集只分成一个训练集和一个测试集的简单策略可能不会导致对模型性能的可靠和准确的估计。

总的来说，我们在上一章中学习的训练集/测试集方法有一个明显的优点，即简单、易于实现、计算开销小。然而，它也有以下缺点:

*   第一个缺点是，它对模型错误率的估计强烈依赖于哪些数据被分配给测试集，哪些数据被分配给训练集。
*   第二个缺点是，在这种方法中，我们只在数据的子集上训练模型。当机器学习模型使用少量数据进行训练时，它们的表现往往会更差。

由于模型的性能可以通过在整个数据集上训练来提高，我们一直在寻找将所有可用数据点包括在训练中的方法。此外，我们有兴趣通过在评估中包括所有可用的数据点来找到模型性能的稳健估计。这些目标可以通过交叉验证技术来实现。以下是交叉验证的两种方法:

*   k 倍交叉验证
*   留一交叉验证

## K 倍交叉验证

在`k-fold cross-validation`中，我们不是将数据集分成两个子集，而是将数据集分成`k`大小近似相等的子集或折叠。在该方法的第一次迭代中，第一个折叠被认为是测试集。在剩余的`k-1`折叠上训练该模型，然后在第一个折叠上对其进行评估(第一个折叠用于估计测试错误率)。

这个过程重复`k`次，在每次迭代中使用不同的折叠作为测试集，而剩余的折叠作为训练集。最终，该方法导致`k`不同的测试错误率。通过平均这些`k`测试误差率，计算出模型误差率的最终 k 倍交叉验证估计值。

下图说明了`k-fold cross-validation`方法中的数据集分割过程:

![Figure 4.3: Overview of dataset splitting in the k-fold cross-validation method
](image/B15777_04_03.jpg)

图 4.3:k 倍交叉验证方法中的数据集分割概述

在实践中，我们通常使用`k=5`或`k=10`来执行`k-fold cross-validation`，如果您很难为数据集选择一个值，这些是推荐值。决定使用的折叠数取决于数据集中的样本数和可用的计算能力。如果`k=5`，模型将被训练和评估 5 次，而如果`k=10`，这个过程将被重复 10 次。折叠次数越多，执行 k-fold 交叉验证所需的时间就越长。

在 k-fold 交叉验证中，每个 fold 的样本分配是完全随机的。但是，通过查看前面的图表，您将会看到，最终，每一条数据都用于培训和评估。这就是为什么如果在同一个数据集和同一个模型上多次重复 k-fold 交叉验证，最终报告的测试错误率会几乎相同。因此，与训练集/测试集方法相比，k 重交叉验证的结果不会有很大的差异。现在，我们来看看交叉验证的第二种形式:留一验证。

## 留一交叉验证

`Leave-One-Out` `(LOO)`是交叉验证技术的一种变体，其中，不是将数据集划分为训练集和测试集的两个大小相当的子集，而是仅使用一个单独的数据进行评估。如果在整个数据集中有`n`数据示例，在`LOO cross-validation`的每次迭代中，模型根据`n-1`示例进行训练，剩下的单个示例用于计算测试错误率。

仅使用一个示例来估计测试误差率会导致对模型性能的无偏但高方差的估计；它是无偏的，因为这一个示例没有用于训练模型，它具有很高的方差，因为它仅基于一个数据示例进行计算，并且它将根据所使用的确切数据示例而变化。这个过程重复`n`次，并且在每次迭代中，使用不同的数据示例进行评估。最终，该方法将导致`n`个不同的测试误差率，并且通过平均这些`n`误差率来计算最终的`LOO cross-validation`测试误差估计。

下图显示了`LOO cross-validation`方法中的数据集分割过程:

![Figure 4.4: Overview of dataset splitting in the LOO cross-validation method
](image/B15777_04_04.jpg)

图 4.4:LOO 交叉验证方法中数据集分割概述

在`LOO cross-validation`的每一次迭代中，数据集中几乎所有的例子都被用来训练模型。另一方面，在训练集/测试集方法中，相对较大的数据子集用于评估，而不用于训练。因此，`LOO`对模型性能的估计更接近于在整个数据集上训练的模型的性能，这是`LOO cross-validation`相对于`training set` / `test set`方法的主要优势。

此外，由于在`LOO cross-validation`的每次迭代中，只有一个独特的数据示例用于评估，并且每个单独的数据示例也用于训练，因此这种方法没有随机性。因此，如果你在同一个数据集和同一个模型上多次重复`LOO cross-validation`，最终报告的测试错误率每次都会完全相同。

`LOO cross-validation`的缺点是计算量大。这样做的原因是模型需要训练`n`次，在`n`很大和/或网络很大的情况下，需要很长时间才能完成。`LOO`和`k-fold cross-validation`各有优缺点，我们将在下一节进行比较。

## 比较 K 倍法和 LOO 法

通过比较前面两个图，很明显`LOO cross-validation`实际上是`k-fold cross-validation`的一个特例，其中`k=n`。然而，如前所述，与选择`k=5`或`k=10`相比，选择`k=n`在计算上非常昂贵。

因此，`k-fold cross-validation`相对于`LOO cross-validation`的第一个优势是计算开销较小。下表针对`bias`和`variance`对`k-fold with low-k`、`k-fold with high-k`和`LOO`以及`no cross-validation`进行了比较。该表显示，最大偏差来自简单的`train-test split approach`，最大方差来自留一次交叉验证。中间是`k-fold cross-validation`。这就是为什么 k 重交叉验证通常是大多数机器学习任务的最合适的选择:

![Figure 4.5: Comparing the train-test split, k-fold cross-validation, and LOO 
cross-validation methods](image/B15777_04_05.jpg)

图 4.5:比较训练测试分割、k 倍交叉验证和 LOO 交叉验证方法

下面的图根据`bias`和`variance`比较了`training set` / `test set`方法、`k-fold cross-validation`和`LOO cross-validation`:

![Figure 4.6: Comparing the training set/test set approach, k-fold cross-validation, and LOO 
cross-validation in terms of bias and variance](image/B15777_04_06.jpg)

图 4.6:根据偏差和方差比较训练集/测试集方法、k 倍交叉验证和 LOO 交叉验证

通常，在机器学习和数据分析中，最理想的模型是带有`lowest bias`和`lowest variance`的模型。如上图所示，图中间标记的区域是感兴趣的，这里`bias`和`variance`都为低。原来这个区域相当于`5`和`10`之间有`k`的`k-fold cross-validation`。在下一节中，我们将探讨如何在实践中实现各种交叉验证方法。

# 深度学习模型的交叉验证

在本节中，您将了解如何将 Keras 包装器与 scikit-learn 一起使用，这是一个有用的工具，它允许我们将 Keras 模型用作 scikit-learn 工作流的一部分。因此，scikit-learn 的方法和函数，比如用于执行交叉验证的方法和函数，可以很容易地应用于 Keras 模型。

您将一步一步地学习如何使用 scikit-learn 实现您在上一节中学到的交叉验证。此外，您将了解如何使用交叉验证来评估 Keras 深度学习模型，使用带有 scikit-learn 的 Keras 包装器。最后，您将通过解决一个涉及真实数据集的问题来实践您所学到的内容。

## 带 scikit 的 Keras 包装器-学习

当涉及到一般的机器学习和数据分析时，scikit-learn 库比 Keras 丰富得多，也更容易使用。这就是为什么能够在 Keras 模型上使用 scikit-learn 方法将具有巨大的价值。

幸运的是，Keras 附带了一个有用的包装器，`keras.wrappers.scikit_learn`，它允许我们为深度学习模型构建 scikit-learn 接口，这些模型可以用作 scikit-learn 中的分类或回归估计器。有两种包装器:一种用于分类估计量，一种用于回归估计量。以下代码用于定义这些 scikit-learn 接口:

```
keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params) 
# wrappers for classification estimators
keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params) 
# wrappers for regression estimators
```

`build_fn`参数需要是一个可调用的函数，其中 Keras 顺序模型在其主体中定义、编译并返回。

`sk_params`参数可以接受用于构建模型的参数(例如层的激活函数)和用于拟合模型的参数(例如时期数和批量大小)。这将在下面的练习中付诸实践，我们将使用 Keras 包装器解决一个回归问题。

注意

本章中的所有活动都将记录在 Jupyter 笔记本中。请下载这本书的 GitHub 资源库，以及所有准备好的模板，可以在这里找到:

[https://packt.live/3btnjfA](https://packt.live/3btnjfA)。

## 练习 4.01:用 scikit 构建 Keras 包装器——学习回归问题

在本练习中，您将学习为 Keras 深度学习模型构建包装器的逐步过程，以便它可以在 scikit-learn 工作流中使用。首先，加载回归问题的`908`数据点的数据集，其中每条记录描述了一种化学品的六个属性，目标是对鱼的急性毒性，或`LC50`:

```
# import data
import pandas as pd
colnames = ['CIC0', 'SM1_Dz(Z)', 'GATS1i', 'NdsCH', 'NdssC','MLOGP', 'LC50']
data = pd.read_csv('../data/qsar_fish_toxicity.csv', sep=';', names=colnames)
X = data.drop('LC50', axis=1)
y = data['LC50']
# Print the sizes of the dataset
print("Number of Examples in the Dataset = ", X.shape[0])
print("Number of Features for each example = ", X.shape[1])
# print output range
print("Output Range = [%f, %f]" %(min(y), max(y)))
```

这是预期的输出:

```
Number of Examples in the Dataset =  908
Number of Features for each example =  6
Output Range = [0.053000, 9.612000]
```

由于该数据集中的输出采用数值，因此这是一个回归问题。目标是建立一个模型，在给定化学品的其他属性的情况下，预测对鱼的急性毒性。现在，让我们来完成这些步骤:

1.  定义一个函数，为这个回归问题构建并返回一个 Keras 模型。您定义的 Keras 模型必须有一个大小为`8`的带有`ReLU activation`功能的隐藏层。同样，使用`Mean Squared Error` ( `MSE`)损失函数和`Adam optimizer`编译模型:

    ```
    from keras.models import Sequential
    from keras.layers import Dense, Activation
    # Create the function that returns the keras model
    def build_model():
        # build the Keras model
        model = Sequential()
        model.add(Dense(8, input_dim=X.shape[1], activation='relu'))
        model.add(Dense(1))
        # Compile the model
        model.compile(loss='mean_squared_error', optimizer='adam')
        # return the model
        return model  
    ```

2.  Now, use the Keras wrapper with scikit-learn to create the scikit-learn interface for your model. Remember that you need to provide the `epochs`, `batch_size`, and `verbose` arguments here:

    ```
    # build the scikit-Learn interface for the keras model
    from keras.wrappers.scikit_learn import KerasRegressor
    YourModel = KerasRegressor(build_fn= build_model, epochs=100, batch_size=20, verbose=1) 
    ```

    现在，`YourModel`已经可以在 scikit-learn 中用作回归估计量了。

在本练习中，我们学习了如何使用 scikit-learn 通过模拟数据集为回归问题构建 Keras 包装器。在本章的其余练习中，我们将继续使用该数据集实现交叉验证。

## 使用 scikit-learn 进行交叉验证

在前一章中，您了解到可以在 scikit-learn 中轻松执行`training set` / `test set`拆分。让我们假设您的原始数据集存储在`X`和`y`数组中。您可以使用以下命令将它们随机分为训练集和测试集:

```
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
```

根据您希望测试集有多大，`test_size`参数可以被分配到`0`和`1`之间的任何数字。通过为`random_state`参数提供一个`int`数，您将能够为随机数生成器选择种子。

在 scikit-learn 中执行交叉验证的最简单方法是使用`cross_val_score`函数。为了做到这一点，您需要首先定义您的估计量(在我们的例子中，估计量将是一个 Keras 模型)。然后，您将能够使用以下命令对您的估计器/模型执行交叉验证:

```
from sklearn.model_selection import cross_val_score
scores = cross_val_score(YourModel, X, y, cv=5)
```

请注意，我们将 Keras 模型和原始数据集作为参数提供给了`cross_val_score`函数，以及折叠的数量(`cv`参数)。在这里，我们使用了`cv=5`，因此`cross_val_score`函数会将数据集随机分成五份，并使用五个不同的训练和测试集对模型执行五次训练和拟合。它将在每次迭代/折叠时计算模型评估的默认指标(或定义 Keras 模型时给出的指标),并将它们存储在分数中。我们可以打印最终的交叉验证分数，如下所示:

```
print(scores.mean())
```

前面，我们提到过由`cross_val_score`函数返回的分数是我们模型的默认度量，或者是我们在定义模型时为它确定的度量。然而，当调用`cross_val_score`函数时，可以通过提供期望的指标作为`scoring`参数来改变交叉验证指标。

注意

您可以在这里的`cross_val_score`函数的`scoring`参数中了解更多关于如何提供期望指标的信息:【https://packt.live/2wendbL[。](https://packt.live/2wendbL)

通过为`cross_val_score`函数的`cv`参数提供一个整数，我们告诉该函数对数据集执行 k 重交叉验证。然而，scikit-learn 中还有其他几个迭代器可用，我们可以将它们分配给`cv`来对数据集执行其他形式的交叉验证。例如，下面的代码块将对数据集执行`LOO cross-validation`:

```
from sklearn.model_selection import LeaveOneOut
loo = LeaveOneOut()
scores = cross_val_score(YourModel, X, y, cv=loo)
```

在下一节中，我们将探索 scikit-learn 中的 k-fold 交叉验证，并了解它如何用于 Keras 模型。

## scikit-learn 中的交叉验证迭代器

这里提供了 scikit-learn 中最常用的交叉验证迭代器列表，以及对每个迭代器的简要描述:

*   `KFold(n_splits=?)`

    这将数据集分成 k 个折叠或组。需要`n_splits`参数来确定使用多少个折叠。如果是`n_splits=n`，就相当于`LOO cross-validation`。

*   `RepeatedKFold(n_splits=?, n_repeats=?, random_state=random_state)`

    这将重复 k 倍交叉验证`n_repeats`次。

*   `LeaveOneOut()`

    这将分割`LOO cross-validation`的数据集。

*   `ShuffleSplit(n_splits=?, test_size=?, random_state= random_state)`

    这将生成`n_splits`个随机且独立的训练集/测试集数据集分裂。可以使用`random_state`参数存储随机数生成器的种子；如果这样做，数据集分割将是可重复的。

除了常规迭代器，比如这里提到的迭代器，还有`stratified`版本。当数据集不同类别中的样本数量不平衡时，分层抽样非常有用。例如，假设我们想要设计一个分类器来预测某人是否会拖欠信用卡债务，其中数据集中几乎`95%`个例子都在`negative`类中。分层抽样确保在每个`training set` / `test set`分割中保留相对类别频率。对于这种情况，建议使用迭代器的分层版本。

通常，在使用训练集来训练和评估模型之前，我们对其进行预处理，以缩放示例，使它们的均值等于`0`，标准差等于`1`。在`training set` / `test set`方法中，我们需要扩展训练集并存储转换。下面的代码块将为我们完成这项工作:

```
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

下面是一个在我们的`X`、`y`数据集上用`k=5`执行`stratified k-fold cross-validation`的例子:

```
from sklearn.model_selection import StratifiedKFold
skf = StratifiedKFold(n_splits=5)
scores = cross_val_score(YourModel, X, y, cv=skf)
```

注意

您可以在 scikit 中了解更多关于交叉验证迭代器的信息——点击此处了解:

[https://packt.live/31Mc0L2](https://packt.live/31Mc0L2)。

现在我们已经了解了交叉验证迭代器，我们可以在一个练习中将它们付诸实践。

## 练习 4.02:使用交叉验证评估深度神经网络

在本练习中，我们将把我们在交叉验证主题中学到的所有概念和方法结合在一起。我们将再次浏览所有步骤，从定义 Keras 深度学习模型到将其转移到 scikit-learn 工作流并执行交叉验证以评估其性能。从某种意义上来说，这个练习是对我们迄今为止所学内容的一个回顾，这里所涵盖的内容将对*活动 4.01* 、*使用交叉验证进行高级纤维化诊断分类器的模型评估*非常有帮助:

1.  第一步总是加载要为其构建模型的数据集。首先，载入回归问题的`908`数据点数据集，其中每条记录描述了一种化学品的六个属性，目标是对黑头鱼的急性毒性，或`LC50` :

    ```
    # import data
    import pandas as pd
    colnames = ['CIC0', 'SM1_Dz(Z)', 'GATS1i', 'NdsCH', 'NdssC','MLOGP', 'LC50']
    data = pd.read_csv('../data/qsar_fish_toxicity.csv', sep=';', names=colnames)
    X = data.drop('LC50', axis=1)
    y = data['LC50']
    # Print the sizes of the dataset
    print("Number of Examples in the Dataset = ", X.shape[0])
    print("Number of Features for each example = ", X.shape[1])
    # print output range
    print("Output Range = [%f, %f]" %(min(y), max(y)))
    ```

2.  使用`Mean Squared Error` ( `MSE`)损失函数和`Adam optimizer` :

    ```
    from keras.models import Sequential
    from keras.layers import Dense, Activation
    # Create the function that returns the keras model
    def build_model():
        # build the Keras model
        model = Sequential()
        model.add(Dense(8, input_dim=X.shape[1], activation='relu'))
        model.add(Dense(1))
        # Compile the model
        model.compile(loss='mean_squared_error', optimizer='adam')
        # return the model
        return model
    ```

    函数定义返回 Keras 模型的函数，该模型具有大小为`8`的单个隐藏层
3.  设置`seed`并使用包装器为我们在`step 2` :

    ```
    # build the scikit-Learn interface for the keras model
    from keras.wrappers.scikit_learn import KerasRegressor
    import numpy as np
    from tensorflow import random
    seed = 1
    np.random.seed(seed)
    random.set_seed(seed)
    YourModel = KerasRegressor(build_fn= build_model, epochs=100, batch_size=20, verbose=1 , shuffle=False)
    ```

    的函数中定义的 Keras 模型构建 scikit-learn 接口
4.  定义用于交叉验证的迭代器。让我们执行`5-fold cross-validation` :

    ```
    # define the iterator to perform 5-fold cross-validation
    from sklearn.model_selection import KFold
    kf = KFold(n_splits=5)
    ```

5.  调用`cross_val_score`函数进行交叉验证。完成这一步需要一段时间，这取决于可用的计算能力:

    ```
    # perform cross-validation on X, y
    from sklearn.model_selection import cross_val_score
    results = cross_val_score(YourModel, X, y, cv=kf) 
    ```

6.  Once cross-validation has been completed, print the `final cross-validation` estimation of model performance (the default metric for performance will be the test loss):

    ```
    # print the result
    print(f"Final Cross-Validation Loss = {abs(results.mean()):.4f}") 
    ```

    下面是一个输出示例:

    ```
    Final Cross-Validation Loss = 0.9680
    ```

交叉验证损失表明，在该数据集上训练的 Keras 模型能够预测平均损失为`0.9680`的化学品的`LC50`。在下一个练习中，我们将尝试进一步研究这个模型。

这些都是在 scikit-learn 中使用交叉验证评估 Keras 深度学习模型所需的步骤。现在，我们将在一次活动中把它们付诸实践。

## 活动 4.01:使用交叉验证对高级纤维化诊断分类器进行模型评估

我们在*活动 3.02、*T9、*第三章*的用神经网络进行高级纤维化诊断、*用 Keras 进行深度学习*中学习了丙肝数据集。该数据集由接受丙肝治疗剂量的`1385`名患者的信息组成。对于每个患者，`28`个不同的属性可用，如年龄、性别和身体质量指数，以及一个只能取两个值的类别标签:`1`，表示晚期纤维化，以及`0`，表示无晚期纤维化迹象。这是一个输入维度等于`28`的`binary` / `two-class`分类问题。

在*第三章*、*用 Keras 进行深度学习*中，我们构建了 Keras 模型对这个数据集进行分类。我们使用`training set` / `test set`分裂来训练和评估模型，并报告测试错误率。在这个活动中，我们将使用我们在这个主题中学到的知识，使用`k-fold cross-validation`来训练和评估一个深度学习模型。我们将使用在之前的活动中产生最佳测试错误率的模型。目标是将交叉验证错误率与训练集/测试集方法错误率进行比较:

1.  导入必要的库。使用`X = pd.read_csv('../data/HCV_feats.csv'), y = pd.read_csv('../data/HCV_target.csv')`从 GitHub 的`Chapter04`文件夹的`data`子文件夹中加载数据集。打印数据集中示例的数量、可用要素的数量以及类标签的可能值。
2.  Define the function that returns the Keras model. The Keras model will be a deep neural network with two hidden layers, where the `first hidden layer` is of `size 4` and the `second hidden layer` is of `size 2`, and use the `tanh activation` function to perform the classification. Use the following values for the hyperparameters:

    `optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']`

3.  用`epochs=100`、`batch_size=20`和`shuffle=False`为 Keras 模型构建 scikit-learn 接口。用`k=5`将交叉验证迭代器定义为`StratifiedKFold`。对模型进行 k 重交叉验证，并存储分数。
4.  打印每次迭代/折叠的准确度，加上总体交叉验证准确度及其相关的标准偏差。
5.  将此结果与*活动 3.02* 、*第三章*、*深度学习*的*神经网络晚期纤维化诊断的结果进行比较。*

实现上述步骤后，预期输出将如下所示:

```
Test accuracy at fold 1 = 0.5198556184768677
Test accuracy at fold 2 = 0.4693140685558319
Test accuracy at fold 3 = 0.512635350227356
Test accuracy at fold 4 = 0.5740072131156921
Test accuracy at fold 5 = 0.5523465871810913
Final Cross-Validation Test Accuracy: 0.5256317675113678
Standard Deviation of Final Test Accuracy: 0.03584760640500936
```

注意

这项活动的解决方案可在第 341 页找到。

我们在*活动 3.02* 、*第 3 章*、*使用 Keras* 进行深度学习的*高级纤维化诊断*中执行的训练集/测试集方法获得的准确度为`49.819%`，低于我们在相同深度学习模型和相同数据集上执行`5-fold cross-validation`时获得的测试准确度，但低于其中一个折叠的准确度。

这种差异的原因是，由训练集/测试集方法产生的测试错误率是通过在模型评估中仅包括数据点的子集来计算的。另一方面，此处的测试错误率是通过在评估中包括所有数据点来计算的，因此对模型性能的这种估计更准确、更稳健，在看不见的测试数据集上表现得更好。

在本活动中，我们使用交叉验证对涉及真实数据集的问题执行模型评估。改进模型评估并不是使用交叉验证的唯一目的，它还可以用于为给定问题选择最佳模型或参数。

# 交叉验证模式选择

交叉验证为我们提供了对未知示例的模型性能的稳健估计。由于这个原因，它可以用于在特定问题的两个模型之间作出决定，或者决定哪个模型参数(或超参数)用于特定问题。在这些情况下，我们希望找出哪个模型或哪组模型参数/超参数导致最低的测试错误率。因此，我们将为我们的问题选择该模型或该组参数/超参数。

在本节中，您将为此练习使用交叉验证。您将学习如何为您的深度学习模型定义一组超参数，然后编写用户定义的函数，以便为每个可能的超参数组合对您的模型执行交叉验证。然后，您将观察哪个超参数组合导致最低的测试错误率，并且该组合将是您对最终模型的选择。

## 模型评估与模型选择的交叉验证

在这一节中，我们将更深入地探讨对模型评估和模型选择使用交叉验证的意义。到目前为止，我们已经了解到，在训练集上评估模型会导致低估模型在未知示例上的错误率。将数据集分割成一个`training set`和一个`test set`给了我们一个更准确的模型性能评估，但是会受到高方差的影响。

最后，交叉验证导致对模型在看不见的例子上的性能的更加健壮和准确的估计。这三种模型评估方法得出的误差率估计值如下图所示。

下图显示了训练集/测试集方法中的错误率估计略低于交叉验证估计的情况。然而，重要的是要记住`training set` / `test set`错误率也可能高于交叉验证估计错误率，这取决于测试集中包含什么数据(因此出现了高方差问题)。另一方面，对训练集执行评估所产生的错误率总是低于其他两种方法:

![Figure 4.7: Illustration of the error rate estimations resulting from the three approaches to model evaluation
](image/B15777_04_07.jpg)

图 4.7:由三种模型评估方法得出的误差率估计图

我们已经确定，交叉验证导致对独立数据示例的模型性能的最佳估计。了解了这一点，我们就可以使用交叉验证来决定针对某个特定问题使用哪个模型。例如，如果我们有四个不同的模型，并且我们想要决定哪一个更适合特定的数据集，我们可以使用交叉验证来训练和评估四个模型中的每一个，并选择交叉验证错误率最低的模型作为数据集的最终模型。下图显示了与四个假设模型相关的交叉验证错误率。由此我们可以得出结论，**模型 1** 是最适合该问题的，而**模型 4** 是最差的选择。这四个模型可以是深度神经网络，其具有不同数量的隐藏层和隐藏层中不同数量的单元:

![Figure 4.8: Illustration of cross-validation error rates associated with four hypothetical models
](image/B15777_04_08.jpg)

图 4.8:与四个假设模型相关的交叉验证错误率图解

在我们找到最适合特定问题的模型后，下一步是为该模型选择最佳的参数或超参数集。之前我们讨论过，在构建深度神经网络时，需要为模型选择几个超参数，这些超参数中的每一个都有几个选择。

这些超参数包括激活函数、损失函数和优化器的类型，以及历元数和批量大小。我们可以为这些超参数中的每一个定义一组可能的选择，然后实现该模型，并进行交叉验证，以找到超参数的最佳组合。

下图显示了与假设的深度学习模型的四个不同超参数集相关联的交叉验证错误率。由此，我们可以得出结论，`Set 1`是该模型的最佳选择，因为对应于`Hyperparameters Set 1`的行具有最低的交叉验证错误率值:

![Figure 4.9: Illustration of cross-validation error rates associated with four different sets of hyperparameters for a hypothetical deep learning model
](image/B15777_04_09.jpg)

图 4.9:与一个假设的深度学习模型的四组不同的超参数相关的交叉验证错误率的图示

在下一个练习中，我们将学习如何迭代不同的模型架构和超参数，以找到产生最佳模型的集合。

## 练习 4.03:编写用户定义的函数来实现带有交叉验证的深度学习模型

在本练习中，您将学习如何使用交叉验证进行模型选择。

首先，加载一个回归问题的`908`数据点数据集，其中每条记录描述了一种化学品的六个属性，目标是对鱼的急性毒性，即`LC50`。目标是建立一个模型来预测每种化学物质的`LC50`，给出化学物质的属性:

```
# import data
import pandas as pd
import numpy as np
from tensorflow import random
colnames = ['CIC0', 'SM1_Dz(Z)', 'GATS1i', 'NdsCH', 'NdssC','MLOGP', 'LC50']
data = pd.read_csv('../data/qsar_fish_toxicity.csv', sep=';', names=colnames)
X = data.drop('LC50', axis=1)
y = data['LC50']
```

按照以下步骤完成本练习:

1.  定义三个函数来返回三个 Keras 模型。第一个模型应该有一个隐藏层`size 4`，第二个模型应该有一个隐藏层`size 8`，第三个模型应该有两个隐藏层，第一层`size 4`，第二层`size 2`。对所有隐藏的图层使用`ReLU activation`功能。目标是找出这三个模型中哪一个导致最低的交叉验证错误率:

    ```
    # Define the Keras models
    from keras.models import Sequential
    from keras.layers import Dense
    def build_model_1():
        # build the Keras model_1
        model = Sequential()
        model.add(Dense(4, input_dim=X.shape[1], activation='relu'))
        model.add(Dense(1))
        # Compile the model
        model.compile(loss='mean_squared_error', optimizer='adam')
        # return the model
        return model
    def build_model_2():
        # build the Keras model_2
        model = Sequential()
        model.add(Dense(8, input_dim=X.shape[1], activation='relu'))
        model.add(Dense(1))
        # Compile the model
        model.compile(loss='mean_squared_error', optimizer='adam')
        # return the model
        return model
    def build_model_3():
        # build the Keras model_3
        model = Sequential()
        model.add(Dense(4, input_dim=X.shape[1], activation='relu'))
        model.add(Dense(2, activation='relu'))
        model.add(Dense(1))
        # Compile the model
        model.compile(loss='mean_squared_error', optimizer='adam')
        # return the model
        return model
    ```

2.  编写一个循环来构建 Keras 包装器，并在`three`模型上执行`3-fold cross-validation`。存储每个型号的分数:

    ```
    # define a seed for random number generator so the result will be reproducible
    seed = 1
    np.random.seed(seed)
    random.set_seed(seed)
    # perform cross-validation on each model
    from keras.wrappers.scikit_learn import KerasRegressor
    from sklearn.model_selection import KFold
    from sklearn.model_selection import cross_val_score
    results_1 = []
    models = [build_model_1, build_model_2, build_model_3]
    # loop over three models
    for m in range(len(models)):
        model = KerasRegressor(build_fn=models[m], epochs=100, batch_size=20, verbose=0, shuffle=False)
        kf = KFold(n_splits=3)
        result = cross_val_score(model, X, y, cv=kf)
        results_1.append(result)
    ```

3.  Print the final cross-validation error rate for each of the models to find out which model has a lower error rate:

    ```
    # print the cross-validation scores
    print("Cross-Validation Loss for Model 1 =", abs(results_1[0].mean()))
    print("Cross-Validation Loss for Model 2 =", abs(results_1[1].mean()))
    print("Cross-Validation Loss for Model 3 =", abs(results_1[2].mean()))
    ```

    下面是一个输出示例:

    ```
    Cross-Validation Loss for Model 1 = 0.990475798256843
    Cross-Validation Loss for Model 2 = 0.926532513151634
    Cross-Validation Loss for Model 3 = 0.9735719371528117
    ```

    `Model 2`导致最低的错误率，因此我们将在接下来的步骤中使用它。

4.  Use cross-validation again to determine the number of epochs and batch size for the model that resulted in the lowest cross-validation error rate. Write the code that performs `3-fold cross-validation` on every possible combination of `epochs` and `batch-size` in the ranges `epochs=[100, 150]` and `batch_size=[20, 15]` and store the scores:

    ```
    # define a seed for random number generator so the result will be reproducible
    np.random.seed(seed)
    random.set_seed(seed)
    results_2 = []
    epochs = [100, 150]
    batches = [20, 15]
    # Loop over pairs of epochs and batch_size
    for e in range(len(epochs)):
        for b in range(len(batches)):
            model = KerasRegressor(build_fn= build_model_3, epochs= epochs[e], batch_size= batches[b], verbose=0, shuffle=False)
            kf = KFold(n_splits=3)
            result = cross_val_score(model, X, y, cv=kf)
            results_2.append(result)
    ```

    注意

    前面的代码块使用两个`for`循环对`epochs` 和`batch_size`的所有可能组合执行`3-fold cross-validation`。因为它们中的每一个都有两个选择，所以四个不同的配对是可能的，因此交叉验证将被执行四次。

5.  Print the final cross-validation error rate for each of the `epochs`/`batch_size` pairs to find out which pair has the lowest error rate:

    ```
    # Print cross-validation score for each possible pair of epochs, batch_size
    c = 0
    for e in range(len(epochs)):
        for b in range(len(batches)):
            print("batch_size =", batches[b],", epochs =", epochs[e], ", Test Loss =", abs(results_2[c].mean()))
            c += 1
    ```

    下面是一个输出示例:

    ```
    batch_size = 20 , epochs = 100 , Test Loss = 0.9359159401008821
    batch_size = 15 , epochs = 100 , Test Loss = 0.9642481369794683
    batch_size = 20 , epochs = 150 , Test Loss = 0.9561188386646661
    batch_size = 15 , epochs = 150 , Test Loss = 0.9359079093029896
    ```

    如你所见，`epochs=150`和`batch_size=15`以及`epochs=100`和`batch_size=20`的性能几乎相同。因此，下一步我们将选择`epochs=100`和`batch_size=20`来加快这个过程。

6.  Use cross-validation again in order to decide on the activation function for the hidden layers and the optimizer for the model from `activations = ['relu', 'tanh']` and `optimizers = ['sgd', 'adam', 'rmsprop']`. Remember to use the best pair of `batch_size` and `epochs` from the previous step:

    ```
    # Modify build_model_2 function
    def build_model_2(activation='relu', optimizer='adam'):
        # build the Keras model_2
        model = Sequential()
        model.add(Dense(8, input_dim=X.shape[1], activation=activation))
        model.add(Dense(1))
        # Compile the model
        model.compile(loss='mean_squared_error', optimizer=optimizer)
        # return the model
        return model
    results_3 = []
    activations = ['relu', 'tanh']
    optimizers = ['sgd', 'adam', 'rmsprop']
    #Define a seed for the random number generator so the result will be reproducible
    np.random.seed(seed)
    random.set_seed(seed)
    # Loop over pairs of activation and optimizer
    for o in range(len(optimizers)):
        for a in range(len(activations)):
            optimizer = optimizers[o]
            activation = activations[a]
            model = KerasRegressor(build_fn= build_model_3, epochs=100, batch_size=20, verbose=0, shuffle=False)
            kf = KFold(n_splits=3)
            result = cross_val_score(model, X, y, cv=kf)
            results_3.append(result)
    ```

    注意

    注意，我们必须修改`build_model_2`函数，将`activation`、`optimizer`以及它们的默认值作为函数的参数。

7.  Print the final cross-validation error rate for each pair of `activation` and `optimizer` to find out which pair has the lower error rate:

    ```
    # Print cross-validation score for each possible pair of optimizer, activation
    c = 0
    for o in range(len(optimizers)):
        for a in range(len(activations)):
            print("activation = ", activations[a],", optimizer = ", optimizers[o], ", Test Loss = ", abs(results_3[c].mean()))
            c += 1
    ```

    以下是输出结果:

    ```
    activation =  relu , optimizer =  sgd , Test Loss =  1.0123592540516995
    activation =  tanh , optimizer =  sgd , Test Loss =  3.393908379781118
    activation =  relu , optimizer =  adam , Test Loss =  0.9662686089392641
    activation =  tanh , optimizer =  adam , Test Loss =  2.1369285960222144
    activation =  relu , optimizer =  rmsprop , Test Loss =  2.1892826984214984
    activation =  tanh , optimizer =  rmsprop , Test Loss =  2.2029884275363014
    ```

8.  `activation='relu'`和`optimizer='adam'`对导致最低的错误率。另外，`activation='relu'`和`optimizer='sgd'`对的结果几乎一样好。因此，我们可以在最终模型中使用这些优化器来预测该数据集的水生毒性。

现在，您可以在另一个数据集上使用交叉验证来练习模型选择了。在*活动 4.02* 、*使用交叉验证进行高级纤维化诊断分类器的模型选择*中，您将通过自己在丙型肝炎数据集的分类问题上实施这些步骤来进一步练习这些步骤。

注意

*练习 4.02* 、*评估具有交叉验证的深度神经网络*、*练习 4.03* 、*编写用户定义的函数来实现具有交叉验证的深度学习模型*，涉及执行`k-fold cross-validation`多次，因此这些步骤可能需要几分钟才能完成。如果它们需要很长时间才能完成，您可以尝试通过减少折叠或时期的数量或增加批次大小来加速该过程。显然，如果您这样做，您将得到与预期输出相比不同的结果，但是相同的原则仍然适用于选择模型和超参数。

## Acti vity 4.02:使用交叉验证进行高级纤维化诊断分类器的模型选择

在本活动中，我们将通过交叉验证模型选择和超参数选择来改进丙型肝炎数据集的分类器。请遵循以下步骤:

1.  导入所需的包。使用`X = pd.read_csv('../data/HCV_feats.csv'), y = pd.read_csv('../data/HCV_target.csv')`从 GitHub 的`Chapter04`文件夹的`data`子文件夹中加载数据集。
2.  Define three functions, each returning a different Keras model. The first Keras model will be a deep neural network with three hidden layers all of `size 4` and `ReLU activation` functions. The second Keras model will be a deep neural network with two hidden layers, the first layer of `size 4` and the second later of `size 2`, and `ReLU activation` functions. The third Keras model will be a deep neural network with two hidden layers, both of `size 8`, and a `ReLU activation` function. Use the following values for the hyperparameters:

    `optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']`

3.  Write the code that will loop over the three models and perform `5-fold cross-validation` on each of them (use `epochs=100`, `batch_size=20`, and `shuffle=False` in this step). Store all the cross-validation scores in a list and print the results. Which model results in the best accuracy?

    注意

    此活动的*步骤* *3* 、 *4* 和 *5* 分别涉及执行`5-fold cross-validation`三次、四次和六次。因此，它们可能需要一些时间来完成。

4.  编写使用`epochs`和`batch_size`的`epochs = [100, 200]`和`batches = [10, 20]`值的代码。在 Keras 模型上对每个可能的配对进行 5 重交叉验证，从*步骤 3* 中获得最佳精确度。将所有交叉验证分数存储在一个列表中，并打印结果。哪一对`epochs`和`batch_size`精度最高？
5.  Write the code that uses the `optimizers = ['rmsprop', 'adam','sgd']` and `activations = ['relu', 'tanh']` values for `optimizer` and `activation`. Perform 5-fold cross-validation for each possible pair on the Keras model that resulted in the best accuracy from *step 3*. Use the `batch_size` and `epochs` values that resulted in the best accuracy from *step 4*. Store all the cross-validation scores in a list and print the results. Which `optimizer` and `activation` pair results in the best accuracy?

    注意

    请注意，在深度神经网络中初始化权重和偏差，以及在执行 k-fold 交叉验证时选择每个 fold 中包括哪些示例，都存在随机性。因此，如果您两次运行完全相同的代码，可能会得到完全不同的结果。因此，在构建和训练神经网络以及执行交叉验证时，设置种子非常重要。通过这样做，您可以确保在重新运行代码时重复完全相同的神经网络初始化以及完全相同的训练集和测试集。

实施这些步骤后，预期输出如下:

```
activation =  relu , optimizer =  rmsprop , Test accuracy =  0.5234657049179077
activation =  tanh , optimizer =  rmsprop , Test accuracy =  0.49602887630462644
activation =  relu , optimizer =  adam , Test accuracy =  0.5039711117744445
activation =  tanh , optimizer =  adam , Test accuracy =  0.4989169597625732
activation =  relu , optimizer =  sgd , Test accuracy =  0.48953068256378174
activation =  tanh , optimizer =  sgd , Test accuracy =  0.5191335678100586
```

注意

这项活动的解决方案可在第 343 页找到。

在本活动中，您学习了如何使用交叉验证来评估深度神经网络，以便找到导致分类问题错误率最低的模型。您还学习了如何通过使用交叉验证来改进给定的分类模型，以便为它找到最佳的超参数集。在下一个活动中，我们用一个回归任务重复这个活动。

## 活动 4.03:在交通量数据集上使用交叉验证的模型选择

在本活动中，您将再次使用交叉验证练习模型选择。这里，我们将使用一个模拟数据集，该数据集代表一个目标变量，该变量代表城市桥梁上每小时的车流量以及与交通数据相关的各种归一化要素，例如一天中的时间和前一天的交通量。我们的目标是建立一个模型，在给定各种特征的情况下，预测城市桥梁的交通量。

数据集包含`10000`条记录，其中每条记录都包含`10`个属性/特征。目标是建立一个深度神经网络，接收`10`特征并预测桥上的交通量。由于输出是一个数字，这是一个回归问题。让我们开始吧:

1.  导入所有必需的包。
2.  打印输入和输出大小，以检查数据集中的示例数量以及每个示例的要素数量。此外，您还可以打印输出的范围(该数据集中的输出表示房主自住房屋的中值，单位为千美元)。
3.  Define three functions, each returning a different Keras model. The first Keras model will be a shallow neural network with one hidden layer of `size 10` and a `ReLU activation` function. The second Keras model will be a deep neural network with two hidden layers of `size 10` and a `ReLU activation` function in each layer. The third Keras model will be a deep neural network with three hidden layers of `size 10` and a `ReLU activation` function in each layer.

    也使用以下值:

    `optimizer = 'adam', loss = 'mean_squared_error'`

    注意

    此活动的*步骤* *4* 、 *5* 和 *6* 分别涉及执行`5-fold cross-validation`三次、四次和三次。因此，它们可能需要一些时间来完成。

4.  编写代码循环遍历三个模型，并对每个模型执行`5-fold cross-validation`(在此步骤中使用`epochs=100`、`batch_size=5`和`shuffle=False`)。将所有交叉验证分数存储在一个列表中，并打印结果。哪种模型的测试错误率最低？
5.  编写使用`epochs`和`batch_size`的`epochs = [80, 100]`和`batches = [5, 10]`值的代码。从*步骤 4* 中得出最低测试错误率的 Keras 模型上的每个可能对进行 5 重交叉验证。将所有交叉验证分数存储在一个列表中，并打印结果。哪一对`epochs`和`batch_size`的测试错误率最低？
6.  编写使用`optimizers = ['rmsprop', 'sgd', 'adam']`的代码，并对 Keras 模型上的每个可能的优化器执行`5-fold cross-validation`，该优化器从*步骤 4* 中产生最低的测试错误率。使用*步骤 5* 中产生最低测试错误率的`batch_size`和`epochs`值。将所有交叉验证分数存储在一个列表中，并打印结果。哪个`optimizer`导致最低的测试错误率？

实施这些步骤后，预期输出如下:

```
optimizer= adam  test error rate =  25.391812739372256
optimizer= sgd  test error rate =  25.140230269432067
optimizer= rmsprop  test error rate =  25.217947859764102
```

注意

这项活动的解决方案可在第 348 页找到。

在本活动中，您学习了如何使用交叉验证来评估深度神经网络，以便找到导致`regression problem`错误率最低的模型。此外，您还学习了如何通过使用交叉验证来改进给定的回归模型，以便为其找到最佳的超参数集。

# 总结

在本章中，您学习了交叉验证，这是最重要的重采样方法之一。它导致对独立数据的模型性能的最佳估计。本章介绍了交叉验证的基础知识及其两种不同的变体，留一法和 k 折法，并对它们进行了比较。

接下来，我们用 scikit-learn 覆盖了 Keras 包装器，这是一个非常有用的工具，它允许 scikit-learn 方法和执行交叉验证的函数轻松应用于 Keras 模型。接下来，向您展示了实施交叉验证的一步一步的过程，以便使用带有 scikit-learn 的 Keras 包装器来评估 Keras 深度学习模型。

最后，您了解了模型性能的交叉验证估计可用于决定特定问题的不同模型，或者决定特定模型应使用哪些参数(或超参数)。为此，您通过编写用户定义的函数来练习使用交叉验证，以便对不同的模型或超参数的不同可能组合执行交叉验证，并选择最终模型的测试错误率最低的模型或超参数集。

在下一章中，你将了解到我们在这里所做的，为了找到我们模型的最佳超参数集，实际上是一种叫做`hyperparameter tuning`或`hyperparameter optimization`的技术。此外，您将学习如何在 scikit-learn 中使用一种叫做`grid search`的方法来执行超参数调整，而无需编写用户定义的函数来循环遍历超参数的可能组合。
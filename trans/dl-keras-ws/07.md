

# 7.卷积神经网络的计算机视觉

概观

这一章涵盖了计算机视觉以及如何通过神经网络来实现。您将学习使用卷积神经网络构建图像处理应用程序和分类模型。我们还将讨论卷积神经网络的架构，以及如何利用最大池化和扁平化、特征映射和特征检测等技术。到本章结束时，你不仅能够建立自己的图像分类器，而且能够为自己的应用有效地评估它们。

# 简介

在前一章中，我们详细探讨了模型评估。我们讨论了准确性以及为什么它可能会误导某些数据集，特别是对于具有高度不平衡类的分类任务。具有不平衡类的数据集，例如太平洋飓风的预测或某人是否会拖欠信用卡贷款的预测，与负面实例相比，正面实例相对较少，因此准确性分数具有误导性，因为空准确性非常高。

为了应对类别不平衡，我们学习了可以用来适当评估模型的技术，包括计算模型评估指标，如灵敏度、特异性、假阳性率和`AUC score`，并绘制`ROC curve`。在这一章中，我们将学习如何分类另一种类型的数据集——即图像。图像分类非常有用，我们将会发现，它在现实世界中有许多应用。

计算机视觉是机器学习和人工智能中最重要的概念之一。随着智能手机每天广泛用于捕捉、共享和上传图像，通过图像生成的数据量呈指数级增长。因此，对计算机视觉领域专家的需求空前高涨。由于医学成像领域的进步，医疗保健行业等行业正处于一场革命的边缘。

本章将向你介绍计算机视觉以及计算机视觉应用的各种行业。您还将了解卷积神经网络(CNN)，这是图像处理中使用最广泛的神经网络。像神经网络一样，CNN 也由神经元组成，这些神经元接收使用加权和和激活函数处理的输入。然而，与`ANNs`使用矢量作为输入不同，CNN 使用图像作为输入。在这一章中，我们将更详细地学习`CNNs`，以及最大池化、扁平化、特征映射和特征选择的相关概念。我们将使用 Keras 作为工具，在真实图像上运行图像处理算法。

# 计算机视觉

为了理解计算机视觉，我们来讨论人类视觉。人类视觉是人类眼睛和大脑看到和识别物体的能力。计算机视觉是赋予机器类似于(如果不是更好的话)在现实世界中看到和识别物体的理解的过程。

对于人眼来说，准确识别动物是老虎还是狮子是相当简单的，但要让计算机系统清楚地理解这些物体需要大量的训练。计算机视觉也可以被定义为建立能够模拟人眼和大脑功能的数学模型。基本上，它是关于训练计算机理解和处理图像和视频。

计算机视觉是机器人技术许多前沿领域不可或缺的一部分:医疗保健和医疗(X 射线、MRI 扫描、CT 扫描等等)、无人机、自动驾驶汽车、体育和娱乐等等。几乎所有的企业都需要计算机视觉来成功运营。

想象一下世界各地的闭路电视录像产生的大量数据，我们的智能手机每天拍摄的图片数量，每天在 YouTube 等互联网网站上分享的视频数量，以及我们在脸书和 Instagram 等热门社交网站上分享的图片数量。所有这些都产生了大量的图像数据。要处理和分析这些数据，让计算机在处理方面更加智能，这些数据需要专门研究计算机视觉的高水平专家。计算机视觉是机器学习中一个非常有利可图的领域。以下部分将描述如何使用神经网络实现计算机视觉，特别是卷积神经网络，它们在计算机视觉任务中表现良好。

# 卷积神经网络

当我们谈论计算机视觉时，我们同时谈论 CNN。CNN 是一类深度神经网络，主要用于计算机视觉和成像领域。CNN 用于识别图像，根据图像的相似性对其进行聚类，并实现场景内的对象识别。CNN 有不同的层，即输入层、输出层和多个隐藏层。CNN 的这些隐藏层由全连接层、卷积层、作为 T1 的 T0、T2 和 T3 组成。在一个非常简单的层面上，CNN 帮助我们识别图像并给它们贴上适当的标签；例如，老虎图像将被识别为老虎:

![Figure 7.1: A generalized CNN
](image/B15777_07_01.jpg)

图 7.1:一个通用的 CNN

以下是 CNN 给老虎分类的一个例子:

![Figure 7.2: A CNN classifying an image of a tiger into the class “Tiger”
](image/B15777_07_02.jpg)

图 7.2:美国有线电视新闻网将一张老虎图片归类为“老虎”

# 美国有线电视新闻网的架构

CNN 架构的主要组件如下:

*   `Input image`
*   `Convolutional layer`
*   `Pooling layer`
*   `Flattening`

## 输入图像

一个`input image`构成了 CNN 架构的第一个组成部分。图像可以是任何类型:人、动物、风景、医学 X 射线图像等等。每个图像都被转换成一个由 0 和 1 组成的数学矩阵。下图解释了计算机如何看待字母 **T** 的图像。所有值为 1 的块代表数据，而 0 代表空白:

![Figure 7.3: Matrix for the letter ‘T’
](image/B15777_07_03.jpg)

图 7.3:字母“T”的矩阵

## 卷积层

`convolution layer`是图像处理开始的地方。卷积层由两部分组成:

*   `Feature detector`或`filter`
*   `Feature map`

`Feature detector`或`filter`:这是一个矩阵或图案，你把它放在一个图像上，把它转换成一个特征图:

![Figure 7.4: Feature detector
](image/B15777_07_04.jpg)

图 7.4:特征检测器

正如我们所看到的，这个特征检测器被放置(叠加)在原始图像上，并且在相应的元素上进行计算。计算是通过将相应的元素相乘来完成的，如下图所示。对所有细胞重复这一过程。这产生了新的处理过的图像— `(0x0+0x0+0x1) + (0x1+1x0+0x0) + (0x0+0x1+0x1) = 0`:

![Figure 7.5: Feature detector masked in an image
](image/B15777_07_05.jpg)

图 7.5:图像中屏蔽的特征检测器

`Feature Map`:这是由`image`和`feature detector`卷积产生的缩小图像。我们必须将特征检测器放在原始图像的所有可能位置上，并从中导出更小的图像；该导出图像是输入图像的特征图:

![Figure 7.6: Feature map
](image/B15777_07_06.jpg)

图 7.6:特征图

注意

这里，`feature detector`是滤镜，`feature map`是缩小图像。缩小图像时会丢失一些信息。

在实际的 CNN 中，许多特征检测器被用来产生许多特征图，如下图所示:

![Figure 7.7: Multiple feature detectors and maps
](image/B15777_07_07.jpg)

图 7.7:多特征检测器和地图

## 汇集层

`pooling layer`帮助我们忽略图像中不太重要的数据，进一步缩小图像，同时保留其重要特征。考虑以下三个图像，总共包含四只猫:

![Figure 7.8: Example of cat images
](image/B15777_07_08.jpg)

图 7.8:猫图像示例

为了识别图像中是否有猫，神经网络对图片进行分析。它可能会看耳朵形状，眼睛形状，等等。与此同时，这幅图像包含了许多与猫无关的特征。前两个图像中的树和树叶在猫的识别中没有用。池机制有助于算法理解图像的哪些部分是相关的，哪些部分是不相关的。

从卷积层导出的特征图通过汇集层进一步缩小图像，同时保留图像的最相关部分。池层由最大池、最小池和平均池等函数组成。这意味着我们选择一个矩阵大小，比如说`2x2`，我们扫描特征图，并从`2x2`矩阵中选择适合该块的最大数。下图让我们清楚地了解了 max pooling 是如何工作的。参考颜色；在汇集的特征图中选择特征图中每个彩色框中的最大数量:

![Figure 7.9: Pooling
](image/B15777_07_09.jpg)

图 7.9:池化

考虑盒子中有数字`4`的情况。让我们假设数字`4`代表猫的耳朵，而耳朵周围的空白处是`0`和`1`。所以，我们忽略该块的`0`和`1`，只选择`4`。下面是一些示例代码，我们将使用它来添加一个池层；这里，`Maxpool2D`用于最大池化，这有助于识别最重要的特性:

```
classifier.add(MaxPool2D(2,2))
```

## 展平

`Flattening`是美国有线电视新闻网的一部分，在这里图像可以作为人工神经网络的输入。顾名思义，合并的图像被展平并转换成单列。每一行被做成一列，一列叠一列。这里，我们将一个`3x3`矩阵转换成了一个`1xn`矩阵，其中`n`，在我们的例子中，是`9`:

![Figure 7.10: Flattening
](image/B15777_07_10.jpg)

图 7.10:展平

实时地，我们有许多汇集的特征地图，我们将它们展平成一列。这一列用作人工神经网络的输入。下图显示了平铺在一列中的多个池层:

![Figure 7.11: Pooling and flattening
](image/B15777_07_11.jpg)

图 7.11:池化和扁平化

下面是一些示例代码，我们将使用添加一个扁平化层；这里`Flatten`是用来拉平 CNN 的:

```
classifier.add(Flatten())
```

现在，让我们来看看 CNN 的整体结构:

![Figure 7.12: CNN architecture
](image/B15777_07_12.jpg)

图 7.12: CNN 架构

以下是一些示例代码，我们将使用这些代码向 CNN 添加第一层:

```
classifier.add(Conv2D(32,3,3,input_shape=(64,64,3),activation='relu'))
```

`32,3,3`是指有`32`个大小为`3x3`的特征检测器。作为一个好的做法，总是从`32`开始；以后可以加`64`或者`128`。

`Input_shape`:由于所有图像的形状和大小不同，这个`input_image`将所有图像转换成统一的形状和大小。`(64,64)`是转换后图像的尺寸。它可以设置为`128`或`256`，但如果你是在笔记本电脑的 CPU 上工作，建议使用`64x64`。使用最后一个参数`3`，因为图像是彩色图像(用红、蓝、绿或 RGB 编码)。如果图像是黑白的，参数可以设置为 1。正在使用的激活函数是 ReLU。

注意

在本书中，我们使用 Keras 和 TensorFlow 作为后端。如果后端是 Theano，那么`input_image`将被编码为(`3,64,64`)。

最后一步是拟合已经创建的数据。下面是我们用来实现这一目的的代码:

```
classifier.fit_generator(training_set,
steps_per_epoch = 5000,
epochs = 25,
validation_data = test_set,
validation_steps = 1000)
```

注意

`steps_per_epoch`是训练图像的数量。`validation_steps`是测试图像的数量。

# 图像增强

单词 augmentation 是指在尺寸或数量上变得更大的行为或过程。图像或数据增强以类似的方式工作。图像/数据增强创建了许多批我们的图像。然后，它对批中的随机图像应用随机变换。数据转换可以是旋转图像、移动图像、翻转图像等等。通过应用这种转换，我们在批次内获得了更多样的图像，并且我们也拥有了比原来多得多的数据。

圆柱体可以从不同的角度旋转，看到不同的东西。在下图中，可以从五个不同的角度看到单个圆柱体。因此，我们有效地从一个图像创建了五个不同的图像:

![Figure 7.13: Image augmentation of a cylinder
](image/B15777_07_13.jpg)

图 7.13:圆柱体的图像放大

以下是我们将用于图像增强的一些示例代码；这里，`ImageDataGenerator`类用于处理。`shear_range`、`zoom_range`和`horizontal_flip`都是用来变换图像的:

```
from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale = 1./255.0,
                                   shear_range = 0.3,
                                   zoom_range = 0.3,
                                   horizontal_flip = False)
test_datagen = ImageDataGenerator(rescale = 1./255.0)
```

## 图像增强的优势

图像增强是处理图像的重要部分:

*   **减少过度拟合**:它通过创建相同图像的多个版本，旋转给定的量来帮助减少过度拟合。
*   **增加图像数量**:单幅图像充当多幅图像。因此，从本质上讲，数据集包含的图像较少，但每个图像都可以通过图像增强转换为多个图像。图像增强将增加图像的数量，并且算法将对每个图像进行不同的处理。
*   **容易预测新图像**:想象一下，从不同角度看一个足球的单个图像，每个角度都被认为是一个不同的图像。这将意味着该算法在预测新图像时将更加准确:

![Figure 7.14: Image augmentation of an image of a football
](image/B15777_07_14.jpg)

图 7.14:足球图像的图像放大

现在我们已经通过 CNN 了解了计算机视觉背后的概念和理论，让我们来看一些实际的例子。

首先，我们将从一个练习开始，在这个练习中我们将构建一个简单的 CNN。在下面的练习和活动中，我们将使用排列和组合来调整 CNN:

*   添加更多 CNN 层
*   添加更多 ANN 层
*   更改优化器功能
*   Changing the activation function

    让我们从创建我们的第一个 CNN 开始，这样我们就可以将汽车和鲜花的图像分类到它们各自的类别中。

## 练习 7.01:构建一个 CNN 并识别汽车和鲜花的图像

对于这个练习，我们有汽车和花的图像，这些图像被分为训练集和测试集，我们必须建立一个 CNN 来识别图像是汽车还是花。

注意

本章中的所有练习和活动将在 Jupyter 笔记本中展开。请从[https://packt.live/39tID2C](https://packt.live/39tID2C)下载这本书的 GitHub 资源库，以及所有准备好的模板。

在开始之前，请确保您已经将本书的 GitHub 资源库中的图像数据集下载到您自己的工作目录中。您将需要一个`training_set`文件夹来训练您的模型，并需要一个`test_set`文件夹来测试您的模型。每个文件夹都包含一个包含汽车图片的`cars`文件夹和一个包含花卉图片的`flowers`文件夹。

完成本练习的步骤如下:

1.  导入`numpy`库和必要的 Keras 库和类:

    ```
    # Import the Libraries
    from keras.models import Sequential from keras.layers import Conv2D, MaxPool2D, Flatten, Dense
    import numpy as np
    from tensorflow import random
    ```

2.  现在，设置一个种子并用`Sequential`类:

    ```
    # Initiate the classifier
    seed = 1
    np.random.seed(seed)
    random.set_seed(seed)
    classifier = Sequential()
    ```

    初始化模型
3.  Add the first layer of the `CNN`, set the input shape to `(64, 64, 3)`, the dimension of each image, and set the activation function as a `ReLU`:

    ```
    classifier.add(Conv2D(32,3,3, input_shape=(64,64,3), activation='relu'))
    ```

    `32,3,3`表示有`32`个`3x3`大小的特征检测器。

4.  现在，添加图像大小为`2x2` :

    ```
    classifier.add(MaxPool2D(2,2))
    ```

    的池层
5.  通过向`CNN`模型添加一个展平层来展平池层的输出:

    ```
    classifier.add(Flatten())
    ```

6.  添加`ANN`的第一个`Dense`层。在这里，`128`是输出的节点数。作为一个很好的练习，`128`很好上手。`activation`是`relu`。作为一个好的实践，二的幂是首选:

    ```
    classifier.add(Dense(128, activation='relu')) 
    ```

7.  添加人工神经网络的输出层。这是一个二元分类问题，所以大小为`1`，激活为`sigmoid` :

    ```
    classifier.add(Dense(1, activation='sigmoid')) 
    ```

8.  用`adam`优化器编译网络，并在训练过程中计算精度:

    ```
    #Compile the network
    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    ```

9.  创建培训和测试数据生成器。通过`1/255`重新缩放训练和测试图像，使所有值都在`0`和`1`之间。仅为训练数据发生器设置这些参数—`shear_range=0.2`、`zoom_range=0.2`和`horizontal_flip=True` :

    ```
    from keras.preprocessing.image import ImageDataGenerator
    train_datagen = ImageDataGenerator(rescale = 1./255,
                                       shear_range = 0.2,
                                       zoom_range = 0.2,
                                       horizontal_flip = True)
    test_datagen = ImageDataGenerator(rescale = 1./255)
    ```

10.  从`training set`文件夹创建一个训练集。`'../dataset/training_set'`是存放我们数据的文件夹。我们的 CNN 模型有一个`64x64`的图像大小，所以这里也应该传递相同的大小。`batch_size`是单批图像的数量，也就是`32`。`Class_mode`被设置为`binary`，因为我们正在处理二元分类器:

    ```
    training_set = train_datagen.flow_from_directory('../dataset/training_set',
    target_size = (64, 64),
    batch_size = 32,
    class_mode = 'binary')
    ```

11.  对测试集重复*步骤 10* ，同时将文件夹设置到测试图像的位置，即`'../dataset/test_set'` :

    ```
    test_set = test_datagen.flow_from_directory('../dataset/test_set',
    target_size = (64, 64),
    batch_size = 32,
    class_mode = 'binary')
    ```

12.  Finally, fit the data. Set the `steps_per_epoch` to `10000` and the `validation_steps` to `2500`. The following step might take some time to execute:

    ```
    classifier.fit_generator(training_set,
    steps_per_epoch = 10000,
    epochs = 2,
    validation_data = test_set,
    validation_steps = 2500,
    shuffle=False)
    ```

    上述代码产生以下输出:

    ```
    Epoch 1/2
    10000/10000 [==============================] - 1994s 199ms/step - loss: 0.2474 - accuracy: 0.8957 - val_loss: 1.1562 - val_accuracy: 0.8400
    Epoch 2/2
    10000/10000 [==============================] - 1695s 169ms/step - loss: 0.0867 - accuracy: 0.9689 - val_loss: 1.4379 - val_accuracy: 0.8422
    ```

    验证集上的精度为`84.22%`。

    注意

    为了获得更准确的结果，尝试将历元的数量增加到大约`25`。这将增加处理数据的时间，总时间取决于机器的配置。

这就完成了处理图像和识别图像内容的练习。这里要记住的重要一点是，这是一个对计算机视觉中的任何二进制分类问题都很鲁棒的代码。这意味着即使图像数据发生变化，代码也保持不变。我们将在下一个活动中通过修改模型的一些参数来测试我们的知识，并评估模型的性能。

## 活动 7.01:用多层和使用 softmax 修改我们的模型

既然我们已经成功地运行了一个`CNN model`，下一个合乎逻辑的步骤就是尝试改进我们算法的性能。有许多方法可以提高其性能，最直接的方法之一是在模型中添加多个人工神经网络层，我们将在本活动中了解这一点。我们还会将激活从 sigmoid 更改为 softmax。通过这样做，我们可以将结果与之前的练习进行比较。按照以下步骤完成本活动:

1.  要构建 CNN 导入库，设置一个种子并创建一个`Sequential`类，导入`Conv2D`、`MaxPool2D`、`Flatten`和`Dense`。`Conv2D`用于构建卷积层。因为我们的照片在 2D，所以我们在这里用了 2D。类似地，`Maxpool2D`用于最大池化，`Flatten`用于平坦化 CNN，`Dense`用于将全连接 CNN 添加到 ANN。
2.  使用前面的库开始构建 CNN 架构。添加第一层后，再添加两层到您的 CNN。
3.  添加一个汇集和扁平化层，这将作为人工神经网络的输入。
4.  建立一个完全连接的人工神经网络，其输入将是 CNN 的输出。添加第一层人工神经网络后，再添加三层。对于人工神经网络的输出层，使用 softmax 激活函数。编译模型。
5.  执行图像增强以处理和转换数据。`ImageDataGenerator`类用于处理。`shear_range`、`zoom_range`、`horizontal_flip`都是用于图像的变换。
6.  创建训练集和测试集数据。
7.  最后，拟合已经创建的数据。

实现这些步骤后，您应该得到以下预期输出:

```
Epoch 1/2
10000/10000 [==============================] - 2452s 245ms/step - loss: 8.1783 - accuracy: 0.4667 - val_loss: 11.4999 - val_accuracy: 0.4695
Epoch 2/2
10000/10000 [==============================] - 2496s 250ms/step - loss: 8.1726 - accuracy: 0.4671 - val_loss: 10.5416 - val_accuracy: 0.4691
```

注意

这项活动的解决方案可以在第 393 页找到。

在本练习中，我们修改了 CNN 模型，尝试提高图像分类器的准确性。我们增加了额外的卷积层和额外的 ANN 全连接层，并改变了输出层中的激活函数。这样做降低了我们的精确度。在下一个练习中，我们将激活函数改回 sigmoid。我们将通过观察在验证数据集上评估的准确性来评估性能。

## 练习 7.02:通过回复到 Sigmoid 激活函数来修改我们的模型

在本练习中，我们将重建模型，但将激活函数从 softmax 恢复为 sigmoid。通过这样做，我们可以将精确度与之前的模型进行比较。按照以下步骤完成本练习:

1.  导入`numpy`库和必要的 Keras 库和类:

    ```
    # Import the Libraries 
    from keras.models import Sequential
    from keras.layers import Conv2D, MaxPool2D, Flatten, Dense
    import numpy as np
    from tensorflow import random
    ```

2.  现在，设置种子并用`Sequential`类:

    ```
    # Initiate the classifier
    seed = 43
    np.random.seed(seed)
    random.set_seed(seed)
    classifier = Sequential()
    ```

    初始化模型
3.  添加 CNN 的第一层，设置输入形状为`(64, 64, 3)`，每张图片的维度，设置激活函数为 ReLU。然后，添加尺寸为`(3, 3)`的`32`特征检测器。添加两个额外的卷积层，具有大小为`(3, 3)`的`32`特征检测器，也具有 ReLU 激活功能:

    ```
    classifier.add(Conv2D(32,3,3,input_shape=(64,64,3),activation='relu'))
    classifier.add(Conv2D(32, (3, 3), activation = 'relu'))
    classifier.add(Conv2D(32, (3, 3), activation = 'relu'))
    ```

4.  现在，添加图像大小为`2x2` :

    ```
    classifier.add(MaxPool2D(2,2))
    ```

    的池层
5.  添加一个与*步骤 3* 相同参数的`Conv2D`和一个池层，以补充我们在*步骤 4* :

    ```
    classifier.add(Conv2D(32, (3, 3), activation = 'relu'))
    classifier.add(MaxPool2D(pool_size = (2, 2)))
    ```

    中使用的相同参数
6.  通过向`CNN model` :

    ```
    classifier.add(Flatten())
    ```

    添加展平层来展平池层的输出
7.  添加 ANN 的第一个`Dense`层。这里，`128`是输出的节点数。`128`作为一个很好的练习，很好上手。`activation`是`relu`。作为一个好的实践，二的幂是首选的。添加三个具有相同参数的附加层:

    ```
    classifier.add(Dense(128,activation='relu'))
    classifier.add(Dense(128,activation='relu'))
    classifier.add(Dense(128,activation='relu'))
    classifier.add(Dense(128,activation='relu'))
    ```

8.  添加`ANN`的输出层。这是一个二进制分类问题，所以输出是`1`，激活是`sigmoid` :

    ```
    classifier.add(Dense(1,activation='sigmoid')) 
    ```

9.  用 Adam 优化器编译网络，并在训练过程中计算精度:

    ```
    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    ```

10.  创建培训和测试数据生成器。通过`1/255`重新缩放训练和测试图像，使所有值都在`0`和`1`之间。仅为训练数据发生器设置这些参数—`shear_range=0.2`、`zoom_range=0.2`和`horizontal_flip=True` :

    ```
    from keras.preprocessing.image import ImageDataGenerator
    train_datagen = ImageDataGenerator(rescale = 1./255,
                                       shear_range = 0.2,
                                       zoom_range = 0.2,
                                       horizontal_flip = True)
    test_datagen = ImageDataGenerator(rescale = 1./255)
    ```

11.  从`training set`文件夹创建一个训练集。`../dataset/training_set`是存放我们数据的文件夹。我们的 CNN 模型的图像大小为 64x64，因此这里也应该传递相同的大小。`batch_size`是单批图像的数量，即`32`。`class_mode`是二元的，因为我们正在研究二元分类器:

    ```
    training_set = train_datagen.flow_from_directory('../dataset/training_set',
    target_size = (64, 64),
    batch_size = 32,
    class_mode = 'binary')
    ```

12.  将文件夹设置到测试图像的位置，即`'../dataset/test_set'` :

    ```
    test_set = test_datagen.flow_from_directory('../dataset/test_set',
    target_size = (64, 64),
    batch_size = 32,
    class_mode = 'binary')
    ```

    ，对测试集重复*步骤 11*
13.  Finally, fit the data. Set the `steps_per_epoch` to `10000` and the `validation_steps` to `2500`. The following step might take some time to execute:

    ```
    classifier.fit_generator(training_set,
    steps_per_epoch = 10000,
    epochs = 2,
    validation_data = test_set,
    validation_steps = 2500,
    shuffle=False)
    ```

    上述代码产生以下输出:

    ```
    Epoch 1/2
    10000/10000 [==============================] - 2241s 224ms/step - loss: 0.2339 - accuracy: 0.9005 - val_loss: 0.8059 - val_accuracy: 0.8737
    Epoch 2/2
    10000/10000 [==============================] - 2394s 239ms/step - loss: 0.0810 - accuracy: 0.9699 - val_loss: 0.6783 - val_accuracy: 0.8675
    ```

模型的精度为`86.75%`，明显大于我们在之前的练习中建立的模型的精度。由此可见激活函数的重要性。只需将输出激活函数从 SoftMax 改为 sigmoid，即可将精度从`46.91%`提高到`86.75%`。这种精度上的巨大变化背后的原因是 SoftMax 激活函数输出概率分布，因此输出节点的总和等于 1。由于只有一个输出，因此预测值始终为 1，并且具有 SoftMax 激活函数的模型的精度表示验证集中值为 1 的值的百分比，这没有多大帮助。在下一个练习中，我们将试验不同的优化器，并观察它如何影响模型性能。

注意

在二进制分类问题中(在我们的例子中，汽车对花)，使用 sigmoid 作为输出的激活函数总是更好。

## 练习 7.03:将优化器从 Adam 更改为 SGD

在本练习中，我们将通过将优化器更改为`SGD`来再次修改模型。通过这样做，我们可以将精确度与我们以前的模型进行比较。按照以下步骤完成本练习:

1.  导入`numpy`库和必要的 Keras 库和类:

    ```
    # Import the Libraries 
    from keras.models import Sequential from keras.layers import Conv2D, MaxPool2D, Flatten, Dense
    import numpy as np
    from tensorflow import random
    ```

2.  现在，用`Sequential`类:

    ```
    # Initiate the classifier
    seed = 42
    np.random.seed(seed)
    random.set_seed(seed)
    classifier = Sequential()
    ```

    初始化模型
3.  添加`CNN`的第一层，设置输入形状为`(64, 64, 3)`，每张图片的尺寸，设置激活函数为`ReLU`。然后，添加`32`大小的特征检测器(`3, 3`)。添加两个额外的卷积层，其特征检测器的数量和大小相同:

    ```
    classifier.add(Conv2D(32,3,3,input_shape=(64,64,3),activation='relu'))
    classifier.add(Conv2D(32,3,3,activation='relu'))
    classifier.add(Conv2D(32,3,3,activation='relu'))
    ```

4.  现在，添加图像大小为`2x2` :

    ```
    classifier.add(MaxPool2D(2,2))
    ```

    的池层
5.  添加一个与*步骤 3* 相同参数的`Conv2D`和一个池层，以补充我们在*步骤 4* :

    ```
    classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))
    classifier.add(MaxPool2D(2,2))
    ```

    中使用的相同参数
6.  添加一个`Flatten`层，完成 CNN 架构:

    ```
    classifier.add(Flatten())
    ```

7.  添加大小为`128`的 ANN 的第一个`Dense`层。用相同的参数添加三个更密集的层到网络中:

    ```
    classifier.add(Dense(128,activation='relu')) 
    classifier.add(Dense(128,activation='relu'))
    classifier.add(Dense(128,activation='relu'))
    classifier.add(Dense(128,activation='relu'))
    ```

8.  添加人工神经网络的输出层。这是一个二进制分类问题，所以输出是`1`，激活是`sigmoid` :

    ```
    classifier.add(Dense(1,activation='sigmoid')) 
    ```

9.  用`SGD optimizer`编译网络，并在训练过程中计算精度:

    ```
    classifier.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])
    ```

10.  创建培训和测试数据生成器。通过`1/255`重新缩放训练和测试图像，使所有值都在`0`和`1`之间。仅为训练数据发生器设置这些参数—`shear_range=0.2`、`zoom_range=0.2`和`horizontal_flip=True` :

    ```
    from keras.preprocessing.image import ImageDataGenerator
    train_datagen = ImageDataGenerator(rescale = 1./255,
                                       shear_range = 0.2,
                                       zoom_range = 0.2,
                                       horizontal_flip = True)
    test_datagen = ImageDataGenerator(rescale = 1./255)
    ```

11.  从`training set`文件夹创建一个训练集。`../dataset/training_set`是存放我们数据的文件夹。我们的 CNN 模型有一个`64x64`的图像大小，所以这里也应该传递相同的大小。`batch_size`是单批图像的数量，也就是`32`。`class_mode`是二元的，因为我们正在创建一个二元分类器:

    ```
    training_set = train_datagen.flow_from_directory('../dataset/training_set',
    target_size = (64, 64),
    batch_size = 32,
    class_mode = 'binary')
    ```

12.  将文件夹设置到测试图像的位置，即`'../dataset/test_set'` :

    ```
    test_set = test_datagen.flow_from_directory('../dataset/test_set',
    target_size = (64, 64),
    batch_size = 32,
    class_mode = 'binary')
    ```

    ，对测试集重复*步骤 11*
13.  Finally, fit the data. Set the `steps_per_epoch` to `10000` and the `validation_steps` to `2500`. The following step might take some time to execute:

    ```
    classifier.fit_generator(training_set,
    steps_per_epoch = 10000,
    epochs = 2,
    validation_data = test_set,
    validation_steps = 2500,
    shuffle=False)
    ```

    上述代码产生以下输出:

    ```
    Epoch 1/2
    10000/10000 [==============================] - 4376s 438ms/step - loss: 0.3920 - accuracy: 0.8201 - val_loss: 0.3937 - val_accuracy: 0.8531
    Epoch 2/2
    10000/10000 [==============================] - 5146s 515ms/step - loss: 0.2395 - accuracy: 0.8995 - val_loss: 0.4694 - val_accuracy: 0.8454
    ```

    精确度是`84.54%`，因为我们使用了多个`ANNs`和`SGD`作为优化器。

到目前为止，我们已经对我们的模型进行了许多不同的排列和组合。似乎通过执行以下操作可以获得该数据集的最佳精度:

*   添加多个 CNN 层。
*   添加多个人工神经网络层。
*   具有像乙状结肠一样的活性。
*   把优化器当成亚当。
*   将历元大小增加到大约`25`(这需要大量的计算时间——确保你有 GPU 来做这件事)。这将增加你预测的准确性。

最后，我们将继续预测一个新的未知图像，将其传递给算法，并验证该图像是否被正确分类。在下一个练习中，我们将演示如何使用该模型对新图像进行分类。

## 练习 7.04:对新图像进行分类

在本练习中，我们将尝试对新图像进行分类。图像还没有暴露给算法，所以我们将使用这个练习来测试我们的算法。您可以运行本章中的任何算法(尽管获得最高准确性的算法是首选)，然后使用该模型对图像进行分类。

注意

本练习中使用的图片可以在本书的 GitHub 资源库中找到，该资源库位于[https://packt.live/39tID2C](https://packt.live/39tID2C)。

在我们开始之前，请确保您已经将本书的 GitHub 资源库中的`test_image_1`下载到您自己的工作目录中。本练习是上一个练习的延续，所以请确保您已经准备好本章中的一个算法，可以在您的工作空间中运行。

完成本练习的步骤如下:

1.  加载图像。`'test_image_1.jpg'`是测试图像的路径。请将路径更改为您在系统中保存数据集的位置。看图片验证是什么:

    ```
    from keras.preprocessing import image
    new_image = image.load_img('../test_image_1.jpg', target_size = (64, 64))
    new_image
    ```

2.  打印位于训练集

    ```
    training_set.class_indices
    ```

    的`class_indices`属性中的类别标签
3.  处理图像:

    ```
    new_image = image.img_to_array(new_image)
    new_image = np.expand_dims(new_image, axis = 0)
    ```

4.  预测新图像:

    ```
    result = classifier.predict(new_image)
    ```

5.  The `prediction` method will output the image as `1` or `0`. To map `1` and `0` to `flower` or `car`, use the `class_indices` method with an `if…else` statement, as follows:

    ```
    if result[0][0] == 1:
        prediction = 'It is a flower'
    else:
        prediction = 'It is a car'
    print(prediction)
    ```

    上述代码产生以下输出:

    ```
    It is a car
    ```

    `test_image_1`是一辆汽车的图像(您可以亲自查看该图像)并且被模型正确预测为一辆汽车。

在这个练习中，我们训练我们的模型，然后给模型一个汽车的图像。通过这样做，我们发现该算法对图像的分类是正确的。您可以使用相同的过程在任何类型的图像上训练模型。例如，如果您使用肺部感染和健康肺部的扫描来训练模型，那么该模型将能够分类新的扫描是代表受感染的肺部还是健康的肺部。

在接下来的活动中，我们将使用在*练习 7.04* 、*中训练的模型对新图像*进行分类，从而将我们的知识付诸实践。

## 活动 7.02: 对新图像进行分类

在本练习中，您将尝试对另一张新图片进行分类，就像我们在之前的练习中所做的那样。图像没有暴露给算法，所以我们将使用这个活动来测试我们的算法。您可以运行本章中的任何算法(尽管获得最高准确度的算法是首选)，然后使用该模型对您的图像进行分类。实施该活动的步骤如下:

1.  运行本章中的任何一种算法。
2.  从您的目录中加载图像(`test_image_2`)。
3.  使用算法处理图像。
4.  Predict the subject of the new image. You can view the image yourself to check whether the prediction is correct.

    注意

    本次活动中使用的图片可以在本书位于[https://packt.live/39tID2C](https://packt.live/39tID2C)的 GitHub 资源库中找到。

在开始之前，确保你已经从本书的 GitHub 库下载了`test_image_2`到你自己的工作目录。本练习是前面练习的直接延续，因此请确保您已经准备好本章中的一个算法，可以在您的工作区中运行。

实现这些步骤后，您应该得到以下预期输出:

```
It is a flower
```

注意

这项活动的解决方案可在第 396 页找到。

在本练习中，我们根据验证数据集的准确性，在给定修改的各种参数(包括优化器和输出层中的激活函数)的情况下，训练了本章中性能最好的模型。我们在测试图像上测试了分类器，发现它是正确的。

# 总结

在这一章中，我们学习了为什么我们需要计算机视觉以及它是如何工作的。我们了解了为什么计算机视觉是机器学习中最热门的领域之一。然后，我们研究了卷积神经网络，了解了它们的架构，并研究了如何在实际应用中构建 CNN。我们还试图通过添加更多的 ANN 和 CNN 层以及改变激活和优化函数来改进我们的算法。最后，我们尝试了不同的激活函数和损失函数。

最终，我们能够通过算法成功地对汽车和鲜花的新图像进行分类。请记住，汽车和鲜花的图像可以用任何其他图像来代替，例如老虎和鹿，或者有肿瘤和没有肿瘤的大脑的 MRI 扫描。任何二元分类计算机成像问题都可以用同样的方法解决。

在下一章中，我们将研究一种更有效的计算机视觉技术，这种技术耗时更少，也更容易实现。下一章将教我们如何为我们自己的应用程序微调预训练模型，这将有助于创建更准确的模型，可以在更短的时间内训练。将使用的模型被称为 VGG-16 和 ResNet50，是用于图像分类的流行的预训练模型。
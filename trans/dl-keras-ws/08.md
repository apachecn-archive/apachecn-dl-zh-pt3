<title>B15777_08_Final_SZ_ePub</title> <link href="css/epub.css" rel="stylesheet" type="text/css">

# 8。迁移学习和预训练模型

概观

本章介绍了预训练模型的概念，以及如何将它们用于不同的应用，即迁移学习。在本章结束时，您将能够对预训练的模型应用特征提取，利用预训练的模型进行图像分类，并对预训练的模型进行微调，以将花卉和汽车的图像分类到各自的类别中。我们将会看到，这与我们在上一章中完成的任务相同，但精度更高，训练时间更短。

# 简介

在前一章中，我们学习了如何使用 Keras 从头开始创建一个卷积神经网络(CNN)。我们通过增加更多的卷积层和密集层以及改变激活函数来试验不同的架构。我们通过将汽车和鲜花的图像分类到各自的类别并比较它们的准确性来比较每个模型的性能。

然而，在现实世界的项目中，您几乎不会从头开始编写卷积神经网络。你总是按照要求调整和训练他们。本章将向您介绍迁移学习和预训练网络(也称为预训练模型)的重要概念，这两个概念在行业中都有使用。

我们将使用图像，而不是从零开始建立 CNN，我们将在预先训练的模型上匹配这些图像，尝试对它们进行分类。我们还将调整我们的模型，使它们更加灵活。我们将在本章中使用的模型称为 VGG16 和 ResNet50，我们将在本章的后面讨论它们。在我们开始研究预训练模型之前，我们需要了解迁移学习。

# 预训练集和迁移学习

人类通过经验学习。我们将在一种情况下获得的知识应用到我们未来面临的类似情况中。假设你想学开 SUV。你没开过 SUV 你只知道如何驾驶小型掀背车。

SUV 的尺寸比掀背车大得多，因此在车流中驾驶 SUV 肯定是一个挑战。尽管如此，一些基本系统(如离合器、油门和刹车)仍然与掀背车相似。所以，知道如何驾驶掀背车肯定会对你学习驾驶 SUV 有很大的帮助。你在开掀背车的时候学到的所有知识，都可以在你学开大型 SUV 的时候用到。

这正是迁移学习。根据定义，迁移学习是机器学习中的一个概念，其中我们存储并使用在一个活动中获得的知识，同时学习另一个类似的活动。掀背式 SUV 车型完全符合这个定义。

假设我们想知道一幅画是一只狗还是一只猫；这里，我们可以有两种方法。一种是从头开始建立深度学习模型，然后将新图片传递给网络。另一种选择是使用预先训练的深度学习神经网络模型，该模型已经通过使用猫和狗的图像建立起来，而不是从头开始创建神经网络。

使用预先训练的模型节省了我们的计算时间和资源。使用预先训练好的网络会有一些意想不到的好处。例如，几乎所有的狗和猫的图片都会在图片中出现一些更多的物体，如树木、天空和家具。我们甚至可以使用这个预先训练好的网络来识别树木、天空和家具等物体。

因此，预训练网络是一个保存的网络(在深度学习的情况下，是一个神经网络)，它在一个非常大的数据集上进行训练，主要是在图像分类问题上。为了在预训练的网络上工作，我们需要理解特征提取和微调的概念。

## 特征提取

为了理解特征提取，我们需要重新考察卷积神经网络的架构。

您可能还记得，`CNN`的完整架构在较高层次上由以下组件组成:

*   一个**卷积层**
*   一个**汇集和展平层**
*   一个**人工神经网络** ( **安**

下图显示了一个完整的 CNN 架构:

![Figure 8.1: CNN architecture
](image/B15777_08_01.jpg)

图 8.1: CNN 架构

现在，让我们把这个架构分成两部分。第一部分包含除了`ANN`之外的所有内容，而第二部分只包含`ANN`。下图显示了一个拆分的`CNN`架构:

![Figure 8.2: CNN split architecture – convolutional base and classifier
](image/B15777_08_02.jpg)

图 8.2: CNN 分离架构——卷积基和分类器

第一部分称为卷积基，而第二部分称为分类器。

在特征提取中，我们不断重用卷积基，分类器也随之改变。因此，我们保留了卷积层的学习，我们可以在卷积层之上传递不同的分类器。一个分类器可以是狗对猫，自行车对汽车，甚至是医学 X 射线图像来分类肿瘤，感染，等等。下图显示了用于不同分类器的一些卷积基础层:

![Figure 8.3: Reusable convolutional base layer
](image/B15777_08_03.jpg)

图 8.3:可重用卷积基础层

下一个明显的问题是，我们不能重用分类器吗，比如基础层？一般的答案是否定的。原因是从卷积基学习可能更通用，因此更可重用。然而，分类器的学习主要是特定于模型被训练的类。因此，建议只重用卷积基础层，而不重用分类器。

从卷积基础层的广义学习量取决于该层的深度。例如，在猫的情况下，模型的初始层学习一般特征，例如边缘和背景，而较高层可能学习更多关于特定细节，例如眼睛、耳朵或鼻子的形状。因此，如果您的新数据集与原始数据集非常不同，例如，如果您希望识别水果而不是猫，那么最好只使用卷积基础层的一些初始层，而不是使用整个层。

**冻结卷积层**:预训练学习最重要的特点之一就是理解冻结一个预训练网络的某些层的概念。冻结实质上意味着我们停止更新某些卷积层的权重的过程。因为我们使用的是预先训练好的网络，所以了解我们需要存储在网络初始层的信息是很重要的。如果在训练网络时更新该信息，我们可能会丢失一些已经学习并存储在预训练网络中的一般概念。如果我们添加一个分类器(`CNN`)，网络顶部的许多密集层被随机初始化，并且可能存在这样的情况，由于反向传播，网络初始层的学习将被完全破坏。

为了避免这种信息衰减，我们冻结了一些层。这是通过使层不可训练来实现的。冻结某些层并训练其他层的过程称为网络微调。

# 对预先训练好的网络进行微调

微调意味着调整我们的神经网络，使其与手头的任务更加相关。我们可以冻结网络的一些初始层，这样我们就不会丢失存储在这些层中的信息。存储在那里的信息是通用和有用的。然而，如果我们可以在分类器学习时冻结这些层，然后解冻它们，我们可以稍微调整它们，使它们更好地适应手头的问题。假设我们有一个预先训练好的识别动物的网络。如果我们想识别特定的动物，比如狗和猫，我们可以稍微调整一下图层，这样他们就可以知道狗和猫的样子。这就像使用整个预先训练好的网络，然后添加一个由狗和猫的图像组成的新层。我们将通过使用一个预先构建的网络并在其上添加一个分类器来进行类似的活动，该分类器将在狗和猫的图片上进行训练。

微调有三个要点:

1.  在预先训练的系统上添加一个分类器(`ANN`)。
2.  冻结`convolutional base`并训练网络。
3.  联合训练添加的`classifier`和`convolutional base`的未冻结部分。

## ImageNet 数据集

在真实的实际工作经验中，你几乎从来不需要自己建立一个基础卷积模型。您将始终使用预先训练好的模型。但是你从哪里得到数据呢？对于视觉计算，答案是 ImageNet。ImageNet 数据集是用于视觉对象识别的大型视觉数据库。它由超过 1400 万个带有对象名称的标记图像组成。ImageNet 包含 20，000 多个类别。

## Keras 的一些预先训练的网络

下面的预训练网络可以被认为是基本卷积层。您使用这些网络并安装一个分类器(ANN):

*   `VGG16`
*   `Inception V3`
*   `Xception`
*   `ResNet50`
*   `MobileNet`

不同的供应商已经创建了前面的预训练网络。比如`ResNet50`是由`Microsoft`创造的，而`Inception V3`和`MobileNet`是由`Google`创造的。在本章中，我们将使用`VGG16`和`ResNet50`型号。

`VGG16`是一个 16 层的卷积神经网络模型，由牛津大学的 K. Simonyan 和 A. Zisserman 提出。该模型于 2014 年提交给了`ImageNet Large Scale Visual Recognition Challenge` ( `ILSVRC`)，这是一项用于测试使用`ImageNet`数据集的最先进模型的挑战。`ResNet50`是另一个卷积神经网络，它在有 50 层的`ImageNet`数据集上训练，并在 2015 年的`ILSVRC`中获得第一名。

现在我们了解了这些网络是什么，我们将练习利用这些预先训练好的神经网络用`VGG16`模型对一片比萨饼的图像进行分类。

注意

本章中的所有练习和活动将在 Jupyter 笔记本中展开。请从[https://packt.live/2uI63CC](https://packt.live/2uI63CC)下载这本书的 GitHub 资源库，以及所有准备好的模板。

## 练习 8.01:使用 VGG16 网络识别图像

我们有一张比萨饼的图片。我们将使用`VGG16`网络来处理和识别图像。在完成以下步骤之前，请确保您已经从 GitHub 下载了`pizza`映像，并将其保存到您的工作目录中:

1.  导入库:

    ```
    import numpy as np
    from keras.applications.vgg16 import VGG16
    from keras.preprocessing import image
    from keras.applications.vgg16 import preprocess_input
    ```

2.  Initiate the model:

    ```
    classifier = VGG16()
    ```

    注意

    最后一层预测(`Dense`)有 1000 个值。这意味着`VGG16`总共有 1000 个标签，我们的图像将是这 1000 个标签中的一个。

3.  Load the image. `'../Data/Prediction/pizza.jpg.jpg'` is the path of the image on our system; it will be different on your system:

    ```
    new_image= image.load_img('../Data/Prediction/pizza.jpg.jpg', target_size=(224, 224))
    new_image
    ```

    下图显示了上述代码的输出:

    ![Figure 8.4: An image of a slice of pizza
    ](image/B15777_08_04.jpg)

    图 8.4:一片比萨饼的图像

    目标尺寸应为`224x224`，因为`VGG16`只接受(`224,224`)。

4.  Change the image to an array by using the `img_to_array` function:

    ```
    transformed_image = image.img_to_array(new_image)
    transformed_image.shape
    ```

    上述代码产生以下输出:

    ```
    (224, 224, 3)
    ```

5.  The image has to be in a four-dimensional form for `VGG16` to allow further processing. Expand the dimension of the image, as follows:

    ```
    transformed_image = np.expand_dims(transformed_image, axis=0)
    transformed_image.shape
    ```

    上述代码产生以下输出:

    ```
    (1, 224, 224, 3)
    ```

6.  Preprocess the image using the `preprocess_input` function:

    ```
    transformed_image = preprocess_input(transformed_image)
    transformed_image
    ```

    下图显示了上述代码的输出:

    ![Figure 8.5: A screenshot of image preprocessing
    ](image/B15777_08_05.jpg)

    图 8.5:图像预处理的截图

7.  创建`predictor`变量:

    ```
    y_pred = classifier.predict(transformed_image)
    y_pred
    ```

8.  Check the shape of the image. It should be (`1,1000`). It's `1000` because the `ImageNet` database has `1000` categories of images. The predictor variable shows the probability of our image being one of those images:

    ```
    y_pred.shape
    ```

    上述代码产生以下输出:

    ```
    (1, 1000)
    ```

9.  Print the top five probabilities of what our image is using the `decode_predictions` function and pass the function of the predictor variable, `y_pred`, and the number of predictions and corresponding labels to output:

    ```
    from keras.applications.vgg16 import decode_predictions
    decode_predictions(y_pred,top=5)
    ```

    上述代码产生以下输出:

    ```
    [[('n07873807', 'pizza', 0.97680503),
      ('n07871810', 'meat_loaf', 0.012848727),
      ('n07880968', 'burrito', 0.0019428912),
      ('n04270147', 'spatula', 0.0019108421),
      ('n03887697', 'paper_towel', 0.0009799759)]]
    ```

    数组的第一列是内部代码号。第二个是可能的标签，第三个是图像成为标签的概率。

10.  Put the predictions in a human-readable form. Print the most probable label from the output from the result of the `decode_predictions` function:

    ```
    label = decode_predictions(y_pred)
    # Most likely result is retrieved, for example, the highest probability
    decoded_label = label[0][0]
    # The classification is printed 
    print('%s (%.2f%%)' % (decoded_label[1], decoded_label[2]*100 ))
    ```

    上述代码产生以下输出:

    ```
    pizza (97.68%)
    ```

在本练习中，我们预测了一幅图像，该图像(以`97.68%`概率)显示该图片是比萨饼。显然，这里更高的精度意味着在 ImageNet 数据库中存在与我们的图片相对相似的对象，并且我们的算法已经成功地识别了该图像。在下面的活动中，我们将通过使用`VGG16`网络对摩托车的图像进行分类，将我们的知识付诸实践。

## 活动 8.01:使用 VGG16 网络训练深度学习网络识别图像

给你一张摩托车的图片。使用`VGG16`网络预测图像。在开始之前，确保您已经将图像(`test_image_1`)下载到您的工作目录中。要完成此活动，请遵循以下步骤:

1.  导入所需的库，以及`VGG16`网络。
2.  启动预训练的`VGG16`模型。
3.  加载将要分类的图像。
4.  通过应用变换对图像进行预处理。
5.  创建一个预测变量来预测图像。
6.  Label the image and classify it.

    注意

    这项活动的解决方案可以在第 397 页找到。

至此，我们完成了本次活动。与《T2》第七章、*中的带有卷积神经网络的计算机视觉*不同，我们没有从零开始构建`CNN`。相反，我们使用了一个预先训练好的模型。我们刚刚上传了一张需要分类的图片。由此可见，以`84.33%`的精度，预测是助力车。在下一个练习中，我们将使用 ImageNet 数据库中没有匹配图像的图像。

## 练习 8.02:对 ImageNet 数据库中不存在的图像进行分类

现在，让我们处理一个不属于我们的`VGG16`网络中的`1000`标签的图像。在这个练习中，我们将使用一个竹节虫的图像，在我们预先训练的网络中没有竹节虫的标签。让我们看看我们得到了什么结果:

1.  导入`numpy`库和必要的`Keras`库:

    ```
    import numpy as np
    from keras.applications.vgg16 import VGG16
    from keras.preprocessing import image
    from keras.applications.vgg16 import preprocess_input
    ```

2.  Initiate the model and print a summary of the model:

    ```
    classifier = VGG16()
    classifier.summary()
    ```

    `classifier.summary()`向我们展示了网络的架构。以下是需要注意的几点——它有一个四维输入形状(`None, 224, 224, 3`)，有三个卷积层。下图显示了输出的最后四层:

    ![Figure 8.6: Summary of the image using the VGG16 classifier
    ](image/B15777_08_06.jpg)

    图 8.6:使用 VGG16 分类器的图像摘要

    注意

    最后一层预测(`Dense`)有`1000`个值。这意味着`VGG16`总共有`1000`个标签，我们的形象将是这些`1000`标签中的一个。

3.  Load the image. `'../Data/Prediction/stick_insect.jpg'` is the path of the image on our system. It will be different on your system:

    ```
    new_image = image.load_img('../Data/Prediction/stick_insect.jpg', target_size=(224, 224))
    new_image
    ```

    下图显示了上述代码的输出:

    ![Figure 8.7: Sample stick insect image for prediction
    ](image/B15777_08_07.jpg)

    图 8.7:用于预测的竹节虫样本图像

    目标尺寸应为`224x224`，因为`VGG16`只接受(`224,224`)。

4.  使用`img_to_array`函数:

    ```
    transformed_image = image.img_to_array(new_image)
    transformed_image.shape
    ```

    将图像更改为数组
5.  图像必须是四维形式，以便`VGG16`进行进一步处理。使用`expand_dims`功能:

    ```
    transformed_image = np.expand_dims(transformed_image, axis=0)
    transformed_image.shape
    ```

    沿第 0 轴扩展图像尺寸
6.  Preprocess the image using the `preprocess_input` function:

    ```
    transformed_image = preprocess_input(transformed_image)
    transformed_image
    ```

    下图显示了上述代码的输出:

    ![Figure 8.8: Screenshot showing a few instances of image preprocessing
    ](image/B15777_08_08.jpg)

    图 8.8:显示一些图像预处理实例的屏幕截图

7.  Create the `predictor` variable:

    ```
    y_pred = classifier.predict(transformed_image)
    y_pred
    ```

    下图显示了上述代码的输出:

    ![Figure 8.9: Creating the predictor variable
    ](image/B15777_08_09.jpg)

    图 8.9:创建预测变量

8.  Check the shape of the image. It should be (`1,1000`). It's `1000` because, as we mentioned previously, the ImageNet database has `1000` categories of images. The predictor variable shows the probabilities of our image being one of those images:

    ```
    y_pred.shape
    ```

    前面的代码生成以下代码:

    ```
    (1, 1000)
    ```

9.  Select the top five probabilities of what our image label is out of the `1000` labels that the `VGG16` network has:

    ```
    from keras.applications.vgg16 import decode_predictions
    decode_predictions(y_pred, top=5)
    ```

    前面的代码生成以下代码:

    ```
    [[('n02231487', 'walking_stick', 0.30524516),
      ('n01775062', 'wolf_spider', 0.26035702),
      ('n03804744', 'nail', 0.14323168),
      ('n01770081', 'harvestman', 0.066652186),
      ('n01773549', 'barn_spider', 0.03670299)]]
    ```

    数组的第一列是内部代码。第二个是标签，第三个是图片是标签的概率。

10.  Put the predictions in a human-readable format. Print the most probable label from the output from the result of the `decode_predictions` function:

    ```
    label = decode_predictions(y_pred)
    # Most likely result is retrieved, for example, the highest probability
    decoded_label = label[0][0]
    # The classification is printed
    print('%s (%.2f%%)' % (decoded_label[1], decoded_label[2]*100 ))
    ```

    前面的代码生成以下代码:

    ```
    walking_stick (30.52%)
    ```

    在这里，你可以看到网络预测我们的图像是一个具有`30.52%`准确性的手杖。显然，这个形象不是手杖而是竹节虫；在`VGG16`网络包含的所有标签中，手杖是最接近竹节虫的东西。下图是一根手杖:

![Figure 8.10: Walking stick
](image/B15777_08_10.jpg)

图 8.10:手杖

为了避免这样的输出，我们可以冻结现有的`VGG16`层并添加我们自己的层。我们还可以添加一个包含手杖和竹节虫图像的图层，这样我们可以获得更好的输出。

如果您有大量的手杖和竹节虫图像，您可以执行类似的任务来提高模型将图像分类到各自类别的能力。然后，您可以通过重新运行之前的练习来测试它。

为了详细理解这一点，让我们来看一个不同的例子，我们冻结了网络的最后一层，并添加了我们自己的汽车和鲜花图像层。这将有助于网络提高其对汽车和鲜花图像分类的准确性。我们还将保存模型，以便在以后需要时可以使用它。可以使用 models save 方法保存训练好的模型，并将文件名作为参数传递。保存训练好的模型将把模型结构、学习到的权重、编译参数和优化器状态一起保存在单个 H5 文件中。然后，可以直接加载和使用模型，而不必重新编译或根据训练数据训练模型，这非常有用，因为一些模型需要很长时间来训练。

## 练习 8.03:微调 VGG16 模型

让我们对`VGG16`模型进行微调。在本练习中，我们将冻结网络并删除最后一层`VGG16`，其中有`1000`标签。去掉最后一层后，我们将建立一个新的花车分类器`ANN`，就像我们在*第七章*、*计算机视觉与卷积神经网络*中所做的一样，并将这个`ANN`连接到`VGG16`，而不是原来那个带有`1000`标签的。本质上，我们要做的是用一个用户定义的层替换`VGG16`的最后一层。

在我们开始之前，请确保您已经从本书的 GitHub 存储库中将图像数据集下载到您自己的工作目录中。您将需要一个`training_set`文件夹和一个`test_set`文件夹来测试您的模型。每个文件夹都包含一个包含汽车图片的`cars`文件夹和一个包含花卉图片的`flowers`文件夹。

完成本练习的步骤如下:

注意

与最初的新模型不同，它有`1000`标签(`100`不同的对象类别)，这个新的微调模型将只有花或汽车的图像。因此，无论你提供什么样的图像作为模型的输入，它都会根据它的预测概率将其归类为花或车。

1.  导入`numpy`库，TensorFlow 的`random`库，以及必要的`Keras`库:

    ```
    import numpy as np
    import keras
    from keras.layers import Dense
    from tensorflow import random
    ```

2.  启动`VGG16`模式:

    ```
    vgg_model = keras.applications.vgg16.VGG16()
    ```

3.  Check the model `summary`:

    ```
    vgg_model.summary()
    ```

    下图显示了上述代码的输出:

    ![Figure 8.11: Model summary after initiating the model
    ](image/B15777_08_11.jpg)

    图 8.11:启动模型后的模型摘要

4.  Remove the last layer, `labeled predictions` in the preceding image, from the model summary. Create a new Keras model of the sequential class and iterate through all the layers of the VGG model. Add all of them to the new model, except for the last layer:

    ```
    last_layer = str(vgg_model.layers[-1])
    np.random.seed(42)
    random.set_seed(42)
    classifier= keras.Sequential()
    for layer in vgg_model.layers:
        if str(layer) != last_layer:
            classifier.add(layer)
    ```

    注意

    代码解释:这里，我们创建了一个新的模型名称的分类器，而不是`vgg_model`。除了最后一层，即`vgg_model`之外的所有层都已经包含在分类器中。

5.  Print the `summary` of the newly created model:

    ```
    classifier.summary()
    ```

    下图显示了上述代码的输出:

    ![Figure 8.12: Rechecking the summary after removing the last layer
    ](image/B15777_08_12.jpg)

    图 8.12:删除最后一层后重新检查摘要

    最后一层预测(`Dense`)已删除。

6.  通过迭代图层并将`trainable`参数设置为`False` :

    ```
    for layer in classifier.layers:
        layer.trainable=False
    ```

    来冻结图层
7.  Add a new output layer of size `1` with a `sigmoid` activation function and print the model summary:

    ```
    classifier.add(Dense(1, activation='sigmoid'))
    classifier.summary()
    ```

    下面的函数显示了前面代码的输出:

    ![Figure 8.13: Rechecking the summary after adding the new layer
    ](image/B15777_08_13.jpg)

    图 8.13:添加新层后重新检查摘要

    现在，最后一层是新创建的用户定义层。

8.  Compile the network with an `adam` optimizer and binary cross-entropy loss and compute the `accuracy` during training:

    ```
    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    ```

    创建一些训练和测试数据生成器，就像我们在*第 7 章*、*使用卷积神经网络的计算机视觉*中所做的那样。通过`1/255`重新缩放训练和测试图像，使所有值都在`0`和`1`之间。仅为训练数据发生器设置以下参数:`shear_range=0.2`、`zoom_range=0.2`和`horizontal_flip=True`。

    接下来，从`training set`文件夹中创建一个训练集。`../Data/dataset/training_set`是存放我们数据的文件夹。我们的 CNN 模型有一个`224x224`的图像大小，所以这里也应该传递相同的大小。`batch_size`是单批图像的数量，也就是`32`。`class_mode`是二元的，因为我们正在创建一个二元分类器。

    注意

    与《T2》第七章、*中带有卷积神经网络的计算机视觉*中图像大小为`64x64`不同，VGG16 需要图像大小为`224x224`。

    最后，将模型拟合到训练数据:

    ```
    from keras.preprocessing.image import ImageDataGenerator
    generate_train_data = ImageDataGenerator(rescale = 1./255,
                                       shear_range = 0.2,
                                       zoom_range = 0.2,
                                       horizontal_flip = True)
    generate_test_data = ImageDataGenerator(rescale =1./255)
    training_dataset = generate_train_data.flow_from_directory('../Data/dataset/training_set',
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'binary')
    test_datasetset = generate_test_data.flow_from_directory('../Data/dataset/test_set',
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'binary')
    classifier.fit_generator(training_dataset,
                             steps_per_epoch = 100,
                             epochs = 10,
                             validation_data = test_datasetset,
                             validation_steps = 30,
                             shuffle=False)
    ```

    这里有 100 个训练图像，所以设置`steps_per_epoch =100`，设置`validation_steps=30`，设置`shuffle=False`:

    ```
    100/100 [==============================] - 2083s 21s/step - loss: 0.5513 - acc: 0.7112 - val_loss: 0.3352 - val_acc: 0.8539
    ```

9.  预测新图像(代码与第七章*、*带卷积神经网络的计算机视觉*中的代码相同)。首先，从`'../Data/Prediction/test_image_2.jpg'`加载图像，并将目标尺寸设置为(`224, 224`)，因为`VGG16`模型接受该尺寸的图像。*
10.  接下来，对图像进行预处理，首先使用`img_to_array`函数将图像转换成一个数组，然后使用`expand_dims`函数沿着第 0 轴添加另一个维度。
11.  Finally, make the prediction using the `predict` method of the classifier and printing the output in human-readable format:

    ```
    from keras.preprocessing import image
    new_image = image.load_img('../Data/Prediction/test_image_2.jpg', target_size = (224, 224))
    new_image = image.img_to_array(new_image)
    new_image = np.expand_dims(new_image, axis = 0)
    result = classifier.predict(new_image)
    training_set.class_indices
    if result[0][0] == 1:
        prediction = 'It is a flower'
    else:
        prediction = 'It is a car'
    print(prediction)
    ```

    上述代码产生以下输出:

    ```
    It is a car
    ```

12.  使用模型保存方法将模型和学习到的重量保存到 H5 文件:

    ```
    classifier.save('car-flower-classifier.h5')
    ```

在这里，我们可以看到算法通过识别汽车的图像，完成了正确的图像分类。我们只是使用了一个预建的`VGG16`模型来进行图像分类，调整了它的图层，并按照我们的要求进行了建模。这是一种非常强大的图像分类技术。模型完成训练后，我们将模型和学习到的参数保存为 H5 文件。可以使用从`keras.models`导入的`load_model`函数，并传递模型的文件名，将模型加载到内存中。在下一个练习中，我们将利用不同的预训练模型，称为`ResNet50`，并演示如何使用该模型对图像进行分类。

## 练习 8.04:使用 ResNet 进行图像分类

最后，在结束本章之前，让我们用`ResNet50`网络做一个练习。我们将使用一个纳斯卡赛车的图像，并试图通过网络预测它。按照以下步骤完成本练习:

1.  导入必要的库:

    ```
    import numpy as np
    from keras.applications.resnet50 import ResNet50, preprocess_input
    from keras.preprocessing import image 
    ```

2.  Initiate the `ResNet50` model and print the `summary` of the model:

    ```
    classifier = ResNet50()
    classifier.summary()
    ```

    下图显示了上述代码的输出:

    ![Figure 8.14: A summary of the model
    ](image/B15777_08_14.jpg)

    图 8.14:模型的总结

3.  Load the image. `'../Data/Prediction/test_image_3.jpg'` is the path of the image on our system. It will be different on your system:

    ```
    new_image = image.load_img('../Data/Prediction/test_image_3.jpg', target_size=(224, 224))
    new_image
    ```

    下图显示了上述代码的输出:

    ![Figure 8.15: Sample Nascar racer image for prediction
    ](image/B15777_08_15.jpg)

    图 8.15:用于预测的样本 Nasca r 赛车图像

    注意，目标大小应该是`224x224`，因为`ResNet50`只接受(`224,224`)。

4.  使用`img_to_array`函数:

    ```
    transformed_image = image.img_to_array(new_image)
    transformed_image.shape
    ```

    将图像更改为数组
5.  图像必须是四维形式，以便`ResNet50`进行进一步处理。使用`expand_dims`功能:

    ```
    transformed_image = np.expand_dims(transformed_image, axis=0)
    transformed_image.shape
    ```

    沿第 0 轴扩展尺寸
6.  使用`preprocess_input`功能对图像进行预处理:

    ```
    transformed_image = preprocess_input(transformed_image)
    transformed_image
    ```

7.  使用分类器创建预测变量，以使用其`predict`方法:

    ```
    y_pred = classifier.predict(transformed_image)
    y_pred
    ```

    预测图像
8.  Check the shape of the image. It should be (`1,1000`):

    ```
    y_pred.shape
    ```

    上述代码产生以下输出:

    ```
    (1, 1000)
    ```

9.  Select the top five probabilities of what our image is using the `decode_predictions` function and by passing the predictor variable, `y_pred`, as the argument and the top number of predictions and corresponding labels:

    ```
    from keras.applications.resnet50 import decode_predictions
    decode_predictions(y_pred, top=5)
    ```

    上述代码产生以下输出:

    ```
    [[('n04037443', 'racer', 0.8013074),
      ('n04285008', 'sports_car', 0.06431753),
      ('n02974003', 'car_wheel', 0.024077434),
      ('n02504013', 'Indian_elephant', 0.019822922),
      ('n04461696', 'tow_truck', 0.007778575)]]
    ```

    数组的第一列是内部代码。第二个是标签，第三个是图片是标签的概率。

10.  Put the predictions in a human-readable format. Print the most probable label from the output from the result of the `decode_predictions` function:

    ```
    label = decode_predictions(y_pred)
    # Most likely result is retrieved, for example, the highest probability
    decoded_label = label[0][0]
    # The classification is printed
    print('%s (%.2f%%)' % (decoded_label[1], decoded_label[2]*100 ))
    ```

    上述代码产生以下输出:

    ```
    racer (80.13%)
    ```

在这里，模型清楚地显示(概率为`80.13%`)图片是一个赛车手的图片。这就是预训练模型的力量，Keras 让我们可以灵活地使用和调整这些模型。在下一个活动中，我们将使用预训练的`ResNet50`模型对另一幅图像进行分类。

## 活动 8.02: 使用 ResNet 进行图像分类

现在，让我们进行一项活动，它使用另一个预先训练好的网络，称为`ResNet`。我们有一个位于`../Data/Prediction/test_image_4`的电视图像。我们将使用`ResNet50`网络来预测图像。要实施活动，请遵循以下步骤:

1.  导入所需的库。
2.  启动`ResNet`模式。
3.  加载需要分类的图像。
4.  通过应用适当的变换对图像进行预处理。
5.  创建一个预测变量来预测图像。
6.  Label the image and classify it.

    注意

    这项活动的解决方案可在第 401 页找到。

因此，该网络以接近于`100%`的准确度称，该图像是一台电视机的图像。这一次，我们使用了一个`ResNet50`预训练模型对电视图像进行分类，并获得了与我们使用`VGG16`模型预测一片披萨图像类似的结果。

# 总结

在本章中，我们介绍了迁移学习的概念，以及它与预训练网络的关系。我们通过使用预先训练的深度学习网络`VGG16`和`ResNet50`来利用这些知识来预测各种图像。我们练习了如何利用这种预训练的网络，使用诸如特征提取和微调之类的技术来更快更准确地训练模型。最后，我们学习了调整现有模型并使它们根据我们的数据集工作的强大技术。这种在现有的`CNN`上建造我们自己的`ANN`的技术是业内使用的最强大的技术之一。

在下一章中，我们将通过使用 Google Assistant 查看一些真实案例来了解顺序建模和顺序记忆。此外，我们将了解顺序建模如何与`Recurrent Neural Networks` ( `RNN`)相关联。我们将详细了解消失梯度问题，以及如何使用`LSTM`比简单的`RNN`更好地克服消失梯度问题。我们将通过预测相当准确的股票趋势，将我们所学的知识应用于时间序列问题。
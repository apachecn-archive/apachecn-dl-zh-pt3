

# 七、基于 LSTM 网络的股票价格预测

股票市场价格预测是最具挑战性的任务之一。一个主要原因是噪声和这种类型数据集的不稳定特性。因此，如何准确地预测股票价格运动对于现代交易世界来说仍然是一个悬而未决的问题。然而，经典的机器学习算法，如支持向量机、决策树和树集成(例如，随机森林和梯度增强树)，已经在过去十年中使用。

然而，股票市场价格具有剧烈的波动性和历史视角，这使得它们适合于时间序列分析。这也对那些经典算法提出了挑战，因为使用那些算法不能利用长期依赖性。考虑到这些挑战和现有算法的局限性，在本章中，我们将看到如何在 DL4J 库的基础上使用 LSTM 开发一个真实的普通股票开盘价或收盘价预测。

从现实生活中的股票数据集生成的时间序列数据集将用于训练 LSTM 模型，该模型每次仅用于预测未来一天。简而言之，我们将在这个端到端项目中学习以下主题:

*   股票价格预测和网上交易
*   数据收集和描述
*   用 LSTM 预测股票价格
*   常见问题。



# 最先进的自动股票交易

通常，在证券交易所中，交易所维护所有买卖订单的订单簿列表及其数量和价格，当发现有人在买卖之间匹配时，它们执行这些订单。此外，交易所还保存并提供有关国有交易的统计数据，通常以一对交易者的两种货币的**OHCL**(T2 的简称，开盘-盘高-收盘-盘低)和交易量的形式获取。

顺便说一下，条形图被用来显示开盘价、最高价、最低价和收盘价。与折线图不同，OHLC 图使技术分析师能够评估日内波动，并看到价格的开盘价和收盘价。请看这张图表:

![](assets/82d2422a-194a-432b-ba95-c5cb07a2f637.png)

显示特定时间段的开盘价、最高价、最低价和收盘价的 OHLC 定价模型(来源:http://en.tradimo.com/tradipedia/ohlc-chart/)

这些数据在某些时段以聚合的形式呈现，从几秒到几天，甚至几个月。有专门的服务器为专业交易者和机构收集这些数据。虽然你不能指望所有的订单数据都是免费的，但其中一些数据是公众可以访问和使用的。第一组是历史股票交易数据(OHLC)，第二组包含股票交易的技术指标。

例如，作为首批加密货币之一的比特币已经引起了投资者和交易者的兴趣。这是因为以下原因:

*   有了比特币，才有可能开始交易
*   比特币允许你保持伪匿名
*   在比特币的历史上，它经历了戏剧性的增长(见下图的一些统计数据)，这吸引了长期投资者
*   波动性很大，这吸引了日内交易者

很难预测比特币的长期价值，因为比特币背后的价值不太明显，其价格主要反映了市场看法，并高度依赖于新闻、监管、政府和银行的合作、平台的技术问题，如交易费用和区块大小、机构投资者对将比特币纳入其投资组合的兴趣等。看看这张截图:

![](assets/5ff3ea00-951a-4fdb-81e1-cff8e2922efb.jpg)

比特币及其直到 2017 年 9 月的大幅涨价(来源:http://www.bitcoin2040.com/bitcoin-price-history/)

现在的问题是如何以自动化的方式分析这个数据集，以帮助投资者或在线外汇交易者。在传统证券领域，比如公司股票，过去是由人来做分析、预测股价和进行交易。目前，与传统交易所相比，比特币的交易量相对较低。其中的两个原因是股票市场的高波动性和加密货币的监管。请看这张图表:

![](assets/71929ab3-01a2-46fa-8a9d-fee88f1af575.png)

BTC/美元对的比特币买卖单(截止 2018 年 6 月 18 日，来源:https://cex.io/trade#)

因此，今天，人们大多买卖比特币，所有非理性行为的后果都与此相关，但已经有人尝试自动化比特币交易。最著名的是麻省理工学院和斯坦福大学研究人员的一篇论文，发表于 2014 年。

许多事情都变了，考虑到过去三年比特币价格的大幅上涨，任何人只要购买并持有就会对结果足够满意。肯定的是，一些交易者使用**机器学习** ( **ML** )进行交易，这样的应用看起来很有前景。到目前为止，几种可能的最佳方法。

对于训练，使用订单数据而不是导出的 *OHLC +成交量数据*。因此，对于定型和预测，请按以下方式使用数据:

*   将数据分割成一定大小的时间序列(其中大小是要调整的参数)。
*   将时间序列数据聚类成 *K* 个聚类，其中 *K* 是唯一要调整的参数。假设会出现一些自然趋势的集群(价格大幅下跌/上涨等)。
*   对于每个分类，训练回归/分类器分别预测价格和价格变化。

对于推理和评估，该方法考虑具有特定窗口大小的最近时间序列，并训练模型。然后，它将数据分类如下:

*   它采用具有用于训练的窗口大小的最新时间序列，并对其进行分类——它属于哪个聚类？
*   它使用 ML 模型来预测价格和价格变化的分类

这个解决方案来自 2014 年，但是，它仍然提供了一定程度的健壮性。在这个项目中，由于需要识别许多参数，并且没有可用的订单历史数据，所以我们使用了一种更简单的方法和数据集。



# 开发股票价格预测模型

如前所述，股票市场价格具有剧烈的波动性和历史视角，这使得它适合于时间分析。这也对那些经典算法提出了挑战，因为使用那些算法不能利用长期依赖性。

如下图所示，首先我们收集历史财务数据。在必要的预处理和特征工程之后，数据被转换成时间序列。由此产生的时间序列数据然后被输入 LSTM 进行训练。下图说明了这一点:

![](assets/f14e1f05-03e4-49e8-b51d-2cb98fb5e010.png)

用于此项目的原型的高级数据管道

因此，我们将使用 LSTM，不仅因为它优于经典算法，而且因为我们可以用它来解决长期的依赖性。因此，我们的项目将有以下步骤:

1.  加载和预处理数据，并将其分成训练集和测试集
2.  用数据训练`LSTM`模型
3.  根据测试数据评估模型
4.  可视化模型的性能

我们将详细介绍每一步。然而，在此之前，了解数据集是强制性的。



# 数据收集和探索性分析

如前所述，我们将利用历史股票数据来训练我们的 LSTM 网络。该数据集包含 2016 年 1 月至 2016 年 12 月期间 506 种不同证券的一分钟 OHLC 数据。让我们来看看我们将使用的数据:

```
//DataPreview.java
SparkSession spark = SparkSession.*builder*().master("local").appName("StockPricePredictor").getOrCreate();
spark.conf().set("spark.sql.crossJoin.enabled", "true");//enables cross joining across Spark DataFrames

// load data from csv file
String filename = "data/prices-split-adjusted.csv"; 
Dataset<Row> data = spark.read().option("inferSchema", false).option("header", true)
       .format("csv").load(filename)
             .withColumn("openPrice", functions.*col*("open").cast("double")).drop("open")
             .withColumn("closePrice", functions.*col*("close").cast("double")).drop("close")
             .withColumn("lowPrice", functions.*col*("low").cast("double")).drop("low")
             .withColumn("highPrice", functions.*col*("high").cast("double")).drop("high")
             .withColumn("volumeTmp", functions.*col*("volume").cast("double")).drop("volume")
             .toDF("date", "symbol", "open", "close", "low", "high", "volume");
data.show(10);
```

以下快照显示了此代码的输出:

![](assets/208ceae0-fcfb-426c-8b6a-9155f4a640b9.png)

此项目中使用的历史数据集的快照

如前面的屏幕截图所示，我们的数据集有七个特征。它们描述如下:

*   `date`:2016 年 1 月到 2016 年 12 月之间的时间
*   `symbol`:506 种不同证券的股票代码
*   `open`:时段开盘时的价格
*   `close`:时段收盘时的价格
*   `high`:区间内执行的所有订单的最高价
*   一样，但价格最低
*   `volume`:该时间间隔内转让的所有股票的总和

现在让我们来看看一些股票代号(详见`securities.csv`文件):

```
data.createOrReplaceTempView("stock");
spark.sql("SELECT DISTINCT symbol FROM stock GROUP BY symbol").show(10);
```

is 快照显示了前面代码的输出:

![](assets/f37203cb-a74a-45d1-a265-b15798aa6f39.png)

此项目中使用了其股票价格数据的一些符号

如果我们需要了解证券，下表可以让我们对此有所了解:

![](assets/3a316da5-b3f4-456e-8f19-ae25733137ce.png)

一些证券及其详细信息，其股票价格数据用于本项目

然后，我们决定查看所有单个证券的四个类别(开盘、收盘、盘低和盘高)的平均价格。看一下这段代码:

```
spark.sql("SELECT symbol, avg(open) as avg_open, "
                + "avg(close) as avg_close, "
                + "avg(low) as avg_low, "
                + "avg(high) as avg_high "
                + "FROM stock GROUP BY symbol")
                .show(10); 
```

此快照显示了前面代码的输出:

![](assets/0d3ef10e-1382-4c28-925b-47e88fdf52dd.png)

开盘、收盘、盘低和盘高类别的平均价格

然而，上表除了涉及平均价格之外，没有提供太多的信息。因此，知道了最低和最高价格，我们就有了一个概念，股票市场是否真的具有非常高的波动性。看一下这段代码:

```
spark.sql("SELECT symbol, "
                + "MIN(open) as min_open, MAX(open) as max_open, "
                + "MIN(close) as min_close, MAX(close) as max_close, "
                + "MIN(low) as min_low, MAX(low) as max_low, "
                + "MIN(high) as min_high, MAX(high) as max_high "
                + "FROM stock GROUP BY symbol")
                .show(10);   
```

该快照显示了代码的输出:

![](assets/04cd7d7a-8537-4109-82b3-ad82144cae72.png)

开盘、收盘、盘低和盘高类别的平均最高价和最低价

例如，该表显示最低开盘价和收盘价没有显著差异。然而，最高开盘价甚至收盘价却大相径庭。这是时间序列数据的本质，它促使我通过将数据转换成时间序列来选择`LSTM`。



# 准备训练集和测试集

数据科学管道中最重要的部分之一，在数据收集(在某种意义上是外包的，我们使用他人收集的数据)之后，是数据预处理，即清除数据集并转换它以适应我们的需求。

因此，我们的目标是从美元的实际价格预测价格随时间变化的方向。为此，我们定义了诸如`file`、`symbol`、`batchSize`、`splitRatio`和`epochs`这样的变量。您可以在这段代码的行内注释中看到每个变量的解释:

```
// StockPricePrediction.java
String file = "data/prices-split-adjusted.csv";
String symbol = "GRMN"; // stock name
int batchSize = 128; // mini-batch size
double splitRatio = 0.8; // 80% for training, 20% for testing
int epochs = 100; // training epochs
```

我们使用`StockDataSetIterator`构造函数变量为模型准备数据集。这里，我们为模型准备输入数据集作为`category = PriceCategory.ALL`的序列格式，这意味着我们将预测所有五个价格类别(开盘、收盘、盘低、盘高和成交量)。看一下这段代码:

```
//StockPricePrediction.java
System.*out*.println("Creating dataSet iterator...");
PriceCategory category = PriceCategory.*ALL*; // CLOSE: predict close price

*iterator* = new StockDataSetIterator(file, symbol, batchSize, *exampleLength*, splitRatio, category);
System.*out*.println("Loading test dataset...");
List<Pair<INDArray, INDArray>> test = *iterator*.getTestDataSet();
```

在前面的代码块中，我们使用的`PriceCategory`构造函数具有以下签名:

```
public enum PriceCategory {
      OPEN, CLOSE, LOW, HIGH, VOLUME, ALL}
```

在同一行中，以下选项也有效:

```
PriceCategory category = PriceCategory.OPEN; // OPEN: predict open price
PriceCategory category = PriceCategory.CLOSE; // CLOSE: predict close price
PriceCategory category = PriceCategory.LOW; // LOW: predict low price
PriceCategory category = PriceCategory.HIGH; // HIGH: predict high price.
```

然而，在内部，`StockDataSetIterator`类的构造函数具有以下功能:

*   我们从文件中读取股票数据，并为每个符号创建一个列表
*   我们将`miniBatchSize`、`exampleLength`和`category`变量设置为类属性
*   然后基于`splitRation`变量计算`split`变量
*   我们将`stockDataList`分成两部分:训练和测试
*   然后，股票数据被分成训练集和测试集
*   我们调用函数`initializeOffsets()`来为数组`exampleStartOffsets`取初始值

在此之后，`StockDataSetIterator()`构造函数具有以下签名，它生成测试数据集作为`List<Pair<INDArray, INDArray>>`:

```
//StockDataSetIterator.java
/** stock dataset for training */
private List<StockData> train;
```

在下面的代码中，`StockData`是一个 case 类，它提供了要从输入`CSV`文件中提取或准备的数据集的结构:

```
//StockData.java
private String date; // date
private String symbol; // stock name

private double open; // open price
private double close; // close price
private double low; // low price
private double high; // high price
private double volume; // volume

public StockData () {}

public StockData (String date, String symbol, double open, double close, double low, double high, double volume) {
        this.date = date;
        this.symbol = symbol;
        this.open = open;
        this.close = close;
        this.low = low;
        this.high = high;
        this.volume = volume;
    }
```

然后，我们为上述变量提供了以下 getter 和 setter 方法，如下所示:

```
public String getDate() { return date; }
public void setDate(String date) { this.date = date; }

public String getSymbol() { return symbol; }
public void setSymbol(String symbol) { this.symbol = symbol; }

public double getOpen() { return open; }
public void setOpen(double open) { this.open = open; }

public double getClose() { return close; }
public void setClose(double close) { this.close = close; }

public double getLow() { return low; }
public void setLow(double low) { this.low = low; }

public double getHigh() { return high; }
public void setHigh(double high) { this.high = high; }

public double getVolume() { return volume; }
public void setVolume(double volume) { this.volume = volume; }
```

现在我们已经看到了`StockData.java`类的签名，是时候创建测试数据集为`StockDataSetIterator`:

```
/** adjusted stock dataset for testing */
private List<Pair<INDArray, INDArray>> test;

public StockDataSetIterator (String filename, String symbol, int miniBatchSize, int exampleLength, 
        double splitRatio, PriceCategory category) {
        List<StockData> stockDataList = readStockDataFromFile(filename, symbol);

        this.miniBatchSize = miniBatchSize;
        this.exampleLength = exampleLength;
        this.category = category;

        int split = (int) Math.round(stockDataList.size() * splitRatio);
        train = stockDataList.subList(0, split);
        test = generateTestDataSet(stockDataList.subList(split, stockDataList.size()));
        initializeOffsets();
    }
```

在前面的方法中，调用了`initializeOffsets()`方法来初始化小批量偏移量:

```
private void initializeOffsets() {
        exampleStartOffsets.clear();
        int window = exampleLength + predictLength;
        for(int i = 0; i < train.size() - window; i++) {
              exampleStartOffsets.add(i); 
                }
    }
```

使用`readStockDataFromFile()`方法完成实际读数。在构造函数内部，首先，我们调用函数`readStockDataFromFile()`从文件中读取数据并将其加载到`stockDataList`。然后我们初始化`StockDataList`列表来包含从`csv`文件中读取的数据。

接下来，我们用`Double.MIN_VALUE`和`Double.MAX_VALUE`初始化 min 数组中的 max。然后逐行读取`CSV`文件中的五个值。这些值随后被插入到`StockData`对象的构造函数中，我们将这个对象添加到`StockDataList`。此外，如果我们有任何异常，我们抛出。最后，方法返回`StockDataList`。该方法的签名如下:

```
private List<StockData> readStockDataFromFile (String filename, String symbol) {
        List<StockData> stockDataList = new ArrayList<>();
        try {
            for(int i = 0; i < maxArray.length; i++) { // initialize max and min arrays
                maxArray[i] = Double.MIN_VALUE;
                minArray[i] = Double.MAX_VALUE;
            }
            List<String[]> list = new CSVReader(new FileReader(filename)).readAll();//load as a list
            for(String[] arr : list) {
                if(!arr[1].equals(symbol)) continue;
                double[] nums = new double[VECTOR_SIZE];

                for(int i = 0; i < arr.length - 2; i++) {
                    nums[i] = Double.valueOf(arr[i + 2]);

                    if(nums[i] > maxArray[i]) maxArray[i] = nums[i];
                    if(nums[i] < minArray[i]) minArray[i] = nums[i];
                }
                stockDataList.add(new StockData(arr[0], arr[1], nums[0], nums[1], 
                                  nums[2], nums[3], nums[4]));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
        return stockDataList;
    }
```

然后，`generateTestDataSet()`方法实际上生成了仅可由`LSTM`模型消费的特性作为`List<Pair<INDArray, INDArray>>`，其中排序被设置为`f`以便更快地构建:

```
private List<Pair<INDArray, INDArray>> generateTestDataSet (List<StockData> stockDataList) {
        int window = exampleLength + predictLength;
        List<Pair<INDArray, INDArray>> test = new ArrayList<>();

        for (int i = 0; i < stockDataList.size() - window; i++) {
            INDArray input = Nd4j.create(new int[] {exampleLength, VECTOR_SIZE}, 'f');

            for (int j = i; j < i + exampleLength; j++) {
                StockData stock = stockDataList.get(j);
                input.putScalar(new int[] {j - i, 0}, (stock.getOpen() - minArray[0]) / (maxArray[0] - 
                     minArray[0]));
                input.putScalar(new int[] {j - i, 1}, (stock.getClose() - minArray[1]) / (maxArray[1] -    
                     minArray[1]));
                input.putScalar(new int[] {j - i, 2}, (stock.getLow() - minArray[2]) / (maxArray[2] - 
                     minArray[2]));
                input.putScalar(new int[] {j - i, 3}, (stock.getHigh() - minArray[3]) / (maxArray[3] - 
                     minArray[3]));
                input.putScalar(new int[] {j - i, 4}, (stock.getVolume() - minArray[4]) / (maxArray[4] - 
                       minArray[4]));
            }
            StockData stock = stockDataList.get(i + exampleLength);
            INDArray label;

            if (category.equals(PriceCategory.ALL)) {
                label = Nd4j.create(new int[]{VECTOR_SIZE}, 'f'); // ordering is set faster construct
                label.putScalar(new int[] {0}, stock.getOpen());
                label.putScalar(new int[] {1}, stock.getClose());
                label.putScalar(new int[] {2}, stock.getLow());
                label.putScalar(new int[] {3}, stock.getHigh());
                label.putScalar(new int[] {4}, stock.getVolume());
            } else {
                label = Nd4j.create(new int[] {1}, 'f');
                switch (category) {
                    case OPEN: label.putScalar(new int[] {0}, stock.getOpen()); break;
                    case CLOSE: label.putScalar(new int[] {0}, stock.getClose()); break;
                    case LOW: label.putScalar(new int[] {0}, stock.getLow()); break;
                    case HIGH: label.putScalar(new int[] {0}, stock.getHigh()); break;
                    case VOLUME: label.putScalar(new int[] {0}, stock.getVolume()); break;
                    default: throw new NoSuchElementException();
                }
            }
            test.add(new Pair<>(input, label));
        }
        return test;
    }
```

在前面的代码块中，我们将`miniBatchSize`、`exampleLength`和`category`变量保存为类属性。然后我们根据`splitRation`变量计算`split`变量。然后我们将`stockDataList`分成两部分:

*   从开始到`split`的索引属于训练集
*   从 split+1 开始到列表末尾的索引属于测试集。

生成的测试数据与训练数据集非常不同。调用函数`generatedTestDataSet()`来设置测试数据集。首先，我们通过示例长度和预测长度设置一个窗口变量。然后我们从 0 开始循环测试数据长度减去窗口。考虑以下情况:

*   读取五个输入变量:开盘价、收盘价、最低价、最高价和成交量。
*   基于`category`的值，读取标签值。如果`category`等于`ALL`，则读取输入变量等五个变量。否则，通过`category`的值只读取一个变量。

在前面的代码块中，使用`feedLabel()`方法输入标签，如下所示:

```
private double feedLabel(StockData data) {
        double value;

        switch(category) {
            case OPEN: value = (data.getOpen() - minArray[0]) / (maxArray[0] - minArray[0]); break;
            case CLOSE: value = (data.getClose() - minArray[1]) / (maxArray[1] - minArray[1]); break;
            case LOW: value = (data.getLow() - minArray[2]) / (maxArray[2] - minArray[2]); break;
            case HIGH: value = (data.getHigh() - minArray[3]) / (maxArray[3] - minArray[3]); break;
            case VOLUME: value = (data.getVolume() - minArray[4]) / (maxArray[4] - minArray[4]); break;
            default: throw new NoSuchElementException();
        }
        return value;
    }
```

在前面的代码块中，我们初始化了变量`value`。然后我们检查变量`category`的值，变量`value`的计算值可以用如下数学符号表示:

`value = (data.getOpen() - minArray[0]) / (maxArray[0] - minArray[0])`

然后使用要素和标注来准备数据集。看一下这段代码:

```
public DataSet next(int num) {
        if(exampleStartOffsets.size() == 0) throw new NoSuchElementException();
        int actualMiniBatchSize = Math.min(num, exampleStartOffsets.size());

        INDArray input = Nd4j.create(new int[] {actualMiniBatchSize, VECTOR_SIZE, exampleLength}, 'f');
        INDArray label;

        if(category.equals(PriceCategory.ALL)) 
            label = Nd4j.create(new int[] {actualMiniBatchSize, VECTOR_SIZE, exampleLength}, 'f');
        else 
            label = Nd4j.create(new int[] {actualMiniBatchSize, predictLength, exampleLength}, 'f');

        for(int index = 0; index < actualMiniBatchSize; index++) {
            int startIdx = exampleStartOffsets.removeFirst();
            int endIdx = startIdx + exampleLength;

            StockData curData = train.get(startIdx);
            StockData nextData;

            for(int i = startIdx; i < endIdx; i++) {
                int c = i - startIdx;
                input.putScalar(new int[] {index, 0, c}, (curData.getOpen() - minArray[0]) 
                                 / (maxArray[0] - minArray[0]));
                input.putScalar(new int[] {index, 1, c}, (curData.getClose() - minArray[1]) 
                                 / (maxArray[1] - minArray[1]));
                input.putScalar(new int[] {index, 2, c}, (curData.getLow() - minArray[2]) 
                                 / (maxArray[2] - minArray[2]));
                input.putScalar(new int[] {index, 3, c}, (curData.getHigh() - minArray[3]) 
                                 / (maxArray[3] - minArray[3]));
                input.putScalar(new int[] {index, 4, c}, (curData.getVolume() - minArray[4]) 
                                 / (maxArray[4] - minArray[4]));
                nextData = train.get(i + 1);

                if(category.equals(PriceCategory.ALL)) {
                    label.putScalar(new int[] {index, 0, c}, (nextData.getOpen() - minArray[1]) 
                                    / (maxArray[1] - minArray[1]));
                    label.putScalar(new int[] {index, 1, c}, (nextData.getClose() - minArray[1]) 
                                   / (maxArray[1] - minArray[1]));
                    label.putScalar(new int[] {index, 2, c}, (nextData.getLow() - minArray[2]) 
                                   / (maxArray[2] - minArray[2]));
                    label.putScalar(new int[] {index, 3, c}, (nextData.getHigh() - minArray[3]) 
                                   / (maxArray[3] - minArray[3]));
                    label.putScalar(new int[] {index, 4, c}, (nextData.getVolume() - minArray[4]) 
                                   / (maxArray[4] - minArray[4]));
                } else {
                    label.putScalar(new int[]{index, 0, c}, feedLabel(nextData));
                }
                curData = nextData;
            }
            if(exampleStartOffsets.size() == 0) break;
        }
        return new DataSet(input, label);
    }
```

在前面的代码块中，我们循环通过`epochs`时间，并且对于每一次循环，直到我们得到数据，用数据获取函数`iterator.next()`来拟合网络。请考虑以下情况:

*   我们初始化两个变量:使用`actualMinibatchSize`初始化`input`，使用`category`初始化`label`。
*   然后我们从 0 到`actualMiniBatchSize`循环。每次，我们创建两个额外的变量:`curData`，它是当前时间的一个`StockData`点。然后我们把它们的值放入`input`列表。类似地，`nextData`变量也是一天中的`StockData`点，在`curData`日之后。最后，我们把`nextData`的值放到`label`列表中。



# LSTM 网络建设

如前所述，我编写了一个名为`RecurrentNets.java`的类来构建一个 LSTM 网络。我们创建一个`MultilayerNetwork` LSTM 网络，它由一个输入层、四个 LSTM 层、三个密集层和一个输出层组成。输入由遗传变异序列组成。

我们使用带有两个参数的`BuildBuildLstmNetworks()`方法——输入层的输入数和输出层的输出数，如下所示:

```
private static final int lstmLayer1Size = 128;
private static final int lstmLayer2Size = 128;
private static final int denseLayerSize = 32;
private static final double dropoutRatio = 0.5;
private static final int truncatedBPTTLength = 22;
```

现在，在我们开始创建和构建网络之前，让我们看看我们的模型是什么样子的:

![](assets/f4bfded0-ee1e-4a5e-9966-35f85db1c7b5.png)

股票价格 LSTM 网

然后，使用`createAndBuildLstmNetworks()`方法创建和构建具有前述参数设置的网络:

```
public static MultiLayerNetwork createAndBuildLstmNetworks(int nIn, int nOut) {
        // Creating MultiLayerConfiguration 
        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
                .seed(123456)// for the reproducibility
                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)//optimizer
                .updater(new Adam(0.001)) // Adam updater with SGD
                .l2(1e-4)// l2 regularization
                .weightInit(WeightInit.XAVIER)// network weight initialization
                .activation(Activation.RELU)// ReLU as activation
                .list()
                .layer(0, new LSTM.Builder()//LSTM layer 1
                        .nIn(nIn)
                        .nOut(lstmLayer1Size)
                        .activation(Activation.TANH)
                        .gateActivationFunction(Activation.HARDSIGMOID)// Segment-wise linear       
                                                                       // approximation of sigmoid
                        .dropOut(dropoutRatio)// keeping drop-out ratio
                        .build())
                .layer(1, new LSTM.Builder()// LSTM layer 2
                        .nIn(lstmLayer1Size)
                        .nOut(lstmLayer2Size)
                        .activation(Activation.TANH)
                        .gateActivationFunction(Activation.HARDSIGMOID)
                        .dropOut(dropoutRatio)//kee drop-out ratio
                        .build())
                .layer(2, new LSTM.Builder()//LSTM layer 3
                        .nIn(lstmLayer1Size)
                        .nOut(lstmLayer2Size)
                        .activation(Activation.TANH)
                        .gateActivationFunction(Activation.HARDSIGMOID)
                        .dropOut(dropoutRatio)// keep drop-out ratio
                        .build())
                .layer(3, new DenseLayer.Builder()// FC layer 1
                        .nIn(lstmLayer2Size)
                        .nOut(denseLayerSize)
                        .activation(Activation.RELU)
                        .build())
                .layer(4, new DenseLayer.Builder()//FC layer 2
                        .nIn(denseLayerSize)
                        .nOut(denseLayerSize)
                        .activation(Activation.RELU)
                        .build())
                .layer(5, new DenseLayer.Builder()//FC layer 3
                        .nIn(denseLayerSize)
                        .nOut(denseLayerSize)
                        .activation(Activation.RELU)
                        .build())
                .layer(6, new RnnOutputLayer.Builder() // RNN output layer
                        .nIn(denseLayerSize)
                        .nOut(nOut)
                        .activation(Activation.IDENTITY)// Regression with MSE as the loss function
                        .lossFunction(LossFunctions.LossFunction.MSE)
                        .build())
                .backpropType(BackpropType.TruncatedBPTT)// Back propagation with time
                .tBPTTForwardLength(truncatedBPTTLength)
                .tBPTTBackwardLength(truncatedBPTTLength)
                .pretrain(false).backprop(true)//no pretraining necessary
                .build();

        // Creating MultiLayerNetwork using the above MultiLayerConfig
        MultiLayerNetwork net = new MultiLayerNetwork(conf);
        net.init(); // initilize the MultiLayerNetwork
        net.setListeners(new ScoreIterationListener(100));// shows score in each 100th iteration/epoch
        return net; // return the MultiLayerNetwork
    }
```

因为我们在本章中创建和使用了几次`LSTM`网络，所以我决定不讨论它的细节。然而，这里有一件重要的事情是用`Root Means Square Errors (RMSE)`激活`IDENTITY`，它用于回归问题。

简而言之，要使用 DL4J 中的神经网络执行回归，您需要设置一个多层神经网络，并在最后添加一个具有以下属性的输出层，如前所示:

```
//Create output layer
    .layer()
    .nIn($NumberOfInputFeatures)
    .nOut(1)// regression hence, only a single output
    .activation(Activation.IDENTITY)//Regression with RMSE as the loss function
    .lossFunction(LossFunctions.LossFunction.RMSE)
```

有关使用 DL4j 进行回归分析的更多信息，感兴趣的读者可以访问[https://deeplearning4j.org/evaluation#Regression](https://deeplearning4j.org/evaluation#Regression)。



# 网络训练，并保存训练好的模型

现在我们的网络以及训练和测试集都准备好了，我们可以开始训练网络了。为此，我们再次使用 DL4J 提供的`fit()`方法。我们循环通过`epochs`次，每次循环直到我们得到数据。我们在每个时间步用`miniBatchSize`数量的数据拟合网络，如下所示:

```
// StockPricePrediction.java
System.out.println("Training LSTM network...");
for(int i = 0; i < epochs; i++) {
            while(iterator.hasNext()) net.fit(iterator.next()); // fit model using mini-batch data
            iterator.reset(); // reset iterator
            net.rnnClearPreviousState(); // clear previous state
        }

>>
 Creating dataSet iterator...
 Loading test dataset...
 Building LSTM networks...
 Training LSTM network...
```

一旦训练完成，我们将训练好的模型保存到磁盘(在目录`data`中)。这里我指定了一个样本名`StockPriceLSTM_+ category name + .zip`,如下所示:

```
# StockPricePrediction.java
System.*out*.println("Saving model...");
File locationToSave = new File("data/StockPriceLSTM_".concat(String.*valueOf*(category)).concat(".zip"));

// saveUpdater: i.e., state for Momentum, RMSProp, Adagrad etc. Save this to train your network in future
ModelSerializer.*writeModel*(net, locationToSave, true);
```

现在让我们看看每一层的参数数量:

```
//Print the  number of parameters in the network (and for each layer)
Layer[] layers_before_saving = net.getLayers();
              int totalNumParams_before_saving = 0;

              for(int i=0; i<layers_before_saving.length; i++ ){
                  int nParams = layers_before_saving[i].numParams();
                  System.out.println("Number of parameters in layer " + i + ": " + nParams);
                  totalNumParams_before_saving += nParams;
              }
System.out.println("Total number of network parameters: " + totalNumParams_before_saving);
```

```
>>>
 Saving model...
 Number of parameters in layer 0: 68608
 Number of parameters in layer 1: 131584
 Number of parameters in layer 2: 131584
 Number of parameters in layer 3: 4128
 Number of parameters in layer 4: 1056
 Number of parameters in layer 5: 1056
 Number of parameters in layer 6: 165
 Total number of network parameters: 338181
```

然而，我们启用 DL4J UI 来查看培训进度和参数，如下所示:

```
//Initialize the user interface backend
UIServer uiServer = UIServer.*getInstance*();

//Configure where the network information (gradients, activations, score vs. time etc) is to be stored. //Then add the StatsListener to collect this information from the network, as it trains:
StatsStorage statsStorage = new InMemoryStatsStorage();

//Alternative: new FileStatsStorage(File) - see UIStorageExample. Attach the StatsStorage instance to the //UI: this allows the contents of the StatsStorage to be visualized:
uiServer.attach(statsStorage);

int listenerFrequency = 1;
net.setListeners(new StatsListener(statsStorage, listenerFrequency));
```

以下屏幕截图显示了输出:

![](assets/8621da6a-21ff-4d2a-b57c-51a991d9a3fa.png)

用户界面上的网络参数

这些图表看起来似乎没有规律，可能是因为我们没有足够的训练数据。



# 为推理恢复保存的模型

既然我们已经完成了训练，并且训练好的模型就在手边，我们可以直接使用训练好的模型并从磁盘恢复保存的模型，或者开始推理。看一下这段代码:

```
System.*out*.println("Restoring model...");
net = ModelSerializer.*restoreMultiLayerNetwork*(locationToSave);

//print the score with every 1 iteration
net.setListeners(new ScoreIterationListener(1));

//Print the number of parameters in the network (and for each layer)
Layer[] layers = net.getLayers(); 

int totalNumParams = 0;
for( int i=0; i<layers.length; i++ ){
        int nParams = layers[i].numParams(); 
       System.*out*.println("Number of parameters in layer " + i + ": " + nParams);
       totalNumParams += nParams;
}
System.*out*.println("Total number of network parameters: " + totalNumParams);
```

```
>>>
 Restoring model...
 Number of parameters in layer 0: 68608
 Number of parameters in layer 1: 131584
 Number of parameters in layer 2: 131584
 Number of parameters in layer 3: 4128
 Number of parameters in layer 4: 1056
 Number of parameters in layer 5: 1056
 Number of parameters in layer 6: 165
 Total number of network parameters: 338181
```



# 评估模型

参数的数量与我们保存在磁盘上的数量相同。这意味着我们训练的模型没有被污染，所以我们是安全的。接下来，我们开始在测试集上评估模型。但是，如前所述，我们将对模型进行双向评估。首先，我们预测股票的一个特征，提前一天，如下所示:

```
/** Predict one feature of a stock one-day ahead */
private static void predictPriceOneAhead (MultiLayerNetwork net, List<Pair<INDArray, INDArray>> testData, double max, double min, PriceCategory category) {
        double[] predicts = new double[testData.size()];
        double[] actuals = new double[testData.size()];

        for (int i = 0; i < testData.size(); i++) {
            predicts[i] = net.rnnTimeStep(testData.get(i).getKey()).getDouble(exampleLength - 1) 
                          * (max - min) + min;
            actuals[i] = testData.get(i).getValue().getDouble(0);
        }

        RegressionEvaluation eval = net.evaluateRegression(iterator);   
        System.out.println(eval.stats());

        System.out.println("Printing predicted and actual values...");
        System.out.println("Predict, Actual");

        for (int i = 0; i < predicts.length; i++) 
            System.out.println(predicts[i] + "," + actuals[i]);

        System.out.println("Plottig...");
        PlotUtil.plot(predicts, actuals, String.valueOf(category));
    }
```

在前面的代码块中，我们为单个类别执行培训，例如，通过设置下列选项之一:

```
PriceCategory category = PriceCategory.OPEN; // OPEN: predict open price
PriceCategory category = PriceCategory.CLOSE; // CLOSE: predict close price
PriceCategory category = PriceCategory.LOW; // LOW: predict low price
PriceCategory category = PriceCategory.HIGH; // HIGH: predict high price
```

我们可以通过设置`PriceCategory category = PriceCategory.***ALL***; // **ALL**: predict close price`同时对所有类别进行评估。

因此，我们提前一天预测股票的所有特征(开盘价、收盘价、最低价、最高价和成交量)。在所有类别中，对一个类别的评估过程是相同的。只有一点不同:我们需要使用`PlotUtil`遍历多个类别，绘制`XY`折线图，如下所示:

```
/** Predict all the features (open, close, low, high prices and volume) of a stock one-day ahead */
private static void predictAllCategories (MultiLayerNetwork net, List<Pair<INDArray, INDArray>> testData, INDArray max, INDArray min) {
        INDArray[] predicts = new INDArray[testData.size()];
        INDArray[] actuals = new INDArray[testData.size()];
        for(int i = 0; i < testData.size(); i++) {
            predicts[i] = net.rnnTimeStep(testData.get(i).getKey()).getRow(exampleLength - 1)
                          .mul(max.sub(min)).add(min);
            actuals[i] = testData.get(i).getValue();
        }

        System.out.println("Printing predicted and actual values...");
        System.out.println("Predict, Actual");

        for(int i = 0; i < predicts.length; i++) 
            System.out.println(predicts[i] + "\t" + actuals[i]);
        System.out.println("Plottig...");

        RegressionEvaluation eval = net.evaluateRegression(iterator);   
        System.out.println(eval.stats());

        for(int n = 0; n < 5; n++) {
            double[] pred = new double[predicts.length];
            double[] actu = new double[actuals.length];

            for(int i = 0; i < predicts.length; i++) {
                pred[i] = predicts[i].getDouble(n);
                actu[i] = actuals[i].getDouble(n);
            }
            String name;
            switch(n) {
                case 0: name = "Stock OPEN Price"; break;
                case 1: name = "Stock CLOSE Price"; break;
                case 2: name = "Stock LOW Price"; break;
                case 3: name = "Stock HIGH Price"; break;
                case 4: name = "Stock VOLUME Amount"; break;
                default: throw new NoSuchElementException();
            }
            PlotUtil.plot(pred, actu, name);
        }
    }
```

在前面的代码块中，我们转到函数`predictAllCategories()`来查看所有类别中的评估是如何进行的。接下来，我们创建两个数组，`predicts`和`actuals`，来存储预测结果和实际结果。然后我们循环测试数据。然后，我们执行以下操作:

*   调用带参数的函数`net.rnnTimeStep()`作为第 I 行的键，并将结果追加到`predicts`列表中
*   实际值取自测试数据行 *i* ^(th) 的值
*   打印预测值和实际值

最后，我们循环五个类别；我们使用`PlotUtil.java`来绘制预测值和实际值之间的 *XY* 线图。请考虑以下情况:

*   最初的两个双数组被命名为`pred`和`actu`，大小等于预测长度的大小。
*   遍历`predicts`和`actuals`数组，获得每个列表中每个元素的 double 值。
*   对于每一个*的值，n* 具有从 0 到 4 的四个值。将变量`name`设置到 *Y* 柱的凸缘上。
*   调用函数`PlotUtil`绘制 *XY* 线。

顺便说一下，`PlotUtil.java`类用于为预测值和实际值绘制一条 *XY* 线，如下所示:

```
public static void plot(double[] predicts, double[] actuals, String name) {
        double[] index = new double[predicts.length];
        for(int i = 0; i < predicts.length; i++)
            index[i] = i;

        int min = minValue(predicts, actuals);
        int max = maxValue(predicts, actuals);

        final XYSeriesCollection dataSet = new XYSeriesCollection();
        addSeries(dataSet, index, predicts, "Predicted");
        addSeries(dataSet, index, actuals, "Actual");

        final JFreeChart chart = ChartFactory.createXYLineChart(
                "Predicted vs Actual", // chart title
                "Index", // x axis label
                name, // y axis label
                dataSet, // data
                PlotOrientation.VERTICAL,
                true, // include legend
                true, // tooltips
                false // urls
              );

        XYPlot xyPlot = chart.getXYPlot();

        // X-axis
        final NumberAxis domainAxis = (NumberAxis) xyPlot.getDomainAxis();
        domainAxis.setRange((int) index[0], (int) (index[index.length - 1] + 2));
        domainAxis.setTickUnit(new NumberTickUnit(20));
        domainAxis.setVerticalTickLabels(true);

        // Y-axis
        final NumberAxis rangeAxis = (NumberAxis) xyPlot.getRangeAxis();
        rangeAxis.setRange(min, max);
        rangeAxis.setTickUnit(new NumberTickUnit(50));

        final ChartPanel panel = new ChartPanel(chart);
        final JFrame f = new JFrame();
        f.add(panel);
        f.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE);
        f.pack();
        f.setVisible(true);
    }
```

在前面的代码块中，`addSeries()`方法用于添加 *XY* 系列，如下所示:

```
private static void addSeries (final XYSeriesCollection dataSet, double[] x, double[] y, final String label){
        final XYSeries s = new XYSeries(label);
        for(int j = 0; j < x.length; j++ ) s.add(x[j], y[j]);
        dataSet.addSeries(s);
    }
```

除此之外，查找我们在前面的代码中使用的`predicted`和`actual`的最小值、最大值的过程如下:

*   **查找 min:** 首先，我们将变量`min`设置为`MAX_VALUE.`，然后我们遍历`predicted`和`actual`数组，这样，如果`min`大于任何元素，那么我们将`min`重置为当前元素。然后我们取最小值的整数最接近的下限:

```
private static int minValue (double[] predicts, double[] actuals) {
        double min = Integer.MAX_VALUE;

        for(int i = 0; i < predicts.length; i++) {
            if(min > predicts[i]) min = predicts[i];
            if(min > actuals[i]) min = actuals[i];
        }
        return (int) (min * 0.98);
    }
```

*   **查找 max:** 首先，我们将变量`max`设置为`MIN_VALUE.`，然后我们遍历`predicts`和`actual`数组，这样如果`max` <有任何元素，我们将`max`重置为该元素。然后，我们取最接近 max 值上限的整数，如下所示:

```
private static int maxValue (double[] predicts, double[] actuals) {
        double max = Integer.MIN_VALUE;

        for(int i = 0; i < predicts.length; i++) {
            if(max < predicts[i]) max = predicts[i];
            if(max < actuals[i]) max = actuals[i];
        }
        return (int) (max * 1.02);
    }
```

最后，我们使用`addSeries()`方法在绘制图表时向数据集添加一个系列。然而，由于任务是一个回归，我们也执行显示回归度量的评估，例如`MSE`、`MAE`、`R2`等等。

现在，基于前面的计划和变量`category`的值，我们有两种方法来评估模型。如果类别是`ALL`，那么网络会预测所有类别；否则，网络将只对一个类别起作用。首先，仅针对一个类别，比如说`OPEN`。看一下这段代码:

```
System.out.println("Evaluating...");
if(category.equals(PriceCategory.OPEN)) {
            INDArray max = Nd4j.create(iterator.getMaxArray());
            INDArray min = Nd4j.create(iterator.getMinArray());
            predictAllCategories(net, test, max, min);
} else {
            double max = iterator.getMaxNum(category);
            double min = iterator.getMinNum(category);
            predictPriceOneAhead(net, test, max, min, category);
 }
System.out.println("Done...");
```

```
>>>
 Evaluating...
 Printing predicted and actual values...
 Predict, Actual
 ---------------------------------------
 29.175033326034814,35.61000061035156
 29.920153324534823,35.70000076293945
 30.84457991629533,35.9900016784668
 31.954761620513793,36.150001525878906
 33.171770076832885,36.79999923706055
 34.42622247035372,36.150001525878906
 35.63831635695636,36.41999816894531
 36.79695794284552,36.04999923706055
 37.79222186089784,35.9900016784668
 38.45504267616927,35.470001220703125
 38.837315702846766,35.66999816894531
```

然后，回归度量将打印如下(尽管您可能会体验到稍微不同的结果):

```
Column MSE MAE RMSE RSE PC R^2
 -------------------------------------------------------------------------------------------
 col_0 3.27134e-02 1.14001e-01 1.80868e-01 5.53901e-01 7.17285e-01 4.46100e-01
```

最后，我们看到下面的屏幕截图显示了预测价格与实际价格的对比:

![](assets/9d1020c0-ee25-4e63-85d1-c322756232db.png)

`OPEN`类别的预测价格与实际价格

然后，仅对于`**ALL**`类别，我们运行类似的代码，除了如下使用`PriceCategory.ALL`:

```
System.out.println("Evaluating...");
if(category.equals(PriceCategory.ALL)) {
            INDArray max = Nd4j.create(iterator.getMaxArray());
            INDArray min = Nd4j.create(iterator.getMinArray());
            predictAllCategories(net, test, max, min);
} else {
            double max = iterator.getMaxNum(category);
            double min = iterator.getMinNum(category);
            predictPriceOneAhead(net, test, max, min, category);
   }
System.out.println("Done...");
```

```
>>>
 Evaluating...
 Printing predicted and actual values...
 Predict, Actual
 ------------ ---------------------------------------------------------------
 [[27.8678,27.1462,27.0535,27.9431, 9.7079e5]] [[35.6100,35.8900,35.5500,36.1100, 1.5156e6]]
 [[28.3925,27.2648,27.2769,28.4423, 1.2579e6]] [[35.7000,35.8100,35.6500,36.1000,8.623e5]]
 [[29.0413,27.4402,27.6015,29.1540, 1.6014e6]] [[35.9900,36.1400,35.9000,36.3200, 1.0829e6]]
 [[29.9264,27.6811,28.0419,30.1133, 2.0673e6]] [[36.1500,36.7100,36.0700,36.7600, 1.0635e6]]
 [[30.9201,27.9385,28.5584,31.2908, 2.5381e6]] [[36.8000,36.5700,36.4600,37.1600, 1.0191e6]]
 [[32.0080,28.2469,29.1343,32.6514, 3.0186e6]] [[36.1500,36.2300,35.9300,36.7600, 1.8299e6]]
 [[33.1358,28.5809,29.7641,34.1525, 3.4644e6]] [[36.4200,36.5400,36.1800,36.8900,8.774e5]]
 [[45.2637,31.2634,39.5828,53.1128, 5.0282e6]] [[50.3600,49.2200,49.1700,50.4500,9.415e5]]
 [[45.1651,31.2336,39.5284,52.9815, 4.9879e6]] [[49.1700,49.0100,48.8100,49.4400,9.517e5]]
```

然后，回归度量将打印如下(尽管您可能会体验到稍微不同的结果):

```
Column MSE MAE RMSE RSE PC R^2
 -------------------------------------------------------------------------------------------------
 col_0 4.52917e-02 1.35709e-01 2.12819e-01 7.49715e-01 6.60401e-01 2.50287e-01
 col_1 1.52875e-01 3.27669e-01 3.90993e-01 2.54384e+00 6.61151e-01 -1.54384e+00
 col_2 8.46744e-02 2.19064e-01 2.90989e-01 1.41381e+00 6.01910e-01 -4.13806e-01
 col_3 6.05071e-02 1.93558e-01 2.45982e-01 9.98581e-01 5.95618e-01 1.41977e-03
 col_4 2.34488e-02 1.17289e-01 1.53130e-01 9.97561e+00 5.59983e-03 -8.97561e+00
```

现在看一下下图，图中显示了`ALL`的预测价格和实际价格:

![](assets/8b74636f-a246-4971-b678-f266defb34f5.png)

`ALL`类别的预测价格与实际价格

从图表中，我们可以看到`OPEN`和`HIGH`的价格显示出很好的拟合，而`LOW`显示出有点好的拟合。不幸的是，`CLOSE`和`VOLUME`表现出非常令人失望的契合度(见前面的回归结果表)。一个可能的原因是缺乏数据。此外，使用的超参数根本不是超调的。然而，大多数超参数选择得很幼稚。



# 常见问题(FAQ)

在这一部分，我们将看到一些你可能已经想到的常见问题。这些问题的答案可以在附录 A 中找到:

1.  我可以为了比特币价格预测的目的而扩展这个项目吗？如果是，我如何以及在哪里可以获得这样的数据集？
2.  如果将预测值作为下一次预测的输入，会发生什么情况？
3.  我知道这是一个回归问题，但是我如何预测一个价格是上涨还是下跌呢？
4.  我想扩展这个应用程序，并部署一个 web 应用程序。我该怎么做呢？
5.  我想扩展这个应用程序，不仅用于价格预测，还用于价格异常检测。我该怎么做呢？
6.  我可以使用类似的技术来推荐股票价格吗？



# 摘要

在这一章中，我们看到了如何开发一个演示项目来预测五类股票的价格:`OPEN`、`CLOSE`、`LOW`、`HIGH`和`VOLUME`。然而，我们的方法不能产生实际的信号。尽管如此，它给出了一些如何使用 LSTM 的想法。我知道这种方法有一些严重的缺点。然而，我们没有使用足够的数据，这潜在地限制了这样一个模型的性能。

在下一章中，我们将看到如何将深度学习方法应用于视频数据集。我们将描述如何从大量视频剪辑中处理和提取特征。然后，我们将通过在多个设备(CPU 和 GPU)上分布训练来使整个管道可扩展和更快，并并行运行它们。

我们将看到一个完整的例子，说明如何使用 CNN-LSTM 网络和 DL4J 的组合来开发一个深度学习应用程序，该应用程序可以对视频数据集的大型集合进行准确分类，例如`UCF101`。它克服了独立 CNN 或`LSTM`网络的局限性。培训将在 Amazon EC2 GPU 计算集群上进行。最终，这个端到端的项目可以被视为从视频或其他视频中识别人类活动的基础。



# 问题的答案

**回答** **提问** **1:** 可以从 Kaggle 下载一些比特币的历史数据，比如[https://www . ka ggle . com/mczielinski/bit coin-historical-data/data](https://www.kaggle.com/mczielinski/bitcoin-historical-data/data)。

下载数据集后，尝试提取最重要的特征，并将数据集转换为时间序列，以便将其输入 LSTM 模型。然后，可以用每个时间步长的时间序列来训练模型。

**问题 2 答案****:**我们的样本项目只计算那些给出实际股价的股票的股价，而不计算第二天的股价。显示的是`actual`和`predicted`，但是第二天的股价应该只包含`predicted`。如果我们将预测值作为下一次预测的输入，就会发生这种情况:

![](assets/f9c0c769-0e8a-467d-9771-8c9d377e2565.png)

`ALL`类别的预测价格与实际价格，其中预测值是下一次预测的输入

**回答** **对问题** **3:** 好吧，那么这个任务就是一个二进制分类问题。要做到这一点，您需要做出两项改变:

*   转换数据集，以便有两个标签
*   用交叉熵损失代替`IDENTITY`激活函数和`RMSE`损失

问题 4 的答案:这是个好主意。您可以通过遵循问题 1 和 2 来尝试改进建模。然后，您可以将模型保存在磁盘上，供以后的推理使用。最后，如前几章所述，您可以将这个模型作为 web 应用程序。

**回答** **提问** **5** :在这样的数据集中应用异常检测非常具有挑战性，我不确定这是否可行，因为市场的波动性非常高。所以时间序列有时候会有非常多的沧桑，这是股市的本性。这有助于训练好的模型识别异常波动。

对问题 6 的回答**:**是的，你可以。可以尝试使用**基于机器学习的 ZZAlpha Ltd .股票推荐 2012-2014 数据集。**本数据集可在[从`UCI ML repository`下载 https://archive . ics . UCI . edu/ml/datasets/Machine+Learning+based+ZZAlpha+ltd+Stock+recommenders+2012-2014](https://archive.ics.uci.edu/ml/datasets/Machine+Learning+based+ZZAlpha+Ltd.+Stock+Recommendations+2012-2014)。存储库还描述了问题和数据集。
<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 高级主题建模

在前一章中，我们看到了主题建模的强大功能，以及理解和探索数据的直观方式。在这一章中，我们将进一步探讨这些主题模型的效用，以及如何创建更有用的主题模型，更好地封装语料库中可能存在的主题。由于主题建模是理解语料库文档的一种方式，这也意味着我们可以用以前从未做过的方式分析文档。

在本章中，我们将讨论以下主题:

*   高级培训技巧
*   浏览文档
*   话题连贯与话题模型评估
*   可视化主题模型

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 高级培训技巧

在[第 8 章](02e3238f-db9c-4d6e-ba96-70ba9db11dc0.xhtml)、*主题模型*中，我们探讨了什么是主题模型，以及如何用 Gensim 和 scikit-learn 设置它们。但是仅仅建立一个主题模型是不够的——一个训练不足的主题模型不会给我们提供任何有用的信息。

我们已经讨论了最重要的*预培训*提示-预处理。现在很明显，垃圾输入就是垃圾输出，但有时即使确保输入的不是垃圾，我们仍然会得到无意义的输出。在这一部分，我们将简要讨论你还可以做什么来润色你的结果。

明智的做法是重新审视一下[第 3 章](be6f4ff3-1217-474a-8923-5eeeed17bfa1.xhtml)、*空间*、、 *s 语言模型*和[第 4 章](ad7d7774-1bef-4a55-ae7c-0d77097a43b7.xhtml)、 *Gensim* 、*-*-*向量化文本和转换以及 n* 、 *-* 、*克*，现在——他们介绍了预处理中使用的方法，这通常是第一次*高级*培训值得注意的是，与其他形式的文本分析算法相比，这些预处理技巧更适合于生成主题模型。例如，使用词汇化而不是词干化是一种实践，这种实践在主题建模中特别有用，因为词汇化的单词比词干化的单词更易于阅读。类似地，在应用主题建模算法之前，使用二元语法或三元语法作为语料库的一部分意味着我们的结果将更容易被人类理解。

因为我们使用主题模型的目的是探索语料库，所以我们努力获得人类更容易理解的结果是有意义的。这将与聚类文档略有不同，例如，在聚类文档时，我们将更关注具有更高的准确性，而不是任何人可以理解的东西。在预处理我们的文档时，记住这一点很重要，这也意味着我们可以自由地添加我们自己的预处理步骤来帮助我们处理结果。

第一次尝试对数据进行主题建模时，我们不太可能得到非常*有用的*结果——成功的主题建模需要多次清理数据、读取结果、相应地调整预处理并再次尝试。例如，在查看了第一个主题模型后，我们可能想在停用词列表中添加新的停用词。这通常是基于你进行文本分析的领域；停止词会非常不同。

在我们在第 8 章、*主题模型*中第一次看到的 Jupyter 笔记本中，我们正在处理 Lee Newspaper 语料库。在最初的几次主题建模运行中，结果并不是最有用的——单词`say`在主题中出现的次数不成比例地高。这当然是有意义的——在包含报纸文章的语料库中，单词`said`或`saying`会经常出现，这些单词会被词条化为`say`。但是即使它有意义，它仍然意味着我们的主题模型不是最有用的。在这种情况下，解决方案很清楚——从语料库中删除单词`say`的变体，这样它就不会出现在我们的主题模型中。

使用 spacy，可以这样完成:

```
my_stop_words = [u'say', u'\'s', u'Mr', u'be', u'said', u'says', u'saying'] 
for stopword in my_stop_words: 
    lexeme = nlp.vocab[stopword] 
    lexeme.is_stop = True
```

这到底是怎么回事？对于我们希望添加为停用词的每一个单词，我们改变那个`lexeme`类的`is_stop`属性。词汇不区分大小写，所以我们可以忽略这里的大小写。要添加更多的停用词，我们只需将这些词添加到`my_stop_words`列表**中。**

这就是 spaCy 处理停用词的方式——移除停用词的一种更常见的方式是将所有停用词放在一个列表中，并简单地从语料库中移除这些词的所有出现。如果您使用的是 NLTK，应该是这样的:

```
from nltk.corpus import stopwords
stopword_list = stopwords.words("english")
```

这里，`stopword_list`是一个列表，所以向我们的列表添加新单词就像向列表追加单词一样简单。

我们将始终使用 spaCy 进行任何类型的预处理，所以这是我们应该真正关心的停用词移除方法；也就是说，从技术上讲，你可以使用任何方法来删除停用词。

另一种删除不想要的单词的方法是使用 Gensim `Dictionary`类。考虑这个例子:

```
filter_n_most_frequent(remove_n)
```

这将过滤掉文档中出现最频繁的`remove_n`标记。

Gensim `Dictionary`文档[ [1](https://radimrehurek.com/gensim/corpora/dictionary.html) ]中的这个简单例子说明了这一点:

```
from gensim.corpora import Dictionary
corpus = [["máma", "mele", "maso"], ["ema", "má", "máma"]]
dct = Dictionary(corpus)
len(dct)
5
dct.filter_n_most_frequent(2)
len(dct)
3
```

这种生成主题模型、手动检查它并适当改变我们的预处理步骤的过程是几乎所有机器学习或数据科学项目中的常见练习——在文本分析中，区别在于结果的人类可解释性质。

我们什么时候停止预处理和生成主题模型的循环过程？当我们对我们看到的结果感到满意时——因为我们并不试图在主题建模时获得更高的准确性，当我们认为我们的主题模型最终*有用*时，我们可以停止。当然，也有更客观的方法来衡量主题模型的*有用程度*，我们将在我们的*主题连贯性和评估主题模型*部分讨论这些技术。

现在，所有这些提示都涉及到我们在开始主题建模之前所做的事情。即使在创建主题模型时，我们也可以做大量的调整。虽然 Gensim 和 scikit-learn 的这些培训选项是不同的，但有一点是共同的——我们为最佳主题模型选择多少个主题？

这个问题没有真正的答案，同样，衡量最佳主题数量的标准实际上取决于你使用的语料库的类型、语料库的大小以及你可能期望看到的主题数量——大型语料库可能有 100 个主题，小型语料库可能有 10 个主题。如果我们没有关于数据集的先验知识，运行一个包含 5 个主题的模型，然后是 10 个主题，以此类推，每 10 个步骤实际上是一个足够合理的方法，尽管也有更多的定量方法来衡量这一点，我们将在主题一致性一节中讨论。

在所有的机器学习算法中，我们有各种影响算法结果的参数。改变这些参数以达到不同结果的过程称为参数调优，这些参数也通俗地称为**调优**参数。

至少对于 Gensim 来说，一些重要的调谐参数包括:

1.  `chunksize`:控制训练算法中一次处理多少张单据。增加块大小将会加快训练速度，至少只要文档块容易放入内存(RAM)中。
2.  这控制了我们在整个语料库上训练模型的频率。通行证的另一个词可能是**时代**。
3.  这控制了我们对每个文档重复特定循环的频率。重要的是将**遍数**和**迭代数**设置得足够高。

你可以在这里看到`LdaModel` [的其他参数](https://radimrehurek.com/gensim/models/ldamodel.html)【2】——你可以用[第八章](02e3238f-db9c-4d6e-ba96-70ba9db11dc0.xhtml)、*主题模型*中的`LdaModel`来回忆我们。对于 scikit-learn，[这些](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) [3]是其 LDA 实现的参数，用于快速比较。这些有助于理解我们可以使用什么样的参数。超参数是描述机器学习算法的参数的词，这些参数在机器学习算法开始之前设置。

在机器学习中，我们经常将我们算法的结果称为模型——在主题建模的上下文中，LDA 模型、HDP 模型或 LSI 模型只是描述语料库中文档的概率模型。例如，当我们谈到主题模型或 LDA 模型时，我们指的是这种经过训练的模型。

通常，LDA 算法会有两个超参数:

1.  **Alpha** :表示文档主题密度。alpha 值越高，文档包含的主题越多；alpha 值越低，文档包含的主题越少。
2.  **Beta** :这代表了主题词密度。如果 beta 值较高，则主题由语料库中的大量单词组成，而 beta 值较低时，则由很少的单词组成。
3.  **主题数量**:我们希望建模的主题数量。

在训练过程中，为了获得更多信息，打开日志记录是有意义的，因为 Gensim 在默认情况下不打印训练信息。

这可以通过以下方式实现:

```
import logging
logging.basicConfig(filename='logfile.log', format='%(asctime)s : 
                    %(levelname)s : %(message)s', level=logging.INFO)
```

Chris Tufts 的这篇博文也是训练 LDA 模型的有用资源。Gensim FAQ 和食谱页面也值得一读[ [5](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) ]。

一旦我们对我们训练的模型足够满意，我们就可以进行更多的尝试——你会看到我们可以做的不仅仅是查看语料库中存在什么样的主题。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 浏览文档

一旦我们建立了我们选择的主题模型，我们就可以用它来分析我们的语料库，并且对我们的主题模型的本质有更多的了解。虽然知道我们的数据集中存在什么样的主题肯定是有用的，但为了更进一步，我们应该能够，例如，根据它们是由什么主题组成的来对我们的文档进行聚类或分类。

在我们 Jupyter 笔记本的例子中，从[第 8 章](02e3238f-db9c-4d6e-ba96-70ba9db11dc0.xhtml)、*主题模型*开始，让我们看看文档-主题比例。这些到底是什么？当我们在前一章看主题时，我们在观察主题-词的比例-某些词出现在某些主题中的几率是多少。我们之前提到过，我们假设文档是从主题中*生成的*——通过确定文档-主题的比例，我们可以确切地看到主题是如何生成文档的。

我们要做这个基因工程吗？这非常简单:

```
ldamodel[document]
```

就是你需要得到的文档-主题比例。这里的文档是我们希望分析的文档的向量表示。

这不必是用于训练 LDA 模型的文档，它可以是看不见的文档，只要文档中的单词在 LDA 模型的相同词汇表中。

让我们用李报纸文集的上下文来尝试一下:

```
ldamodel[corpus[0]]
```

这为我们提供了以下信息:

```
[(1, 0.99395897621183538)]
```

这是什么意思？该列表包含具有主题号和该主题出现在该主题中的相应概率(高于某个截止概率)的元组。由于我们的列表中只有一个元组，这意味着其他主题对本文档的贡献可以忽略不计。我们来验证一下。

话题 1 是什么？

```
ldamodel.show_topics()[1]

(1, u'0.008*"area" + 0.007*"fire" + 0.006*"people" + 0.005*"sydney" + 0.005*"force" + 0.004*"pakistan" + 0.004*"new" + 0.004*"afghan" + 0.004*"new_south" + 0.004*"wales"')
```

它似乎代表了两个主题-阿富汗-巴基斯坦冲突和新南威尔士或悉尼可能发生的火灾或事故。让我们看看我们的第一个文档是否有这些主题出现。

现在让我们看一下第一份文件中的几句话，看看主题分配是否有意义:

```
texts[0][:15] **[u'hundred',** **u'people',** **u'force',** **u'vacate',** **u'home',** **u'southern',** **u'highlands',** **u'new_south',** **u'wales',** **u'strong',** **u'wind',** **u'today',** **u'push',** **u'huge',** **u'bushfire']**
```

我们看到它确实与主题的主题之一相匹配，并且我们的主题模型确实是有用的。我们可以进一步使用这些信息，根据文档-主题比例将文档聚类到每个主题中。

需要注意的非常重要的一点是:你可能会看到不同的主题、不同的比例和不同的单词——主题模型是概率性的，我们不会每次都得到相同的结果。

现在需要注意的是，我们有文档-主题比例的表示也是一个向量表示，比如 TF-IDF；不是我们跨越词汇表的向量长度，而是主题数量的大小。

Gensim 不仅仅停留在这里，它还有进一步的方法来帮助我们分析文档和单词的主题比例。

我们将使用我为 Gensim 编写的这个 Jupyter 笔记本[ [6](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb) ]来说明 Gensim 必须提供的方法。

让我们快速地看一下我们将用来说明这些方法的语料库:

```
texts = [['bank','river','shore','water'], 
        ['river','water','flow','fast','tree'], 
        ['bank','water','fall','flow'], 
        ['bank','bank','water','rain','river'], 
        ['river','water','mud','tree'], 
        ['money','transaction','bank','finance'], 
        ['bank','borrow','money'],  
        ['bank','finance'], 
        ['finance','money','sell','bank'], 
        ['borrow','sell'], 
        ['bank','loan','sell']]
```

关于这个语料库的一些快速注释-它包含有两个不同主题的句子-一个与金融有关，另一个与河流有关。你还应该注意到，单词库在两种上下文中都重复出现——这让我们可以对单词做更多的实验。

让我们看看从这个语料库中产生的主题:

```
model.show_topics()

[(0, u'0.164*"bank" + 0.142*"water" + 0.108*"river" + 0.076*"flow" + 0.067*"borrow" + 0.063*"sell" + 0.060*"tree" + 0.048*"money" + 0.046*"fast" + 0.044*"rain"'),
(1, u'0.196*"bank" + 0.120*"finance" + 0.100*"money" + 0.082*"sell" + 0.067*"river" + 0.065*"water" + 0.056*"transaction" + 0.049*"loan" + 0.046*"tree" + 0.040*"mud"')]
```

我们可以看到，不出所料，一个话题是和河岸有关，另一个话题是和金融银行有关。

在文档中，可以找到特定单词属于特定主题的几率。这是通过`get_term_topics()`方法完成的。让我们看几个例子:

```
model.get_term_topics('water')

[(0, 0.12821234071249418), (1, 0.047247458568794511)]
```

这有道理；属于 topic_0 的值要大得多。

```
model.get_term_topics('finance')

[(0, 0.017179349495865623), (1, 0.10331511184214655)]
```

正如所料，`finance`这个词出现在第二个主题中的概率要高得多。如果我们对单词 *bank* 运行相同的方法，我们让读者自己去想结果会是什么样子。

这种方法关注语料库中的特定单词——现在让我们看看如何找到整个文档的主题比例。`get_document_topics`方法是 Gensim 功能，它使用推理函数来获得足够的统计数据，并计算出文档的主题分布。

让我们用两个包含单词 bank 的不同文档进行测试，一个在金融上下文中，另一个在河流上下文中。

当`per_word_topics`设置为 true 时，`get_document_topics`方法返回(连同标准文档主题比例)word_type，后跟一个按最可能的主题 id 排序的列表。

看看这个笔记本的摘录:

```
bow_water = ['bank','water','bank'] 
bow_finance = ['bank','finance','bank'] 

bow = model.id2word.doc2bow(bow_water) # convert to bag of words format first 
doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True) 

word_topics

[(0, [0, 1]), (3, [0, 1])]
```

那么，这个输出意味着什么呢？意思是和 word_type 1 一样，我们的 word_type 3，也就是单词`bank`，更有可能在 topic_0，而不是 topic_1。这里提醒一下，数字 0、1 和 3 指的是那个单词的 id 或索引。单词 1 是字典中 id 为 1 的单词，topic 0 是第一个主题。

你一定注意到了，在我们解包成`doc_topics`和`word_topics`的同时，还有另一个变量——`phi_values`。Phi 本质上是该单词在该文档中属于特定主题的概率。顾名思义，`phi_values`包含特定单词的每个主题的 phi 值，根据特征长度进行缩放。接下来的几行应该可以说明这一点:

```
phi_values

[(0, [(0, 0.92486455564294345), (1, 0.075135444357056574)]),
 (3, [(0, 1.5817120973072454), (1, 0.41828790269275457)])]
```

这意味着 word_type 0 对于每个主题都有下面的`phi_values`。值得注意的是 word _ type 3——因为它出现了 2 次(即单词 bank 在 bow 中出现了两次)，我们可以看到按特征长度的缩放非常明显。`phi_values`的和是 2，而不是 1。

既然我们已经确切地知道了`get_document_topics`做了什么，现在让我们对第二个文档`bow_finance`做同样的事情。

```
bow = model.id2word.doc2bow(bow_finance) # convert to bag of words format first 
doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True) 

word_topics
[(3, [1, 0]), (12, [1, 0])]
```

你瞧，因为 bank 这个词现在用在金融领域，它很快就变得更有可能与 topic_1 联系在一起了。

我们已经很清楚地看到，根据上下文，与一个词相关的最可能的主题会发生变化。这与我们之前的方法`get_term_topics`不同，它是一种*静态的*主题分布。

还必须注意的是，因为 LDA 的 Gensim 实现使用**变分贝叶斯采样**，所以文档中的 word_type 只被赋予一个主题分布。例如，句子 *the bank by the river bank* 很可能被分配给 topic_0，并且每个银行词实例具有相同的分布。

使用这两种方法，我们可以看到如何从我们的主题模型中推断出更多的信息。拥有文档-主题分布意味着我们还可以使用这些信息来做一些很酷的事情——例如，根据它属于哪个主题来给文档中的所有单词着色，或者使用距离度量来推断两个主题或文档有多近或多远。

以下我写给 Gensim 的 Jupyter 笔记本准确地告诉了我们如何完成以下任务——强烈建议您在进入下一部分之前，先看一下并运行这些笔记本。

*   给文档中的单词着色-笔记本 1 [ [6](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb)
*   距离指标-笔记本 2 [ [7](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/distance_metrics.ipynb)

Scikit-learn similarly 有更多的注意事项可以探索——博客文章[[8](https://towardsdatascience.com/improving-the-interpretation-of-topic-models-87fd2ee3847d)将是一个很好的起点！

我们现在要讨论主题模型的关键部分——定量地理解主题模型的表现。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 话题连贯与话题模型评估

在前面的章节中，我们广泛地讨论了主题模型在本质上是如何定性的——很难确定主题模型有多有用。尽管如此，仍然有必要评估主题模型，最流行的方法是主题一致性——幸运的是，Gensim 有一套相当广泛的主题一致性方法供我们尝试。

到底什么是话题连贯？简而言之，它是对人类可解释主题的一种衡量。主题建模文献中有多种一致性度量方法，我们不会详细介绍这些方法的理论，但如果您感兴趣，可以通过以下链接了解理论和直觉:

1.  什么是话题连贯？[ [9](https://rare-technologies.com/what-is-topic-coherence/)
2.  探索话题连贯性度量的空间

第一个链接是一篇 Gensim 博客文章，第二个链接是一篇研究论文，深入探讨了进一步的理论细节。

接下来我们需要知道的是，我们现在有了一个对我们的主题模型有多好的*定量*度量。这为我们打开了许多可能性——我们现在可以在两个不同训练的(例如，具有不同的迭代或通过次数)LDA 模型之间进行比较，或者在 HDP 模型和 LSI 模型之间进行比较，或者甚至在具有不同主题数量的类似训练的模型之间进行比较。这意味着我们现在也有了一种定量的方法来衡量语料库的最佳主题数量，以及在完全不同的模型类别之间进行比较的方法。

当然，我们仍然可以使用定性的方法来了解我们的主题模型表现如何。可视化主题模型是实现这一点的一种方法——我们已经在前面的章节中探索了这样一种方法，Jupyter notebook 引导我们对文档中的单词进行着色。通过快速浏览文档中的彩色单词，我们可以了解主题模型对哪些单词属于哪个主题的理解程度。使用更高级的主题可视化工具，我们可以进一步分析我们的主题模型有多高效。我们将在下一节详细讨论这些工具——现在，让我们看看 Gensim 的主题一致性管道！

在主题一致性之前，困惑被用来衡量主题模型的拟合程度——事实上，即使现在 Gensim 也允许我们在训练我们的模型时拿出一个测试集并测量困惑。你可以在[这里](http://qpleple.com/perplexity-to-evaluate-topic-models/)【11】阅读更多关于困惑和主题模型的内容。

Gensim 有一个非常简单的 API 来执行主题一致性:

例如，如果我们希望检查 Lee Newspaper 语料库数据集中三个模型的一致性值，我们只需运行。请注意，这些例子来自附在第八章、*主题模型*末尾的 Jupyter 笔记本。

```
lsi_coherence = CoherenceModel(topics=lsitopics[:10], texts=texts, dictionary=dictionary, window_size=10)

hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=texts, dictionary=dictionary, window_size=10)

lda_coherence = CoherenceModel(topics=ldatopics, texts=texts, dictionary=dictionary, window_size=10)
```

在这里，主题只是每个主题的前 *n* 个单词的列表。因为主题都是不同的，所以我们传递顶部的*单词列表*，而不是传递模型本身。然后，我们可以打印每个模型的一致性值，以获得相对一致性值——这个练习已经在 Jupyter 笔记本[ [12](https://github.com/bhargavvader/personal/blob/master/notebooks/text_analysis_tutorial/topic_modelling.ipynb) ]中完成，我们敦促读者探索这个比较。

例如，在我们只是比较两种不同类型的`LdaModel`对象的情况下，我们也可以传递模型。在这里，`goodLdaModel`和`badLdaModel`只是一个好的和坏的模型的占位符变量名——你应该通过你想通过的任何模型。

```
goodcm = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')
badcm = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')
```

我们在这里注意到，在两个例子中，我们都传递了`texts`——这里的文本是在我们将其转换成向量形式之前的原始语料库。你可以看一下笔记本上的课文清单来确认它的内容。

一旦我们训练好了一致性模型，我们只需运行`get_coherence()`来获得一致性的值。请注意，一致性值本身没有意义——只有在与同一语料库中的另一个一致性值进行比较时才有意义——一致性值越高，模型越好。

在*坏的*和*好的* `LdaModel`的例子中，坏的`LdaModel`对象仅用 1 次迭代训练，好的`LdaModel`对象用 50 次迭代训练。当我们试图打印一致性的值时:

```
print(goodcm.get_coherence())
print(badcm.get_coherence())

-13.8029561191-14.1531313765
```

我们可以看到，好的`LdaModel`对象具有更高的一致性值，这证实了我们的假设，即经过更多迭代训练的模型会表现得更好。注意:这些是基于任何模型组的样本一致性值，其中一个模型比另一个模型训练得更多。用户应该尝试训练他或她自己的好的和坏的模型，并对结果进行实验。

就像我们之前提到的，我们也可以使用一致性度量来查看一个语料库的最佳主题数量。下面是一个简单的 for 循环示例，它可以实现同样的功能:

```
c_v = [] 
limit = 10 
for num_topics in range(1, limit): 
        lm = LdaModel(corpus=corpus, num_topics=num_topics, 
                      id2word=dictionary) 
        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, 
                            coherence='c_v') 
        c_v.append(cm.get_coherence()) 
```

打印`c_v`将为我们提供每个主题编号对应的一致性值的列表——最高的一致性值将是一种识别人类最容易理解的主题数量的方法。

我们还可以打印 LDA 模型中的热门话题，这取决于我们打算使用的一致性度量。`top_topics`方法有助于实现这一点，并使用一致性模型来生成热门话题。虽然我们已经在本节中介绍了 coherence 模型的大部分功能，但还有多个 Gensim Jupyter 笔记本更详细地介绍了 coherence 模型可以提供的不同功能:

1.  一致性模型管道[ [13](https://radimrehurek.com/gensim/models/coherencemodel.html)
2.  使用 Gensim [ [14](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/gensim_news_classification.ipynb) ]进行新闻分类
3.  电影数据集上的主题一致性[ [15](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence-movies.ipynb)
4.  话题连贯性介绍[ [16](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence_tutorial.ipynb)
5.  主题一致性用例[ [17](https://gist.github.com/dsquareindia/ac9d3bf57579d02302f9655db8dfdd55)
6.  话题连贯模式选择[ [18](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence_model_selection.ipynb)

既然我们已经建立了模型，并且进行了分析，我们就可以开始可视化它们了。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 可视化主题模型

就像我们之前说过的，主题模型的目的是为了更好地理解我们的文本数据——而可视化是理解和查看我们的数据的最佳方式之一。有多种方法和技术来可视化主题模型——我们将重点关注与 Gensim 实现和兼容的方法，但就像我们在整本书中所做的那样，我们将提供其他流行的主题建模可视化工具的链接和文档。

最受欢迎的主题建模可视化库之一是`LDAvis`——一个主要基于 D3 构建的 R 库，它已经作为`pyLDAvis`移植到 Python 中，在 Python 中也很漂亮，并且与 Gensim 集成得很好。它基于卡森·西维尔和肯尼斯·e·雪莉的原始论文( *LDAvis:一种可视化和解释主题* [ [19](https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf) ])。

库不知道你的模型是如何被训练的——这意味着我们不局限于 Gensim 甚至 LDA。我们需要的只是主题术语分布和文档主题分布，以及关于被训练的语料库的基本信息。

![](Images/28dbeb5c-6ec3-4b3e-88ca-8049434920f6.png)

图 9.1 皮尔戴维斯

如果我们使用基于 Gensim 的模型，那就更容易了。我们需要做的就是这个:

```
import pyLDAvis.gensim 
pyLDAvis.gensim.prepare(model, corpus, dictionary)
```

在这里，模型是一个占位符变量，我们可以传递任何经过训练的 lda 模型。

这样，我们就可以一次看到关于我们主题的大量信息——这比手动检查你的控制台上打印出来的主题要容易得多。在上图中，我们可以看到每个主题在一个二维空间中被表示为一个圆——这个空间是通过查找主题之间的距离而生成的。右边的单词指的是主题中的单词，这是查看单词在主题中如何分布的快速而有用的方法。参考文献 19 中提到的原始论文进一步详述了视觉元素。

`pyLDAvis`库本身有更多的选项供你修改，强烈推荐你查看 Jupyter 笔记本[ [20](http://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb) ]教程，它会带你了解细节。

现在，这个可视化是在之后*我们完成了训练——如果我们想在训练期间可视化进度呢？Gensim 新增了一些功能来帮助解决这一问题。*

我们之前讨论了一致性和困惑性，作为检查模型拟合程度的度量——我们能够看到这些模型在被训练时的进展。

![](Images/4012035b-eb21-46f7-a605-bab8086ec31a.png)

图 9.2 可视化一致性、困惑、主题差异和趋同

我们还可以测量主题差异——它使用 Gensim 中实现的许多距离度量之一来计算两个主题模型之间的距离。我们可以观察的另一个指标是趋同性——这是两个连续时代所有相同主题之间的差异总和。

使用 Gensim 设置这一点相当容易，尽管我们还需要 **visdom** [ [21](https://github.com/facebookresearch/visdom) 服务器来完成这项工作。visdom 服务器是一种基于 Python 的服务器，专门用于帮助可视化数据。由于我们正在可视化一个现场培训过程，我们将需要一台服务器。Jupyter 的笔记本[ [22](https://github.com/parulsethi/gensim/blob/tensorboard_logs/docs/notebooks/Training_visualizations.ipynb) ]中清楚地解释了设置服务器和可视化的说明。

主题模型可以进一步被视为集群——例如，通过使用机器学习算法**T-分布式随机邻居嵌入** ( **T-SNE** ) [ [23](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) ]我们可以使用文档-主题比例来对我们的语料库进行集群。

![](Images/31d00586-5762-457b-9b1d-6a0dee533af1.png)

图 9.3 基于主题和 T-SNE 的 LDA 文档聚类

也可以使用 Word2Vec 进行集群 Jupyter 笔记本[ [24](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Tensorboard_visualizations.ipynb) ]中给出了这种集群的详细信息。

使用 Gensim 和 scipy，我们还可以做一些很酷的事情，例如创建我们的主题如何相关的树状图 Jupyter 笔记本[ [25](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Topic_dendrogram.ipynb) ]详细介绍了这些细节。

![](Images/355b88ec-a11f-4e26-9ed4-ffb9de29e0f9.png)

图 9.4 主题树形图

![](Images/2b17db78-9450-4403-8954-2776d42bdfd6.png)

图 9.5 带有热图的主题树状图

树状图是一种树形结构的图形，可用于可视化任何种类的层次聚类的结果。分层聚类将各个数据点放入相似性组中，根据组的内容，一些组位于彼此的顶部。例如，如果我们对各种行业的语料库进行建模，那么*奔驰*主题可能位于*汽车*主题之下。我们可以使用它来探索主题模型，并查看在聚类过程中出现的连续融合或分割序列中主题是如何相互连接的。

所有这些可视化都是基于 Gensim 的，链接到的 Jupyter 笔记本都来自 Gensim 文档——值得花时间运行 Jupyter 笔记本，亲自看看这些可视化。

也有一些简洁的可视化工具，它们不是正式的 Gensim，但允许我们以有趣的方式查看我们的数据。我们将链接到页面，以便读者可以看一看:

*   可视化趋势[ [26](https://de.dariah.eu/tatom/visualizing_trends.html)
*   主题建模和 t-SNE 可视化[ [27](https://shuaiw.github.io/2016/12/22/topic-modeling-and-tsne-visualzation.html)
*   可视化话题分享[ [28](https://de.dariah.eu/tatom/topic_model_visualization.html)
*   David Blei -可视化主题模型[ [29](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM12/paper/viewFile/4645/5021)

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 摘要

有了[第 8 章](02e3238f-db9c-4d6e-ba96-70ba9db11dc0.xhtml)、*主题模型*和[第 9 章](a3906dc9-57a9-470f-adbe-5695111700e2.xhtml)、*高级主题建模*，我们现在已经具备了将主题模型应用于文本数据的工具和知识。主题建模在很大程度上是一种数据探索工具，但我们也可以进行一些更有针对性的分析，如查看组成文档的主题，或者文档中的哪些单词属于哪个主题。Gensim 为我们提供了相当容易地执行这些任务的功能，其 API 的构建使得我们可以轻松地访问主题模型背后的数学信息。

在下一章，我们将进行更有针对性的文本分析任务，如聚类或分类。聚类和分类算法主要用于文本分析，将相似的文档分组在一起，是机器学习算法。我们将解释这些方法背后的直觉，并举例说明代码示例。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 参考

[1] Gensim 字典类:
[https://radimrehurek.com/gensim/corpora/dictionary.html](https://radimrehurek.com/gensim/corpora/dictionary.html)

[2] Gensim LdaModel 类:
[https://radimrehurek.com/gensim/models/ldamodel.html](https://radimrehurek.com/gensim/models/ldamodel.html)

[3] Scikit-Learn LDA 类:
[http://sci kit-Learn . org/stable/modules/generated/sk Learn . decomposition . latentdirichletallocation . html](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)

[4] Gensim LDA:提示和技巧:
[https://miningthedetails.com/blog/python/lda/GensimLDA/](https://miningthedetails.com/blog/python/lda/GensimLDA/)

[5]食谱和常见问题:
[https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-常见问题](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ)

[6]学期专题 Jupyter 笔记本:
[https://github . com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic _ methods . ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb)

[7]距离度量:
[https://github . com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Distance _ Metrics . ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/distance_metrics.ipynb)

[8]主题模型解读:
[https://towards data science . com/improving-the-Interpretation-of-Topic-Models-87fd 2 ee 3847d](https://towardsdatascience.com/improving-the-interpretation-of-topic-models-87fd2ee3847d)

【9】什么是话题连贯:
[https://rare-technologies.com/what-is-topic-coherence/](https://rare-technologies.com/what-is-topic-coherence/)

[10]探索话题连贯性度量的空间:
[https://SVN . aksw . org/papers/2015/WSDM _ Topic _ Evaluation/public . pdf](https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf)

[11]题目模型中的困惑:
[http://qpleple.com/perplexity-to-evaluate-topic-models/](http://qpleple.com/perplexity-to-evaluate-topic-models/)

[12]话题建模笔记本:
[https://github . com/bhargavader/personal/blob/master/notebooks/text _ analysis _ tutorial/Topic _ modeling . ipynb](https://github.com/bhargavvader/personal/blob/master/notebooks/text_analysis_tutorial/topic_modelling.ipynb)

[13]相干模型管道:
[https://radimrehurek.com/gensim/models/coherencemodel.html](https://radimrehurek.com/gensim/models/coherencemodel.html)

[14]用 Gensim 进行新闻分类:
[https://github . com/RaRe-Technologies/Gensim/blob/develop/docs/notebooks/Gensim _ News _ Classification . ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/gensim_news_classification.ipynb)

[15]电影数据集上的主题一致性:
[https://github . com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Topic _ Coherence-Movies . ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence-movies.ipynb)

[16]话题连贯性介绍:
[https://github . com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Topic _ Coherence _ tutorial . ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence_tutorial.ipynb)

[17]话题连贯用例:
[https://gist . github . com/dsquareindia/AC 9d 3 BF 57579d 02302 f 9655 db 8 dfdd 55](https://gist.github.com/dsquareindia/ac9d3bf57579d02302f9655db8dfdd55)

[18]话题连贯性模型选择:
[https://github . com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Topic _ Coherence _ Model _ Selection . ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence_model_selection.ipynb)

[19] LDAvis:一种可视化和解释主题的方法:
[https://NLP . Stanford . edu/events/ill VI 2014/papers/sievert-ill VI 2014 . pdf](https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf)

[20]pyl Davis:
[http://nb viewer . jupyter . org/github/bmabey/pyl Davis/blob/master/notebooks/pyl Davis _ overview . ipynb](http://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb)

[21] visdom: 
[https://github.com/facebookresearch/visdom](https://github.com/facebookresearch/visdom)

[22] LDA 训练可视化:
[https://github . com/parulsethi/gensim/blob/tensor board _ logs/docs/notebooks/Training _ visualizations . ipynb](https://github.com/parulsethi/gensim/blob/tensorboard_logs/docs/notebooks/Training_visualizations.ipynb)

[23]T-SNE:
[https://en . Wikipedia . org/wiki/T-distributed _ random _ neighbor _ embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)

[24]tensor board Visualizations:
[https://github . com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/tensor board _ Visualizations . ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Tensorboard_visualizations.ipynb)

[25]话题树状图:
[https://github . com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Topic _ dendrogram . ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Topic_dendrogram.ipynb)

[26]可视化趋势:
[https://de.dariah.eu/tatom/visualizing_trends.html](https://de.dariah.eu/tatom/visualizing_trends.html)

[27]话题建模与 t-SNE 可视化:
[https://Shuai w . github . io/2016/12/22/Topic-Modeling-and-tsne-Visualization . html](https://shuaiw.github.io/2016/12/22/topic-modeling-and-tsne-visualzation.html)

[28]可视化题材股:
[https://de.dariah.eu/tatom/topic_model_visualization.html](https://de.dariah.eu/tatom/topic_model_visualization.html)

[29]大卫·布莱-可视化主题模型:
[https://www . aaai . org/OCS/index . PHP/ICWSM/ICWSM 12/paper/view file/4645/5021](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM12/paper/viewFile/4645/5021)
<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 词性标注及其应用

[第 1 章](26004756-ab10-461a-b1ed-b254daa537ea.xhtml)、*什么是文本分析*和[第 2 章](0e3d7fa2-dde1-4780-9d8f-422eaca9ba1b.xhtml)、 *Python 对文本分析的提示*，介绍了文本分析和 Python，而[第 3 章](be6f4ff3-1217-474a-8923-5eeeed17bfa1.xhtml) *、SpaCy 的语言模型*和[第 4 章](ad7d7774-1bef-4a55-ae7c-0d77097a43b7.xhtml)、 *Gensim -向量化文本和转换以及 n-grams* ，帮助我们设置我们的代码以进行更高级的文本分析。本章将讨论第一种高级技术——词性标注，通常称为词性标注。我们将研究存在哪些词类，如何在我们的文档中识别它们，以及这些词类标签可能的用途。

*   什么是词性标注？
*   词性标注的空间
*   培训你的张贴者
*   词性标注示例

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 什么是词性标注？

理解词性标注的第一步显然是扩展首字母缩略词—**词性**标注。现在，事情就简单多了，不是吗？顾名思义，它是在文本输入中用适当的词性标注单词的过程。我们之前已经简要讨论过这个问题，特别是在处理 spaCy 及其语言模型时。因此，虽然我们知道词性标注指的是用词性标注单词的行为，但我们并没有过多地讨论自然语言(尤其是英语)中的词性到底是什么，以及为什么它可能与我们在文本分析领域相关。

传统上，词类是具有相似语法性质或用法的词的范畴。我们将把我们的努力集中在英语语言上(正如我们已经并将继续在本书中所做的那样)，但一般来说，这些类别可以扩展到大多数语言，如果不是所有语言的话。英语中通常列出的类别有:

*   名词 -一个人、地方、事物或想法的名字
*   动词 -行动或存在
*   形容词 -修饰或描述一个名词或代词
*   副词 -修饰或描述一个动词、形容词或另一个副词
*   代词 -用来代替名词的词
*   **介词** -放在名词或代词前形成短语修饰句子中另一个词的词
*   连接词 -连接单词、短语或从句
*   **感叹词**——用来表达情感的词

一个词还可以有各种各样的子类，也没有一个官方的词类清单。事实上，出于文本分析或计算语言学的目的，我们将关注一个特定的标记者可以将一个单词标记为的所有可能的划分！正如我们将在 spaCy 中看到的，这可以在*普通*类别或甚至更详细的类别之间的任何地方。

由于本书的目的不是解释语言学的概念，我们不会详细描述各种词类，鼓励读者浏览一下每个词类的意思。我们希望读者能够熟悉基本的 POS 类别，这将在以后派上用场！

以下链接将有助于您更好地熟悉词类:

1.  八个词类[ [1](http://www.butte.edu/departments/cas/tipsheets/grammar/parts_of_speech.html)
2.  partofspeech.org[[2](http://partofspeech.org/)

我们之前提到过，我们将关注英语和英语词性，但是大多数可用的词性标注器也为非英语语言提供标注功能。还应该注意的是，我们用来训练张贴者的原则，以及我们可以使用这些信息的不同方式往往保持不变，人们可以继续我们在这里学到的经验教训。

全自然语言之间通常保持的共同点是名词和动词，但当我们超越这一点时，确定不同的词类变得越来越困难。例如，一些语言不区分形容词和副词，而日语有三个不同的形容词类别。

即使在英语中，词性标注也不总是一项简单的任务，单词根据上下文有不同的词性标注。一个简单的例子是单词*reject*，如果用作动词，它的意思是拒绝一个提议，当用作名词时，它用来指你扔掉的东西或垃圾。对我们来说，能够识别出这个词指的是什么意思是很重要的，而词性标签在这里可以帮助我们。至于首先识别词性标签，上下文是至关重要的——我们不可能用词性来标记一个词，除非它在一个句子或短语中。

那么如何识别一个单词的词性标签呢？当然，传统上这是手工完成的，但是从计算的角度来看，我们有不止一种方法可以做到这一点。我们之前提到过，我们必须关注标记者识别的许多位置标记——在某些情况下，有多达 100 个不同的标记，但这并不总是非常有用——我们将主要使用的空间位置标记器使用 19 个不同的类别来对标记进行分类。在所有现实的文本分析场景中，我们都不会处理纯文本数据——很可能会有无法识别的数字、符号和单词，在这种情况下，我们很可能会有多个类别。

在 spaCy 中，为了进行更详细的分析，我们还使用了`.tag_`属性，它向之前给出的`.pos_`属性添加了更多信息。下表给出了 spaCy 用来注释其单词的分类。

![](Images/fa024603-9259-42ba-8232-9bd1ab3f230c.png)

图 5.1 spaCy 注释规范中描述的位置列表[3]

既然我们已经确定了*什么是*词性标注，那么让我们来讨论一下*是如何实现的。*由于所有原始的词性标注都是在观察后手工完成的，因此在构建统计模型时，我们需要处理大量的分类数据。Brown 语料库是用词性标注数据很好注释的语料库的一个例子。最初几个用来训练标签的概率模型将使用**隐马尔可夫模型** [ [4](https://en.wikipedia.org/wiki/Hidden_Markov_model) ]来预测标签。

每当有序列出现时，就倾向于使用隐马尔可夫模型——这被证明是有用的，因为我们可以使用关于单词上下文的信息来预测词性标签可能是什么。例如，一旦你看到一篇文章，比如*，也许下一个词 40%的时候是名词，35%是形容词，25%是数字。知道了这一点，程序就可以决定*拒绝*在*中，拒绝*更可能是名词而不是动词，这就解决了我们之前讨论的问题。*

 *除了统计模型，还有基于规则的词性标注器，它使用预定义的规则来执行标注或从语料库中学习这些规则。当然，这些方法并没有抛弃统计方法，只是更少依赖统计方法。Eric Brill 在他 1998 年的论文中描述了其中最流行的一种方法，该论文名为*一个简单的基于规则的词性标注器* [ [5](http://www.aclweb.org/anthology/A92-1021) 。

您可以尝试其他更简单的方法，只是为了尝试了解我们正在尝试的任务，例如使用正则表达式来评估词性，或者简单地存储某个单词最可能的标签，并用相同的标签标记所有未来出现的单词。尽管词性标注已经有了很大的发展，但就像大多数高精度的计算任务一样，统计学习或深度学习是未来的发展方向。

神经网络已经在多个数据集上取得了最先进的结果 ACL web 在其网站上维护了一个列表-[https://ACL web . org/ACL wiki/POS _ Tagging _(State _ of _ the _ art)](https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art))。

即使使用更简单的机器学习模型，如感知器分类器，也有可能接近这种结果。事实上，spaCy 的第一批贴标者之一是一个平均感知机，他们的博客上有一篇文章详细介绍了他们的贴标者的内部工作方式，并作为如何建立它的教程。用于词性标注的感知器通过基于各种特征或信息学习单词标签的概率来工作，这些特征或信息可以包括前一个单词的标签或单词的最后几个字母。通过积极奖励正确的分类和惩罚不正确的分类，该模型学习用于预测新词标签的权重。事实上，大多数有监督的机器学习算法都基于类似的原理，这些算法在词性标注任务中表现良好。

现在我们对*如何，*有了更好的了解，让我们来谈谈*为什么。*从直觉上看，知道一个单词的词性可能很有用，但我们究竟能利用这些信息做什么呢？出于各种原因和目的，历史上在自然语言处理中使用了 POS 标签。一个有趣的目的是语音到文本的转换和语言翻译，这时可以使用强大的词性标注器来消除同音异义词的歧义。考虑这个例子，当一个人说:*我要去抓鱼*，并希望这个句子被翻译成另一种语言，例如法语或西班牙语；重要的是要知道这里的鱼是名词还是动词——与英语不同，在目标语言中，描述捕鱼行为的词很可能与动物的词截然不同。

类似地，词性标注用于**依存解析**。顾名思义，依存解析是识别句子或短语中单词之间的依存关系或关系的过程。我们将用整整一章的时间来讨论这些依存关系以及它们是如何工作的，但是现在理解识别每个单词的词性是生成这种依存关系树的重要部分就足够了。如果我们在例句中使用漂亮的空间**显示**模块[6](https://explosion.ai/demos/displacy)—*我要去抓鱼。*，这就是我们得到的。

![](Images/5d5252f2-6c9b-4b77-8589-c5a63f9f1516.png)

图 5.2 句子“我要去钓鱼”经过 spaCY 的依存分析

我们可以看到，词类标注除了仅仅为了找出词类之外，还有大量的应用。但是，即使只是这些信息也能给我们一些非常有趣的结果，其中一些我们将在下一节看到。* *<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# Python 中的词性标注

每次我们提到实际执行词性标注时，我们都会链接到或提到 spaCy——它可以说是最快的标记器、标记器和解析器之一，我们将在所有示例中使用它。

但是在我们深入 spaCy 之前，我们将简要讨论一下它在 Python 中的主要竞争对手,也就是 NLTK。我们以前已经讨论过 spaCy 与 NLTK 的争论，我们将坚持我们以前的立场，将 spaCy 用于我们所有的现实世界应用程序目的，但是仍然值得看看 NLTK 提供了什么。

NLTK 用于试验或沙盒的相当简单的 API 通常使它成为对初学者有吸引力的选择。要为一个句子获取合适的标签，我们只需运行以下代码:

```
import nltk
text = nltk.word_tokenize("And now for something completely different")
nltk.pos_tag(text)

[('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'), ('completely', 'RB'), ('different', 'JJ')]
```

如果我们希望使用一个特定的标记符(NLTK 提供了许多选项)，我们只需导入这个特定的标记符。`train_sents`对象是您希望用来训练`bigram`标记者的训练句子。

```
bigram_tagger = nltk.BigramTagger(train_sents)
bigram_tagger.tag(text)
```

如果读者有兴趣查看，下面的链接提供了关于使用 NLTK 进行词性标注的更多信息:

1.  标签模块[ [7](https://www.nltk.org/api/nltk.tag.html) ]的官方文档
2.  NLTK 书第五章[ [8](https://www.nltk.org/book/ch05.html)
3.  培训 NLTK POS-tagger [ [9](https://textminingonline.com/dive-into-nltk-part-iii-part-of-speech-tagging-and-pos-tagger)

NLTK 并不是 POS-tagging 的唯一 Python 替代品—*人工智能实践:识别 Python 中的词性* [ [10](https://medium.com/@brianray_7981/ai-in-practice-identifying-parts-of-speech-in-python-8a690c7a1a08) ]:带我们浏览 Python 中所有不同的选项。在众多标签中，`TextBlob`可能是唯一值得一看的另一个标签。这个标记器的性能与 spaCy 中的非常相似，这是有意义的，因为算法是由 spaCy 维护者编写的。这篇博文更详细地介绍了如何使用`TextBlob` [ [11](https://stevenloria.com/pos-tagging/) ]来完成你的位置标记。

当涉及到 NLTK 和其他 Python 选项时，这就是我们要讨论的全部内容——因为涉及到词性标注时，它的方法更加学术化、臃肿，所以我们将坚持使用 spaCy。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 带空格的词性标注

spaCy 的词性标注就像 spaCy 的任何其他基本语言功能一样——这是载入其管道的核心功能之一。如果您加载您选择的空间模块，并通过管道运行文本，您将对该文本进行位置标记——以及标记化、NER 标记，并准备好进行依赖解析。在介绍 spaCy 语言模型的章节中，我们已经看到了 spaCy 在这方面的能力。

设置我们的模型包括我们之前看到的相同步骤。

```
import spacy
nlp = spacy.load('en')
```

现在让我们决定一些我们想要添加标签的句子。

```
sent_0 = nlp(u'Mathieu and I went to the park.')
sent_1 = nlp(u'If Clement was asked to take out the garbage, he would refuse.')
sent_2 = nlp(u'Baptiste was in charge of the refuse treatment center.')
sent_3 = nlp(u'Marie took out her rather suspicious and fishy cat to go fish for fish.')
```

句子 0 是直截了当的，它将说明一个基本句子将如何进行词性标注。

```
for token in sent_0:
    print(token.text, token.pos_, token.tag_)

(u'Mathieu', u'PROPN', u'NNP')
(u'and', u'CCONJ', u'CC')
(u'I', u'PRON', u'PRP')
(u'went', u'VERB', u'VBD')
(u'to', u'ADP', u'IN')
(u'the', u'DET', u'DT')
(u'park', u'NOUN', u'NN')
(u'.', u'PUNCT', u'.')
```

让我们来看看这里的一些标签——`Mathieu`是一个名字，它被正确地标记为专有名词，`went`是一个动词，`park`是一个名词——所有这些都是我们所期望的。我们之前讨论过单词*拒绝*，以及它是如何既是名词又是动词的。

```
for token in sent_1:
    print(token.text, token.pos_, token.tag_)

(u'If', u'ADP', u'IN')
(u'Clement', u'PROPN', u'NNP')
(u'was', u'VERB', u'VBD')
(u'asked', u'VERB', u'VBN')
(u'to', u'PART', u'TO')
(u'take', u'VERB', u'VB')
(u'out', u'PART', u'RP')
(u'the', u'DET', u'DT')
(u'garbage', u'NOUN', u'NN')
(u',', u'PUNCT', u',')
(u'he', u'PRON', u'PRP')
(u'would', u'VERB', u'MD')
(u'refuse', u'VERB', u'VB')
(u'.', u'PUNCT', u'.')
```

在这里，单词`refuse`是一个动词，正如我们所期望的那样。单词`garbage`是一个名词，是我们的朋友`Clement`拒绝拿出来的对象。我们的下一个句子也是一个涉及`garbage`的例子，但是这里的`refuse`是指在工厂里被处理的物质。

```
for token in sent_2:
    print(token.text, token.pos_, token.tag_)

(u'Baptiste', u'PROPN', u'NNP')
(u'was', u'VERB', u'VBD')
(u'in', u'ADP', u'IN')
(u'charge', u'NOUN', u'NN')
(u'of', u'ADP', u'IN')
(u'the', u'DET', u'DT')
(u'refuse', u'NOUN', u'NN')
(u'treatment', u'NOUN', u'NN')
(u'center', u'NOUN', u'NN')
(u'.', u'PUNCT', u'.')
```

瞧啊。正如我们想看到的，单词`refuse`现在被正确地标记为名词。随着 it 的上下文显示为`Baptiste`负责的事情，它被适当地改为名词。事实上，最后三个单词都是名词，或者是我们称之为**的名词短语**。我们将在依赖解析一章中更详细地讨论这个术语。

现在让我们看看最后一句话:

```
for token in sent_3:
    print(token.text, token.pos_, token.tag_)

(u'Marie', u'PROPN', u'NNP')
(u'took', u'VERB', u'VBD')
(u'out', u'PART', u'RP')
(u'her', u'ADJ', u'PRP$')
(u'rather', u'ADV', u'RB')
(u'suspicious', u'ADJ', u'JJ')
(u'and', u'CCONJ', u'CC')
(u'fishy', u'ADJ', u'JJ')
(u'cat', u'NOUN', u'NN')
(u'to', u'PART', u'TO')
(u'fish', u'VERB', u'VB')
(u'for', u'ADP', u'IN')
(u'fish', u'NOUN', u'NN')
(u'.', u'PUNCT', u'.')
```

这个句子的目的是试图用单词`fish`*的不同变体来欺骗我们的标记者，但是我们的标记者可以很容易地在适当的上下文中分辨出不同。我们的模型是一个机器学习模型，除了其他训练功能，它还使用先前单词和即将出现的单词的标签来决定新标签——单词`fishy`被标记为动词，部分原因是名词紧随其后，部分原因是连接词出现在前面，也可能是因为它以字母`y` *结尾。大多数机器学习模型在决定新标签时会考虑多个特征。**

 *单词 *fish* 的其他出现很容易预测，我们在本章前面也看到了这一点。spaCy 在这方面做得非常好——我们还应该记住，我们还有大量关于句子中标记的其他数据，而不仅仅是词性标记。我们是在一石多鸟！

尽管 spaCy 的预训练模型令人印象深刻，但我们不必局限于它们。spaCy 为我们提供了使用他们的机器学习模型来训练我们的模型的功能，我们将看看这是如何完成的。* *<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 培训我们自己的张贴者

由 spaCy 模型完成的关于其位置标签的预测是统计预测；不像，比方说，它是否是一个停用词，它只是一个单词列表的检查。如果它是一个统计预测，这意味着我们可以为它训练一个模型来执行更好的预测或与我们打算使用它的数据集更相关的预测。在这里，更好并不意味着从字面上理解——当前的 spaCy 模型在标记准确性方面已经达到 97%。

在深入我们的训练过程之前，让我们澄清一些机器学习和文本机器学习的常用术语。

训练——教你的机器学习模型如何做出正确预测的过程。在文本分析中，我们通过向模型提供分类数据来做到这一点。这是什么意思？在词性标注的设置中，它将是一个单词及其标注词性的列表。这个标记的信息然后用于学习某些*权重*，这些权重进一步用于进行预测。我们以前在描述感知器标记器时使用过这些术语。

那么这些重量是怎么学来的呢？我们提到，我们为模型提供分类数据，这些数据被称为我们的训练数据。一旦我们开始做预测并犯错误，权重就会相应地调整以最小化错误。我们通过损失函数的误差梯度来计算这种反馈。性能越差，误差梯度越大，性能越好，误差梯度越小——我们也可以将其理解为权重需要改变的方向，以便我们的预测更好。

![](Images/5b7f18a3-abeb-44a9-830c-79fb45e19fc4.png)

图 5.3 spaCy 模型的训练过程说明，如其训练页面[ [12](https://spacy.io/usage/training) ]所述

我们将遇到的最后一个行话是*测试数据*。这只是我们在训练后最终将使用的数据，以查看我们的模型表现如何。这也是一组标记或分类的数据，通过检查模型预测的标签与单词的实际标签，我们可以验证我们的模型执行得有多好。虽然所有这些都是在词性标签的上下文中，但它可以扩展到文本分析内外的其他预测形式。spaCy 训练页面[ [12](https://spacy.io/usage/training) 值得一看，并进一步讨论 spaCy 中的训练模式是如何工作的。

既然我们已经有了理论——我们如何实际训练我们的模型呢？

获取数据有时是一件痛苦的事情，对于非常大规模的项目来说，这可能是一个瓶颈。在培训文档页面中，有关于大规模培训问题的例子，建议使用`prodigy`工具[ [13](https://prodi.gy/) 收集上述数据。在 v2.0 之前，`GoldParse` [ [14](https://spacy.io/api/goldparse) ]对象用于训练目的，但是我们更愿意探索使用原始文本和注释字典的更简单的方法。同样，我们不会详细讨论 prodigy 或如何使用`GoldParse`，因为它们不是推荐的方法——但仍然值得了解。

一个简单的训练循环如下所示:

```
TRAIN_DATA = [ 
     ("Facebook has been accused for leaking personal data of users.", {'entities': [(0, 8, 'ORG')]}), 
     ("Tinder uses sophisticated algorithms to find the perfect match.", {'entities': [(0, 6, "ORG")]})]

nlp = spacy.blank('en')
optimizer = nlp.begin_training()
for i in range(20):
    random.shuffle(TRAIN_DATA)
    for text, annotations in TRAIN_DATA:
        nlp.update([text], [annotations], sgd=optimizer)
nlp.to_disk('/model')
```

我们可以看到它在理论上是多么简单——只需提供句子，我们打算训练的部分(这可以是:*实体，头部，deps，标签，*和*猫*)，以及句子中对应于实体或标签的部分，元组中的第三个值对应于我们希望给予元组的第一个和第二个值中标记出的索引之间的单词的标签。在给出的例子中，我们可以看到`Facebook`和`Tinder`是两个被标记为`ORG`或组织的实体。

训练一个贴标签者在理论上没有任何不同，我们将使用 spaCy GitHub 页面中的示例代码(`train_tagger.py` [ [18](https://github.com/explosion/spacy/blob/master/examples/training/train_tagger.py) ])来指导我们如何去做。

```
import plac
import random
from pathlib import Path
import spacy

TAG_MAP = { 
    'N': {'pos': 'NOUN'}, 
    'V': {'pos': 'VERB'}, 
    'J': {'pos': 'ADJ'} 
}
```

我们已经设置了基本的导入，并初始化了`TAG_MAP`字典。我们需要定义从数据的词性标签名称到**通用词性标签**集[ [15](http://universaldependencies.org/docs/u/pos/index.html) ]的映射，因为 spaCy 包括这些标签的枚举。在这个例子中，我们只打算训练名词、动词和形容词，所以我们将它们包含在我们的标记图中。

```
TRAIN_DATA = [ 
    ("I like green eggs", {'tags': ['N', 'V', 'J', 'N']}), 
    ("Eat blue ham", {'tags': ['V', 'J', 'N']}) 
]
```

当然，这么多的训练数据不会训练出一个非常好的模型。正如在大多数机器学习问题中一样，更多的数据会产生更好的模型，这里提供的数据只是给出训练数据应该如何的想法。

```
@plac.annotations( 
    lang=("ISO Code of language to use", "option", "l", str), 
    output_dir=("Optional output directory", "option", "o", Path), 
    n_iter=("Number of training iterations", "option", "n", int))
```

我们为语言、输出目录和一些训练迭代设置了一些注释。

```
def main(lang='en', output_dir=None, n_iter=25):
    """Main function to create a new model, set up the pipeline and train 
    the tagger. In order to train the tagger with a custom tag map, 
    we're creating a new Language instance with a custom vocab.
    """
    nlp = spacy.blank(lang)
    tagger = nlp.create_pipe('tagger')
```

我们现在已经创建了一个新的空白语言模型，并使用`create_pipe`方法将标记器添加到管道中。注意，这适用于向 spaCy 注册的内置程序。

```
    for tag, values in TAG_MAP.items():
        tagger.add_label(tag, values)
    nlp.add_pipe(tagger)
```

我们现在已经添加了标签。这需要在你开始训练之前完成。

```
    optimizer = nlp.begin_training()
    for i in range(n_iter):
        random.shuffle(TRAIN_DATA)
        losses = {}
        for text, annotations in TRAIN_DATA:
            nlp.update([text], [annotations], sgd=optimizer, losses=losses)
        print(losses)
```

我们已经在示例中看到过这部分培训过程。

```
    test_text = "I like blue eggs"
    doc = nlp(test_text)
    print('Tags', [(t.text, t.tag_, t.pos_) for t in doc])
```

在将模型保存到输出目录之前，让我们在测试模型的地方做一个快速的完整性检查。

```
    if output_dir is not None: 
        output_dir = Path(output_dir) 
        if not output_dir.exists(): 
            output_dir.mkdir() 
        nlp.to_disk(output_dir) 
        print("Saved model to", output_dir) 

        # test the save model 
        print("Loading from", output_dir) 
        nlp2 = spacy.load(output_dir) 
        doc = nlp2(test_text) 
        print('Tags', [(t.text, t.tag_, t.pos_) for t in doc]) 

if __name__ == '__main__': 
    plac.call(main)
```

```
# Expected output:
# [
#   ('I', 'N', 'NOUN'),
#   ('like', 'V', 'VERB'),
#   ('blue', 'J', 'ADJ'),
#   ('eggs', 'N', 'NOUN')
# ]
```

这就是我们拥有的。我们自己的定制培训的 POS-tagger！当然，这不会是最好的贴标，除非我们的语料库是我们对不同早餐食品的意见的微小语料库——但通常情况并非如此。对于所有真实世界的场景，训练数据将更加庞大，汇集这些数据将是我们训练任务的一个重要部分。

在我们训练空间模型的情况下，我们用来训练标注者的机器学习模型被抽象给我们。我们只使用了`update()`方法来训练我们的模型，并不了解模型的*性质*，除了知道它工作良好，并且是一个神经网络。虽然在所有实际情况下，这都非常有效，但是如果我们真的希望训练我们自己的*T4 分类器，这并不难做到。*

对于了解 scikit-learn 如何工作的更高级的用户，博客文章[ [16](https://nlpforhackers.io/training-pos-tagger/) ]展示了一个使用 NLTK 来生成数据的示例，以便使用 scikit-learn 来训练自己的分类器。我们将在本书的后面部分遇到 scikit-learn 以及如何训练这样的模型，但是好奇的读者可以查看链接以了解如何构建它。

但是对于权威的*如何建立自己的词性标注器*教程，spaCy 博客有一篇文章描述了完全相同的内容——*一个很好的词性标注器，大约 200 行 Python* [ [17](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python) ]。我们之前在描述基于感知器的标签时链接到了这篇文章，这也是`TextBlob`使用的标签。

我们走吧！我们现在有足够的知识来训练我们自己的空间标记，在我们的管道中使用它，更重要的是，我们知道为什么它是文本分析的一个重要部分。我们最后的简短部分展示了一些代码片段，描述了我们可以利用 POS-tag 知识做些什么。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 位置标记代码示例

下面的代码片段说明了我们可以利用 POS-tag 知识完成的一些简单任务。这些例子在深入的文本分析方面没有取得太多的成就，但是在我们处理完文本后，提供了对文本操作的快速浏览。

```
def make_verb_upper(text, pos):
    return text.upper() if pos == "VERB" else text
doc = nlp(u'Tom ran swiftly and walked slowly')
text = ''.join(make_verb_upper(w.text_with_ws, w.pos_) for w in doc)
print(text)
```

正如函数名所示，前面的代码是将句子的所有动词改为大写。通过快速检查 POS-tag 和基本的字符串函数`upper`，我们可以用 5 行代码实现！

另一个在文本分析过程中经常做的流行任务是统计每种词性的出现次数。使用下面的代码片段可以很快做到这一点，在这里我们可以找到这些单词在第一部^(到第一部)哈利波特书中出现的次数(你可以购买/下载并保存为文本文件):

```
import pandas as pd

harry_potter = open("HP1.txt").read()
hp = nlp(harry_potter)
hpSents = list(hp.sents)
hpSentenceLengths = [len(sent) for sent in hpSents]
[sent for sent in hpSents if len(sent) == max(hpSentenceLengths)]
hpPOS = pd.Series(hp.count_by(spacy.attrs.POS))/len(hp)

tagDict = {w.pos: w.pos_ for w in hp}
hpPOS = pd.Series(hp.count_by(spacy.attrs.POS))/len(hp)
df = pd.DataFrame([hpPOS], index=['Harry Potter'])
df.columns = [tagDict[column] for column in df.columns]
df.T.plot(kind='bar')
```

![](Images/aef75686-8298-432b-aeb1-c9023b487b46.png)

y 轴是出现在文本中的位置标签的百分比。

如果我们想找到最常用的代词呢？对于这个任务，我们只需要两行:

```
hpAdjs = [w for w in hp if w.pos_ == 'PRON']
Counter([w.string.strip() for w in hpAdjs]).most_common(10)

[(u'he', 1208), 
 (u'I', 923), 
 (u'it', 898), 
 (u'you', 846), 
 (u'He', 549), 
 (u'they', 507), 
 (u'him', 493), 
 (u'them', 325), 
 (u'It', 287), 
 (u'me', 215)]
```

词性标签的知识可以帮助我们进行更深入的文本分析。它是自然语言处理的一个支柱，在标记化文本之后，通常是我们进行的第一个分析。spaCy 为我们提供了执行词性标注的最佳方式，但是我们也研究了 Python 提供给我们的所有其他选项。对于我们将探索的计算语言学任务的剩余部分，我们将坚持 spaCy，例如在下一章中的 NER 标记和依存句法分析。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 摘要

在本章中，我们已经探索了如何使用 spaCy 作为管道的一部分，特别是如何提取 POS-tag。我们讨论了什么是位置标签，以及它们如何在不同种类的分析中有用。我们很快就开始在 spaCy 中训练你自己的位置标签，并且看了我们使用位置标签的不同例子。我们现在将探索其他空间功能，如 NER 标记和依存解析。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles1.css" rel="stylesheet" type="text/css">

# 参考

[1] 8 词性:
[http://www . butte . edu/departments/cas/tipsheets/grammar/Parts _ of _ Speech . html](http://www.butte.edu/departments/cas/tipsheets/grammar/parts_of_speech.html)

[2]词类概述:
[http://partofspeech.org/](http://partofspeech.org/)

[3]空间标注规格:
[https://spacy.io/api/annotation#pos-tagging](https://spacy.io/api/annotation#section-pos-tagging)

[4]隐马尔可夫模型:
[https://en.wikipedia.org/wiki/Hidden_Markov_model](https://en.wikipedia.org/wiki/Hidden_Markov_model)

[5]一个简单的基于规则的词性标注器:
[【http://www.aclweb.org/anthology/A92-1021】](http://www.aclweb.org/anthology/A92-1021)

[6]displaCy:
[https://explosion.ai/demos/displacy](https://explosion.ai/demos/displacy)

[7] ntlk 标签模块:
[https://www.nltk.org/api/nltk.tag.html](https://www.nltk.org/api/nltk.tag.html)

[8] nltk 第五章:
[https://www.nltk.org/book/ch05.html](https://www.nltk.org/book/ch05.html)

[9]训练 NLTK tagger:
[http://textminingonline . com/dive-into-NLTK-part-iii-词性标注和词性标注器](https://textminingonline.com/dive-into-nltk-part-iii-part-of-speech-tagging-and-pos-tagger)

[10] AI 在实践中:Python 中的词性识别:
[https://medium . com/@ Brian ray _ 7981/AI-in-Practice-Identifying-Parts-in-Python-8a 690 c 7 a1a 08](https://medium.com/@brianray_7981/ai-in-practice-identifying-parts-of-speech-in-python-8a690c7a1a08)

[11]text blob 中的语音标注:
[https://stevenloria.com/pos-tagging/](https://stevenloria.com/pos-tagging/)

[12]空间训练:
[https://spacy.io/usage/training](https://spacy.io/usage/training)

【13】神童:
[https://prodi.gy/](https://prodi.gy/)

[14]金本位:
[https://spacy.io/api/goldparse](https://spacy.io/api/goldparse)

[15]通用 POS 标签:
[http://universaldependencies.org/docs/u/pos/index.html](http://universaldependencies.org/docs/u/pos/index.html)

[16]训练你的广告员:
[https://nlpforhackers.io/training-pos-tagger/](https://nlpforhackers.io/training-pos-tagger/)

【17】200 行左右的 python 中的一个不错的词性标注器:
[https://explosion . ai/blog/词性标注器-在 Python 中](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python)

[18]train _ tagger . py:
[https://github . com/explosion/spacy/blob/master/examples/training/train _ tagger . py](https://github.com/explosion/spacy/blob/master/examples/training/train_tagger.py)**
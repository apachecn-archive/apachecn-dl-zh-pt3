

# 什么是文本分析？

没有时间像现在这样进行文本分析——我们有大量容易获得的数据，强大和免费的开源工具来进行我们的分析，机器学习，计算语言学和文本计算的研究正在以我们从未见过的速度前进。

在这一章中，我们将详细介绍什么是文本分析，并看看学习和理解文本分析的动机。以下是我们将在本章中涉及的主题:

*   什么是文本分析？
*   数据在哪里？
*   垃圾进，垃圾出
*   你为什么会感兴趣？
*   参考

关于参考文献的说明:它们将作为链接出现在书的 PDF 版本中，如果是学术参考文献，它将链接到参考文献的 PDF 或期刊页面。所有这些链接和参考资料都会显示在本章的最后一节，这样离线读者也可以访问网站或研究论文。



# 什么是文本分析？

如果有一种媒介是我们每天都接触到的，那就是文字。无论是我们的晨报还是我们收到的信息，很可能你是以文本的形式收到信息的。

让我们从更长远的角度来看问题——考虑一下谷歌(每年 1+万亿次查询)、Twitter(每天 16 亿次查询)和 WhatsApp(每天 300+亿条消息)等公司处理的文本数据量。这是一个不可思议的资源，文本无处不在的本质足以让我们认真对待它。文本数据也具有巨大的商业价值，公司可以使用这些数据来帮助描述客户和了解客户趋势。这既可以用来为用户提供更个性化的体验，也可以作为有针对性的营销信息。例如，脸书大量使用文本数据，我们将在本书后面学习的算法之一是由脸书的人工智能研究团队开发的。

![](Images/9abac296-d0e1-4e66-bd39-2603cef2b8f6.png)

图 1.1 2006 年至 2018 年的数据增长率，以及 2019 年和 2020 年的预测数据增长率。资料来源:https://www.eetimes.com/author.asp?，帕特里克·齐斯曼 section_id=36&doc_id=1330462

文本分析可以理解为从文本中收集有用信息的技术。这可以通过各种技术来实现，我们使用**自然语言处理** ( **NLP** )、**计算语言学** ( **CL** )，以及数值工具来获取这些信息。这些数字工具是机器学习算法或信息检索算法。我们将简要地、非正式地解释这些术语，因为它们将在整本书中出现。

自然语言处理(NLP)是指使用计算机来处理自然语言。例如，从文本主体中删除所有出现的单词*从而*就是一个这样的例子，尽管这是一个基本的例子。

计算语言学，顾名思义，是从计算的角度研究语言学。这意味着使用计算机和算法来执行语言学任务，如将文本标记为词性(如名词或动词)，而不是手动执行这项任务。

**机器学习** ( **ML** )是我们使用统计算法来教会机器执行特定任务的研究领域。这种*学习*发生在数据上，我们的任务通常是根据之前观察到的数据预测一个新的值。

**信息检索** ( **IR** )是基于用户的查询来查找或检索信息的任务。帮助完成这项任务的算法被称为信息检索算法，我们将在整本书中遇到它们。

文本分析本身已经存在很长时间了——在 1958 年 10 月由 H. P. Luhn、*撰写的一篇 IBM 期刊文章中，**商业智能** ( **BI** )本身的第一个定义是，一个商业智能系统* [ [1](https://dl.acm.org/citation.cfm?id=1662381) ，描述了一个将执行以下操作的系统:

"...利用数据处理机器对文档进行自动摘要和自编码，并为组织中的每个“行动点”创建兴趣档案。传入的和内部生成的文档都被自动提取，用一个词模式来表征，并自动发送到适当的行动点。”

有趣的是，看到谈论的是文档，而不是数字——想到商业智能的最初想法是理解文本和文档，这再次证明了整个时代的文本分析。但是，即使在商业文本分析的领域之外，使用计算机来更好地理解文本和语言自人工智能思想出现以来就一直存在。约翰·哈钦斯的 1999 年关于文本分析的综述，*对基于计算机的翻译的回顾与展望* [ [2](http://www.mt-archive.info/90/MTS-1999-Hutchins.pdf) ] *，*谈到了早在 20 世纪 50 年代，美国军方就在努力进行机器翻译，以便将俄语科学期刊翻译成英语。

制造智能机器的努力也是从文本开始的——1966 年麻省理工学院的约瑟夫·韦岑鲍姆开发的伊莱扎程序就是一个例子。即使程序没有真正理解语言，但通过基本的模式匹配，它可以尝试进行对话。这些只是分析文本的一些最早的尝试——计算机(和人类！)已经走了很长的路，现在我们有了难以置信的工具。

机器翻译本身已经取得了很大的进步，我们现在可以使用智能手机有效地在语言之间进行翻译，并且通过谷歌的**神经机器翻译**等尖端技术，学术界和工业界之间的差距正在缩小——这使我们能够直接体验自然语言处理的魔力。

![](Images/4cccf6e9-3adf-4ca1-8688-59a8ad701dce.png)

图 1.2 一个神经翻译模型的例子，致力于法语到英语的翻译

这一领域的进展也有助于推进我们处理语音的方式——视频中的隐藏字幕，以及苹果的 Siri 或亚马逊的 Alexa 等个人助理都极大地受益于卓越的文本处理。理解对话中的结构和提取信息是早期 NLP 的关键问题，所做的研究成果在 21 世纪非常明显。

谷歌或必应等搜索引擎！也站在 NLP 和 CL 所做研究的肩膀上，以前所未有的方式影响着我们的生活。信息检索(IR)建立在文本处理的统计方法上，允许我们对文档进行分类、聚类和检索。像主题建模这样的方法可以帮助我们识别大型非结构化文本中的关键主题。识别这些主题不仅仅是搜索关键词，我们使用统计模型来进一步理解文本主体的潜在本质。没有计算机的力量，我们不可能对文本进行这种大规模的统计分析。我们将在本书的后面详细探讨主题建模。

![](Images/c173a0eb-b3b0-4268-970b-fa09f3acafa3.png)

图 1.2 主题建模等技术使用概率建模方法从文本中识别关键主题。我们将在本书后面详细研究这一点

除了能够在我们的手机上体验现代计算的奇迹之外，Python 和 NLP 的最新发展意味着我们现在可以自己开发这样的系统了！

不仅在自然语言处理和文本分析中使用的技术有了发展，它对我们来说也变得非常容易——开源包正在成为最先进的、性能和商业工具一样好的工具。商业工具的一个例子是微软的**文本分析 API**([https://azure . Microsoft . com/en-us/services/cognitive-services/Text-analytics/](https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/))。

MATLAB 是用于科学计算的流行商业工具的另一个例子。虽然从历史上看，这种商业工具比免费的开源软件表现得更好，但是对开源库做出贡献的人的增加，以及来自行业的资助极大地帮助了开源社区。现在，形势似乎已经发生了转变，许多软件巨头将开源包用于他们的内部系统——例如 Google 使用 TensorFlow，Apple 使用 scikit-learn！TensorFlow和 scikit-learn 是两个开源的 Python 机器学习包。

可以说，python 生态系统提供的包的数量意味着它在进行文本分析时处于领先地位，我们将在这里集中精力。一个非常强大和活跃的开源社区增加了吸引力。

在本书的整个过程中，我们将讨论现代自然语言处理和计算语言学技术，以及我们可以用来应用这些技术的最佳开源工具。



# 数据在哪里？

虽然了解 NLP 和 CL 中涉及的技术和工具很重要，但是没有任何数据，这当然是没有意义的。幸运的是，如果我们在正确的地方寻找，我们可以获得大量的数据。寻找文本数据的最简单方法是寻找一个*语料库*。

文本语料库是一个大型的结构化文本集，是开始文本分析的好方法。这种免费语料库的例子是开放的美国国家语料库[ [5](http://www.anc.org/) ]或英国国家语料库[ [6](http://www.natcorp.ox.ac.uk/) ]。维基百科在关于文本语料库的文章中提供了一个有用的最大语料库列表[ [7](https://en.wikipedia.org/wiki/List_of_text_corpora) ]。这些不局限于英语，在欧洲和亚洲语言中也存在各种语料库，并且在世界范围内一直在努力为大多数语言创建语料库。大学研究实验室是获得语料库的另一个有价值的来源——事实上，最具标志性的英语语料库之一**布朗语料库**就是在布朗大学建立的。

不同的语料库往往会呈现不同级别的信息，这通常取决于该语料库的主要目的，例如，主要功能是在翻译过程中提供帮助的语料库可能会在多种语言中出现相同的句子。语料库获取额外信息的另一种方式是通过注释。文本标注的例子通常有**词性** ( **词性**)标注或者**命名实体识别** ( **NER** )。词性标注指的是用词性(名词、动词、副词等等)来标记句子中的每个单词，为 NER 标注的语料库将识别所有命名的实体，如地点、人物和时间。我们将在本书后面的[第 5 章](e7fc28c4-94a9-41aa-8836-ad4c9a55e880.xhtml)、*词性标注及其应用*和[第 6 章](e803ff9f-004a-40ac-a6c7-0cb3dffd74fe.xhtml)、 *NER 词性标注及其应用*、*中进一步探讨词性标注和 NER 的细节。*

基于语料库中存在的结构和不同层次的信息，它将具有不同的目的。一些语料库还被构建来评估聚类或分类任务，其中标注并不重要，标签或类别才是重要的。这意味着一些语料库旨在通过提供带有人类标签的文本来帮助机器学习任务，如聚类或分类。聚类是指将相似的对象分组在一起的任务，而分类是决定哪个预定义类的过程。确定数据集的确切用途是文本分析的关键部分，也是重要的第一步。

除了下载数据集或从互联网上搜集数据，还有一些丰富的来源来收集我们的文本数据——特别是文献。这方面的一个例子是宾夕法尼亚大学的研究，亚历杭德罗·里贝罗、圣地亚哥·塞加拉、马克·艾森和加布里埃尔·伊根发现了莎士比亚的可能合作者，这是一个困扰许多研究人员的文学史问题[14]。他们通过识别文学风格来解决这个问题——这是计算语言学中一个即将到来的研究领域，叫做**风格分析**。

越来越多地使用计算工具来进行人文学科的研究也导致了大学中数字人文学科实验室的增长，在这些实验室中，传统的研究方法要么得到计算机科学的帮助，要么被计算机科学取代，特别是机器学习(以及自然语言处理)。例如，政治家的演讲或议会的会议记录是这个社区中经常使用的数据源的另一个例子。他们为你工作[ [17](https://www.theyworkforyou.com/) ]是一个英国议会追踪系统，它获取演讲并上传，是许多做这种工作的网站的一个例子。

古登堡计划可能是下载书籍的最佳资源，包含超过 50，000 本免费电子书和许多文学经典。个人 pdf 和电子书也是一种资源，但是再次强调，在分析之前了解你的文本的法律性质是很重要的。比如说，从网上下载一个盗版的《哈利·波特》并公布文本分析结果，如果你不能解释你从哪里得到的文本，这可能不是一个好主意。同样，对私人短信的文本分析不仅会让你的朋友烦恼，还会违反隐私法。

![](Images/28cb2ed2-0403-4edb-a649-8b888f131146.png)

图 1.3 文本数据集列表示例-此处是上的评论数据集

那么，除了直接从互联网上下载结构化数据集，我们还能从哪里获得文本数据呢？当然是互联网了。即使没有标注，互联网上大量的文本意味着我们可以访问其中的大部分内容——[ 7]就是一个这样的例子，维基百科上所有内容的媒体转储在解压缩后约为 58 GB(截至 2018 年 4 月)——足够多的文本可供使用。广受欢迎的新闻聚合网站[reddit.com](https://www.reddit.com)【9】可以方便地浏览网页，也是另一个很好的文本分析资源。

Python 仍然是一个很好的选择，像`BeautifulSoup` [ [10](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) 、`urllib` [ [11](https://docs.python.org/2/library/urllib.html) 和`scrapy` [ [12](https://scrapy.org/) 这样的库就是专门为此设计的。重要的是要小心法律方面的事情，并确保检查您收集数据的网站的条款和条件-许多网站不允许您将网站上的信息用于商业目的。

推特是另一个正在迅速成为文本分析非常重要的一部分的网站——你甚至让学术界非常严肃地对待这个资源(*推特是什么，社交网络还是新闻媒体？* [ [13](https://dl.acm.org/citation.cfm?id=1772751) ]有超过 5000 条引文！)，有多篇关于推特文本分析的论文，甚至已经建立了完备的工具[ [15](https://www.csc2.ncsu.edu/faculty/healey/tweet_viz/tweet_app/) ]进行情感分析！推特流应用编程接口也允许我们从推特上轻松挖掘文本数据，Python 界面[ [16](http://www.tweepy.org/) ]非常简单。大多数世界领导人都是推特的用户，也有名人和大型新闻公司——推特可以为我们提供许多有趣的见解。

![](Images/af9ccd2a-23b7-471a-a97e-63fcffc589a0.png)

图 Twitter 已经成为富文本资源的一个例子，拥有多个可用的结构化数据集[7]。这些数据集都是从 Twitter 上挖掘出来的，有特定的任务，可以用于我们之前讨论过的标签数据集类别。

你可以从互联网上获得的文本信息的其他例子包括研究文章、医疗报告、餐馆评论(Yelp！dataset 浮现在脑海中)，以及其他社交媒体网站。在这些情况下，情感分析通常是首要目标。顾名思义，情感分析是指识别文本中的情感的任务。这些情绪可以是基本的，例如积极或消极的情绪，但是我们可以有更复杂的情绪分析任务，其中我们分析一个句子是否包含快乐、悲伤或愤怒的情绪。

很明显，如果我们足够努力地寻找，找到可以摆弄的数据是非常容易的。但是让我们从网上下载数据后退一小步——我们还能在哪里找到信息呢？

就在我们手中，看似如此，我们每天发送和接收短信和电子邮件，我们可以使用这些文本进行文本分析。大多数短信应用程序都有下载聊天内容的界面。比如 WhatsApp 会把数据邮寄给你[ [18](https://faq.whatsapp.com/en/android/23756533/) ]，媒体和文字都有。大多数邮件客户端都有相同的选项，这两种情况的优点是这种数据通常组织得很好，便于在我们深入研究数据之前进行清理和预处理。

到目前为止，我们在谈论数据时忽略的一个方面是文本中经常出现的噪音，例如，在推文中，经常使用的简短形式和表情符号，在某些情况下，我们有多语言数据，简单的分析可能会失败。这就把我们带到了文本分析最重要的方面——预处理。



# 垃圾进，垃圾出

垃圾进，垃圾出(或 **GIGO** )是计算机科学的一句格言，在处理机器学习时甚至更重要，在处理文本数据时可能更重要。垃圾输入，垃圾输出意味着如果我们的数据格式不正确，很可能会得到不好的结果。

![](Images/d021d95f-d067-4d32-942b-bff1c81f9e4f.jpg)

图 1.5 XKCD 再次一针见血(https://xkcd.com/1838/)

虽然更多的数据通常会导致更好的预测，但文本分析并不总是如此，更多的数据可能会导致无意义的结果或我们并不总是想要的结果。一个直观的例子:词类、文章，如单词 *a* ，或 *the* 往往在文本中出现很多，但不会给文本增加任何信息，而且通常仅限于语法或结构。

像这样不提供有用信息的词被称为**停用词**，在对它们应用文本分析技术之前，这些词通常被从文本中移除。同样，有时我们会删除文本中出现频率非常高的单词，以及只出现一两次的单词，这些单词很可能对我们的分析没有用处。也就是说，这在很大程度上取决于正在执行的任务的类型——例如，如果我们想要复制人类的写作风格，停用词很重要，因为人类在写作时会用到很多这样的词。关于停用词也可以包含有用信息的一个例子在这篇文章中，*基于停用词排名的仿作检测。揭露一位罗马尼亚作家的模仿者* [ [20](http://www.aclweb.org/anthology/W12-0411) ]，是一项使用停用词频率来识别某个作者的研究。

让我们考虑另一个例子，我们可能正在处理*无用的*数据——如果在文本中搜索有影响力的单词或主题，在结果中同时出现单词*读作*和*读作*是否有意义？这里，将单词*读作*缩短为*读作*不会导致任何信息丢失。但是类似地，让单词 *information* 和 *inform* 在同一个正文中单独存在也是有意义的，因为根据上下文，它们可能表示不同的意思。然后，我们需要适当缩短单词的技巧。词汇化和词干化是我们用来解决这个问题的两种方法，也是自然语言处理中的两个核心概念。我们将在第三章、 *spaCy 的语言模型*中更详细地探讨这两种技术。

即使经过基本的文本处理，我们的数据仍然是单词的集合。由于机器本身并不理解与单词相关的概念，我们可以用代表单个单词的数字来代替。文本分析的下一个重要步骤是将单词转换成数字，无论是**词袋** ( **弓**)，还是**词频-逆文档频** ( **TF-IDF** )，都是统计每个文档或句子字数的不同方式。还有更高级的技术来表示单词，比如 Word2Vec 和 GloVe。

我们将在预处理技术一章中更详细地讨论这些细节和技术——理解这些技术背后的动机尤其重要，并且计算机的输出取决于您输入的内容。



# 为什么要做文本分析？

我们已经讨论了什么是文本分析，在哪里可以找到数据，以及在开始文本分析之前需要记住的一些事情。但毕竟，作为读者，你有什么动力去做文本分析呢？

首先，我们可以使用大量容易获得的数据。在大数据时代，真的没有借口不看看我们所有的数据到底意味着什么。事实上，除了大量的数据集，我们可以从网上下载，我们还可以访问*小数据*——短信、电子邮件、诗集都是这样的例子。你甚至可以做一个元分析，对这本书进行分析！文本数据更容易获得，但更重要的是——它很容易解释和理解分析的结果。数字可能不总是有意义的，也不总是吸引人的——但文字对我们人类来说更容易欣赏。

文本分析仍然令人兴奋，因为我们可以使用直接涉及用户的数据——我们自己的文本对话，我们最喜欢的童年书籍，或者我们最喜欢的名人的推文。文本数据的个人性质总是增加额外的动力，这也可能意味着我们知道数据的性质，以及期望什么样的结果。

自然语言处理技术还可以帮助我们构建能够帮助个人商业或企业的工具——例如，聊天机器人在主要网站上越来越常见，如果方法正确，拥有个人聊天机器人是可能的。这在很大程度上是由于机器学习的一个子领域，称为**深度学习**，我们在其中使用的算法和结构受到了人脑结构的启发。这些算法和结构也被称为神经网络。深度学习的进步引入了强大的神经网络，如**循环神经网络** ( **RNN** s)和**卷积神经网络** ( **CNN** s)。现在，即使对这些算法的数学功能了解很少，高级 API 也允许我们使用这些工具。将这一点融入我们的日常生活不再是计算机科学研究人员或全职工程师的专利——通过正确的数据收集和开源软件包，这完全在我们的能力范围之内。

开源包已经成为行业标准——谷歌发布并维护了 **TensorFlow** [ [21](https://www.tensorflow.org/) ]，苹果和 Spotify 使用了**scikit-learn**[[22](http://scikit-learn.org/stable/)]等包，广受欢迎的问答网站 Quora 也使用了 **spaCy** [ [23](https://spacy.io/) ]。

我们不再受数据或工具的限制——这是我们进行文本分析时唯一需要的两样东西。

在整本书中，编程语言 python 将是我们的朋友，我们使用的所有工具都将是免费的开源软件。当我们走向开放科学时，我们也走向开放源代码，这将是贯穿全书的一个关键理念。在研究领域，开源代码意味着学术成果是可复制的，所有感兴趣的人都可以获得。Python 仍然是一种易于使用且功能强大的语言，并且是进入自然语言处理世界的一种很好的方式。

有人可能会说，最不需要的是如何应用这些工具和与数据争论的知识——但这正是本书的目的，希望让读者在旅程结束时建立自己的自然语言处理管道和模型。



# 摘要

我们已经了解了文本分析不可思议的力量，以及我们可以利用它做的事情，以及我们将利用它的工具。数据对我们来说变得越来越容易访问，随着社交媒体的发展，我们可以持续访问新数据以及标准化的注释数据集。

这本书将旨在引导读者了解对他们自己的个人数据或自己的标准化数据集进行文本分析所需的工具和知识。我们将讨论访问和清理数据的方法，以便为预处理做好准备，以及如何探索和组织我们的文本数据。分类和聚类是另外两个常见的文本处理任务，在结束如何对文本使用深度学习之前，我们也将弄清楚如何执行这一任务。

在下一章，我们将介绍 python 如何以及为什么是我们的正确选择，以及讨论一些 Python 技巧和提示来帮助我们进行文本分析。



# 参考

[1]商业智能系统–h . p . Lunn，1958 年 10 月([https://dl.acm.org/citation.cfm?id=1662381](https://dl.acm.org/citation.cfm?id=1662381))

[2]计算机翻译的回顾与展望-约翰·哈钦斯，1999 年 9 月([http://www.mt-archive.info/90/MTS-1999-Hutchins.pdf](http://www.mt-archive.info/90/MTS-1999-Hutchins.pdf))

【3】用 GPU 进行神经机器翻译简介:
[https://dev blogs . NVIDIA . com/parallel forall/Introduction-Neural-Machine-Translation-GPU-part-2/](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/)

[4]文本挖掘:
[https://en.wikipedia.org/wiki/Text_mining](https://en.wikipedia.org/wiki/Text_mining)

[5]打开美国国家文集:
[http://www.anc.org](http://www.anc.org)

[6]英国国家语料库:
[http://www . natcorp . ox . AC . uk](http://www.natcorp.ox.ac.uk)

[7]文本语料库列表:
[https://en.wikipedia.org/wiki/List_of_text_corpora](https://en.wikipedia.org/wiki/List_of_text_corpora)

[8]维基百科数据集:
[https://en.wikipedia.org/wiki/Wikipedia:Database_download](https://en.wikipedia.org/wiki/Wikipedia:Database_download)

[9] Reddit，新闻聚合网站:
[https://www.reddit.com](https://www.reddit.com)

[10]汤美丽:
[https://www.crummy.com/software/BeautifulSoup/bs4/doc/](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

[11]UrlLib:
[https://docs.python.org/2/library/urllib.html](https://docs.python.org/2/library/urllib.html)

[12]刺儿头:
[https://scrapy.org](https://scrapy.org)

[13]什么是推特，社交网络还是新闻媒体？:
[https://dl.acm.org/citation.cfm?id=1772751](https://dl.acm.org/citation.cfm?id=1772751)

[14]莎士比亚和他的合著者:
[https://www . upenn . edu/spot lights/Shakespeare-and-his-co-authors-tell-Penn-engineers](https://www.upenn.edu/spotlights/shakespeare-and-his-co-authors-told-penn-engineers)

[15]推文情绪可视化:
[https://www . cs C2 . ncsu . edu/faculty/Healey/Tweet _ viz/Tweet _ app/](https://www.csc2.ncsu.edu/faculty/healey/tweet_viz/tweet_app/)

[16] Tweepy，Twitter API:
[http://www.tweepy.org](http://www.tweepy.org)

[17]他们为你工作:
[https://www.theyworkforyou.com](https://www.theyworkforyou.com)

[18]邮寄 WhatsApp 聊天记录:
[https://faq.whatsapp.com/en/android/23756533/](https://faq.whatsapp.com/en/android/23756533/)

[19]古腾堡项目:
[https://www.gutenberg.org](https://www.gutenberg.org)

[20]基于停用词排名的仿作检测。揭露罗马尼亚作家冒名顶替者:
[http://www.aclweb.org/anthology/W12-0411](http://www.aclweb.org/anthology/W12-0411)

[21] TensorFlow: 
[https://www.tensorflow.org](https://www.tensorflow.org)

[22]Scikit-learn:
[http://scikit-learn.org/stable/](http://scikit-learn.org/stable/)

[23]spaCy:[https://spaCy . io](https://spacy.io)


# 四、产品化

概述

在本章中，您将处理新数据并创建一个模型，该模型能够从显示的模式中不断学习，并帮助做出更好的预测。我们将以一个 web 应用为例，展示如何部署深度学习模型，这不仅是因为 web 应用的简单性和普及性，还因为它们提供了不同的可能性，例如使用 web 浏览器在移动设备上获得预测，以及为用户制作 REST APIs。

# 简介

本章重点介绍如何*将*一个深度学习模型产品化。我们使用“产品化”这个词来定义从深度学习模型中创建的软件产品，该产品可以被其他人和应用使用。

我们对模型感兴趣，这些模型在新数据可用时使用新数据，不断从新数据中学习模式，从而做出更好的预测。在本章中，我们将研究两种处理新数据的策略:一种是重新训练现有模型，另一种是创建一个全新的模型。然后，我们在我们的比特币价格预测模型中实施后一种策略，以便它可以持续预测新的比特币价格。

到本章结束时，我们将能够部署一个工作的 web 应用(带有一个正常工作的 HTTP API ),并按照我们的意愿修改它。

# 处理新数据

模型可以使用一组数据进行一次训练，然后用于进行预测。这种静态模型可能非常有用，但通常情况下，我们希望我们的模型能够不断地从新数据中学习，并在学习的过程中不断地变得更好。

在这一节中，我们将讨论处理新数据的两种策略，并看看如何在 Python 中实现它们。

## 分离数据和模型

在构建深度学习应用时，最重要的两个领域是数据和模型。从体系结构的角度来看，建议将这两个区域分开。我们认为这是一个很好的建议，因为这些领域中的每一个都包含彼此独立的功能。通常需要收集、清理、组织和规范化数据，而模型需要训练、评估并能够做出预测。

根据这个建议，我们将使用两个不同的代码库来帮助我们构建 web 应用:Yahoo Finance API 和`Model()`:

*   The Yahoo Finance API: The API can be installed by using `pip` with the following command:

    ```
    pip install yfinance
    ```

    安装后，我们将能够访问与财务领域相关的所有历史数据。

*   这个类实现了我们到目前为止在一个类中编写的所有代码。它提供了与我们之前训练的模型进行交互的工具，并允许我们使用更容易理解的非标准化数据进行预测。`Model()`类是我们的模型组件。

这两个代码库在我们的示例应用中被广泛使用，它们定义了数据和模型组件。

## 数据组件

Yahoo Finance API 有助于检索和解析股票的历史数据。它包含一个相关的方法`history()`，在下面的代码中有详细说明:

```
import yfinance as yf
ticker =  yf.Ticker("BTC-USD")
historic_data = ticker.history(period='max')
```

这个`history()`方法从 Yahoo Finance 网站收集数据，对其进行解析，并返回一个 pandas DataFrame，供`Model()`类使用。

Yahoo Finance API 使用参数 ticker 来确定收集什么加密货币。雅虎金融 API 有许多其他可用的加密货币，包括以太坊和比特币现金等流行货币。使用`ticker`参数，您可以更改加密货币，并训练一个不同于本书中创建的比特币模型的模型。

## 模型组件

`Model()`类是我们实现应用模型组件的地方。`Model()`类包含五个方法，这些方法实现了本书中所有不同的建模主题。它们是:

*   `build()`:该方法使用 TensorFlow 建立 LSTM 模型。这个方法作为一个手工创建的模型的简单包装器。
*   `train()`:这个方法使用类实例化的数据来训练模型。
*   `evaluate()`:该方法使用一组损失函数来评估模型。
*   `save()`:该方法将模型本地保存为一个文件。
*   `predict()`:该方法基于按周排序的输入观察序列做出并返回预测。

我们将在本章中使用这些方法来工作、训练、评估和发布我们的模型预测。`Model()`类是如何将基本 TensorFlow 函数包装到 web 应用中的一个例子。前面的方法几乎可以像前面的章节一样实现，但是具有增强的接口。例如，在以下代码中实现的`train()`方法使用来自`self.X`和`self.Y`的数据来训练`self.model`中可用的模型:

```
def train(self, data=None, epochs=300, verbose=0, batch_size=1): 
    self.train_history = self.model.fit(x=self.X, y=self.Y, \
                                        batch_size=batch_size, \
                                        epochs=epochs, \
                                        verbose=verbose, \
                                        shuffle=False)
    self.last_trained = datetime.now()\
    .strftime('%Y-%m-%d %H:%M:%S') 
    return self.train_history
```

总的想法是，Keras 工作流程中的每一个过程(构建或设计、训练、评估和预测)都可以很容易地转化为程序的不同部分。在我们的例子中，我们将它们变成了可以从`Model()`类调用的方法。这组织了我们的程序，并提供了一系列的约束(比如模型架构或者某些 API 参数)，这帮助我们在一个稳定的环境中部署我们的模型。

在接下来的部分中，我们将探索处理新数据的常用策略。

## 处理新数据

机器学习模型(包括神经网络)的核心思想是，它们可以从数据中学习模式。想象一下，一个模型用某个数据集进行了训练，现在它正在发布预测。现在，假设有新的数据可用。您可以采用不同的策略，以便模型可以利用新的可用数据来学习新的模式并改进其预测。在本节中，我们将讨论两种策略:

*   重新训练旧模型
*   训练新模型

### 重新训练旧模型

在这个策略中，我们用新数据重新训练现有模型。使用这种策略，您可以不断调整模型参数以适应新现象。但是，后期培训中使用的数据可能与早期数据有很大不同。这种差异可能会导致模型参数发生重大变化，比如让它学习新模式，忘记旧模式。这种现象一般被称为**灾难性遗忘**。

注意

灾难性遗忘是影响神经网络的一种常见现象。多年来，深度学习研究人员一直在试图解决这个问题。英国谷歌旗下的深度学习研究小组 DeepMind 在寻找解决方案方面取得了显著进展。文章，*克服* *神经网络中的灾难性遗忘*，*詹姆斯·柯克帕特里克*，*等。al* 。是此类工作的良好参考，可在[https://arxiv.org/pdf/1612.00796.pdf](https://arxiv.org/pdf/1612.00796.pdf)获得。

第一次用于训练的界面(`model.fit()`)也可以用于新数据的训练。下面的代码片段加载数据，并帮助训练一个指定时期和批量大小的模型:

```
X_train_new, Y_train_new = load_new_data()
model.fit(x=X_train_new, y=Y_train_new, batch_size=1, \
          epochs=100, verbose=0)
```

在 TensorFlow 中，当训练模型时，模型的状态作为权重保存在磁盘上。当您使用`model.save()`方法时，该状态也被保存。当您调用`model.fit()`方法时，使用以前的状态作为起点，用新的数据集重新训练模型。

在典型的 Keras 模型中，可以使用这种技术，而不会出现其他问题。然而，当使用 LSTM 模型时，这种技术有一个关键的限制:训练和验证数据的形状必须相同。例如，在*第三章*、*使用 TensorFlow 和 Keras 的真实世界深度学习:评估比特币模型*中，我们的 LSTM 模型(`bitcoin_lstm_v0`)使用 186 周来预测未来一周。如果我们尝试用 187 周来重新训练模型以预测未来一周，模型会引发一个异常，其中包含有关数据形状不正确的信息。

处理这个问题的一种方法是按照模型所期望的格式来安排数据。例如，要基于一年的数据(52 周)进行预测，我们需要配置一个模型来使用 40 周预测未来的一周。在这种情况下，我们首先用 2019 年的前 40 周训练模型，然后在接下来的几周继续重新训练它，直到我们到达第 51 周。我们使用`Model()`类在下面的代码中实现一种再训练技术:

```
M = Model(data=model_data[0*7:7*40 + 7], variable='close', \
          predicted_period_size=7)
M.build()
M.train()
for i in range(41, 52):
    j = i - 40
    M.train(model_data.loc[j*7:7*i + 7])
```

这种技术训练起来很快，并且对于大的系列很有效。下一种技术更容易实现，并且在较小的系列中工作良好。

### 训练新的模型

另一个策略是，每当有新数据可用时，就创建并训练一个新模型。这种方法有助于减少灾难性遗忘，但随着数据的增加，训练时间也会增加。它的实现非常简单。

以比特币模型为例，我们现在假设我们有 2019 年 49 周的旧数据，一周后，新数据可用。在下面的代码片段中，我们用`old_data`和`new_data`变量来表示这一点，其中我们实现了一个在新数据可用时训练新模型的策略:

```
old_data = model_data[0*7:7*48 + 7]
new_data = model_data[0*7:7*49 + 7]
M = Model(data=old_data,\
          variable='close', predicted_period_size=7)
M.build()
M.train()
M = Model(data=new_data,\
          variable='close', predicted_period_size=7)
M.build()
M.train()
```

这种方法实现起来非常简单，并且对于小数据集来说效果很好。这将是我们的比特币价格预测应用的首选解决方案。

## 练习 4.01:动态地重新训练一个模型

在本练习中，您必须重新训练模型以使其具有动态性。每当加载新数据时，它应该能够做出相应的预测。以下是要遵循的步骤:

从导入`cryptonic`开始。Cryptonic 是为本书开发的一个简单的软件应用，它使用 Python 类和模块实现了本节之前的所有步骤。将 Cryptonic 视为用于创建应用的模板。Cryptonic 作为 Python 模块提供给本练习，可以在下面的 GitHub 链接中找到:[https://packt.live/325WdZQ](https://packt.live/325WdZQ)。

1.  首先，我们将启动一个 Jupyter 笔记本实例，然后我们将加载`cryptonic`包。
2.  Using your Terminal, navigate to the `Chapter04/Exercise4.01` directory and execute the following code to start a Jupyter Notebook instance:

    ```
    $ jupyter-lab
    ```

    服务器会自动在你的浏览器中打开，然后打开名为`Exercise4.01_Re_training_a_model_dynamically.ipynb`的 Jupyter 笔记本。

3.  现在，我们将从`cryptonic`包:`Model()`和 Yahoo Finance API 中导入类。这些类简化了操作模型的过程。
4.  In the Jupyter Notebook instance, navigate to the header `Fetching Real-Time Data`. We will now be fetching updated historical data from Yahoo Finance by calling the `history()` method:

    ```
    import yfinance as yf
    ticker =  yf.Ticker("BTC-USD")
    historic_data = ticker.history(period='max')
    ```

    `historic_data`变量现在由 pandas DataFrame 填充，其中包含运行这段代码之前比特币汇率的历史数据。这很好，当有更多数据可用时，重新训练我们的模型变得更加容易。

5.  You can view the first three rows of data stored in `historic_data` using the following command:

    ```
    historic_data.head(3)
    ```

    然后您可以查看存储在`historic_data`中的数据:

    ![Figure 4.1: Output displaying the head of the data
    ](image/B15911_04_01.jpg)

    图 4.1:显示数据头部的输出

    这些数据实际上包含了我们使用的比特币数据集中相同的变量。然而，许多数据来自更早的时期，2017 年至 2019 年。

6.  Using the pandas API, filter the data for only the dates available in 2019, and store them in `model_data`. You should be able to do this by using the date variable as the filtering index. Make sure the data is filtered before you continue:

    ```
    start_date = '01-01-2019'
    end_date = '31-12-2019'
    mask = ((historic_data['date'] \
             >= start_date) & (historic_data['date'] \
             <= end_date))
    model_data = historic_data[mask]
    ```

    在下一个单元格中运行`model_data`，输出模型如下所示:

    ![Figure 4.2: The model_data variable showing historical data
    ](image/B15911_04_02.jpg)

    图 4.2:显示历史数据的 model_data 变量

    `Model()`类编译了我们迄今为止在所有活动中编写的所有代码。在本次活动中，我们将使用该课程来构建、训练和评估我们的模型。

7.  我们现在将使用过滤后的数据来训练模型:

    ```
    M = Model(data=model_data, \
              variable='close', predicted_period_size=7)
    M.build()
    M.train()
    M.predict(denormalized=True)
    ```

8.  Run the following command to see the trained model:

    ```
    M.train(epochs=100, verbose=1)
    ```

    经过训练的模型如下图所示:

    ![Figure 4.3: The output showing our trained model
    ](image/B15911_04_03.jpg)

    图 4.3:显示我们训练好的模型的输出

    前面的步骤展示了使用`Model()`类训练模型时的完整工作流程。

    注意

    要获得完整的代码，请使用`Chapter04/Exercise4.01`文件夹。

9.  Next, we'll focus on retraining our model every time more data is available. This readjusts the weights of the network to new data.

    为此，我们将模型配置为使用 40 周来预测一周。我们现在想用剩下的整整 11 周来创建 40 周的重叠期。这些包括一次 11 周中的一周，并在每一周中重新训练模型。

10.  Navigate to the `Re-Train Old Model` header in the Jupyter Notebook. Now, complete the `range` function and the `model_data` filtering parameters using an index to split the data into overlapping groups of seven days. Then, retrain our model and collect the results:

    ```
    results = []
    for i in range(A, B): 
        M.train(model_data[C:D])
        results.append(M.evaluate())
    ```

    `A`、`B`、`C`和`D`变量是占位符。使用整数创建七天的重叠组，其中重叠时间为一天。

    将这些占位符替换为周，我们运行如下循环:

    ```
    results = []
    for i in range(41, 52):
        j = i-40
        print("Training model {0} for week {1}".format(j,i))
        M.train(model_data.loc[j*7:7*i+7])
        results.append(M.evaluate())
    ```

    下面是显示该循环结果的输出:

    ```
    Training model 1 for week 41
    Training model 2 for week 42
    Training model 3 for week 43
    Training model 4 for week 44
    Training model 5 for week 45
    Training model 6 for week 46
    Training model 7 for week 47
    Training model 8 for week 48
    Training model 9 for week 49
    Training model 10 for week 50
    Training model 11 for week 51
    ```

11.  在您重新训练了您的模型之后，继续调用`M.predict(denormalized=True)`函数并检查结果:

    ```
    array([7187.145 , 7143.798 , 7113.7324, 7173.985 , 7200.346 ,
           7300.2896, 7175.3203], dtype=float32)
    ```

12.  接下来，我们将关注每次新数据可用时创建和训练新模型。为了做到这一点，我们现在假设我们有 2019 年 49 周的旧数据，一周后，我们现在有新数据。我们用`old_data`和`new_data`变量来表示。
13.  导航到`New Data New Model`标题，在`old_data`和`new_data`变量:

    ```
    old_data = model_data[0*7:7*48 + 7]
    new_data = model_data[0*7:7*49 + 7]
    ```

    之间分割数据
14.  Then, train the model with `old_data` first:

    ```
    M = Model(data=old_data,\
              variable='close', predicted_period_size=7)
    M.build()
    M.train()
    ```

    我们现在已经拥有了动态训练模型所需的所有部分。

    注意

    要访问该特定部分的源代码，请参考[https://packt.live/2AQb3bE](https://packt.live/2AQb3bE)。

    你也可以在[https://packt.live/322KuLl](https://packt.live/322KuLl)在线运行这个例子。您必须执行整个笔记本才能获得想要的结果。

在下一节中，我们将把我们的模型部署为一个 web 应用，通过 HTTP API 在浏览器中提供它的预测。

## 将模型部署为 Web 应用

在本节中，我们将把我们的模型部署为一个 web 应用。我们将使用 Cryptonic web 应用来部署我们的模型，探索它的架构，以便我们可以在未来进行修改。其目的是让您将此应用作为更复杂应用的起点——一个完全工作的起点，并且可以根据您的需要进行扩展。

除了熟悉 Python 之外，本主题还假设您熟悉创建 web 应用。具体来说，我们假设您对 web 服务器、路由、HTTP 协议和缓存有所了解。您将能够在本地部署演示的 Cryptonic 应用，而不需要对这些 web 服务器、HTTP 协议和缓存有广泛的了解，但是学习这些主题将使任何未来的开发更加容易。

最后，Docker 用于部署我们的 web 应用，因此该技术的基本知识也很有用。

在我们继续之前，请确保您的计算机上安装了以下应用并且可用:

*   Docker(社区版)17.12.0-ce 或更高版本
*   Docker Compose ( `docker-compose` ) 1.18.0 或更高版本

这两个组件都可以从[http://docker.com/](http://docker.com/)下载并安装在所有主要系统上。这些对于完成本活动至关重要。在继续之前，请确保您的系统中有这些功能。

## 应用架构和技术

为了部署我们的 web 应用，我们将使用*图 4.4* 中描述的工具和技术。Flask 是关键，因为它帮助我们为模型创建一个 HTTP 接口，允许我们访问 HTTP 端点(比如`/predict`)并以通用格式接收数据。使用其他组件是因为它们是开发 web 应用时的流行选择:

![Figure 4.4: Tools and technologies used for deploying a deep learning web application
](image/B15911_04_04.jpg)

图 4.4:用于部署深度学习 web 应用的工具和技术

这些组件组合在一起，如下图所示:

![Figure 4.5: System architecture for the web application built in this project
](image/B15911_04_05.jpg)

图 4.5:这个项目中构建的 web 应用的系统架构

用户使用浏览器访问 web 应用。然后，Nginx 将流量路由到包含 Flask 应用的 Docker 容器(默认情况下，在端口`5000`上运行)。Flask 应用已经在启动时实例化了我们的比特币模型。如果给定了一个模型，它就使用那个模型，而不需要训练；如果没有，它会创建一个新模型，并使用雅虎财经(Yahoo Finance)的数据从头开始训练。

准备好模型后，应用验证请求是否已经缓存在 Redis 上；如果是，它返回缓存的数据。如果不存在缓存，那么它将继续发出预测，并在 UI 中呈现出来。

## 练习 4.02:部署和使用密码

Cryptonic 是作为一个 dockerized 应用开发的。用 Docker 术语来说，这意味着应用可以构建为 Docker 映像，然后在开发或生产环境中部署为 Docker 容器。

在本练习中，我们将了解如何使用 Docker 和 Cryptonic 来部署应用。在开始之前，请从 https://www.docker.com/products/docker-desktop 下载 Docker for Desktop】在开始练习之前，请确保该应用正在后台运行。

注意

这个练习的完整代码可以在[https://packt.live/2AM5mLP](https://packt.live/2AM5mLP)找到。

1.  Docker uses files called `Dockerfiles` to describe the rules for how to build an image and what happens when that image is deployed as a container. Cryptonic's Dockerfile is available in the following code:

    注意

    下面代码片段中显示的三重引号(`"""`)用于表示多行代码注释的起点和终点。注释被添加到代码中以帮助解释特定的逻辑。

    ```
    FROM python:3.6 
    ENV TZ=America/New_York
    """
    Setting up timezone to EST (New York)
    Change this to whichever timezone your data is configured to use.
    """
    RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone
    COPY . /cryptonic
    WORKDIR "/cryptonic"
    RUN pip install -r requirements.txt
    EXPOSE 5000
    CMD ["python", "run.py"]
    ```

2.  A Dockerfile can be used to build a Docker image with the following command:

    ```
    $ docker build --tag cryptonic:latest
    ```

    该命令将使`cryptonic:latest`映像可以作为容器进行部署。构建过程可以在生产服务器上重复，或者可以直接部署映像，然后作为容器运行。

3.  After an image has been built and is available, you can run the Cryptonic application by using the `docker run` command, as shown in the following code:

    ```
    $ docker run --publish 5000:5000 \
    --detach cryptonic:latest
    ```

    `--publish`标志将本地主机上的端口`5000`绑定到 Docker 容器上的端口`5000`，而`--detach`将容器作为后台守护进程运行。

    如果您已经训练了一个不同的模型，并且想要使用它而不是训练一个新的模型，您可以改变`docker-compose.yml`上的`MODEL_NAME`环境变量。该变量应该包含您已经训练并想要服务的模型的文件名(例如，`bitcoin_lstm_v1_trained.h5`)；应该也是 Keras 的型号。如果这样做，请确保将一个本地目录挂载到`/models`文件夹中。您决定挂载的目录必须包含您的模型文件。

    Cryptonic 应用还包括几个环境变量，在部署您自己的模型时，您可能会发现这些变量很有用:

    `MODEL_NAME`:允许我们提供一个训练好的模型供应用使用。

    `BITCOIN_START_DATE`:决定哪一天作为比特币系列的起始日。近年来，比特币的价格比早期有了更多的变化。该参数仅过滤感兴趣年份的数据。默认为`January 1, 2017`。

    `PERIOD_SIZE`:以天数为单位设置周期大小。默认为`7`。

    `EPOCHS`:配置每次运行时模型训练的时期数。默认为`300`。

    这些变量可以在`docker-compose.yml`文件中配置。下面的代码片段显示了该文件的一部分:

    ```
    version: "3" 
       services:
          cache:
             image: cryptonic-cache:latest
             build:
                context: ./cryptonic-cache
                dockerfile: ./Dockerfile
             volumes:
                - $PWD/cache_data:/data
             networks:
                - cryptonic
          cryptonic:
             image: cryptonic:latest
             build:
                context: .
                dockerfile: ./Dockerfile
             ports:
                - "5000:5000"
             environment:
                - BITCOIN_START_DATE=2019-01-01
                - EPOCH=50
                - PERIOD_SIZE=7
    ```

4.  The easiest way to deploy Cryptonic is to use the `docker-compose.yml` file in the repository ([https://packt.live/2AM5mLP](https://packt.live/2AM5mLP)).

    该文件包含应用运行所需的所有规范，包括如何连接 Redis 缓存以及使用什么环境变量的说明。导航到`docker-compose.yml`文件的位置后，可以使用`docker-compose up`命令启动 Cryptonic，如以下代码所示:

    ```
    $ docker-compose up -d
    ```

    `-d`标志在后台执行应用。

5.  After deployment, Cryptonic can be accessed on port `5000` via a web browser. The application has an HTTP API that makes predictions when invoked. The API has the endpoint `/predict`, which returns a JSON object containing the de-normalized Bitcoin price prediction for a week into the future. Here's a snippet showing an example JSON output from the `/predict` endpoint:

    ```
    {
      message: "API for making predictions.",
      period_length: 7,
        result: [ 15847.7,
          15289.36,
          17879.07,
          …
          17877.23,
          17773.08
        ],
        success: true,
        7
    }
    ```

    注意

    要访问该特定部分的源代码，请参考[https://packt.live/2ZZlZMm](https://packt.live/2ZZlZMm)。

    本节目前没有在线交互示例，需要在本地运行。

该应用现在可以部署在远程服务器上，然后您可以使用它来持续预测比特币价格。您将在接下来的活动中部署一个应用。

## 活动 4.01:部署深度学习应用

在本节中，基于到目前为止所解释的概念，尝试将模型部署为本地 web 应用。您需要遵循以下步骤:

1.  导航到`cryptonic`目录。
2.  为所需的组件构建 Docker 映像。
3.  更改`docker-compose.yml`中的必要参数。
4.  在本地主机上使用 Docker 部署应用。

预期产出如下:

![Figure 4.6: Expected output
](image/B15911_04_06.jpg)

图 4.6:预期产出

注意

这项活动的解决方案可在第 150 页找到。

# 总结

本课结束了我们创建深度学习模型并将其部署为 web 应用的旅程。我们最后的步骤包括部署一个使用 Keras 和 TensorFlow 引擎构建的预测比特币价格的模型。我们通过将应用打包成 Docker 容器并部署它来完成我们的工作，这样其他人就可以通过它的 API 使用我们的模型以及其他应用的预测。

除了这项工作，您还了解到还有许多可以改进的地方。我们的比特币模型只是模型所能做的一个例子(尤其是 LSTMs)。现在的挑战是双重的:如何让这种模式在久而久之表现得更好？您可以在 web 应用中添加哪些功能来使您的模型更易于访问？借助你在本书中学到的概念，你将能够开发模型并不断增强它们以做出准确的预测。
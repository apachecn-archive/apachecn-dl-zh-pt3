

# 三、真实世界深度学习：评估比特币模型

概述

本章重点介绍如何评估神经网络模型。我们将修改网络的超参数以提高其性能。然而，在改变任何参数之前，我们需要测量模型的表现。在本章结束时，你将能够使用不同的函数和技术来评估一个模型。您还将通过实现函数和正则化策略了解 hypermeter 优化。

# 简介

在上一章中，您训练了您的模型。但是你将如何检查它的性能，以及它是否表现良好？让我们通过评估一个模型来了解一下。在机器学习中，通常会定义两个截然不同的术语:**参数**和**超参数**。参数是影响模型如何根据数据(例如特定数据集)进行预测的属性。超参数指的是模型如何从数据中学习。参数可以从数据中学习并动态修改。另一方面，超参数是在训练开始之前定义的高级属性，通常不从数据中学习。在本章中，您将详细了解这些因素，并了解如何将它们与不同的评估技术结合使用，以提高模型的性能。

注意

关于机器学习更详细的概述，参见 *Python 机器学习*，*塞巴斯蒂安·拉什卡和瓦希德·米尔贾利利，帕克特出版社，2017)* 。

## 问题类别

一般来说，神经网络可以解决的问题有两类:**分类**和**回归**。分类问题涉及从数据中预测正确的类别，例如，温度是热还是冷。回归问题是关于连续标量值的预测，例如，实际温度值是多少。

这两类问题具有以下特征:

*   **分类**:这些是以类别为特征的问题。类别可以不同，也可以不同。它们也可能是一个二元问题，结果可能是`yes`或`no`。但是，它们必须明确地分配给每个数据元素。分类问题的一个例子是使用卷积神经网络将`car`或`not a car`标签分配给图像。我们在*第一章*、*神经网络和深度学习介绍*中探讨的 MNIST 例子，是分类问题的另一个例子。
*   **回归**:这些是以连续变量(即标量)为特征的问题。它们根据范围进行测量，并且它们的评估考虑网络与真实值的接近程度。一个例子是时间序列分类问题，其中使用递归神经网络来预测未来的温度值。比特币价格预测问题是回归问题的另一个例子。

虽然对于这两类问题，评估这些模型的总体结构是相同的，但我们采用不同的技术来评估模型的表现。在下一节中，我们将探索这些用于分类或回归问题的技术。

## 损失函数、精确度和误差率

神经网络利用测量网络与**验证集**相比表现如何的功能，即，一部分数据被单独保存，以用作训练过程的一部分。这些函数被称为**损失函数**。

损失函数评估神经网络预测的错误程度。然后，它们将这些错误传播回去，并对网络进行调整，修改单个神经元的激活方式。损失函数是神经网络的关键组成部分，选择正确的损失函数会对网络的性能产生重大影响。误差通过称为**反向传播**的过程传播，反向传播是一种将损失函数返回的误差传播到神经网络中每个神经元的技术。传播的错误影响神经元如何激活，并最终影响网络的输出。

许多神经网络包，包括 Keras，默认使用这种技术。

注意

关于反向传播数学的更多信息，请参考*伊恩·古德菲勒等人的*深度学习*。艾尔。，麻省理工出版社，2016* 。

对于回归和分类问题，我们使用不同的损失函数。对于分类问题，我们使用精度函数(即预测正确的次数与做出预测的次数的比例)。例如，如果你预测一枚硬币的投掷将导致当你投掷 *n* 次时有 *m* 次正面朝上，并且你的预测是正确的，那么准确度将被计算为 *m/n* 。对于回归问题，我们使用误差率(即预测值与观察值的接近程度)。

这里总结了可以利用的常见损失函数及其常见应用:

![Figure 3.1: Common loss functions used for classification and regression problems
](image/B15911_03_01.jpg)

图 3.1:用于分类和回归问题的常见损失函数

对于回归问题，MSE 函数是最常见的选择，而对于分类问题，二元交叉熵(对于二元类别问题)和范畴交叉熵(对于多类别问题)是常见的选择。建议从这些损失函数开始，然后随着神经网络的发展，尝试其他函数，以获得性能。

我们在*第二章*、*用 TensorFlow 和 Keras 开发的真实世界深度学习:预测比特币价格*的网络，使用 MSE 作为它的损失函数。在下一节中，我们将探索该功能在网络训练时的表现。

## 不同的损失函数，相同的架构

在进入下一节之前，让我们从实践的角度来探讨一下，这些问题在神经网络的环境中有什么不同。

TensorFlow 团队已经推出了 tensor flow Playground(【https://playground.tensorflow.org/】T2)应用程序来帮助我们理解神经网络是如何工作的。在这里，我们可以看到一个神经网络用它的层来表示:输入层(左边)，隐藏层(中间)，输出层(右边)。

注意:

这些图片可以在 GitHub 的资源库中查看，网址:[https://packt.live/2Cl1t0H](https://packt.live/2Cl1t0H)。

我们还可以选择不同的样本数据集在最左侧进行实验。最后，在最右边，我们可以看到网络的输出:

![Figure 3.2: TensorFlow Playground web application
](image/B15911_03_02.jpg)

图 3.2: TensorFlow 游乐场 web 应用程序

以此可视化中显示的神经网络的参数为例，了解每个参数如何影响模型的结果。这个应用程序帮助我们探索我们在上一节中讨论的不同问题类别。当我们选择`Regression`(右上角)时，圆点的颜色在橙色和蓝色之间的颜色值范围内:

![Figure 3.3: Regression problem example in TensorFlow Playground
](image/B15911_03_03.jpg)

图 3.3:tensor flow 游乐场中的回归问题示例

当我们选择`Classification`作为`Problem type`时，数据集中的点只有两种颜色值:蓝色或橙色。当处理分类问题时，网络根据网络出错的次数来评估其损失函数。它检查网络中每个点的颜色值向右的距离，如下面的屏幕截图所示:

![Figure 3.4: Details of the TensorFlow Playground application. Different colors are assigned to different classes in classification problems
](image/B15911_03_04.jpg)

图 3.4:tensor flow 游乐场应用程序的详细信息。在分类问题中，不同的颜色被分配给不同的类别

点击播放按钮后，我们注意到随着网络的不断训练，`Training loss`区域的数字一直在下降。每个问题类别中的数字非常相似，因为损失函数在两个神经网络中扮演相同的角色。

然而，用于每个类别的实际损失函数是不同的，并且根据问题类型来选择。

## 使用张量板

TensorBoard 擅长评估神经网络。正如我们在*第 1 章*、*神经网络和深度学习简介*中解释的那样，TensorBoard 是 TensorFlow 附带的一套可视化工具。此外，我们可以探索每个时期后损失函数评估的结果。TensorBoard 的一个很大的特点是，我们可以单独组织每次运行的结果，并比较每次运行的结果损失函数度量。然后，我们可以决定调整哪些超参数，并对网络的性能有一个大致的了解。最棒的是，这一切都是实时完成的。

为了在我们的模型中使用 TensorBoard，我们将使用 Keras 的函数。我们通过导入 TensorBoard `callback`并在调用其`fit()`函数时将其传递给我们的模型来实现这一点。下面的代码展示了如何在我们在*第 2 章*、*使用 TensorFlow 和 Keras 的真实世界深度学习:预测比特币价格*中创建的比特币模型中实现这一点的示例:

```
from tensorflow.keras.callbacks import TensorBoard
model_name = 'bitcoin_lstm_v0_run_0'
tensorboard = TensorBoard(log_dir='logs\\{}'.format(model_name)) \
                          model.fit(x=X_train, y=Y_validate, \
                          batch_size=1, epochs=100, verbose=0, \
                          callbacks=[tensorboard])
```

Keras `callback`函数在每次运行结束时被调用。在这种情况下，Keras 调用 TensorBoard `callback`在磁盘上存储每次运行的结果。还有许多其他有用的`callback`函数，您可以使用 Keras API 创建自定义函数。

注意

有关更多信息，请参考 Keras 回调文档([https://keras.io/callbacks/](https://keras.io/callbacks/))。

实现 TensorBoard 回调后，损失函数度量现在在 TensorBoard 界面中可用。你现在可以运行一个 TensorBoard 进程(用`tensorboard --logdir=./logs`)并让它运行，同时用`fit()`训练你的网络。

要评估的主要图形通常称为损失。我们可以通过将已知的指标传递给`fit()`函数中的指标参数来添加更多的指标。这些将可用于 TensorBoard 中的可视化，但不会用于调整网络权重。互动图形将继续实时更新，让你了解每个时代发生了什么。在下面的屏幕截图中，您可以看到 TensorBoard 实例显示了损失函数结果，以及添加到 metrics 参数的其他度量:

![Figure 3.5: Screenshot of a TensorBoard instance showing the loss function results
](image/B15911_03_05.jpg)

图 3.5:显示损失函数结果的 TensorBoard 实例的屏幕截图

在下一节中，我们将更多地讨论如何实现我们在这一节中讨论的不同指标。

## 实施模型评估指标

在回归和分类问题中，我们将输入数据集分成其他三个数据集:训练、验证和测试。训练集和验证集都用于训练网络。训练集被网络用作输入，而验证集被损失函数用于将神经网络的输出与真实数据进行比较，并计算预测的错误程度。最后，在对网络进行训练之后，使用测试集来测量网络如何对其从未见过的数据执行操作。

注意

没有明确的规则来确定训练、验证和测试数据集必须如何划分。常见的方法是将原始数据集分为 80%的训练和 20%的测试，然后将训练数据集进一步分为 80%的训练和 20%的验证。关于这个问题的更多信息，请参考 *Python 机器学习*，作者 *Sebastian Raschka 和 Vahid Mirjalili (Packt Publishing，2017)* 。

在分类问题中，您将数据和标签作为相关但不同的数据传递给神经网络。然后，网络了解数据如何与每个标签相关联。在回归问题中，我们不是传递数据和标签，而是将感兴趣的变量作为一个参数传递，将用于学习模式的变量作为另一个参数传递。Keras 用`fit()`方法为这两种用例提供了一个接口。

注意

`fit()`方法可以使用`validation_split`或`validation_data`参数，但不能同时使用两者。

请参见下面的代码片段，了解如何使用`validation_split`和`validation_data`参数:

```
model.fit(x=X_train, y=Y_ train, \
          batch_size=1, epochs=100, verbose=0, \
          callbacks=[tensorboard], validation_split=0.1, \
          validation_data=(X_validation, Y_validation))
```

`X_train`:训练集中的特征

`Y_train`:来自训练集的标签

`batch_size`:一批的大小

`epochs`:迭代次数

`verbose`:您想要的输出水平

`callbacks`:每个历元后调用一个函数

`validation_split`:如果您没有明确创建验证百分比分割，请执行此操作

`validation_data`:验证数据，如果你已经明确地创建了它

损失函数评估模型的进度，并在每次运行时调整它们的权重。然而，损失函数仅仅描述了训练数据和验证数据之间的关系。为了评估模型是否正确执行，我们通常使用第三组数据(不用于训练网络)，并将我们的模型所做的预测与该组数据中的可用值进行比较。这就是测试集的作用。

Keras 提供了`model.evaluate()`方法，这使得根据测试集评估训练好的神经网络的过程变得容易。下面的代码说明了如何使用`evaluate()`方法:

```
model.evaluate(x=X_test, y=Y_test)
```

`evaluate()`方法返回损失函数的结果和传递给`metrics`参数的函数的结果。我们将在比特币问题中频繁使用该函数来测试该模型在测试集上的表现。

你会注意到，我们之前训练的比特币模型看起来与这个例子有点不同。这是因为我们使用的是 LSTM 架构。LSTMs 被设计用来预测序列。

正因为如此，我们不使用一组变量来预测一个不同的单一变量——即使这是一个回归问题。相反，我们使用单个变量(或一组变量)的先前观测值来预测同一变量(或一组变量)的未来观测值。`keras.fit()`上的`y`参数包含与`x`参数相同的变量，但仅包含预测序列。那么，我们来看看如何评价我们之前训练的比特币模型。

## 评估比特币模式

我们在*第 1 章*、*神经网络和深度学习简介*的活动中创建了一个测试集。该测试集包含 21 周的比特币每日价格观察，相当于原始数据集的 10%左右。

我们还使用了《T2》第二章、*用 TensorFlow 和 Keras 进行真实世界深度学习:预测比特币价格*中另外 90%的数据(即 187 周数据的训练集，验证集减 1)来训练我们的神经网络，并将训练好的网络存储在磁盘上(`bitcoin_lstm_v0`)。我们现在可以在来自测试集的 21 周数据的每一周中使用`evaluate()`方法，并检查第一个神经网络的表现。

但是，为了做到这一点，我们必须提供 186 周的前期数据。我们必须这样做，因为我们的网络已经被训练为使用精确的 186 周连续数据来预测一周的数据(我们将通过在第四章*、*产品化*中以更大的周期定期重新训练我们的网络来处理这种行为，当我们将神经网络部署为 web 应用程序时)。下面的代码片段实现了`evaluate()`方法来评估我们的模型在测试数据集中的性能:*

```
combined_set = np.concatenate((train_data, test_data), axis=1) \
               evaluated_weeks = []
for i in range(0, validation_data.shape[1]):
    input_series = combined_set[0:,i:i+187]
X_test = input_series[0:,:-1].reshape(1, \
         input_series.shape[1] – 1, ) \
         Y_test = input_series[0:,-1:][0]
result = B.model.evaluate(x=X_test, y=Y_test, verbose=0) \
         evaluated_weeks.append(result)
```

在前面的代码中，我们使用 Keras' `model.evaluate()`方法评估每周，然后将其输出存储在`evaluated_weeks`变量中。然后，我们绘制每周的 MSE，如下图所示:

![Figure 3.6: MSE for each week in the test set
](image/B15911_03_06.jpg)

图 3.6:测试集中每周的 MSE

从我们的模型得到的 MSE 表明，我们的模型在大多数周期间表现良好，除了第 2、8、12 和 16 周，此时它的值从大约 0.005 增加到 0.02。我们的模型似乎在几乎所有其他测试周都表现良好。

## 过度拟合

我们第一个训练好的网络(`bitcoin_lstm_v0`)可能正遭受一种被称为**过度拟合**的现象。过度拟合是指模型被训练来优化验证集，但这是以我们感兴趣预测的现象中更可概括的模式为代价的。过度拟合的主要问题是，模型知道如何预测验证集，但无法预测新数据。

我们在模型中使用的损失函数在训练过程结束时达到非常低的水平。不仅如此，这种情况发生得很早:在我们的数据中，用于预测最后一周的 MSE 损失函数在第 30 个纪元左右下降到一个稳定的平台。这意味着我们的模型使用之前的 186 周，几乎完美地预测了第 187 周的数据。这可能是过度拟合的结果吗？

我们再来看看前面的情节。我们知道，我们的 LSTM 模型在我们的验证集中达到了极低的值(大约 2.9 × 10-6)，然而它在我们的测试集中也达到了低值。然而，关键的区别在于规模。我们的测试集中每周的 MSE 大约是测试集中的 4000 倍(平均)。这意味着模型在我们的测试数据中的表现比在验证集中的表现差得多。这个值得考虑。

然而，这个规模隐藏了我们的 LSTM 模型的力量；即使在我们的测试集中表现很差，预测的 MSE 误差仍然非常非常低。这表明我们的模型可能正在从数据中学习模式。

## 模型预测

测量我们的模型比较 MSE 误差是一回事，能够直观地解释其结果是另一回事。

使用相同的模型，让我们使用 186 周作为输入，为接下来的几周创建一系列预测。我们通过在完整系列(即训练加测试集)上滑动 186 周的窗口，并对这些窗口中的每个窗口进行预测来做到这一点。

下面的代码片段使用`Keras model.predict()`方法对测试数据集的所有周进行预测:

```
combined_set = np.concatenate((train_data, test_data), \
               axis=1) predicted_weeks = []
for i in range(0, validation_data.shape[1] + 1): 
    input_series = combined_set[0:,i:i+186]
    predicted_weeks.append(B.predict(input_series))
```

在前面的代码中，我们使用`model.predict()`方法进行预测，然后将这些预测存储在`predicted_weeks`变量中。然后，我们绘制结果预测，绘制如下图:

![Figure 3.7: MSE for each week in the test set
](image/B15911_03_07.jpg)

图 3.7:测试集中每周的 MSE

我们的模型的结果表明它的性能并没有那么差。通过观察`Predicted`线(灰色)的模式，我们可以看到网络已经确定了一个每周发生的波动模式，其中标准化价格在周中上升，然后在周末下降。然而，仍有很大的改进空间，因为它无法拾取更高的波动。除了少数几周——与我们之前的 MSE 分析相同——大多数周都接近正确值。

现在，让我们对预测进行反规范化，以便我们可以使用与原始数据相同的比例(即美元)来调查预测值。我们可以通过实现一个反规范化函数来做到这一点，该函数使用预测数据中的日索引来标识测试数据中的等效周。识别出该周之后，该函数将获取该周的第一个值，并使用该值通过使用相同的点相对规范化技术(但取反)对预测值进行反规范化。以下代码片段使用反向点相对规范化技术对数据进行反规范化:

```
def denormalize(reference, series, normalized_variable=\
                'close_point_relative_normalization', \
                denormalized_variable='close'):
    if('iso_week' in list(series.columns)):
        week_values = reference[reference['iso_week'] \
                      == series['iso_week'].values[0]]
        last_value = week_values[denormalized_variable].values[0]
        series[denormalized_variable] = \
        last_value * (series[normalized_variable] + 1)
    return series
predicted_close = predicted.groupby('iso_week').apply(lambda x: \
                  denormalize(observed, x))
```

`denormalize()`函数从测试的同一个星期的第一天获取第一个收盘价。

我们的结果现在使用美元将预测值与测试集进行比较。如下图所示，`bitcoin_lstm_v0`模型似乎在预测接下来 7 天的比特币价格方面表现得相当不错。但是我们如何用可解释的术语来衡量这种表现呢？

![Figure 3.8: De-normalized predictions per week
](image/B15911_03_08.jpg)

图 3.8:每周的非标准化预测

## 解读预测

我们的最后一步是增加预测的可解释性。前面的图似乎表明，我们的模型预测与测试数据有些接近，但有多接近呢？

Keras' `model.evaluate()`函数有助于理解模型在每个评估步骤中的表现。然而，考虑到我们通常使用规范化数据集来训练神经网络，由`model.evaluate()`方法生成的指标也很难解释。

为了解决这个问题，我们可以从我们的模型中收集完整的预测集，并使用*图 3.1* 中更容易解释的另外两个函数与测试集进行比较:MAPE 和 RMSE，它们分别实现为`mape()`和`rmse()`。

注意

这些功能是使用 NumPy 实现的。最初的实现来自[https://stats . stack exchange . com/questions/58391/mean-absolute-percentage-error-mape-in-scikit-learn](https://stats.stackexchange.com/questions/58391/mean-absolute-percentage-error-mape-in-scikit-learn)和[https://stack overflow . com/questions/16774849/mean-squared-error-in-numpy](https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy)

我们可以在下面的代码片段中看到这些方法的实现:

```
def mape(A, B):
    return np.mean(np.abs((A - B) / A)) * 100
def rmse(A, B):
    return np.sqrt(np.square(np.subtract(A, B)).mean())
```

将我们的测试集与使用这两个函数的预测进行比较后，我们得到了以下结果:

*   **反规格化的 RMSE**:596.6 美元
*   **非规格化的 MAPE**:4.7%

这表明我们的预测平均与真实数据相差约 596 美元。这意味着与真实比特币价格相差约 4.7%。

这些结果有助于理解我们的预测。我们将继续使用`model.evaluate()`方法来跟踪我们的 LSTM 模型是如何改进的，但也将在我们模型的每个版本的完整系列上计算`rmse()`和`mape()`，以解释我们离预测比特币价格有多近。

## 练习 3.01:创造一个积极的培训环境

在本练习中，我们将为神经网络创建一个训练环境，以促进其训练和评估。这个环境对于下一个主题尤其重要，在这个主题中，我们将搜索超参数的最佳组合。

首先，我们将启动一个 Jupyter 笔记本实例和一个 TensorBoard 实例。在本练习的剩余部分，这两个实例都可以保持开放。让我们开始吧:

1.  Using your Terminal, navigate to the `Chapter03/Exercise3.01` directory and execute the following code to start a Jupyter Notebook instance:

    ```
    $ jupyter-lab
    ```

    服务器应该会自动在您的浏览器中打开。

2.  Open the Jupyter Notebook named `Exercise3.01_Creating_an_active_training_environment.ipynb`:![Figure 3.9: Jupyter Notebook highlighting the section, Evaluate LSTM Model
    ](image/B15911_03_09.jpg)

    图 3.9: Jupyter 笔记本突出显示了“评估 LSTM 模型”部分

3.  Also using your Terminal, start a TensorBoard instance by executing the following command:

    ```
    $ cd ./Chapter03/Exercise3.01/
    $ tensorboard --logdir=logs/
    ```

    确保存储库中的`logs`目录为空。

4.  打开屏幕上显示的 URL，并保持浏览器选项卡打开。执行包含导入语句的初始单元格，以确保加载了依赖项。
5.  Execute the two cells under Validation Data to load the train and test datasets in the Jupyter Notebook:

    ```
    train = pd.read_csv('data/train_dataset.csv')
    test = pd.read_csv('data/test_dataset.csv')
    ```

    注意

    不要忘记根据文件在系统中的保存位置来更改文件的路径(突出显示)。

6.  Add TensorBoard callback and retrain the model. Execute the cells under Re-Train model with TensorBoard.

    现在，让我们根据测试数据来评估我们的模型的表现。我们的模型使用 186 周来训练，以预测未来的一周，即以下 7 天的序列。当我们构建第一个模型时，我们将原始数据集分为训练集和测试集。现在，我们将采用两个数据集的组合版本(姑且称之为组合集)，并移动 186 周的滑动窗口。在每个窗口，我们执行 Keras 的`model.evaluate()`方法来评估网络在特定周的表现。

7.  执行表头下的单元格，`Evaluate LSTM Model`。这些单元格的关键概念是为测试集中的每一周调用`model.evaluate()`方法。这一行最重要:

    ```
    result = model.evaluate(x=X_test, y=Y_test, verbose=0)
    ```

8.  Each evaluation result is now stored in the `evaluated_weeks` variable. That variable is a simple array containing the sequence of MSE predictions for every week in the test set. Go ahead and plot the results:![Figure 3.10: MSE results from the model.evaluate() method for each week of the test set
    ](image/B15911_03_10.jpg)

    图 3.10:测试集每周的 model.evaluate()方法的 MSE 结果

    正如我们已经讨论过的，MSE 损失函数很难解释。为了便于我们理解我们的模型是如何执行的，我们还在每周从测试集中调用`model.predict()`方法，并将它的预测结果与测试集的值进行比较。

9.  Navigate to the *Interpreting Model Results* section and execute the code cells under the `Make Predictions` subheading. Notice that we are calling the `model.predict()` method, but with a slightly different combination of parameters. Instead of using both the `X` and `Y` values, we only use `X`:

    ```
    predicted_weeks = []
    for i in range(0, test_data.shape[1]):
        input_series = combined_set[0:,i:i+186]
        predicted_weeks.append(model.predict(input_series))
    ```

    在每个窗口，我们将发布下周的预测并存储结果。现在，我们可以绘制标准化结果以及测试集中的标准化值，如下图所示:

    ![Figure 3.11: Plotting the normalized values returned from model.predict() for each 
    week of the test set](image/B15911_03_11.jpg)

    图 3.11:绘制测试集每周从 model.predict()返回的标准化值

    我们也将进行相同的比较，但是使用非规格化的值。为了使我们的数据非正常化，我们必须确定测试集和预测之间的等价周。然后，我们可以获得该周的第一个价格值，并使用它来反转第二章、*中的点相对归一化方程，使用 TensorFlow 和 Keras 进行真实世界深度学习:预测比特币的价格*。

10.  导航到`De-normalized Predictions`标题并执行该标题下的所有单元格。
11.  In this section, we defined the `denormalize()` function, which performs the complete denormalization process. In contrast to the other functions, this function takes in a pandas DataFrame instead of a NumPy array. We do this to use dates as an index. This is the most relevant cell block from that header:

    ```
    predicted_close = predicted.groupby('iso_week').apply(\
                      lambda x: denormalize(observed, x))
    ```

    我们的反规范化结果(如下图所示)显示，我们的模型做出的预测接近真实的比特币价格。但是有多近？

    ![Figure 3.12: Plotting the denormalized values returned from model.predict() 
    for each week of the test set
    ](image/B15911_03_12.jpg)

    图 3.12:绘制测试集每周从 model.predict()返回的反规格化值

    LSTM 网络使用 MSE 值作为其损失函数。然而，正如我们已经讨论过的，MSE 值很难解释。为了解决这个问题，我们需要实现两个函数(从`utilities.py`脚本加载),分别实现`rmse()`和`mape()`函数。这些函数通过返回与原始数据相同尺度的测量值，并通过比较尺度差异的百分比，为我们的模型增加了可解释性。

12.  Navigate to the `De-normalizing Predictions` header and load two functions from the `utilities.py` script:

    ```
    from scripts.utilities import rmse, mape
    ```

    这个脚本中的函数实际上非常简单:

    ```
    def mape(A, B):
      return np.mean(np.abs((A - B) / A)) * 100
    def rmse(A, B):
      return np.sqrt(np.square(np.subtract(A, B)).mean())
    ```

    每个函数都是使用 NumPy 的向量运算实现的。它们在相同长度的向量中工作良好。它们旨在应用于一组完整的结果。

    使用`mape()`函数，我们现在可以理解我们的模型预测与测试集的价格相差约 4.7%。这相当于约 596.6 美元的 RSME(使用`rmse()`函数计算)。

    在进入下一部分之前，回到笔记本并找到`Re-train Model with TensorBoard`标题。您可能已经注意到，我们创建了一个名为`train_model()`的助手函数。这个函数是我们模型的包装器，它训练(使用`model.fit()`)我们的模型，将各自的结果存储在一个新的目录下。TensorBoard 使用这些结果来显示不同模型的统计数据。

13.  继续修改传递给`model.fit()`函数的一些参数值(例如，尝试 epochs)。现在，运行将模型从磁盘加载到内存中的单元(这将替换您的训练模型):

    ```
    model = load_model('bitcoin_lstm_v0.h5')
    ```

14.  Now, run the `train_model()` function again, but with different parameters, indicating a new run version. When you run this command, you will be able to train a newer version of the model and specify the newer version in the version parameter:

    ```
    train_model(model=model, X=X_train, Y=Y_train, \
                epochs=10, version=0, run_number=0)
    ```

    注意

    要访问该特定部分的源代码，请参考[https://packt.live/2ZhK4z3](https://packt.live/2ZhK4z3)。

    你也可以在[https://packt.live/2Dvd9i3](https://packt.live/2Dvd9i3)在线运行这个例子。您必须执行整个笔记本才能获得想要的结果。

在本练习中，我们学习了如何使用损失函数评估网络。我们知道损失函数是神经网络的关键元素，因为它们评估网络在每个时期的性能，并且是将调整传播回层和节点的起点。我们还探索了为什么一些损失函数可能难以解释(例如，MSE 函数),并开发了一种策略，使用另外两个函数——RMSE 和 MAPE——来解释我们的 LSTM 模型的预测结果。

最重要的是，我们在积极的培训环境中结束了这次练习。我们现在有一个系统，可以训练深度学习模型，并持续评估其结果。这将是我们在下一个主题中继续优化网络的关键。

# 超参数优化

到目前为止，我们已经训练了一个神经网络，使用之前 76 周的价格来预测未来 7 天的比特币价格。平均而言，该模型发布的预测与实际比特币价格的差距约为 8.4%。

本节描述了提高神经网络模型性能的常用策略:

*   添加或删除层以及更改节点数
*   增加或减少训练时期的数量
*   尝试不同的激活功能
*   使用不同的正则化策略

我们将使用我们在*模型评估*部分结束时开发的相同主动学习环境来评估每个修改，衡量这些策略如何帮助我们开发更精确的模型。

## 层和节点–添加更多层

具有单一隐藏层的神经网络可以在许多问题上表现得相当好。我们的第一个比特币模型(`bitcoin_lstm_v0`)就是一个很好的例子:它可以使用单个 LSTM 层预测未来 7 天的比特币价格(根据测试集)，误差率约为 8.4%。然而，并不是所有的问题都可以用单层来建模。

预测的函数越复杂，需要添加更多图层的可能性就越大。确定添加新层是否是一个好主意的好方法是理解它们在神经网络中的作用。

每一层都创建其输入数据的模型表示。链中较早的层创建较低级别的表示，而较晚的层创建较高级别的表示。

虽然这种描述可能很难转化为现实世界的问题，但它的实际直觉很简单:当处理具有不同表示级别的复杂函数时，您可能希望尝试添加层。

### 添加更多节点

层所需的神经元数量与输入和输出数据的结构有关。例如，如果您正在处理一个二元分类问题来对一个 4 x 4 像素的图像进行分类，那么您可以尝试以下方法:

*   有一个有 12 个神经元的隐藏层(每个可用像素一个)
*   有一个只有两个神经元的输出层(每个预测类一个)

通常在添加新层的同时添加新的神经元。然后，我们可以添加一个与前一层神经元数量相同的层，或者是前一层神经元数量的倍数。例如，如果您的第一个隐藏层有 12 个神经元，您可以尝试添加第二个具有 12、6 或 24 个神经元的层。

添加层和神经元会有很大的性能限制。请随意尝试添加层和节点。通常从一个较小的网络(即具有少量层和神经元的网络)开始，然后根据其性能增益增长。

如果这显得不精确，你的直觉是对的。

注意

引用 YouTube 前视频分类负责人 Aurélien Géron 的话，“*找到神经元的完美数量仍然是一种黑色艺术*

最后，提醒一句:添加的层数越多，需要调整的超参数就越多，网络训练的时间也就越长。如果您的模型运行良好，并且没有过度拟合您的数据，请在向网络添加新图层之前尝试本章中概述的其他策略。

## 层和节点-实现

现在，我们将通过添加更多的层来修改我们原来的 LSTM 模型。在 LSTM 模型中，我们通常按顺序添加 LSTM 层，在 LSTM 层之间形成一个链。在我们的例子中，新的 LSTM 层与原始层具有相同数量的神经元，因此我们不必配置该参数。

我们将把我们模型的修改版本命名为`bitcoin_lstm_v1`。根据每个模型尝试不同的超参数配置来命名每个模型是一种很好的做法。这有助于您跟踪每种不同体系结构的性能，并轻松比较 TensorBoard 中的模型差异。我们将在本章末尾比较所有不同的改进结构。

注意

在添加一个新的 LSTM 层之前，我们需要在第一个 LSTM 层上设置`return_sequences`参数为`True`。我们这样做是因为第一层期望数据序列具有与第一层相同的输入。当该参数设置为`False`时，LSTM 层以不同的、不兼容的输出输出预测参数。

下面的代码示例将第二个 LSTM 图层添加到原始的`bitcoin_lstm_v0`模型，使其成为`bitcoin_lstm_v1`:

```
period_length = 7
number_of_periods = 186
batch_size = 1
model = Sequential() 
model.add(LSTM(
units=period_length,
batch_input_shape=(batch_size, number_of_periods, period_length), \
                  input_shape=(number_of_periods, period_length), \
                  return_sequences=True, stateful=False))
model.add(LSTM(units=period_length,\
               batch_input_shape=(batch_size, number_of_periods, \
                                  period_length), \
               input_shape=(number_of_periods, period_length), \
               return_sequences=False, stateful=False))
model.add(Dense(units=period_length)) \
model.add(Activation("linear"))
model.compile(loss="mse", optimizer="rmsprop")
```

## 划时代

**时期**是网络根据通过的数据及其产生的损失函数调整其权重的次数。运行更多时期的模型可以让它从数据中学到更多，但你也有过度拟合的风险。

当训练模型时，倾向于指数地增加历元，直到损失函数开始趋于平稳。在`bitcoin_lstm_v0`模型的情况下，其损失函数在大约 100 个历元处达到稳定。

我们的 LSTM 模型使用少量数据进行训练，因此增加历元数不会对其性能产生显著影响。例如，如果我们试图在 103 个时期训练它，模型几乎没有任何改进。如果被训练的模型使用大量数据，情况就不是这样了。在这些情况下，大量的历元对于实现良好的性能至关重要。

我建议您使用以下经验法则:*用于训练您的模型的数据越大，它将需要越多的时期来实现良好的性能*。

### 时代——实施

我们的比特币数据集相当小，因此增加我们的模型训练的纪元可能对其性能只有很小的影响。为了让模型训练更多的时期，我们只需改变`model.fit()`方法中的`epochs`参数。在下面的代码片段中，您将看到如何更改我们的模型所训练的时期数:

```
number_of_epochs = 10**3 
model.fit(x=X, y=Y, batch_size=1,\
          epochs=number_of_epochs, \
          verbose=0, \
          callbacks=[tensorboard])
```

这一变化将我们的模型提升到`v2`，实际上使它成为`bitcoin_lstm_v2`。

## 激活功能

**激活函数**评估你需要激活多少单个神经元。它们使用前一层的输入和损失函数的结果来确定每个神经元将传递给网络下一个元素的值，或者神经元是否应该传递任何值。

注意

激活函数是科学界研究神经网络的人非常感兴趣的话题。关于目前正在进行的关于该主题的研究的概述以及关于激活功能如何工作的更详细的回顾，请参考 Ian Goodfellow 等人的*深度学习。艾尔。，麻省理工出版社，2017* 。

TensorFlow 和 Keras 提供了许多激活功能，并且偶尔会添加新的功能。作为介绍，有三点需要考虑:让我们逐一探究。

注意

本节受到 Avinash Sharma V 的文章*理解神经网络中的激活功能*的极大启发，该文章可从[https://medium . com/the-theory-of-theory-of-everything/Understanding-Activation-Functions-in-Neural-Networks-9491262884 E0](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0)获得。

## 线性(恒等)函数

线性函数仅基于常数值激活神经元。它们由以下等式定义:

![Figure 3.13: Formula for linear functions
](image/B15911_03_13.jpg)

图 3.13:线性函数的公式

这里， *c* 是常数值。当 *c = 1* 时，神经元将按原样传递这些值，无需激活函数所需的任何修改。使用线性函数的问题是，由于神经元是线性激活的，所以链式层现在作为单个大层来工作。换句话说，我们失去了构建多层网络的能力，其中一层的输出会影响另一层:

![Figure 3.14: Illustration of a linear function
](image/B15911_03_14.jpg)

图 3.14:线性函数的图示

对于大多数网络来说，线性函数的使用通常被认为是过时的，因为它们不计算复杂的特征，并且不在神经元中引起适当的非线性。

### 双曲正切函数

Tanh 是一个非线性函数，由以下公式表示:

![Figure 3.15: Formula for hyperbolic tangent function
](image/B15911_03_15.jpg)

图 3.15:双曲正切函数的公式

这意味着它们对节点的影响是不断评估的。此外，由于它的非线性，我们可以使用该函数来改变链中一层如何影响下一层。当使用非线性函数时，层以不同的方式激活神经元，从而更容易从数据中学习不同的表示。然而，它们有一个类似 sigmoid 的模式，重复惩罚极端节点值，导致一个称为消失梯度的问题。消失梯度对网络的学习能力有负面影响:

![Figure 3.16: Illustration of a tanh function
](image/B15911_03_16.jpg)

图 3.16:双曲正切函数的图示

Tanhs 是流行的选择，但是由于它们计算量很大，所以通常使用 ReLUs。

### 校正线性单位函数

**ReLU** 代表**整流线性单元**。它过滤掉负值，只保留正值。在尝试其他函数之前，ReLU 函数通常被推荐为很好的起点。它们由以下公式定义:

![Figure 3.17: Formula for ReLU functions
](image/B15911_03_17.jpg)

图 3.17:ReLU 函数的公式

ReLUs 具有非线性属性:

![Figure 3.18: Illustration of a ReLU function
](image/B15911_03_18.jpg)

图 3.18:ReLU 函数的图示

ReLUs 倾向于惩罚负面价值。因此，如果输入数据(例如，在-1 和 1 之间归一化)包含负值，那么这些值现在将被 ReLUs 惩罚。这可能不是预期的行为。

我们不会在我们的网络中使用 ReLU 函数，因为我们的标准化过程会产生许多负值，从而产生一个慢得多的学习模型。

## 激活功能–实施

在 Keras 中实现激活功能最简单的方法是实例化`Activation()`类并将其添加到`Sequential()`模型中。可以用 Keras 中可用的任何激活函数实例化`Activation()`(完整列表见[https://keras.io/activations/](https://keras.io/activations/))。

在我们的例子中，我们将使用`tanh`函数。在实现一个激活函数之后，我们将模型的版本提升到`v2`，使其成为`bitcoin_lstm_v3`:

```
model = Sequential() model.add(LSTM(
                               units=period_length,\
                               batch_input_shape=(batch_size, \
                               number_of_periods, period_length), \
                               input_shape=(number_of_periods, \
                                            period_length), \
                               return_sequences=True, \
                               stateful=False))
model.add(LSTM(units=period_length,\
          batch_input_shape=(batch_size, number_of_periods, \
                             period_length), \
          input_shape=(number_of_periods, period_length), \
          return_sequences=False, stateful=False))
model.add(Dense(units=period_length)) \
model.add(Activation("tanh"))
model.compile(loss="mse", optimizer="rmsprop")
```

执行`compile`命令后，您的模型已经根据指定的层构建好了，现在可以开始训练了。还有许多其他值得尝试的激活功能。TensorFlow 和 Keras 都在各自的官方文档中提供了已实现功能的列表。在实现您自己的之前，先从我们已经在 TensorFlow 和 Keras 中实现的开始。

## 正规化策略

神经网络特别容易过度拟合。当网络学习训练数据的模式，但无法找到也可以应用于测试数据的可概括模式时，就会发生过度拟合。

正则化策略是指通过调整网络的学习方式来处理过拟合问题的技术。在下面几节中，我们将讨论两种常见的策略:

*   L2 正则化
*   拒绝传统社会的人

### L2 正规化

**L2 正则化**(或**权重衰减**)是处理过拟合模型的常用技术。在一些模型中，某些参数变化幅度很大。L2 正则化惩罚了这些参数，减少了这些参数对网络的影响。

L2 正则化使用![3](image/B15911_03_Formula_01.png)参数来确定惩罚模型神经元的程度。我们通常将其设置为一个非常低的值(即 0.0001)；否则，我们就有可能完全消除某个神经元的输入。

### 辍学

Dropout 是一种基于简单问题的正则化技术:*如果我们从层中随机取走一部分节点，另一个节点将如何适应？*结果是，剩余的神经元适应了，学习代表先前由缺失的神经元处理的模式。

放弃策略易于实施，并且在避免过度拟合方面通常非常有效。这将是我们的首选正规化。

### 正规化战略——实施

为了使用 Keras 实现丢弃策略，我们将导入`Dropout()`方法，并在每个 LSTM 层之后立即将其添加到我们的网络中。这一增加有效地使我们的网络`bitcoin_lstm_v4`。在这个代码片段中，我们将`Dropout()`步骤添加到我们的模型(`bitcoin_lstm_v3`)中，使其成为`bitcoin_lstm_v4`:

```
model = Sequential()
model.add(LSTM(\
          units=period_length,\
          batch_input_shape=(batch_size, number_of_periods, \
                             period_length), \
          input_shape=(number_of_periods, period_length), \
          return_sequences=True, stateful=False))
model.add(Dropout(0.2))
model.add(LSTM(\
          units=period_length,\
          batch_input_shape=(batch_size, number_of_periods, \
                             period_length), \
          input_shape=(number_of_periods, period_length), \
          return_sequences=False, stateful=False))
model.add(Dropout(0.2))
model.add(Dense(units=period_length))
model.add(Activation("tanh"))
model.compile(loss="mse", optimizer="rmsprop")
```

我们本可以使用 L2 正规化，而不是辍学。丢弃在每个时期丢弃随机神经元，而 L2 正则化惩罚具有高权重值的神经元。为了应用 L2 正则化，只需将 L2 参数设置为一个低值(例如，0.0001)来实例化`ActivityRegularization()`类。然后，将它放在已经将`Dropout()`类添加到网络中的位置。在保留两个`Dropout()`步骤的情况下，可以随意试验将它添加到网络中，或者简单地用`ActivityRegularization()`替换所有的`Dropout()`实例。

## 优化结果

总而言之，我们已经创建了四个版本的模型。其中三个版本，即`bitcoin_lstm_v1`、`bitcoin_lstm_v2`和`bitcoin_lstm_v3`，是通过应用本章概述的不同优化技术创建的。现在，我们必须评估哪种模型表现最好。为了做到这一点，我们将使用我们在第一个模型中使用的相同指标:MSE、RMSE 和 MAPE。MSE 用于比较模型在每个预测周的误差率。计算 RMSE 和 MAPE 是为了使模型结果更容易解释。下表显示了这一点:

![Figure 3.19: Model results for all models
](image/B15911_03_19.jpg)

图 3.19:所有模型的模型结果

有趣的是，我们的第一个模型(`bitcoin_lstm_v0`)在几乎所有定义的指标中表现最好。我们将使用该模型来构建我们的网络应用程序，并持续预测比特币价格。

## 活动 3.01:优化深度学习模型

在本活动中，我们将对我们在*第二章*、*使用 TensorFlow 和 Keras 的真实世界深度学习:预测比特币价格* ( `bitcoin_lstm_v0`)中创建的模型实施不同的优化策略。该模型在完整的去归一化测试集上实现了大约 8.4%的 MAPE 性能。我们将努力缩小差距，获得更准确的预测。

以下是步骤:

1.  从终端启动 TensorBoard。
2.  开始一个 Jupyter 笔记本。
3.  加载训练和测试数据，并按照模型要求的格式拆分`lstm`输入。
4.  在上一个练习中，我们创建了一个模型架构。复制模型架构并添加一个新 LSTM 层。编译并创建一个模型。
5.  通过创建一个新模型，改变第 4 步中的时期数。编译并创建一个新模型。
6.  将激活功能更改为`tanh`或`relu`并创建一个新模型。编译和训练一个新模型。
7.  在 LSTM 图层后添加一个新的 dropout 图层，并创建一个新的模型。保留值，如`0.2`或`0.3`用于辍学。编译和训练一个新模型。
8.  Evaluate and compare all the models that were trained in this activity.

    注意

    这项活动的解决方案可在第 141 页找到。

# 总结

在这一章中，我们学习了如何使用 MSE、RMSE 和 MAPE 指标来评估我们的模型。我们在第一个神经网络模型做出的一系列 19 周预测中计算了后两个指标。通过这样做，我们了解到它的性能很好。

我们还学习了如何优化模型。我们研究了优化技术，这些技术通常用于提高神经网络的性能。此外，我们实现了许多这样的技术，并创建了几个模型来预测不同错误率的比特币价格。

在下一章中，我们将把我们的模型变成一个 web 应用程序，它做两件事:定期用新数据重新训练我们的模型，并且能够使用 HTTP API 接口进行预测。
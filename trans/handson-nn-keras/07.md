        

# 七、循环神经网络

在前一章中，我们对视觉皮层感到惊叹，并利用它处理视觉信号的方式来为**卷积神经网络**(**CNN**)的架构提供信息，这些网络构成了许多最先进的计算机视觉系统的基础。然而，我们并不仅仅通过视觉来理解我们周围的世界。例如，声音也起着非常重要的作用。更具体地说，我们人类喜欢通过一系列的象征性简化和抽象表达来交流和表达复杂的思想和观点。我们的内置硬件允许我们解释发声或其界限，构成了人类思想和集体理解的基础，在此基础上可以组成更复杂的表达(例如人类语言)。本质上，这些符号序列是通过我们自己的镜头对我们周围世界的简化表示，我们用它来导航我们的周围环境并有效地表达我们自己。显而易见，我们希望机器理解这种处理顺序信息的方式，因为它可以帮助我们解决我们在现实世界中面临的许多问题。但是什么样的问题呢？

以下是本章将涉及的主题:

*   建模序列
*   总结不同类型的序列处理任务
*   预测每个时间步长的输出
*   穿越时间的反向传播
*   爆炸和消失渐变
*   天鹤座
*   在 keras 中构建字符级语言模型
*   角色建模统计
*   随机控制的目的
*   测试不同的 RNN 模型
*   构建一个简单的
*   建筑集团
*   论顺序处理现实
*   Keras 中的双向层
*   可视化输出值

        

# 建模序列

也许当你在国外旅游时，你想在餐馆里为你点的菜得到正确的翻译。也许你想让你的车自动完成一系列动作，这样它就能自己停车了。或者你可能想了解人类基因组中腺嘌呤、鸟嘌呤、胸腺嘧啶和胞嘧啶分子的不同序列如何导致人体内发生的生物过程的差异。这些例子之间有什么共性？这些都是序列建模任务。在这样的任务中，训练实例(作为单词的向量，由车载控制生成的一组汽车运动，或者 *A* 、 *G* 、 *T* 和 *C* 分子的配置)本质上是长度可能变化的多个时间相关数据点。

例如，句子是由单词组成的，这些单词的空间结构不仅暗示了已经说过的话，还暗示了将要发生的事情。试着填写下面的空白:

不要根据一本书的 ___ 来判断它。

你怎么知道下一个词会是 *cover* ？您只需查看单词及其相对位置，并利用您之前看到的句子及其与手边示例的明显相似性进行某种贝叶斯推理。本质上，你使用你的英语语言内部模型来预测最有可能出现的单词。在这里，*语言模型*简单来说就是指单词的特定配置在给定序列中一起出现的概率。这种模型是现代语音识别和机器翻译系统的基本组件，并且仅仅依赖于对单词序列的可能性进行建模。

        

# 使用 RNNs 进行顺序建模

自然语言理解领域是一个常见的领域，其中**循环神经网络** ( **RNNs** )往往表现出色。你可以想象一些任务，比如识别命名的实体，对给定文本中的主要情感进行分类。然而，正如我们提到的，rnn 适用于广泛的任务，包括建模依赖于时间的数据序列。生成音乐也是一项序列建模任务，因为我们倾向于通过对以给定速度播放的音符序列进行建模来区分音乐和杂音。

RNN 架构甚至适用于一些视觉智能任务，如视频活动识别。在给定的视频中识别一个人是在做饭、跑步还是抢劫银行，本质上是对人类运动序列进行建模，并将它们与特定的类别进行匹配。事实上，rnn 已经被部署用于一些非常有趣的用例，包括生成莎士比亚风格的文本，创建现实的(但不正确的)代数论文，甚至为 Linux 操作系统生成适当格式的源代码。

那么，是什么让这些网络在执行这些看似多样化的任务时如此灵活多变呢？好吧，在我们回答这个问题之前，让我们回顾一下到目前为止我们在使用神经网络时遇到的一些困难:

![](Images/a3ef793d-f2f1-4923-a5b9-0e1680930241.png)

RNN 提出的伪代数几何，由安德烈·卡帕西提供

这意味着:

![](Images/ee7a9951-c981-4b4f-b1d8-9b3e02bf45eb.png)        

# 有什么条件？

到目前为止，我们已经建立的所有网络的一个问题是，对于给定的训练样本，它们只接受固定大小的输入和输出。我们总是不得不指定我们的输入形状，定义进入我们网络的张量的维度，这反过来又返回固定大小的输出，例如以类概率分数的形式。此外，我们的网络中的隐藏层都有自己的权重和激活，它们的行为在某种程度上相互独立，没有识别连续输入值之间的关系。这适用于我们在前几章已经熟悉的前馈和 CNN。对于我们构建的每个网络，我们使用非顺序的训练向量，这些向量将通过恒定数量的层传播并产生单个输出。

虽然我们确实看到了一些多输出模型来可视化 CNN 的中间层，但我们从未真正修改我们的架构来操作一系列向量。这基本上禁止我们分享任何可能影响我们预测可能性的时间相关信息。到目前为止，丢弃依赖于时间的信息已经使我们完成了我们所处理的任务。在图像分类的情况下，您的神经网络在最后一次迭代中看到了一只猫的图像这一事实并没有真正帮助它对正在查看的当前图像进行分类，因为这两个实例的分类概率在时间上并不相关。然而，这种方法已经给情感分析的用例带来了一些麻烦。回想一下在[第三章](46e25614-bb5a-4cca-ac3e-b6dfbe29eea5.xhtml)、*信号处理——用神经网络进行数据分析*中，我们通过将每一篇评论视为一袋无向词(也就是说，不是按照它们的顺序)来对电影评论进行分类。这种方法需要将每个评论转换成一个固定长度的向量，该向量由我们的词汇量(即语料库中唯一单词的数量，我们选择为 12，000 个单词)定义。虽然有用，但这肯定不是表示信息的最有效或可伸缩的形式，因为任何给定长度的句子都必须由 12，000 维向量表示。我们训练的简单前馈网络(达到 88 %以上的准确率)错误地对其中一篇评论的情绪进行了分类，如下所示:

![](Images/0d2f4a36-47d1-46d5-a154-564f4aff2342.png)

我们的网络似乎已经变得混乱，因为(不必要的)复杂的句子有几个长期依赖和上下文变价。回想起来，我们注意到不清楚的双重否定指的是各种实体，如导演、演员和电影本身；然而，我们可以看出，审查的总体情绪显然是积极的。为什么？这仅仅是因为当我们逐字阅读时，我们能够跟踪与评论的总体情绪相关的概念。在我们的头脑中，我们能够评估我们所看到的评论中的每一个新词是如何影响我们到目前为止所阅读的陈述的一般含义的。以这种方式，当我们阅读并遇到可能在给定时间步影响评分的新信息(如形容词或否定)时，我们调整我们对评论的情感评分。

就像在 CNN 中一样，我们希望我们的网络能够使用在输入的某个片段中学习到的表示，然后在其他片段和例子中使用。换句话说，我们需要能够分享我们的网络在之前的时间步骤中的权重，以便在我们按顺序检查输入时连接信息位。这几乎是 RNNs 允许我们做的。这些层利用编码在连续事件中的附加信息，这是通过循环一系列输入值来实现的。根据架构实现，RNNs 可以在其存储器中保存相关信息(也称为其状态),并使用该信息在后续时间步骤执行预测。

这种机制明显不同于我们之前看到的网络，后者独立处理每个训练迭代，并且在预测之间不保持任何状态。循环神经网络有几种不同的实现方式，从**门控递归单元** ( **GRUs** )、有状态和无状态**长期短期记忆** ( **LSTM** )网络、双向单元等等。我们很快就会发现，这些体系结构中的每一种都有助于解决特定类型的问题，它们都是建立在彼此的缺点之上的:

![](Images/7d9ac677-7a6d-493d-8769-4c6a1737b07c.png)        

# 基本 RNN 建筑

现在，让我们来看看 RNN 架构如何通过随时间展开来区别于我们迄今为止看到的其他网络。让我们考虑一个新的时间序列问题:语音识别。这项任务可以由计算机来执行，以识别一段人类语音中的单词流。这可以用来转录语音本身，翻译它，或使用它作为指令的输入，类似于我们相互指导的方式。这类应用构成了 Siri 或 Alexa 等系统的基础，或许还会构成未来更复杂、更具认知能力的虚拟助手。那么，RNN 是如何将计算机麦克风记录的分解振动序列解码成与输入语音相对应的字符串变量的呢？

让我们考虑一个简化的理论例子。想象一下，我们的训练数据将人类发声序列映射到一组人类可读的单词。换句话说，你向你的网络展示一段音频剪辑，它就会转述这段音频的内容。我们让 RNN 检查一段语音，把它当作向量序列(代表声音字节)。然后，网络可以尝试预测这些声音字节在每个时间步长可能代表的英语单词:

![](Images/d74466a5-cfac-4d7a-b9d7-a03245b7de68.png)

考虑代表单词*的声音字节的向量集，今天是美好的一天*。一个循环层将在几个时间步骤中展开这个序列。在第一个时间步骤中，它将把代表序列中第一个单词的发声的向量作为输入(即今天的*)，计算与层权重的点积，并将该积通过非线性激活函数(通常对于 RNNs 为 tanh)来输出预测。这个预测对应的是网络认为听到的一个词。在第二时间步，递归层接收序列中的下一个声音字节(即，对于单词*是*)，以及来自第一时间步的激活值。然后，通过激活函数对这两个值进行压缩，以产生当前时间步长的预测。这基本上允许图层利用先前时间步长的信息来通知当前时间步长的预测。当循环层接收给定序列中的每个发声以及来自先前发声的激活值时，该过程被重复。该层可以为我们的字典中的每个单词计算 Softmax 概率分数，挑选具有最高值的一个作为给定层的输出。这个词对应的是我们的网络认为此时听到的。*

*        

# 临时共享重量

为什么临时连接激活很有用？正如我们之前指出的，每个单词都会影响下一个单词出现的概率分布。如果我们的句子以昨天的*这个词*开始，后面更有可能是*是*这个词，而不是*是*这个词，这反映了过去时态的使用。这种句法信息可以通过递归层传递，以通过使用网络在先前时间步骤中输出的内容来通知网络在每一步的预测。当我们的网络对给定的语音片段进行训练时，它将调整其层权重，通过(希望)学习这样的语法和句法规则等，来最小化它预测的内容和每个输出的真实值之间的差异。重要的是，重现层的权重在时间上是共享的，从而允许先前时间步长的激活对后续时间步长的预测产生影响。这样，我们不再孤立地对待每个预测，而是作为网络在先前时间步激活的函数，以及当前时间步的一些输入。

语音识别模型的实际工作流程可能比我们之前描述的要复杂一点，这涉及到数据标准化技术，如傅立叶变换，它让我们可以将音频信号分解为其组成频率。本质上，我们总是试图规范化我们的输入数据，目标是更好地向我们的神经网络表示数据，因为这有助于它更快地收敛，以编码有用的预测规则。从该示例中获得的关键信息是，递归图层可以利用更早的时态信息来通知其在当前时间步长的预测。随着本章的深入，我们将看到如何采用这些架构来建模不同长度的序列输入和输出数据。

        

# RNNs 中的序列建模变化

语音识别示例包括对同步的多对多序列进行建模，在该序列中，我们将许多发声集合预测为对应于这些发声的许多单词。我们可以使用类似的架构来完成视频字幕的任务，在这种情况下，我们希望按顺序标记视频的每一帧，其中包含主要对象。这是另一个同步的多对多序列，因为我们在每个时间步长输出一个对应于视频输入帧的预测。

        

# 编码多对多表示

在机器翻译的情况下，我们也可以有半同步的多对多序列。这个用例是半同步的，因为我们不会在每个时间步立即输出预测。相反，我们使用 RNN 的编码器部分来捕获整个短语，以便在我们继续并实际翻译它之前可以翻译它。这让我们可以在输出语言中找到更好的输入数据表示，而不是一次只翻译一个单词。后一种方法不是很健壮，并且经常导致不准确的翻译。在下面的例子中，一个 RNN 人翻译了法语短语 *C'est pas mal！*转化为英语中的对等术语，*真好！*，这是一个比直译准确得多的翻译，*还不错！*。因此，RNNs 可以帮助我们解读法语中用于补充人的特殊规则。这可能有助于避免一些误解:

![](Images/0dc153e8-dbf9-4326-8147-380991d5df01.png)        

# 多对一

类似地，您也可以有一个多对一的架构来处理任务，比如将组成一个句子的许多单词序列归属于一个相应的情感得分。这就像我们在之前的 IMDb 数据集练习中所做的一样。上一次，我们的方法包括将每个评论表示为一个无方向的单词袋。使用 RNNs，我们可以通过将评论建模为按正确顺序排列的单个单词的定向序列来解决这个问题，因此利用来自单词排列的空间信息来通知我们的情感得分。以下是用于情感分类的多对一 RNN 架构的简化示例:

![](Images/e5504705-2713-4b8a-bc3c-3854837869a7.png)        

# 一对多

最后，顺序任务的不同变化可能需要不同的架构。另一个常用的架构是一对多 RNN 模型，我们将它用于音乐生成或图像字幕的用例。对于音乐生成，我们主要是向网络输入一个输入音符，让它预测序列中的下一个音符，然后利用它自己的预测作为下一个时间步的输入:

![](Images/f8f6a4c0-d250-4103-9ede-c2ba360e3e4b.png)        

# 用于图像字幕的一对多

一对多架构的另一个新颖示例是通常用于图像字幕任务的架构。这是当我们向我们的网络展示一幅图像，并要求它用一个小标题来描述正在发生的事情。为了做到这一点，我们实际上是一次向我们的网络输入一幅图像，以输出与图像中正在发生的事情相对应的许多单词。通常，您可以在已经在一些实体(对象、动物、人等)上训练过的 CNN 的顶部堆叠一个递归层。这样做，您可以使用递归层将卷积网络的输出值一起输入，然后依次检查图像，输出与输入图像描述相对应的有意义的单词。这是一个更复杂的设置，我们将在后面的章节中详述。现在，知道 LSTM 网络(如下所示)是一种 RNN 是很有用的，它受到人类记忆结构的语义和情节划分的启发，并将成为第六章、*长短期记忆网络*中讨论的主要话题。在下图中，我们可以看到网络如何利用从 CNN 接收到的输出，发现有几只长颈鹿站在附近。

        

# 总结不同类型的序列处理任务

现在，我们已经熟悉了递归层的基本概念，并查看了一些具体的用例示例(来自语音识别、机器翻译和图像字幕),其中可能会使用这种依赖于时间的模型的变体。下图直观总结了我们讨论过的一些顺序任务，以及适合该工作的 RNN 类型:

![](Images/0bd4c08a-3dbf-4d48-9fb8-d7800c486b63.png)

接下来，我们将深入研究控制方程，以及 RNNs 背后的学习机制。

        

# RNNs 如何学习？

正如我们之前看到的，对于几乎所有的神经网络，你可以将学习机制分解成两个独立的部分。前向传播方程控制允许数据在我们的神经网络中向前传播的规则，一直到网络预测。误差的反向传播是由等式(如损失函数和优化器)定义的，它允许我们的模型的预测误差通过我们的模型的层向后移动，朝着正确的预测值调整每个层上的权重。

对于 rnn 来说，这基本上是相同的，但是考虑到依赖于时间的信息流，有一些架构上的变化。为此，RNNs 可以利用内部状态或*内存*，对有用的时间相关表示进行编码。首先，让我们来看看递归层中的数据向前传递。递归层基本上将进入该层的输入向量与状态向量相结合，以在每个时间步长产生新的输出向量。很快，我们将看到如何迭代更新这些状态向量，以保持给定序列中的时间相关信息。

        

# 通用 RNN 图层

下图有望让大家熟悉这个过程。在左侧，图表中的灰色箭头说明了当前时间步骤的激活是如何向前发送到未来时间步骤的。这适用于所有 rnn，形成其架构的独特特征。在右侧，您会注意到 RNN 单位的简化表示。这是你会在无数计算机科学研究论文中发现的 rnn 最常见的分界之一:

![](Images/30b9a91b-026c-4fe1-a6c4-93fa6eb8a63f.png)

要排序，还是不要排序？

RNN 层本质上以时间相关和顺序的方式处理其输入值。它采用了一种状态(或记忆)，允许我们以一种新的方式处理序列建模任务。然而，有相当多的例子表明，以顺序的方式处理非顺序数据使我们能够以更有效的方式处理标准用例。以 DeepMind 进行的关于引导网络对图像的注意力的研究为例。

DeepMind 的研究人员没有简单地将计算量很大的 CNN 应用于图像分类，而是展示了如何通过强化学习训练的 rnn 可以用来执行相同的功能，并在更复杂的任务中实现更好的准确性，例如对杂乱的图像进行分类，以及其他动态视觉控制问题。从他们的工作中获得的一个主要架构是，他们的 RNN 通过自适应地选择序列或区域来以高分辨率处理，从而有效地从图像或视频中提取信息，从而降低以高分辨率处理整个图像的冗余计算复杂性。这非常简洁，因为我们不需要处理图像的所有部分来执行分类。我们所需要的大部分内容通常都是围绕着问题图片的某个局部区域:[https://deep mind . com/research/publications/recurrent-models-visual-attention/](https://deepmind.com/research/publications/recurrent-models-visual-attention/)。

        

# 正向传播

那么，信息是如何在这个 RNN 建筑中流动的呢？让我们用一个演示性的例子来介绍 RNNs 中的前向传递操作。想象一下预测短语中的下一个单词的简单任务。假设我们的短语是:*生存还是毁灭*。当单词进入网络时，我们可以将每个时间步执行的计算分为两个概念类别。在下图中，您可以将每个箭头视为对一组给定的值执行计算(或点积运算):

![](Images/ecf33ff7-1e17-4e70-b5cd-a5c3983031d3.png)

我们可以看到，在一个循环单元中，当数据通过它传播时，计算同时发生在垂直方向和水平方向。请务必记住，图层的所有参数(或权重矩阵)都是暂时共享的，这意味着在每个时间步长都使用相同的参数进行计算。在第一个时间步，我们的层将使用这些参数集来计算两个输出值。其中一个是当前时间步长的图层激活值，而另一个表示当前时间步长的预测值。先说第一个。

        

# 计算每个时间步长的激活

下面的等式表示在时间 *t* 循环层的激活。术语 *g* 表示为循环层选择的非线性激活函数，通常是双曲正切函数。在括号内，我们发现正在执行两个矩阵级乘法，然后加上一个偏置项( *ba* ):

*at = g[(W^(ax)x x^t)+(魏如萱 x a(t-1)) + ba ]*

项( *W ^(ax)* )控制我们的输入向量![](Images/ebdcf4e7-33d9-4f4e-b3f1-6e2a1b117f3d.png)在时间 *t* 进入递归层时的变换。这个权重矩阵是暂时共享的，这意味着我们在每个时间步使用相同的权重矩阵。然后，我们得到了术语(*魏如萱*)，它指的是管理来自前一时间步的激活的时间共享权重矩阵。在第一时间步，(*魏如萱*)被随机初始化为非常小的值(或零)，因为我们实际上还没有任何激活权重要计算。这同样适用于值( *a < 0 >* )，该值也被初始化为一个归零向量。因此，在第一步，我们的方程看起来像这样:

*a1 = tanH [ (W ^(ax) x x1 ) +(魏如萱 x a(0)) + ba ]*

        

# 简化激活方程

我们可以通过将两个权重矩阵(Wax 和魏如萱)水平堆叠成单个矩阵(W [a] )来进一步简化这个等式，该矩阵定义了递归层的所有权重(或状态)。我们还将垂直堆叠代表来自前一时间步的激活( *a(t-1)* )和当前时间的输入(![](Images/d3b3e016-18de-4d98-be08-c5d9a8826797.png) t)的两个向量，以形成我们表示为*【a(t-1)】![](Images/45557d34-7a42-4cc5-b4ea-eb504c46f4eb.png)t】*的新矩阵。这使我们可以简化之前的激活，如下所示:

*at = tanH [ (W ![](Images/e76fecd2-fe5a-4716-a1da-048104147a2e.png) x ![](Images/b7d3a7c5-8985-4076-9db2-0ab3f5c850ca.png) t ) +(魏如萱 x a(t-1)) + ba ]或者 at = tanH (W ![](Images/5f597f64-f660-4896-be74-16289a777546.png) a(t-1)，![](Images/71373feb-6c48-4dcb-9caa-3bd3750e0dd8.png) t ] + ba )*

从概念上讲，由于两个矩阵的高度(W ![](Images/7ee6ef33-8386-4d3a-a8eb-31f499fa003f.png))保持不变，我们能够以我们所做的方式水平堆叠它们。输入(![](Images/22c27f03-9e5f-401d-80ba-870c948b2871.png) t)和激活向量( *a(t-1)* )的长度也是如此，当数据通过 RNN 传播时，它也保持不变。现在，计算步骤可以表示为权重矩阵(W [a] )乘以来自前一时间步骤的激活，以及来自当前时间步骤的输入，之后添加偏置项，并且整个项通过非线性激活函数。我们可以使用新的权重矩阵来直观显示这一过程随时间的发展，如下图所示:

![](Images/3e5e7f94-b73d-42bb-9ed6-7a9c089fb868.png)

本质上，使用时间共享的权重参数(如 *Wa* 和 *Wya* )允许我们利用序列中早期的信息来通知后续时间步的预测。现在，您知道了当数据流经递归层时，如何针对每个时间步长迭代计算激活。

        

# 预测每个时间步长的输出

接下来，我们将查看利用我们刚刚计算的激活值来产生预测的等式(![](Images/94bdb4d8-346d-4392-8547-4550156203ea.png)在给定的时间步长( *t* )。这是这样表示的:

*![](Images/c2da3b60-fd3d-41a0-b36f-2deb2800f3f5.png) = g [(道 x 处)+由]*

这告诉我们，我们的层在一个时间步长的预测是通过计算另一个时间共享的权重输出矩阵的点积来确定的，以及我们刚刚使用前面的等式计算的激活输出( *at* )。

由于权重参数的共享，来自先前时间步骤的信息被保留并通过递归层传递以通知当前预测。例如，时间步骤三的预测利用了来自先前时间步骤的信息，如这里的绿色箭头所示:

![](Images/020d9e3e-b7ad-4fed-b41b-db712bab664b.png)

为了使这些计算形式化，我们用数学方法显示了第三时间步的预测输出与之前时间步的激活之间的关系，如下所示:

*   *![](Images/c003db51-5aab-473c-9e57-5bea6611fa35.png) =乙状结肠[(道 x a3 * ) * +由* ]

其中 *a(3)* 定义如下:

*   *a3 =乙状结肠(W![](Images/49ef1f9f-c46d-4975-92fa-0cf0963c59d0.png)a(2)![](Images/da73e7b9-513b-4b84-a764-8c01ef19d543.png)**3】+ba)*

其中**(2)*定义如下:*

 **   *a2 =***(W**![](Images/89282f8e-619a-418d-9988-d949c010a5aa.png)a(1)![](Images/01d42088-c76b-475a-83bd-c1d6d5c4cfcf.png)**2】+ba)**

 *其中 *a(1)* 定义如下:

*   *a1 = sigmoid(W![](Images/3eca3c48-eacc-4485-8d76-da83a1a9fc8c.png)a(0)![](Images/23fc8ac4-b910-41d8-a11e-7dffeba43a8c.png)**1】+ba)*

最后， *a(0)* 通常被初始化为零向量。这里要理解的主要概念是，在向前传递激活之前，RNN 层通过许多时间步骤递归地处理序列。现在，您已经完全熟悉了在较高层次上控制 RNNs 中信息向前传播的所有方程。这种方法虽然在建模许多时间序列方面很强大，但也有其局限性。** **        

# 单向信息流的问题

一个主要的限制是，我们只能用以前时间步的激活值来通知我们在当前时间步的预测，而不能用未来时间步的激活值。我们为什么要这么做？好吧，考虑命名实体识别的问题，其中我们可以使用同步的多对多 RNN 来预测句子中的每个单词是否是命名实体(例如人名、地名、产品名等等)。我们可能会遇到一些问题，例如:

*   尽管障碍重重，斯巴达人还是继续前进。
*   这些人所面临的斯巴达式的生活方式是许多人无法想象的。

正如我们所看到的，只看前两个词，我们自己将无法分辨单词 Spartan 是指名词(因此是一个命名实体)还是指形容词。只是到了后来，当我们阅读句子的其余部分时，我们才能够给这个词加上正确的标签。同样，我们的网络将无法准确预测第一句话中的单词 Spartan 是一个命名实体，除非我们让它利用来自未来时间步骤的激活值。由于 RNNs 可以从带注释的数据集中学习顺序语法规则，因此它将能够了解到命名实体后面经常跟随动词(如游行)而不是名词(如生活方式)，因此将能够准确预测单词 *Spartan* 仅指第一句中的命名实体。这可以通过一种称为双向 RNN 的特殊类型的 RNN 来实现，我们将在本章后面讨论这一点。同样值得注意的是，一个带有词性标记(标记是指一个词是名词还是形容词等等)的带注释的数据集将极大地提高您的网络学习有用的顺序表示的能力，就像我们希望它在这里所做的那样。我们可以将两个句子的第一部分形象化，用词性标签标注，如下所示:

*   斯巴达人行进了...à:

![](Images/081b15e7-8f55-49de-a32e-235c6cfc7ff0.png)

*   斯巴达的生活方式...à:

![](Images/3b55564c-c0b7-40bf-af27-76eb9b8b0bf4.png)

这之前的单词序列比之前的单词为我们提供了更多关于当前单词的信息。我们将很快看到双向 RNNs 如何利用来自未来时间步和过去时间步的信息来计算当前时间的预测。

        

# 长期依赖的问题

简单递归层面临的另一个常见问题是它们在建模长期序列依赖性方面的弱点。为了澄清我们这样说的意思，考虑下面的例子，我们把这些例子一个字一个字地输入到 RNN 中，以预测接下来将要出现的单词:

*   这只猴子已经喜欢吃香蕉有一段时间了，它渴望吃更多的香蕉，
*   猴子们已经享受了一段时间的香蕉，并渴望得到更多。

为了在每个序列的第 11 个^(时间步长)预测单词，网络必须记住在时间步长 2 看到的句子(猴子)的主语是单数还是复数实体。然而，随着模型训练和误差随时间反向传播，与较早时间步长的权重相比，更接近当前时间步长的时间步长的权重受到更大程度的影响。从数学上讲，这是消失梯度的问题，它与我们的损失函数的基于链规则的偏导数的极小值相关联。我们的递归层中的权重，通常在每个时间步与这些偏导数成比例地更新，没有在正确的方向上足够地*推动*，阻止我们的网络进一步学习。以这种方式，模型不能更新层权重以反映来自较早时间步骤的长期语法依赖性，就像我们的示例中反映的那样。这是一个特别麻烦的问题，因为它会显著影响重现层中错误的反向传播。很快，我们将看到如何用更复杂的体系结构(如 GRU 和 LSTM 网络)来部分解决这个问题。先来了解一下 RNNs 中反向传播的过程，是这个过程催生了这个问题。

您可能很想知道 RNN 如何准确地反向传播其误差，以在经过一系列输入时调整图层的临时共享权重。这个过程甚至用一个有趣的名字来描述。与我们遇到的其他神经网络不同，我们知道 RNNS 可以随时进行反向传播。

        

# 穿越时间的反向传播

本质上，我们通过几个时间步骤反向传播我们的误差，反映了一个序列的长度。正如我们所知，我们需要能够反向传播误差的第一件事是损失函数。我们可以使用交叉熵损失的任何变化，这取决于我们是在执行每个序列的二元任务(即，实体与否，每个词±二元交叉熵)还是类别任务(即，我们的词汇表中词的类别之外的下一个词±类别交叉熵)。这里的损失函数计算在时间步长 *t* 的预测输出![](Images/6ebd4a7c-8d96-4cd2-9c2d-2fb746fb420d.png)和实际值 *(y)* 之间的交叉熵损失:

*![](Images/46ec09e1-ff3f-49fc-a4e7-4d2cab07b46a.png) ( ![](Images/aa137547-d065-4e5f-946c-fcb135fc277b.png) ![](Images/59cd5142-6f5b-4cb8-b930-f2cb8c7b63ae.png))日志![](Images/0f3b1dbe-0f85-4cfb-abdf-c011330710ed.png)-[(1-![](Images/15d6e47b-8878-42b1-b060-0af7fabf429c.png))*

该函数本质上让我们在循环层的每个时间步对每个预测和实际输出进行元素损失计算。因此，对于网络看到的每个单词(或序列)，我们在每次预测时都会生成一个损失值。然后，我们可以对每个损失值求和，以定义循环层的总损失，在 *ty* 个时间步上操作。因此，我们网络的总损耗可以表示为:

![](Images/eae7767c-e6d4-4719-94ee-5b37bb3d6eee.png)

使用我们的网络的总损耗的这种表示，我们可以在每个时间步长上相对于层权重来区分它，以计算模型的误差。我们可以通过参考我们的递归层图来可视化这个过程。箭头标明了误差随时间的反向传播。

        

# 通过时间可视化反向传播

在这里，我们反向传播我们的模型中关于每个时间步长的层权重的误差，并随着模型的训练调整权重矩阵， *Way* 和 *Wa* 。我们本质上仍在计算损失函数相对于所有网络参数的梯度，并在我们序列中的每个时间步长在相反方向上成比例地推动两个权重矩阵:

![](Images/ca8eeab8-a691-4bd8-baa3-eb46419af982.png)

现在，我们知道了 RNNs 是如何在一系列向量上过度反应，并利用时间相关的偶然性来通知每一步的预测的。

        

# 爆炸和消失渐变

然而，在深度神经网络中反向传播该模型的误差也有其自身的复杂性。这同样适用于 rnn，面对他们自己版本的消失和爆炸梯度问题。正如我们之前讨论的，给定时间步长中神经元的激活取决于以下等式:

*at = tanH [ (W ![](Images/49479bca-1721-40de-9026-bc9268c48c87.png) x ![](Images/3175fbaa-c555-4dde-8aa9-6641b48527ea.png) t ) +(魏如萱 x a(t-1)) + ba ]*

我们看到了如何*蜡*和*魏如萱*是两个独立的权重矩阵，RNN 层通过时间共享。这些矩阵分别乘以当前时间的输入矩阵和前一时间步的激活。然后将点积与偏置项相加，并通过双曲正切激活函数来计算当前时间的神经元激活( *t* )。然后，在将激活传递到下一个时间步骤之前，我们使用该激活矩阵计算当前时间(![](Images/0d6d9ba5-a6ca-4868-b7fc-5db15a607871.png))的预测输出:

*![](Images/fcfd4173-60dc-4147-ad63-3e8ba6eaf87c.png) = softmax [(方式 x at) + by ]*

因此，权重矩阵( *Wax* 、*魏如萱*和 *Way* )表示给定层的可训练参数。在随时间反向传播的过程中，我们首先计算梯度的乘积，它代表每个时间步长的层权重相对于预测和实际输出的变化。然后，我们使用这些乘积在变化的相反方向上更新各自的层权重。然而，当跨越多个时间步长反向传播时，这些乘积可能变得极小(因此不会显著改变层权重)，或者变得非常大(因此超过理想权重)。这对于激活矩阵(*魏如萱*)来说基本上是正确的。它代表我们的 RNN 层的记忆，因为它编码了来自先前时间步骤的时间相关信息。让我们用一个概念性的例子来阐明这个概念，看看在处理长序列时，如何在更早的时间步骤更新激活矩阵变得越来越困难。例如，假设您想要计算第三个时间步骤中损失相对于图层权重的梯度。

        

# 关于梯度层次的思考

给定时间步长的激活矩阵是来自前一时间步长的激活矩阵的函数。因此，我们被迫将时间步骤三的损失递归定义为来自先前时间步骤的层权重的子梯度的乘积:

![](Images/3fa444c5-b97f-42f8-ae0d-3746cb3a7c0e.png)

这里，( *L* )表示损失，( *W* )表示时间步长的权重矩阵， *x* 值是给定时间步长的输入。从数学上讲，这相当于以下内容:

![](Images/90b4c49d-fe88-4e31-841d-4879da3ea31b.png)

这些函数的导数存储在雅可比矩阵中，表示权重和损失向量的逐点导数。从数学上讲，这些函数的导数受绝对值 1 的限制。然而，小导数值(接近于 0)在矩阵乘法的几个时间步长上呈指数下降，几乎为零，这反过来又阻止了模型收敛。这同样适用于激活矩阵中的大值(大于 1)，其中梯度将变得越来越大，直到它们被归属于 NaN 值(不是数字)，突然终止训练过程。我们如何解决这些问题？

有关消失渐变的更多信息，请访问:[http://www . wild ml . com/2015/10/recurrent-neural-networks-tutorial-part-3-back propagation-through-time-and-vanishing-gradients/](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/)。

        

# 通过剪辑防止渐变爆炸

在爆炸梯度的情况下，这个问题更加明显。您的模型简单地停止训练，返回 NaN 的值误差，对应于分解的梯度值。一个简单的解决方案是通过定义一个任意的上限或阈值来裁剪你的渐变，以防止渐变变得太大。Keras 让我们可以轻松地实现这一点，因为您可以通过手动启动优化器并向其传递一个`clipvalue`或`clipnorm`参数来定义该阈值，如下所示:

![](Images/43b2da26-4987-453f-a13e-2fe6ee04da70.png)

然后，在编译模型时，可以将`optimizers`变量传递给模型。在标题为:*关于训练循环神经网络的困难*的论文中，广泛讨论了这种剪切梯度的想法，以及与训练 rnn 相关的其他问题，该论文可在[http://proceedings.mlr.press/v28/pascanu13.pdf](http://proceedings.mlr.press/v28/pascanu13.pdf)获得。

        

# 用记忆防止渐变消失

在消失梯度的情况下，我们的网络停止学习任何新的东西，因为权重在每次更新时都被轻微推动。对于 rnn 的情况，这个问题尤其麻烦，因为它们试图在潜在的许多时间步长上对长序列建模，因此该模型很难反向传播误差以微调较早时间步长的层权重。我们看到了这是如何影响语言建模任务的，比如学习语法规则和基于实体的依赖(以猴子为例)。幸运的是，已经设计了几种解决方案来解决这个问题。一些人已经冒险沿着激活矩阵*魏如萱*的小心初始化的路线，使用 ReLU 激活函数以无监督的方式预训练层权重。然而，更常见的是，其他人通过设计更复杂的架构来解决这个问题，这些架构能够基于其与序列中当前事件的统计相关性来存储长期信息。这本质上是更复杂的 RNN 变异背后的基本直觉，例如**门控循环单元** ( **GRUs** )和**长短期记忆** ( **LSTM** )网络。让我们看看 GRUs 如何解决长期依赖的问题。

        

# 天鹤座

GRU 可以被认为是 LSTM 的弟弟妹妹，我们将在第六章、*中看到[和](62bc2e63-11f3-43ab-a3ae-967c6603c306.xhtml)*。本质上，两者都利用相似的概念来模拟长期依存关系，例如在生成后续序列时记住句子的主语是否是复数。很快，我们将看到如何使用存储单元和流门来解决梯度消失问题，同时更好地模拟序列数据中的长期相关性。GRUs 和 LSTMs 之间的根本区别在于它们所代表的计算复杂度。简而言之，LSTMs 是更复杂的架构，虽然训练时计算昂贵且耗时，但在将训练数据分解成有意义且可概括的表示方面表现非常好。另一方面，GRUs 虽然计算量较小，但与 LSTM 相比，它们的表示能力有限。然而，并不是所有的任务都需要庞大的 10 层 LSTMs(就像 Siri、Cortana、Alexia 等使用的那些)。正如我们将很快看到的，字符级语言建模可以从非常简单的架构开始，使用相对轻量级的模型(如 GRUs)产生越来越有趣的结果。下图显示了到目前为止我们所讨论的 SimpleRNN 和 GRU 之间的基本架构差异。

        

# 该存储单元

同样，我们有两个输入值进入该单元，即当前时间的序列输入和来自先前时间步骤的层激活。GRU 的主要区别之一是增加了一个记忆单元( *c* )，它让我们在给定的时间步长存储一些相关信息，以便为以后的预测提供信息。实际上，这改变了我们在 GRUs 中计算给定时间步长(*c^t，这里与 *a ^t* )的激活的方式:*

![](Images/5d45b808-83ca-40ac-ba99-bb81fc3b79b4.png)

回到猴子的例子，单词级 GRU 模型有可能更好地表示这里给出的第二个句子中有几个实体的事实，因此会记得使用单词 **were** 而不是 **was** 来完成序列:

![](Images/3adae2d4-7633-4586-9ad5-15cc5dd89532.png)

这个记忆细胞实际上是如何工作的？嗯，( *c ^t* )的值存储给定时间步长(时间步长 2)的激活值( *a ^t* )，并且如果认为与手头的序列相关，则向前传递到后续时间步长。一旦该激活的相关性丢失(即，在序列中检测到新的相关性)，存储单元可以用新的值( *c ^t* )更新，反映可能更相关的时间相关信息:

![](Images/a4f4ffc2-9b3f-44df-ab6c-1fe7306206bf.png)

近距离观察 GRU 细胞

        

# 代表存储单元

当处理我们的示例句子时，单词级 RNN 模型可以存储时间步骤 2 的激活(对于单词*猴子*和*猴子*，并且保存它直到时间步骤 11，在时间步骤 11，它被用于分别预测输出单词*是*和*是*。在每个时间步，产生一个竞争值( *c ^(̴t)* )，它试图替换存储单元的值( *c ^t* )。然而，只要( *c ^t* )保持与序列的统计相关性，它就是保守的，只是在以后为了更相关的表示而被丢弃。让我们看看这在数学上是如何实现的，从竞争者的值开始，( *c ^(̴t)* )。为了实现这个参数，我们将初始化一个新的权重矩阵，( *Wc* )。然后，我们将计算( *Wc* )与先前激活( *c ^(t-1)* )和当前时间(![](Images/005b1e37-203a-4ae1-b717-95d0ed56f958.png) t)的输入的点积，并将结果向量通过非线性激活函数(如 tanh)传递。这个操作与我们之前看到的标准正向传播操作惊人地相似。

        

# 更新存储值

在数学上，我们可以将这种计算表示如下:

*c^(̴t)= tanh(WC[c^(t-1)，![](Images/d30f337b-9a65-4151-82d8-203b210d2aee.png)t】+BC)*

更重要的是，GRU 还实现了一个由希腊字母 gamma(γu)表示的门，它主要通过另一个非线性函数计算输入和先前激活的点积:

*γu =乙状结肠(吴【c ^(t-1) ，![](Images/8d63a839-9c80-49b7-80cf-5789501a6bb9.png)t】+卜)*

这个门的目的是确定我们是否应该用一个候选值( *c ^(̴t)* )来更新我们的当前值( *c ^t* )。门(γu)的值可以认为是一个二进制值。在实践中，我们知道，sigmoid 激活函数的挤压值在 0 和 1 之间。事实上，进入 sigmoid 激活函数的绝大多数输入值将以 0 或 1 的形式出现，因此实际上可以将伽马变量视为一个二进制值，它决定是否在每个时间步用( *c ^(̴t)* )替换( *c ^t* ):

![](Images/68fa8246-5c30-4b86-ab85-939a6ff30292.png)        

# 更新方程的数学

让我们看看这在实践中是如何实现的。我们将再次使用我们之前的例子，这个例子在这里已经被扩展到从理论上证明一个世界级的 GRU 模型何时可以工作:

这只猴子已经喜欢吃香蕉有一段时间了，并且渴望吃更多。香蕉本身是在岛的这一边能找到的最好的...

当 GRU 层遍历该序列时，它可以将第二时间步的激活值存储为(c ^t ，检测单个实体(即*猴子*)的存在。它将继续这种表示，直到它达到序列中的新概念(*香蕉*)，此时更新门(γu)将允许新的候选激活值(c ̴t)替换存储单元(c)中的旧值，反映新的复数实体*香蕉*。从数学上讲，我们可以通过定义如何在 GRU 中计算激活值(ct)来将所有这些联系起来:

*CT =(γu x c ̴t)+[(1-γu)x CT-1]*

正如我们在这里看到的，给定时间步长的激活值由两项之和定义。第一项反映了门值和候选值的乘积。第二项表示门值的倒数，乘以前一时间步的激活。直观上，第一项简单地控制是否让更新项被包括在等式中，是 1 还是 0。第二项控制前一时间步(ct-1)激活的潜在中和。让我们看看这两个术语是如何共同决定是否在给定的时间步长执行更新的。

        

# 实施无更新方案

在值(γu)为零的情况下，第一项完全降为零，消除了(c ̴t)的影响，而第二项仅取前一时间步的激活值:

```py
If Γu = 0:
ct = ( 0 x c ̴t ) + ((1 - 0) x ct-1 )
   = 0 + ct-1
Therefore, ct = ct-1
```

在这种情况下，不执行任何更新，之前的激活(`ct`)被保留，并向前传递到下一个时间步骤。

        

# 实现更新场景

另一方面，如果门保持一个`1`，该等式允许 c ̴t 成为`ct`的新值，因为第二项减少到零`(( 1-1) x ct-1)`。这使得我们能够有效地对存储单元进行更新，从而保存有用的时间相关表示。更新场景在数学上可以表示为:

```py
If Γu = 1:
ct = ( 1 x c ̴t ) + ((1 - 1) x ct-1 )
   = c ̴t+ (0 x ct-1)
Therefore, ct = c ̴t
```

        

# 保持时间步长之间的相关性

用于执行内存更新的两个术语的性质有助于我们跨多个时间步长保存相关信息。因此，这种实施方式通过对使用存储单元的长期依赖性进行建模，潜在地提供了消失梯度问题的解决方案。然而，你可能想知道，GRU 到底是如何评估激活的相关性的？更新门只是允许用新的候选向量(*c^t)替换激活向量( *c ^(̴t)* )，但是我们如何知道先前的激活( *c ^(t-1)* )与当前时间步有多相关呢？之前，我们提出了一个控制 GRU 单位的简化方程。它的最后一个实现是关联门(γr ),它帮助我们做它所建议的事情。因此，我们使用这个相关性门(γr)来计算候选值( *c ^(̴t)* )，以合并从先前时间步(*c*^(**t*-1*))到当前时间步( *c ^t* )的激活值的相关性。这有助于我们评估先前时间步骤中的激活与当前输入序列的相关性，并以非常熟悉的方式实施，如下图所示:*

![](Images/88c3f787-2091-4af8-8fb0-f1baebc84124.png)        

# 形式化关联门

下面的等式显示了 GRU 等式的全部范围，包括相关门项，其现在被包括在我们早先执行的计算中以获得竞争者记忆值(c ̴t):

*   **早先** : *c ̴t = tanh ( Wc [ ct-1，![](Images/1666159b-52ff-45a0-a1d6-2ed0792818e5.png) t ] + bc)*
*   **现在**:*c ̴t = tanh(WC[γr，ct-1，![](Images/8a195fb9-f845-4c0c-b258-dbe27c76fcac.png) t ] + bc)*
*   **其中**:*γr = sigmoid(Wr[CT-1，![](Images/8b555231-db98-4e95-926a-b4ed29399edf.png) t ] + br)*

毫不奇怪，(γr)是通过初始化另一个权重矩阵( *Wr* )并计算其与过去激活( *c ^(t-1)* )和当前输入(![](Images/288f2225-c922-4231-9fb6-8a3474d237fa.png) t)的点积来计算的，然后通过 sigmoid 激活函数对它们求和。计算当前激活的等式( *c ^( t )* )保持不变，除了其中的( *c ^( ̴t )* )项，它现在将关联门(γr)合并到其计算中:

*CT =(γu x c ̴t)+[(1-γu)x CT-1]*

给定时间步长的预测输出以与 SimpleRNN 层相同的方式计算。唯一的区别是术语( *a ^t* )被术语( *c ^t* )代替，其表示在时间步长(*t*)GRU 层中神经元的激活:

*![](Images/f0e96174-8b99-4ab8-8570-59e838271286.png)= soft max[(Wcy x CT)+by]*

实际上，这两个术语(*a^t 和 *c ^t* )在 GRUs 的情况下可以被认为是同义的，但是我们稍后将看到这不再适用的架构，例如在 LSTMs 中。目前，我们已经讨论了在 GRU 单位中控制数据向前传播的基本方程。您已经看到了我们如何计算每个时间步的激活和输出值，并使用不同的门(如更新和相关性门)来控制信息流，从而允许我们评估和存储长期依赖关系。我们在这里看到的是一个非常常见的解决渐变消失问题的实现。然而，这只是潜在的许多问题中的一个。自从 Kyunghyun Cho 等人在 2014 年引入这种特定的公式化实现以来，研究人员发现这种特定的公式化实现是衡量相关性和为一系列不同问题建模的成功方式。*

        

# 在 Keras 中构建字符级语言模型

现在，我们已经很好地掌握了不同类型的 rnn 的基本学习机制，包括简单的和复杂的。我们还知道一些不同的序列处理用例，以及允许我们对这些序列建模的不同 RNN 架构。让我们将所有这些知识结合起来并加以利用。接下来，我们将在实际操作任务中测试这些不同的模型，看看每个模型的表现如何。

我们将探索构建字符级语言模型的简单用例，非常类似于几乎每个人都熟悉的自动更正模型，它在几乎所有设备的字处理器应用上实现。一个关键的不同是，我们将训练我们的 RNN 从莎士比亚的《哈姆雷特》中推导出一个语言模型。因此，我们的网络将从莎士比亚的*哈姆雷特*中获取一系列字符作为输入，并迭代计算序列中下一个字符的概率分布。让我们进行一些导入并装入必要的包:

```py
from __future__ import print_function
import sys
import numpy as np
import re
import random
import pickle

from nltk.corpus import gutenberg

from keras.models import Sequential
from keras.layers import Dense, Bidirectional, Dropout
from keras.layers import SimpleRNN, GRU, BatchNormalization

from keras.callbacks import LambdaCallback
from keras.callbacks import ModelCheckpoint
from keras.utils.data_utils import get_file
from keras.utils.data_utils import get_file
```

        

# 装载莎士比亚的哈姆雷特

我们将使用 Python 中的**自然语言工具包** ( **NLTK** )包对该剧进行导入和预处理，可以在`gutenberg`语料库中找到:

```py
from nltk.corpus import gutenberg
hamlet = gutenberg.words('shakespeare-hamlet.txt')
text =''
for word in hamlet:            # For each word
text+=str(word).lower()        # Convert to lower case and add to string variable
text+= ' '                     # Add space   
print('Corpus length, Hamlet only:', len(text))

-----------------------------------------------------------------------
Output:
Corpus length, Hamlet only: 166765

```

字符串变量(`text`)包含了构成戏剧《哈姆雷特》的整个字符序列。我们现在将把它分解成更短的序列，我们可以在连续的时间步骤中馈送给我们的循环网络。为了伪造输入序列，我们将定义网络在每个时间步看到的任意长度的字符。我们将从文本字符串中对这些字符进行采样，通过迭代滑动它们并收集字符序列(表示我们的训练特征)，以及给定序列的下一个字符(作为我们的训练标签)。自然地，在更长的序列上采样允许网络计算更精确的概率分布，因此反映了随后字符的上下文信息。然而，其结果是，无论是训练模型还是在测试期间生成预测，这在计算上也更加密集。

我们的每个输入序列(`x`)对应 40 个字符，一个输出字符(`y1`)对应序列中的下一个字符。我们可以创建每行 11 个字符的数据结构，方法是使用 range 函数一次按段跨越整个字符串(文本)的字符，并将它们保存在一个列表中，如下所示。我们可以看到，我们已经把整部剧分成了大约 55，575 个角色序列。

        

# 建立一个字符字典

现在，我们将继续创建一个词汇表或字符字典，用于将每个字符映射到一个特定的整数。这是我们能够将这些整数表示为向量的必要步骤，我们可以在每个时间步将这些向量顺序输入到我们的网络中。我们将创建两个版本的字典:一个将字符映射到索引，另一个将索引映射到字符。

这只是为了实用起见，因为我们需要两个列表作为参考:

```py
characters = sorted(list(set(text)))
print('Total characters:', len(characters))
char_indices = dict((l, i) for i, l in enumerate(characters))
indices_char = dict((i, l) for i, l in enumerate(characters))
-----------------------------------------------------------------------
Output:
Total characters= 65
```

你总是可以通过检查映射字典的长度来检查你的词汇量有多大。在我们的例子中，似乎我们有`66`独特的人物，它们组成了构成戏剧《哈姆雷特》的序列。

        

# 准备字符的训练序列

在构建了我们的字符字典之后，我们将把组成 Hamlet 的文本分解成一组可以输入到我们的网络中的序列，每个序列有一个相应的输出字符:

```py
'''
Break text into :
Features  -    Character-level sequences of fixed length        
Labels    -    The next character in sequence     
'''
training_sequences = []          # Empty list to collect each sequence

next_chars = []                  # Empty list to collect next character in sequence

seq_len, stride = 35, 1    # Define lenth of each input sequence & stride to move before sampling next sequence

for i in range(0, len(text) - seq_len, stride):     # Loop over text with window of 35 characters, moving 1 stride at a time

training_sequences.append(text[i: i + seq_len]) # Append sequences to traning_sequences

next_chars.append(text[i + seq_len])            # Append following character in sequence to next_chars
```

我们创建了两个列表，循环遍历文本字符串，一次添加 40 个字符的序列。一个列表保存训练序列，而另一个保存序列的 40 个字符之后的下一个字符。我们实现了一个长度为 40 的任意序列，但是您可以随意试验。请记住，设置过小的序列将无法让您的网络回顾足够远的时间来提供预测信息，而设置过大的序列可能会使您的网络难以收敛，因为它将无法找到最有效的表示。就像金发姑娘和三只熊的故事一样，你的目标是通过实验和/或领域知识获得一个*恰到好处*的序列长度。

        

# 打印出示例序列

类似地，我们也任意选择一次一个字符的窗口来遍历我们的文本文件。这意味着我们有可能对每个字符进行多次采样，就像我们的卷积滤波器以固定步长对整个图像进行渐进采样一样:

```py
# Print out sequences and labels to verify

print('Number of sequences:', len(training_sequences))
print('First sequences:', training_sequences[:1])
print('Next characters in sequence:', next_chars[:1])
print('Second sequences:', training_sequences[1:2])
print('Next characters in sequence:', next_chars[1:2])
-----------------------------------------------------------------------
Output 
Number of sequences: 166730
First sequences: ['[ the tragedie of hamlet by william']
Next characters in sequence: [' ']
Second sequences: [' the tragedie of hamlet by william ']
Next characters in sequence: ['s']
```

这里的区别是，我们将它顺序嵌入到训练数据本身中，而不是让一个层在训练时执行跨越操作。对于文本数据来说，这是一种更简单(也更符合逻辑)的方法，可以很容易地从我们的整个哈姆雷特文本中以期望的步幅产生字符序列。正如我们所看到的，我们的每个列表现在都存储了字符串序列，这些字符串是从原始文本字符串中以三个步长采样的。我们打印出了我们的训练数据的第一和第二序列和标签，这证明了其排列的顺序性质。

        

# 向量化训练数据

下一步是你已经非常熟悉的一步。我们将通过将我们的训练序列列表转换成三维张量来简单地对我们的数据进行矢量化，该三维张量用它们相应的标签(即，序列中出现的下一个单词)来表示独热编码的训练特征。特征矩阵的维数可以表示为(*时间步长 x 序列长度 x 字符数*)。在我们的例子中，这相当于 55，575 个序列，每个长度为 40。因此，我们的张量将由 55，575 个矩阵组成，每个矩阵都有`66`维的`40`个向量，彼此堆叠在一起。这里，每个向量代表 40 个字符序列中的一个字符。它有 66 个维度，因为我们将每个字符作为一个零向量进行了一次热编码，在字典中该字符的索引位置有`1`:

```py
#Create a Matrix of zeros
# With dimensions : (training sequences, length of each sequence, total unique characters)
x = np.zeros((len(training_sequences), seq_len, len(characters)), dtype=np.bool)
y = np.zeros((len(training_sequences), len(characters)), dtype=np.bool)
for index, sequence in enumerate(training_sequences):     #Iterate over training sequences
for sub_index, chars in enumerate(sequence):          #Iterate over characters per sequence
x[index, sub_index, char_indices[chars]] = 1      #Update character position in feature matrix to 1
y[index, char_indices[next_chars[index]]] = 1         #Update character position in label matrix to 1
print('Data vectorization completed.')
print('Feature vectors shape', x.shape)
print('Label vectors shape', y.shape)

-----------------------------------------------------------------------
Data vectorization completed. 
Feature vectors shape (166730, 35, 43) 
Label vectors shape (166730, 43)

```

        

# 角色建模统计

我们经常把单词和数字区分为不同的领域。碰巧的是，他们相距不远。一切都可以用数学的通用语言来解构。这是我们现实中非常幸运的特性，不仅仅是为了对字符序列的统计分布建模的乐趣。然而，既然我们在这个主题上，我们将继续定义语言模型的概念。本质上，语言模型遵循贝叶斯逻辑，该逻辑将后验事件(或即将到来的标记)的概率与先前事件(即将到来的标记)的函数联系起来。利用这样的假设，我们能够构建对应于一段时间内单词的统计分布的特征空间。我们即将构建的 rnn 将各自构建一个独特的概率分布特征空间。然后，我们可以给它输入一个字符序列，并使用分配方案递归地生成下一个字符。

        

# 建模字符级概率

在**自然语言处理** ( **NLP** )中，字符串的单位被表示为令牌。根据您希望如何预处理字符串数据，您可以使用单词标记或字符标记。出于本示例的目的，我们将使用字符标记，因为我们的训练数据设置为使我们的网络一次预测一个字符。因此，给定一个字符序列，我们的网络将为我们的字符词汇表中的每个字符输出一个 Softmax 概率分数。在我们的例子中，我们最初在莎士比亚的《哈姆雷特》中总共有 66 个角色。其中包括大写字母和小写字母，这对手头的任务来说是非常多余的。因此，为了提高我们的效率并跟踪更少的 Softmax 分数，我们将通过将 Hamlet 文本转换为小写来减少我们的训练词汇，只剩下 44 个字符。这意味着，在每次网络预测时，它将生成 44 路 Softmax 输出。我们可以将得分最高的字符(即进行一些贪婪采样)添加到输入序列中，然后询问我们的网络它认为接下来应该是什么。rnn 能够学习英语单词的一般结构，以及标点和语法规则，甚至有发明新序列的天赋，从听起来很酷的名字到可能挽救生命的分子化合物，取决于你决定给它什么序列。事实上，RNNs 已经被证明可以捕捉分子表达的语法，并且可以被微调以产生特定的分子目标。这在药物发现等任务中对研究人员有很大帮助，是科学研究的一个活跃领域。如需进一步阅读，请查看以下链接:

[https://www.ncbi.nlm.nih.gov/pubmed/29095571](https://www.ncbi.nlm.nih.gov/pubmed/29095571)

        

# 采样阈值

为了能够生成类似莎士比亚的句子序列，我们需要设计一种习惯来采样我们的概率分布。这些概率分布由我们的模型的权重表示，并且在训练过程中在连续的时间步骤中不断变化。采样这些分布类似于在每个训练期结束时窥视网络对莎士比亚文本的想法。我们本质上是使用我们的模型已经学习的概率分布来生成字符序列。此外，根据我们选择的采样策略，我们可能会在生成的文本中引入一些受控的随机性，以迫使我们的模型产生一些新的序列。这可以产生有趣的公式，并且在实践中相当有趣。

        

# 控制随机性的目的

抽样背后的主要概念是，在从可能出现的字符的概率分布中选择下一个字符时，如何选择控制随机性(或随机性)。不同的应用可能需要不同的方法。

        

# 贪婪抽样

如果你正试图训练一个自动文本完成和纠正的 RNN，你可能会更好地采用贪婪的采样策略。这只是意味着，在每个采样步骤中，您将根据 Softmax 输出的最高概率分布选择序列中的下一个字符。这确保了您的网络将输出可能与您最常用的单词相对应的预测。另一方面，当训练 RNN 产生酷名字、特定人风格的笔迹，甚至产生未发现的分子化合物时，你可能想尝试更分层的方法。在这种情况下，你不会想选择最有可能出现的角色，因为这太无聊了。相反，我们可以通过以概率的方式而不是固定的方式挑选下一个字符来引入一些受控的随机性(或随机性)。

        

# 随机采样

一种方法可以是，在给定的时间步长，重新加权这些输出值的概率分布，而不是简单地基于 Softmax 输出值选择下一个字符。这让我们可以做一些事情，比如为我们词汇表中接下来要选择的任何字符分配一个比例概率分数。例如，假设一个给定的字符有 0.25 的分配概率成为序列中的下一个字符。然后我们将从四次中选择一次作为下一个字符。以这种方式，我们能够系统地引入一点随机性，这产生了创造性的和现实的，尽管是人工的单词和序列。正如我们将在后面的章节中看到的那样，在生成建模领域中，通过引入随机性来进行试验通常可以提供有用的信息。现在，我们将通过引入采样阈值在我们的采样策略中实现随机性的受控引入，这让我们可以重新分配我们的模型的 Softmax 预测概率，[https://arxiv.org/pdf/1308.0850.pdf](https://arxiv.org/pdf/1308.0850.pdf):

```py
def sample(softmax_predictions, sample_threshold=1.0):   
softmax_preds = np.asarray(softmax_predictions).astype('float64')    
# Make array of predictions, convert to float

log_preds = np.log(softmax_preds) / sample_threshold                 
# Log normalize and divide by threshold

exp_preds = np.exp(log_preds)                                        
# Compute exponents of log normalized terms

norm_preds = exp_preds / np.sum(exp_preds)                           
# Normalize predictions

prob = np.random.multinomial(1, norm_preds, 1)                       
# Draw sample from multinomial distribution

return np.argmax(prob)                                               #Return max value
```

这个阈值表示我们将使用的概率分布的熵，以从我们的模型中对给定的一代进行采样。更高的阈值将对应于更高的熵分布，导致看起来不真实和更少结构化的序列。另一方面，较低的阈值将简单地编码英语语言表示和词法，生成熟悉的单词和术语。

        

# 测试不同的 RNN 模型

既然我们已经预处理了训练数据，并准备好了张量格式，我们可以尝试一种与前几章稍有不同的方法。通常，我们会先建立一个模型，然后再训练它。相反，我们将构建几个模型，每个模型反映不同的 RNN 架构，并连续训练它们，以观察它们在生成字符级序列的任务中的表现。本质上，这些模型中的每一个都将利用不同的学习机制，并根据它看到的字符序列归纳出合适的语言模型。然后，我们可以对每个网络学习的语言模型进行采样。事实上，我们甚至可以在训练时段之间对我们的网络进行采样，以查看我们的网络在每个时段的水平上如何生成莎士比亚短语。在我们继续构建我们的网络之前，我们必须回顾一些基本的策略，以告知我们的语言建模和采样任务。然后，我们将构建一些 Keras 回调，让我们在模型训练时与它交互并对其进行采样。

        

# 使用自定义回调生成文本

接下来，我们将构建一个定制的 Keras 回调函数，它将允许我们使用刚刚构建的示例函数，在每个训练时段结束时迭代地探测我们的模型。正如您所记得的，回调是一类函数，它允许在训练过程中对我们的模型执行操作(比如保存和测试)。这些都是非常有用的功能，可以直观地显示模型在整个训练过程中的表现。本质上，这个函数将从 Hamlet 文本中随机提取一个字符序列，然后从给定的输入开始生成 400 个字符。它为所选的五个采样阈值中的每一个执行此操作，并在每个时期结束时打印出生成的结果:

```py
def on_epoch_end(epoch, _):
global model, model_name
print('----- Generating text after Epoch: %d' % epoch)
start_index = random.randint(0, len(text) - seq_len - 1)    
# Random index position to start sample input sequence
end_index = start_index + seq_len                           
# End of sequence, corresponding to training sequence length
sampling_range = [0.3, 0.5, 0.7, 1.0, 1.2]                  
# Sampling entropy threshold
for threshold in sampling_range:print('----- *Sampling Threshold* :', threshold)
generated = ''                                          
# Empty string to collect sequence
sentence = text[start_index: end_index]                 
# Random input sequence taken from Hamlet
generated += sentence                                  
 # Add input sentence to generated
print('Input sequence to generate from : "' + sentence + '"')     
sys.stdout.write(generated)                            
# Print out buffer instead of waiting till the end
for i in range(400):                                   
# Generate 400 next characters in the sequence
x_pred = np.zeros((1, seq_len, len(characters)))   
# Matrix of zeros for input sentence
for n, char in enumerate(sentence):                
# For character in sentence
x_pred[0, n, char_indices[char]] = 1\.          
# Change index position for character to 1.
preds = model.predict(x_pred, verbose=0)[0]        
# Make prediction on input vector
next_index = sample(preds, threshold)              
# Get index position of next character using sample function
next_char = indices_char[next_index]               
# Get next character using index
generated += next_char                             
# Add generated character to sequence
sentence = sentence[1:] + next_char
sys.stdout.write(next_char)
sys.stdout.flush()
-----------------------------------------------------------------------
Output: 
print_callback = LambdaCallback(on_epoch_end=on_epoch_end)
```

        

# 测试多个模型

列表中的最后一个任务是构建一个助手函数，它将训练、采样和保存一个 RNN 模型列表。此函数还保存我们之前用于绘制每个历元的损失和精度值的模型的历史对象，这在您想要在以后探索不同的模型及其相对性能时非常有用:

```py
def test_models(list, epochs=10):
    global model, model_name

    for network in list:   
        print('Initiating compilation...')

        # Initialize model
        model = network()
        # Get model name
        model_name = re.split(' ', str(network))[1]  

        #Filepath to save model with name, epoch and loss 
        filepath = "C:/Users/npurk/Desktop/Ch5RNN/all_models/versions/%s_epoch-{epoch:02d}-loss-{loss:.4f}.h5"%model_name

        #Checkpoint callback object 
        checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')

        # Compile model
        model.compile(loss='categorical_crossentropy', optimizer='adam')
        print('Compiled:', str(model_name))

        # Initiate training
        network = model.fit(x, y,
              batch_size=100,
              epochs=epochs,
              callbacks=[print_callback, checkpoint])

        # Print model configuration
        model.summary()

        #Save model history object for later analysis
        with open('C:/Users/npurk/Desktop/Ch5RNN/all_models/history/%s.pkl'%model_name, 'wb') as file_pi:
            pickle.dump(network.history, file_pi)

test_models(all_models, epochs=5)
```

现在，我们终于可以着手构建几种类型的 rnn，并用 helper 函数训练它们，看看不同类型的 rnn 在生成类似莎士比亚的文本方面表现如何。

        

# 构建一个简单的

Keras 中的 SimpleRNN 模型是一个基本的 RNN 层，就像我们前面讨论的那些。虽然它有许多参数，但大多数都有很好的默认值，可以让您适应许多不同的用例。由于我们已经将 RNN 层初始化为模型的第一层，因此我们必须向其传递一个输入形状，该形状对应于每个序列的长度(之前我们选择为 40 个字符)和数据集中唯一字符的数量(44)。虽然这个模型在计算上运行起来很紧凑，但它严重受到我们所说的消失梯度问题的困扰。因此，它在建模长期依赖关系时遇到了一些麻烦:

```py
from keras.models import Sequential
from keras.layers import Dense, Bidirectional, Dropout
from keras.layers import SimpleRNN, GRU, BatchNormalization
from keras.optimizers import RMSprop
'''Fun part: Construct a bunch of functions returning different kinds of RNNs, from simple to more complex'''
def SimpleRNN_stacked_model():
    model = Sequential()
    model.add(SimpleRNN(128, input_shape=(seq_len, len(characters)), return_sequences=True))
    model.add(SimpleRNN(128))
    model.add(Dense(len(characters), activation='softmax'))
    return model
```

请注意，这个两层模型有一个最终的密集层，其中有许多神经元对应于我们数据集中 44 个独特字符中的每一个。我们给它配备了一个 Softmax 激活功能，它会在每个时间步输出一个 44 向概率得分，对应每个角色跟随的可能性。我们为这个实验建立的所有模型都有这个最终的致密层。最后，所有 rnn 都有能力保持状态。这只是指传递层权重，用于对我们的训练数据的后续序列进行计算。可以在所有 rnn 中使用`stateful`参数显式设置此功能，该参数采用布尔值，可以在初始化层时提供。

        

# 堆叠 RNN 图层

当你可以有两个的时候，为什么要有一个？Keras 中的所有递归层都可以返回两种不同类型的张量，这取决于您希望实现的目标。你可以接收一个三维张量作为输出(`batch_size`、`time_steps`、`output_features`)，或者简单地接收一个 2D 张量，维度为(`time_steps`、`output_features`)。如果我们希望我们的模型在每个时间步长上返回连续输出值的完整序列，我们可以查询 3D 张量。如果我们想将一个 RNN 层堆叠在另一个层之上，然后要求第一个层将所有激活返回到堆叠的第二个层，这是非常有用的。返回所有激活实质上意味着返回每个特定时间步长的激活。这些值可以随后被馈送到另一个递归层，该递归层旨在对来自相同输入序列的更高级抽象表示进行编码。下图显示了将布尔参数设置为**真**或**假**的数学结果:

![](Images/03ea7c75-466e-4209-b81f-49a95778f42d.png)

将其设置为 true 将简单地返回每个时间步长的张量预测，而不仅仅是最后一个时间步长的预测。循环层的堆叠非常有用。通过将 RNN 层一层一层地堆叠起来，我们有可能增加我们网络的时间相关表征值，允许它记忆更多可能存在于我们数据中的抽象模式。

另一方面，如果我们希望它只返回每个输入序列最后一个时间步的输出，我们可以要求它返回一个 2D 张量。当我们想要继续并实际预测我们的词汇表中的哪个字符最有可能是下一个时，这是必要的。我们可以用`return_sequences`参数控制这个实现，当我们添加一个递归层时会传递这个参数。或者，我们可以将其设置为 false，使我们的模型仅返回上一时间步的激活值，这些值可以向前传播以进行分类:

```py
def SimpleRNN_stacked_model():
    model = Sequential()
    model.add(SimpleRNN(128, input_shape=(seq_len, len(characters)), return_sequences=True))
    model.add(SimpleRNN(128))
    model.add(Dense(len(characters), activation='softmax'))
    return model
```

请注意，`return_sequences`参数只能为倒数第二个隐藏层调用，而不能为密集连接的输出层之前的隐藏层调用，因为输出层的任务只是对下一个序列进行分类。

        

# 建筑集团

GRU 在缓解渐变消失问题方面表现出色，是对语法、标点符号和词形等长期依赖关系进行建模的良好选择:

```py
def GRU_stacked_model():
    model = Sequential()
    model.add(GRU(128, input_shape=(seq_len, len(characters)), return_sequences=True))
    model.add(GRU(128))
    model.add(Dense(len(characters), activation='softmax'))
    return model
```

就像 SimpleRNN 一样，我们在第一层定义输入的维度，并将 3D 张量输出返回到第二 GRU 层，这将有助于保留我们训练数据中存在的更复杂的时间相关表示。我们还将两个 GRU 层堆叠在一起，看看我们的模型增强的表现能力会产生什么:

![](Images/bc2f701b-6f1c-424b-a062-39703e28e64e.png)

希望这种架构能产生真实但新颖的文本序列，即使是莎士比亚专家也无法将其与真实交易区分开来。让我们通过下图来可视化我们在这里构建的模型:

请注意，我们还在之前构建的训练器函数中加入了线条`model.summary()`,以直观地描述模型拟合后的结构。

        

# 构建双向 GRUs

在我们的模型中，下一个要测试的是另一个 GRU 装置，但这次有所改变。我们将它嵌套在一个双向层中，这允许我们以正常和相反的顺序为我们的模型提供每个序列。以这种方式，我们的模型能够*看到*将要发生的事情，利用未来的序列数据来通知当前时间步的预测。以双向方式处理序列的性质极大地增强了从我们的数据中提取的表示。事实上，处理一个序列的顺序对之后学习的表征类型有很大的影响。

        

# 论顺序处理现实

改变处理序列的顺序是一个非常有趣的想法。我们人类似乎更喜欢某种学习事物的顺序。下图中的第二个句子对我们来说毫无意义，尽管我们知道句子中每个单词的确切意思。类似地，我们中的许多人很难倒背字母表中的字母，即使我们非常熟悉每个字母，并用它们组成更复杂的概念，如单词、想法，甚至 Keras 代码:

![](Images/1a56a47a-a34a-4dc3-9911-acdd412050a6.png)

很有可能我们的顺序偏好与我们现实的性质有关，根据定义，现实是顺序的和向前移动的。在一天结束的时候，我们大脑中 10 个 ^(11 个)神经元的配置已经被时间和自然力设计成最好的编码和代表我们生命中每一秒钟遇到的大量与时间相关的感官信号。显而易见，我们自己的神经架构有效地实现了一种倾向于以特定顺序处理信号的机制。然而，这并不是说我们不能与习得的顺序分道扬镳，因为许多学前儿童接受了倒背字母表的挑战，并且做得相当成功。然而，其他连续的任务，如听自然语言或有节奏的音乐，可能更难以逆序处理。但是不要相信我的话。试着反过来听你最喜欢的歌，看看你是否仍然喜欢它。

        

# 对顺序数据重新排序的好处

在某种程度上，双向网络似乎能够潜在地克服我们在处理信息时的偏见。正如你将会看到的，他们可以学到同样有用的表述，否则我们不会想到要包括这些表述，以告知和增强我们的预测。这完全取决于按顺序处理给定信号对于手头任务的重要性。在我们之前的自然语言示例中，这对于确定单词 *Spartan* 的**词性** ( **词性**)标签非常关键:

![](Images/259ac156-568d-4eb2-938c-498308c58d7f.png)        

# Keras 中的双向层

因此，Keras 中的双向层以正常和反向顺序处理一系列数据，这使我们能够提取序列中稍后出现的单词，以通知我们当前时间的预测。

本质上，双向层复制任何提供给它的层，并使用一个副本以正常的顺序处理信息，而另一个以相反的顺序处理数据。很整洁，不是吗？通过一个简单的例子，我们可以直观地想象双向层实际上做了什么。假设您正在使用双向 GRU 对两个单词的序列**what up**进行建模:

![](Images/179d4b85-f770-4bd3-bfb2-bfeb4ba5e7b1.png)

为此，您将在双向层中嵌套 GRU，这允许 Keras 生成双向模型的两个版本。在上图中，我们将两个双向图层堆叠在一起，然后将它们连接到密集输出图层，就像我们之前所做的那样:

```py
def Bi_directional_GRU():
    model = Sequential()
    model.add(Bidirectional(GRU(128, return_sequences=True), input_shape=(seq_len, len(characters))))
    model.add(Bidirectional(GRU(128)))
    model.add(Dense(len(characters), activation='softmax'))
    return model
```

以正常顺序处理序列的模型显示为红色。类似地，蓝色模型以相反的顺序处理相同的序列。这两个模型在每个时间步都相互协作，以产生相对于当前时间步的预测输出。我们可以看到这两个模型是如何接收输入值并一起产生预测输出(![](Images/5a07aa4f-cdcc-4d84-96af-8024ce385aa7.png))的，它对应于我们输入的两个相应的时间步长:

![](Images/353bfcae-f247-43a6-a7bb-b9699b84c1fc.png)

控制信息正向传播的方程可以稍微改变，以考虑在每个时间步从正向和反向层序层进入 RNN 的数据。误差随时间的反向传播仍然以相同的方式实现，并且针对 GRU 层(红色和蓝色)的每个方向进行。在下面的公式中，我们可以看到如何使用来自正向和反向序列层的激活来计算给定时间步长( *t* )的预测输出(![](Images/5c108a8b-2fe1-40e2-a65a-75cbbc5f1ba6.png)):

![](Images/d977fa08-9d31-4a09-a9f0-43130a7c0a7c.png)

这里的激活和权重矩阵简单地由嵌套在双向层中的模型定义。正如我们前面看到的，它们将在第一个时间步长初始化，并通过时间反向传播误差进行更新。因此，这些是实现的过程，让我们生成一个双向网络，这是一个无环的网络，其中预测是由向前和向后流动的信息通知的，对应于序列的排序。实现双向层的一个主要缺点是，我们的网络需要在能够做出预测之前看到整个数据序列。在诸如语音识别的用例中，这变得有问题，因为我们必须确保在我们执行预测以将每个声音字节分类为一个单词之前，目标已经停止说话。解决这一问题的一种方法是不断迭代地对输入序列执行预测，并随着新信息的流入迭代地更新先前的预测。

        

# 实施经常性辍学

在前面的章节中，我们看到了如何随机丢弃一些神经元的预测，以更好地在我们的网络中分配表示，并避免过度拟合的问题。虽然我们当前手头的任务对过度拟合没有太大的负面影响，但我们不得不简要介绍一下在 rnn 中减轻过度拟合的具体情况。这将帮助我们的模型更好地生成新的序列，而不是从训练数据中复制粘贴片段。

然而，在这里添加一个普通的漏失层并不能解决问题。它引入了太多的随机性。这通常会阻止我们的模型收敛到理想的损失值和编码有用的表示。相反，我们可能会发现一个混乱的模型，无法跟踪相关的时间相关数据。另一方面，似乎有效的是在每个时间步长应用相同的丢弃方案(或屏蔽)的概念。这不同于经典的丢弃操作，后者在每个时间步随机丢弃神经元。我们可以使用这种递归丢失技术来捕捉正则化的表示，因为恒定的丢失遮罩会随着时间而保持。这是有助于防止重复层中过度拟合的最重要的技术之一，被称为**重复下降策略**。这样做实质上允许我们的模型代表性地对顺序数据进行编码，而不会通过随机化丢弃过程丢失有价值的信息:

```py
def larger_GRU():
    model = Sequential()
    model.add(GRU(128, input_shape=(seq_len, len(characters)),
                       dropout=0.2,
                       recurrent_dropout=0.2,
                       return_sequences=True))
    model.add(GRU(128, dropout=0.2,
                  recurrent_dropout=0.2,
                  return_sequences=True))
    model.add(GRU(128, dropout=0.2,
                  recurrent_dropout=0.2))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(len(characters), activation='softmax'))
    return model
# All defined models
all_models = [SimpleRNN_model,
              SimpleRNN_stacked_model,
              GRU_stacked_model,
              Bi_directional_GRU, 
              Bi_directional_GRU,
              larger_GRU]
```

Keras 的设计者友好地实现了两个与 dropout 相关的参数，它们可以在构造递归层时传递。`recurrent_dropout`参数接受一个浮点值，该值指的是将应用相同丢弃遮罩的神经元的比例。您还可以指定输入值中要随机丢弃的部分，以控制数据中的随机噪声。这可以通过向 dropout 参数传递一个浮点值(不同于`recurrent_dropout`)来实现，同时定义 RNN 层。

作为参考，您可以阅读以下文章:

*   **循环神经网络中一个理论上的落地应用**:【https://arxiv.org/pdf/1512.05287[T2。pdf](https://arxiv.org/pdf/1512.05287.pdf)
*   [http://mlg.eng.cam.ac.uk/yarin/blog_2248.html](http://mlg.eng.cam.ac.uk/yarin/blog_2248.html)

        

# 可视化输出值

为了娱乐起见，我们将展示一些来自我们自己的训练实验的更有趣的结果来结束这一章。第一个屏幕截图显示了我们的 SimpleRNN 模型在第一个时段结束时生成的输出(注意，输出将第一个时段打印为时段 0)。这只是一个实现问题，表示第一个索引位置在 *n* 个时期的范围内。正如我们可以看到的，即使在第一个纪元之后，SimpleRNN 似乎已经掌握了单词形态学，并在低采样阈值下生成真正的英语单词。

这正是我们所期望的。类似地，更高熵的样本(例如，阈值为 1.2)产生更多随机结果，并产生(从主观角度来看)有趣的发音单词(例如*eres Odin*、 *harereus* 和 *nimhte* ):

![](Images/76592355-55cd-4b81-ab60-f20f772b6127.png)        

# 可视化较重的 GRU 模型的输出

在下面的屏幕截图中，我们展示了我们的更重的 GRU 模型的输出，该模型仅在两个训练时期后就开始产生漂亮的听起来像莎士比亚的字符串。它甚至到处都有哈姆雷特的名字。请注意，对于我们的示例来说，网络损耗不是最佳的评估指标。这里显示的模型有 1.3 的损耗，这与我们通常要求的仍然相差甚远。当然，你可以继续训练你的模型，以产生更容易理解的莎士比亚作品。然而，在这个用例中，将任何模型的性能与损失度量进行比较类似于判断苹果和橙子。直觉上，达到接近零的损失仅仅意味着模型已经记住了莎士比亚的哈姆雷特，并且不会像我们希望的那样真正产生新的序列。最终，您仍将是这类生成任务性能的最佳评判者:

![](Images/e7fa7810-3b8f-4212-a42a-c23aae919ec4.png)        

# 摘要

在本章中，我们学习了循环神经网络及其在处理时序相关数据方面的适应性。你所学的概念现在可以应用于你可能偶然发现的任何时间序列数据集。虽然这适用于股票市场数据和时间序列等用例，但期望仅向网络提供实时价格变化就能产生惊人的效果是不合理的。这仅仅是因为影响股票市场价格的因素(如投资者的看法、信息网络和可用资源)远没有反映到允许适当的统计建模的水平。关键是尽可能用最*可学的*方式来表示所有相关信息，以便你的网络能够成功地从中编码出有价值的表示。

虽然我们确实广泛探索了几种类型的 rnn 背后的学习机制，但我们也在 Keras 中实现了一个生成建模用例，并学习了如何构造自定义回调，让我们在每个时期结束时生成数据序列。由于篇幅的限制，我们被迫在本章中省略了一些关于 RNNs 的概念。但是，请放心，这些将在下一章中详细阐述。

在接下来的一章中，我们将了解一个非常流行的 RNN 架构，称为 **LSTM 网络**，并为其他令人兴奋的用例实现它。这些网络和 rnn 一样多才多艺，允许我们为诸如语音和实体识别、翻译和机器问答等用例生成非常详细的语言统计模型。对于自然语言理解，LSTMs(和其他 rnn)通常通过利用诸如词嵌入之类的概念来实现，词嵌入是能够编码其语义的密集单词向量。LSTMs 在生成新的序列(如音乐片段)方面也做得更好，但希望您能够亲自聆听。我们还将简要探讨注意力模型背后的直觉，并在下一章更详细地回顾这个概念。

最后，在结束本章之前，我们将注意到 RNNs 和我们在前面章节中提到的一种 CNN 之间的相似性。在对时间序列数据建模时，rnn 是一个受欢迎的选择，然而**一维卷积层** ( **卷积层**)也可以做到这一点。这里的缺点来自于 CNN 独立处理输入值，而不是顺序处理。正如我们将看到的，我们甚至可以通过结合卷积层和递归层来克服这一点。这使得前者在将简化的表示向前传递到 RNN 层进行顺序处理之前，对输入序列执行某种预处理。但稍后会详细介绍。

        

# 进一步阅读

*   **格鲁什**:【https://arxiv.org/abs/1412.3555】T2
*   **神经机器翻译**:【https://arxiv.org/abs/1409.1259】T2

        

# 锻炼

*   在哈姆雷特文本上训练每个模型，并使用它们的历史对象来比较它们的相对损失。哪个收敛更快？他们学到了什么？
*   检查在每个时期不同熵分布下产生的样本，看每个 RNN 如何随着时间的推移改进其语言模型。***
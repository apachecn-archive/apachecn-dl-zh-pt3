<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 长短期记忆网络

“年轻的时候，我经常琢磨这辈子要做什么。对我来说，最令人兴奋的事情似乎是能够解开宇宙之谜。那意味着成为一名物理学家。然而，我很快意识到可能有更宏伟的东西。如果我试着造一台机器，它会成为一个比我想象中更好的物理学家。也许，这就是我如何将我的一点点创造力倍增到永恒的方式。”

–Jeurgen Schmidthuber，长短期记忆网络的共同发明人

在 1987 年的毕业论文中，Schmidthuber 提出了一种元学习机制的理论，这种机制能够检查自己的学习算法，并随后修改它，以有效地优化它所采用的学习机制。这种想法需要向系统本身开放学习空间，这样它就可以在看到新数据时迭代地改进它的学习:一个可以学习的系统，如果你愿意的话。Schmidthuber 甚至将这台机器命名为哥德尔机器，以递归自我改进算法背后的数学概念的创始人命名。不幸的是，我们还没有像 Schmidthuber 描述的那样建立一个自我学习的通用问题解决程序。然而，这可能没有你想象的那么令人失望。有些人可能会说，鉴于人类事务的现状，大自然本身尚未成功建立这样一个系统。

另一方面，Schmidthuber 和他的同事们确实成功地开发出了其他一些相当新颖的东西。当然，我们说的是长短期记忆网络。有趣的是，在许多方面，LSTM 是之前见过的**门控循环单元** ( **GRU** )的哥哥。LSTM 网络不仅比 GRU (Cho 等人，2014 年)构想得更早(Hochreiter 和 Schmidthuber，1997 年)，而且运行起来计算量也更大。这种计算负担确实带来了好处，与我们迄今为止看到的其他**递归神经网络** ( **RNN** )相比，为长期依赖建模带来了强大的表示能力。

LSTM 网络为我们前面讨论的爆炸和消失梯度问题提供了一个更复杂的解决方案。你可能会认为 GRU 是 LSTM 的简化版。

以下是我们将在本章中涉及的主题:

*   LSTM 网络
*   解剖 LSTM
*   LSTM 记忆块
*   可视化信息流
*   计算竞争内存
*   LSTM 和性能的变化
*   理解窥视孔连接
*   计时和计数的重要性
*   运用我们的知识
*   股票市场数据建模研究
*   数据去噪
*   实施指数平滑
*   提前一步预测的问题是
*   创建观察序列
*   建筑垃圾邮件
*   结束语

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 关于复杂序列的处理

在上一章中，我们讨论了人类如何倾向于以连续的方式处理事件。我们把日常任务分解成一系列更小的行动，却没有给予太多思考。当你早上起床的时候，你可能会选择在给自己做早餐之前去洗手间。在浴室里，你可以选择先淋浴再刷牙。有些人可能会选择同时执行这两项任务。通常，这些选择归结为我们个人的偏好和时间限制。从另一个角度来看，我们如何做我们所做的事情，很大程度上与我们的大脑如何选择代表这些相对任务的重要性有关，这是由它保存的关于近期和远期历史的信息决定的。例如，当你早上醒来时，如果你住在有共用供水的公寓楼里，你可能会倾向于先淋浴。

另一方面，如果你知道你的邻居在度假，你可能会在某些日子推迟这项任务。事实证明，我们自己的大脑非常善于选择、减少、分类和提供最有利于预测我们周围世界的信息。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 打破记忆

我们人类在大脑的特定部位聚集了多层神经元，负责维护我们可能感知的不同类型的重要事件的详细而独特的表征。以颞叶为例，它由负责我们陈述性或长期记忆的结构组成。人们普遍认为，这就是我们对事件的有意识回忆的范围。它提醒我们在我们的世界心理模型中发生的所有一般事件，形成关于它的语义事实(在语义记忆中)和事件发生(在情节记忆中)的概念。一个语义事实可能是水的分子化合物代表一个氢原子和两个氧原子。相反，一个偶发的事实可能是一个特定的水池被化学物质污染了，因此不适合饮用。当我们决定优化我们的目标时，无论目标是什么，记忆中的这些差异都有助于我们有效地在信息丰富的环境中导航。此外，有些人甚至认为，对信息进行这种区分对于处理复杂的时间相关数据序列至关重要。

最终，我们需要在很长一段时间内保持预测模型的相关性，无论是为了创建交互式聊天机器人，还是为了预测股票价格的变动。相关性不仅包括了解最近发生的事情，还包括历史是如何展开的。毕竟，正如老话所说，历史往往会重演。因此，在内存中维护一个所谓历史的表示是有用的。正如我们将很快看到的那样，这正是 LSTM 着手实现的目标。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# LSTM 网络

看，LSTM 建筑。该模型以其复杂信息路径和门的使用为标志，能够从显示的输入中学习信息性的时间相关表示。下图中的每条线都代表一个完整向量沿箭头所示方向从一个节点传播到另一个节点。当这些线分开时，它们所携带的价值被复制到每个通路。先前时间步长的记忆显示为从单元的左上角进入，而先前时间步长的激活从左下角进入。

方框表示学习的权重矩阵和通过激活函数传递的一些输入的点积。圆圈代表逐点运算，例如逐点向量乘法(*)或加法(+):

![](Images/570d2652-759a-463b-8066-fc280d0015af.png)

在上一章中，我们看到了 RNNs 如何通过激活使用反馈连接来存储最近输入的表示。这些激活基本上可以被认为是该单元的短期记忆，因为它主要受前一时间步激活的影响。可悲的是，梯度消失的问题阻止了我们利用很早时间点(长期记忆)的信息来为后来的预测提供信息。我们看到，当误差通过越来越多的时间步长反向传播时，组成隐藏状态的权重有衰减或爆炸的倾向。我们如何解决这个问题？我们怎样才能有效地让信息在时间步长中流动，从而在序列的最后通知预测？答案当然来自 Hochreiter 和 Schmidthuber，包括在 RNNs 中使用长期记忆( *c ^((t-1))* )和短期记忆( *a ^((t-1))* )。

这种方法允许他们有效地克服在长序列上进行相关预测的问题，通过实施一种擅长保存遥远事件相关记忆的 RNN 设计。实际上，这是通过使用一组信息门来实现的，这些信息门在保存和传递细胞状态方面表现得非常好，这些细胞状态编码了来自遥远过去的相关表示。这一重大突破已被证明适用于各种用例，包括语音处理、语言建模、非马尔可夫控制和音乐生成。

进一步阅读的资料来源如下:

*   **原 LSTM 造纸厂的霍克雷特和施密德图伯**:【https://www.bioinf.jku.at/publications/older/2604.pdf】T2

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 解剖 LSTM

如上所述，LSTM 架构依赖于一系列门，这些门可以独立地影响激活值( *a ^((t-1))* )，以及当信息流经 LSTM 单元时来自先前时间步长的存储器(*c^(**^(t-1))*)。当单元在每次迭代中吐出与当前时间步长相关的激活(*a^t)和记忆(*c^t)向量时，这些值被转换。虽然他们的早期同行分别进入该单元，但他们被允许以两种广泛的方式相互交流。在下图中，门(用大写希腊字母 gama 或γ表示)代表 sigmoid 激活函数，应用于其各自初始化的权重矩阵的点积，具有先前激活和当前输入:**

![](Images/669d8d78-7f7b-4489-99d3-711e16221bfb.png)<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 比较最近的已知亲属

让我们通过利用我们在上一章中看到的 GRU 架构的现有知识来理解 LSTM 是如何工作的。我们很快就会发现，LSTM 只不过是 GRU 的一个更复杂的版本，尽管其运作遵循类似的原则。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# GRU 记忆

回想一下，GRU 架构通过更新门利用两个向量来计算其单元状态(或存储器)。这两个向量是来自较早时间步长的激活(**c**t-1，以及一个竞争者向量( **c ̴** **t** )。在每个时间步，竞争者向量将自己呈现为当前单元状态的候选。另一方面，激活本质上代表了来自先前时间步长的 GRU 的隐藏状态。这两个向量中的每一个影响当前单元状态的程度由更新门确定。这个门控制着信息的流动，允许记忆细胞用新的表征来更新自己，以通知随后的预测。使用更新门，我们能够在给定的时间步长( **c ^t** )计算新的单元状态，如下所示:

![](Images/dab24003-383f-4f6b-bc4c-1dfbab4104b8.png)

正如我们所观察到的，GRU 使用更新门(**γu**)及其倒数(**1-γu**)来决定是用新值( **c ̴** **^t** )来更新存储单元，还是保留先前时间步(**c****^(t-1)**)的旧值。更重要的是，GRU 利用单个更新门及其逆数值来控制内存值( **c ^t** )。LSTM 体系结构提供了一个更复杂的机制，其核心使用了一个类似于 GRU 体系结构的等式来维护相关状态。但是它到底是怎么做到的呢？

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# LSTM 存储单元

在下图中，您会注意到 LSTM 单元顶部的直线表示其内存或单元状态( *c ^t* )。更专业地说，这里的单元状态由**恒定误差转盘** ( **CEC** )定义，它本质上是一个递归自连接的线性单元。该实现是 LSTM 层的核心组件，它允许在反向传播期间强制执行恒定的错误流。本质上，这允许减轻其他 rnn 遭受的消失梯度问题。

CEC 防止误差信号在反向传播过程中衰减过快，允许早期的表示被很好地保持并结转到未来的时间步。它可以被认为是信息高速公路，让这个体系结构学会在超过 1000 步的时间间隔上连接相关信息。这已被证明在各种时间序列预测任务中成立，有效地解决了以前的架构所面临的问题，并处理有噪声的输入数据。虽然爆炸梯度问题可以通过梯度裁剪来解决(正如我们在上一章中看到的)，但消失梯度问题同样可以通过 CEC 实现来解决。

现在，我们对 CEC 的激活如何表现细胞状态有了一个高层次的理解。该激活(即， *c ^t* )是使用来自几个信息门的输入来计算的。在 LSTM 架构中使用不同的门允许其控制通过独立单元的错误流，帮助维持相关的单元状态(简称为 **c** ):

![](Images/1a78c040-8e81-4b70-9dc0-7b8436506d55.png)<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 分别对待激活和记忆

注意短期记忆( *a* *^(t-1)* )和长期记忆( *c* *^(t-1)* )是如何被分别允许流入架构的。先前时间步长的内存从左上角流入，而先前时间步长的激活从所描绘的图示的左下角流入。这是我们可以从我们已经熟悉的 GRU 架构中注意到的第一个关键区别。这样做允许 LSTM 利用我们网络的短期激活和长期记忆(单元状态)，同时计算当前记忆( *c* *^t* )和激活( *a* *^t* )。这种二分法架构有助于保持恒定的误差流，同时让相关的表示能够传递给未来的预测。这种预测的一个例子，在自然语言处理的情况下，可能是识别不同性别的存在，或者在给定的单词序列中有多个实体。然而，如果我们想从给定的单词序列中记住多个东西呢？如果我们想在一个给定的序列中，在更长的序列集合中记住关于一个主题的多个事实，会怎么样呢？考虑机器问答的情况，用下面两句话:

*   拿破仑被流放到圣海伦已经几个月了。他的精神已经很虚弱，身体也很虚弱，但正是他房间周围淡绿色墙纸上的潮湿霉菌中的砒霜慢慢导致了他的死亡。
*   拿破仑在哪里？拿破仑是怎么死的？

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# LSTM 记忆块

为了能够回答这些问题，我们的网络必须有几个记忆单元，每个记忆单元都可以存储关于我们研究的主题，法国皇帝拿破仑·波拿巴的准依赖位信息。实际上，一个 LSTM 单元可以有多个存储单元，每个存储单元存储来自输入序列的不同表示。一个可能存储主题的性别，另一个可能存储有多个主题的事实，等等。为了有清楚的说明，我们在这一章中冒昧地只描述了每个图中的一个存储单元。我们这样做是因为理解一个单元的工作原理将足以推断具有多个存储单元的存储块的功能。包含其所有存储单元的 LSTM 部分被称为存储块。该架构的自适应信息门由存储块中的所有单元共享，用于控制 LSTM 的短期激活( *a ^(t-1)* )、电流输入( *X ^t* )和长期状态( *c* *^t* )之间的信息流。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 遗忘之门的重要性

正如我们所注意到的，定义 LSTM 的存储单元状态的方程( *c* *^t* )在精神上与 GRU 的相似。然而，一个关键的区别在于，它利用了一个新的门(γf)，即遗忘门，以及更新门，来决定是遗忘在先前时间步( *c* *^(t-1)* )存储的值，还是将其包括在新单元存储器的计算中。下面的公式描述了负责保存 LSTM 细胞状态的 CEC。正是这个公式使得 LSTMs 在记忆长期依赖关系时如此有效。如前所述，CEC 是 LSTM 中每个记忆细胞特有的神经元，它定义了任何给定时间的细胞状态。我们将从 LSTM 单元如何计算值( **C ^t** )开始，该值表示在时间( **t** )存储在其存储单元( **C** )中的内容:

![](Images/4a1b073e-3a2a-46fc-80af-c981b0c76cfe.png)

这让我们将来自竞争者值(*c^̴**^t*)和前一时间步的内存( *c ^(t-1)* )的信息合并到当前内存值中。正如我们将很快看到的，这个遗忘门只不过是一个应用于矩阵级点积的 sigmoid，以及一个帮助我们控制来自先前时间步长的信息流的偏置项。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 将差异概念化

值得注意的是，当与 GRU 体系结构中采用的实现类似目的的机制相比时，遗忘门代表了在保持单元状态方面的重要概念差异。考虑这个门的一种方式是，它允许我们控制先前的细胞状态(或记忆)对当前细胞状态的影响程度。在 GRU 架构的情况下，我们简单地暴露了以前时间步长的全部内存，或者仅仅是新的竞争者值，很少在两者之间做出折衷。

GRU 细胞状态计算如下:

![](Images/b8e8a603-503a-45e1-a0b8-ec11a26fc563.png)

公开整个内存或新的竞争值之间的这种二元权衡实际上是可以避免的，LSTM 体系结构就是这种情况。这是通过使用两个独立的门来实现的，每个门都有自己可学习的权重矩阵，来控制我们的 LSTM 的细胞状态。LSTM 细胞状态计算如下:

![](Images/57675529-9aea-4c31-8d51-066a15df3631.png)<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 走过 LSTM

那么，让我们更仔细地看看描述 LSTM 架构的整个方程组。我们将考察的第一组门是遗忘门和更新门。与 GRU 不同，LSTM 使用这两个门来确定每个时间步长的存储值(*c^t):*

![](Images/049a8aaa-21cf-4b1d-aeee-5650ef72f1a9.png)

首先，让我们看看这些门本身是如何计算的。以下公式向我们揭示了这些门仅仅是应用于先前激活和当前输入的点积的 sigmoid 函数的结果，具有各自的权重矩阵( *Wf* 和 *Wu* 用于遗忘和输出门):

*   *忘门(γF)= sigmoid(Wf[at-1，![](Images/0e51b3c3-3c8a-4270-aa33-e3bd678717f4.png) t ] + bF)*
*   *更新 gate(γU)= sigmoid(Wu[at-1，![](Images/39ad1f6b-908f-4e4a-acf2-6257ced8f68e.png) t ] + bu)*

![](Images/c7c64f11-8f75-4c4f-98ae-f5b2f0bbf27c.png)<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 可视化信息流

两个向量( *a* *^(t-1)* 和![](Images/5c963b23-c24f-448e-ae07-1e67f1f82c77.png) t)分别从左下角进入 LSTM 单元，到达后复制到每个门(γF 和γU)。然后，在将 sigmoid 应用于它们的点积和偏置项之前，它们分别乘以各自门的权重矩阵。众所周知，sigmoid 以将输入压缩在 0 到 1 的范围内而闻名，因此每个门都保存这个范围内的值。重要的是，每个权重矩阵对于给定的门是唯一的(对于遗忘门是 *Wf* ，对于更新门是 *Wu* )。权重矩阵( *Wf* 和 *Wu* )表示 LSTM 单元内可学习参数的子集，并在反向传播过程中迭代更新，就像我们一直在做的那样。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 计算单元状态

现在我们知道了两个门(更新和遗忘)代表什么，以及它们是如何计算的，我们可以继续了解它们如何在给定的时间步长影响我们的 LSTM 记忆(或状态)。请再花一点时间注意流向和远离大门的不同信息路径。从单元左侧进入的输入被转换并向前传播，直到它们到达 LSTM 单元的末端，在此处提供的图示的右侧:

![](Images/52c932fa-8c88-435f-8e96-5f5a4d47b4d9.png)

正如我们所看到的，遗忘门(*γF*)被用来，毫不夸张地说，遗忘来自先前时间步长的存储值。类似地，更新门(*γu*)用于确定是否允许( *c ^(̴t)* )的潜在竞争者值在给定的时间步长被合并。这两个门共同负责在给定的时间步长保存我们的 LSTM 存储器( *c* *^t* )的状态。从数学上来说，这转化为以下内容:

*   *当前内存值**(c^t***)=*(γu * c^(̴t))+(γf * c^(t-1))*

正如我们提到的，每个门本质上代表 0 和 1 之间的值，因为我们通过非线性 sigmoid 压缩我们的值。我们知道，在 sigmoid 的工作范围内，大多数值要么非常接近 0，要么非常接近 1，因此我们可以将这些门想象为二进制值。这是很有用的，因为我们可以想象这些门是打开的(1)让信息通过，或者是关闭的(0)。介于两者之间的任何值都会让一些信息进入，但不是全部信息。

因此，现在我们了解了这些门的值是如何计算的，以及它们如何用于控制竞争者值(*c^̴t5【t)或先前的存储器状态(*c*t11】t-1t13)对当前状态(*c*t16】t17】tt19)的计算的影响程度。LSTM 存储器的状态( *c* *^t* )由之前显示的 LSTM 图顶部的直线定义。在实践中，这条直线(即恒定误差传送带)非常善于保存相关信息，并将其带到未来的时间点，以帮助预测。*

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 计算竞争内存

我们现在知道了时间( *t* )的记忆是如何计算的，但是竞争者( *c ^(̴t)* )本身呢？毕竟，它在一定程度上负责维护记忆的相关状态，其特征是在每个时间步长都可能出现有用的表示。

这与我们在 GRU 单元中看到的想法是一样的，我们允许在每个时间步长使用一个竞争值来更新内存值。之前，对于 GRU，我们使用了一个关联门来帮助我们计算 GRU。但是，在 LSTM 的情况下，这是不必要的，我们得到了一个更简单也可以说更优雅的公式，如下所示:

*   *争夺者记忆值(c^(̴t))= tanh(WC【a^(t-1)，![](Images/07d7a599-b99a-4933-90bb-634bca4e98af.png)t】+BC)*

这里， *Wc* 是在训练会话开始时初始化的权重矩阵，并且随着网络训练而迭代更新。这个矩阵的点积，具有先前的激活(*a^t*-1)和当前输入( *x ^t* )，连同一个偏置项( *bc* )，通过一个双曲正切激活函数以达到竞争值(*c**^(^t)*)。然后，将这个竞争向量与更新门的值相乘(逐元素),我们看到更新门的值形成了当前时间的存储器状态的一部分( *c* *^t* )。在下一张图中，我们说明了竞争内存向量的计算，并显示了信息如何被传递以影响内存单元的最终状态(*c*t):

![](Images/1c2024ce-67fd-4906-8a94-2f324c3efd1a.png)

回想一下，tanh 激活函数有效地将其输出压缩在-1 和 1 之间，因此竞争者向量的值( *c ^(̴t)* )将总是出现在这个范围内。现在，我们了解了如何在给定时间步长计算 LSTMs 单元状态(或存储器)。我们还了解了竞争者的值是如何在被更新门调节并传递到当前内存的计算中之前被计算出来的，( *c* *^t* )。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 计算每个时间步长的激活

正如我们之前在 LSTM 架构中指出的，它被分别馈送来自前一时间步的内存和激活值。这与我们对 GRU 单位所做的假设截然不同，这里*a*t = CT。这种双重的数据处理方式让我们能够在很长的序列中保存相关的表示，甚至可能是 1000 个时间步长！然而，激活总是与每个时间步的记忆功能相关( *c ^t* )。因此，我们可以计算给定时间步长的激活，首先将一个双曲正切函数应用于存储器( *c ^t* )，然后使用输出门值(γo)执行结果的元素式计算。注意，我们在这一步没有初始化权重矩阵，而是简单地将 tanh 应用于( *c ^t* )向量中的每个元素。这可以用数学方法表示如下:

*   *当前激活次数(a^t)=γo * tanh(c^t)*

![](Images/f9dbdd70-4dcf-4421-9c98-f56cf1e2876b.png)

这里，输出门不过是另一个 sigmoid，应用于可学习的权重矩阵的点积，来自先前时间步长的激活和当前时间的输入如下:

*   *输出门(γo)= sigmoid(Wo[a^(t-1)，![](Images/623ea13b-345c-4274-8caf-eba9d43163bc.png)t】+bo)*

对于每个单独的门(分别为遗忘、更新、竞争和输出)存在的每个权重矩阵( *Wf* 、 *Wu* 、 *Wc* 和 *Wo* )可以被认为是 LSTM 单元的可学习参数，并且在训练过程中被迭代更新。在此处提供的图表中，我们可以观察每一个权重矩阵，因为它在将结果传递给架构的其他部分之前，对进入各自门的输入进行建模:

![](Images/bc1c2d48-1925-4cba-af50-f80f56351588.png)<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# LSTM 和性能的变化

您已经看到了 LSTM 的变体，即 GRU。我们已经广泛讨论了这两种架构的不同之处。还有其他的变化也存在，非常值得注意。其中之一是 LSTM 变体，它包括被称为**窥视孔连接**的东西。这些连接允许信息从细胞状态一路流回信息门(遗忘、更新和输出)。这只是让我们的 LSTM 门在计算当前时间的当前门值时，查看先前时间步长的内存值。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 理解窥视孔连接

窥视孔连接背后的要点是需要捕捉时滞信息。换句话说，我们希望在我们的建模工作中包括序列的子模式之间的时间间隔所传达的信息。这不仅与某些语言处理任务(如*语音识别*)相关，还与许多其他任务相关，从机器运动控制到保持计算机生成音乐的复杂节奏。以前的任务方法，比如语音识别，使用了**隐马尔可夫模型** ( **HMMs** )。这些本质上是统计模型，基于隐藏状态转换的序列来估计一组观察的概率。在语音处理的情况下，观察值被定义为对应于语音的数字信号片段，而马尔可夫隐藏状态是我们希望识别为单词的音素序列。正如你会注意到的，在这个模型中，我们没有任何地方能够结合音素之间的延迟来判断给定的数字信号是否对应于某个单词。这些信息通常会在 HMMs 中被丢弃，但对于我们确定是否听过句子*我想打开我的储物单元却至关重要...*或*我想打开我的储物单元，B-4* 。在这些例子中，音素之间的延迟可以很好地区分对 *B-4* 或之前的*的检测。虽然 HMM 超出了本章的范围，但它有助于我们理解 LSTM 如何通过利用时间序列之间的延迟来克服以前的建模限制。*

你可以在[ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf](ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf)看到窥视孔纸:

![](Images/55abc71a-14fc-4aa2-ba7e-629c00ee0ab2.png)

请注意，窥视孔修改可以在任一门。您可以选择对所有的门或者只是其中的一个子集实现这个。

当添加窥视孔连接以包括先前的单元状态时，以下等式展示了为获得相应的门值而执行的计算:

*   *忘门(γF)= sigmoid(Wf[c^(t-1)，a ^(t-1) ，![](Images/8b9f0d7e-71a2-40b8-942d-5b72c2a49b42.png)t】+bF)*
*   *更新 gate(γU)= sigmoid(Wu[c^(t-1)，a ^(t-1) ，![](Images/6594fc16-f906-42e3-b893-ef25808cb580.png)t】+bu)*
*   *输出门(γo)= sigmoid(Wo[c^(t-1)，a ^(t-1) ，![](Images/70de5906-85ac-4d0d-9b26-9c8fae3b5457.png)t】+bo)*

因此，窥视孔修改在数学上归结为在给定门值的计算中执行额外的矩阵级乘法。换句话说，门的值现在可以通过计算其与给定门的权重矩阵的点积来适应先前的单元状态。然后，将得到的点积与前两个点积和偏置项相加，然后通过 sigmoid 函数进行压缩。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 计时和计数的重要性

让我们用另一个概念性的例子来巩固使用时间间隔、相关信息来通知顺序预测的想法，其中这样的信息被认为是准确预测的关键。例如，考虑一个人类鼓手必须如何执行对应于精确节奏流的精确运动命令序列。他们为自己的行为计时，并以一种连续相关的顺序计算他们的进展。这里，表示所生成序列模式的信息至少部分是通过这些相应事件之间的时间延迟来传达的。自然，我们会对人工复制这种相互作用中复杂的序列建模任务感兴趣。理论上，我们甚至可以使用这种方法从计算机生成的诗歌中提取新颖的押韵方案，或者创造出能够在未来的奥运会上与人类一起竞争的机器人运动员(不管出于什么原因，我们都认为这是一个好主意)。如果你希望进一步研究窥视孔连接如何用于增加对复杂时间延迟序列的预测，我们鼓励你阅读 LSTM 最初的窥视孔修改论文，如下所示:

[http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf](http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf)

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 探索其他建筑变化

除了本书中提到的，RNNs 还有许多其他的变体(参见*深度门控 RNNs* ，作者:【姚】等人，2015；或者*发条 RNNs* 作者 *Koutnik 等人* 2014)。其中的每一个都可以适用于一系列特殊的任务——普遍的共识是 LSTMs 在大多数时间序列预测任务中表现出色，并且可以进行相当大的修改以适应最常见和更复杂的用例。事实上，作为进一步的阅读，我们推荐一篇优秀的文章( *LSTM:搜索空间奥德赛*，2017:[https://arxiv.org/abs/1503.04069](https://arxiv.org/abs/1503.04069))，它比较了 LSTM 的不同变体在各种任务上的性能，如语音识别和语言建模。由于使用了大约 15 年的 GPU 时间来进行实验，这项研究对于希望更好地了解不同 LSTM 体系结构考虑因素及其在建模顺序数据时的影响的研究人员来说是独一无二的探索性资源。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 运用我们的知识

既然我们已经很好地理解了 LSTM 是如何工作的，以及他们特别擅长什么样的任务，那么是时候实现一个真实世界的例子了。当然，时间序列数据可以出现在大量的设置中，从工业机械的传感器数据到代表来自遥远恒星的光的光谱数据。然而，今天我们将模拟一个更常见、但却是臭名昭著的用例。我们将实现一个 LSTM 来预测股票价格的运动。为此，我们将采用标准普尔(S&P) 500 数据集，并选择一只随机股票为连续建模做准备。这个数据集可以在 Kaggle 上找到，它包含了在美国股票市场交易的所有当前标准普尔 500 大型资本公司的历史股票价格(开盘价、最高价、最低价和收盘价)。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 股票市场数据建模研究

在继续前进之前，我们必须提醒自己市场趋势固有的随机性。也许你更像是一个有效市场假说类型的人，而不是非理性市场类型的人。无论你对推动股票走势的内在逻辑有什么样的个人信念，现实情况是，即使是最具预测性的模型也往往无法预测到大量的随机性。投资者的行为很难预测，因为投资者往往出于各种动机进行投资。即使是总体趋势也可能是欺骗性的，正如 2017 年底比特币资产泡沫最近所证明的那样；还有许多其他例子(2008 年全球危机、津巴布韦动乱后的通胀、20 世纪 70 年代的石油危机、一战后的德国、荷兰黄金时代的郁金香狂热等等，一直追溯到古代)。

事实上，许多经济学家都引用了股票市场运动看似固有的随机性。差不多半个世纪前，普林斯顿大学的经济学家伯顿·马尔基尔在他名为《漫步华尔街》的书中阐述了这一点。然而，仅仅因为我们不能得到一个完美的预测分数，并不意味着我们不能试图将我们的猜测引入隐喻的棒球场。换句话说，这种序列建模的努力可能仍然有助于预测市场在不久的将来的总体趋势。因此，让我们导入我们的数据，看看我们在这里处理什么，没有更多的麻烦。请随时关注您自己的市场数据，或我们使用的相同数据集，您可以在 https://www.kaggle.com/camnugent/sandp500[找到这些数据。](https://www.kaggle.com/camnugent/sandp500)

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 导入数据

数据存储在**逗号分隔值** ( **CSV** )文件中，可以通过熊猫 CSV 阅读器导入。我们还将导入标准的 NumPy 和 Matplotlib 库，以及来自 sklearn 的`MinMaxScaler`库，以便能够在适当的时候对我们的数据进行整形、绘图和规范化，如以下代码所示:

```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
df = pd.read_csv('D:/Advanced_Computing/Active_Experiments/LSTM/
                  stock_market/all_stocks_5yr.csv')

df.head()
```

我们得到如下输出:

![](Images/ba7364d1-4b01-48be-9ee8-a972145e560f.png)

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 对趋势进行排序和可视化

首先，我们将从数据集中的 505 只不同股票中随机选择一只股票。你可以选择其中任何一个来重复这个实验。我们还将按日期对数据帧进行排序，因为我们处理的是时间序列预测问题，其中序列的顺序对我们任务的预测值至关重要。然后，我们可以通过按发生的先后顺序绘制出(某一天的)最高价和最低价来直观地显示我们的数据。这有助于我们将美国航空集团(股票代码:`AAL`)在五年期间(2013-2017 年)的股票价格的总体趋势可视化如下:

```
plt.figure(figsize = (18,9))
plt.plot(range(aal.shape[0]),(aal['low']), color='r')
plt.plot(range(aal.shape[0]),(aal['high']), color = 'b')
plt.xticks(range(0,aal.shape[0],60),aal['date'].loc[::60],rotation=60)
plt.xlabel('Date',fontsize=18)
plt.ylabel('Price',fontsize=18)
plt.show()
```

![](Images/5866d5f8-356c-48c1-ab7b-5f06f5d40d8c.png)

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 从数据框架到张量

我们观察到，虽然彼此略有不同，但高价和低价都明显遵循相同的模式。因此，使用这两个变量进行预测建模是多余的，因为它们高度相关。当然，我们可以从两个价格指标中只选择一个，但我们也可以在任何给定的交易日，在两个价格指标之间取某种平均值。我们将把包含给定观察日的最高价和最低价的列转换成 NumPy 数组。我们通过调用各个列上的值来实现这一点，这将返回每个列的 NumPy 表示。然后，我们可以使用这些新定义的列来计算第三个 NumPy 数组，该数组存储所有给定观察值的中间价格值(计算方法为*(高+低)/2)* ，如下所示:

```
high_prices = aal.loc[:,'high'].values
low_prices = aal.loc[:,'low'].values
mid_prices = (high_prices+low_prices)/2.0

mid_prices.shape
----------------------------------------------------
Output:
(1259,) ----------------------------------------------------mid_prices
----------------------------------------------------
Output:
array([14.875, 14.635, 14.305, ..., 51.07 , 50.145, 51.435])
```

我们注意到总共有`1259`个观察值，每个对应于我们 AAL 股票在某一天的中间价。我们将使用这个数组来定义我们的训练和测试数据，然后我们将为我们的 LSTM 摄取序列批量准备这些数据。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 分割数据

让我们将整个实例范围(即`mid_prices`变量)分成实例的训练集和测试集。稍后，我们将使用这些集合分别生成训练和测试序列:

```
train_data = mid_prices[:1000]
test_data = mid_prices[1000:1251]
train_data = train_data.reshape(-1,1)         #scaler.fit_transform
test_data = test_data.reshape(-1,1)           #scaler.fit_transform

print('%d training and %d total testing instances'%(len(train_data),    
      len(test_data)))

-----------------------------------------------------------------
Output:
1000 training and 251 total testing instances 
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 制定培训和测试计划

在下面的屏幕截图中，我们简单地展示了两个子图，以可视化 AAL 股票数据的非标准化训练和测试部分。您可能会注意到，这些图不是按比例绘制的，因为训练数据代表 1000 个观察值，而测试数据只有大约四分之一。类似地，测试数据在其代表的观察时间范围内出现在 40 到 57 美元的价格范围之间，而训练数据在其各自较长的观察跨度内出现在 0 到 50+美元的范围之间。回想一下，测试数据只是经过预处理的 AAL 中盘股票价格数据的前 1，000 个观察值之后的时间序列序列:

```
#Subplot with training data
plt.subplot(1,2,1)
plt.plot(range(train_data.shape[0]),train_data,color='r',label='Training split')
plt.title('Train Data')
plt.xlabel('time')
plt.ylabel('Price')
plt.legend()

#Subplot with test data
plt.subplot(1,2,2)
plt.plot(range(test_data.shape[0]),test_data,color='b',label='Test Split')
plt.title('Test Data')
plt.xlabel('time')
plt.ylabel('Price')
plt.legend()

#adjust layout and plot all
plt.tight_layout()
plt.show()
```

前面的代码块生成以下输出:

![](Images/2a4ece85-8d88-4874-b5b4-fe46784ea04b.png)

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 窗口归一化

在我们可以将数据分割成更小的序列进行训练之前，我们必须将所有数据点缩放到 0 和 1 之间的区间，就像我们到目前为止所做的那样。回想一下，这种表示使我们的网络更容易从它显示的数据中捕获相关的表示，并且是深度学习社区内外各种**机器学习** ( **ML** )任务的常见标准化实践。

然而，与以前的方法不同，我们必须针对这个特殊的时间序列问题调整我们的规范化策略。为此，我们采用了窗口归一化方法。为什么？好吧，这只是允许我们以更小的批量来标准化我们的数据，而不是同时标准化整个数据集。早些时候，当我们可视化我们的股票数据的整个时间序列时，我们注意到了一些东西。事实证明，不同年份的数据在完全不同的时间有不同的数值范围。因此，整体标准化过程将导致时间序列早期出现的值非常接近于零。这将阻止我们的模型像我们希望的那样区分相关趋势，并严重削弱了在训练网络时可以捕获的表示。当然，你可以选择更宽的特征范围——然而，这也会对学习过程产生不利影响，因为人工神经网络在处理 0 到 1 之间的值时往往工作得最好。

因此，让我们实现这个窗口规范化方案，如下面的代码块所示:

```
#Window size to normalize data in chunks 
normalization_window = 250

#Feature range for normalization
scaler = MinMaxScaler(feature_range=(0, 1))

# Loop over the training data in windows of 250 instances at a time
for i in range(0,1000,normalization_window):

    # Fit the scaler object on the data in the current window
    scaler.fit(train_data[i:i+normalization_window,:])

    # Transform the data in the current window into values between the chosen feature range (0 and 1)
    train_data[i:i+normalization_window,:] = scaler.transform(train_data[i:i+normalization_window,:])

# normalize the the test data
test_data=scaler.fit_transform(test_data)
```

我们刚刚采用的窗口归一化方法的一个问题值得一提。批量规范化我们的数据可能会在每批结束时引入连续性中断，因为每批都是独立规范化的。因此，建议选择一个合理的窗口大小，它不会在我们的训练数据中引入太多的中断。在我们的例子中，我们将选择 250 天的窗口大小，因为这不仅完美地划分了我们的训练集和测试集，而且仅引入了四个潜在的连续性中断，同时规范化了我们的整个数据集(即 1000 / 250 = 4)。我们认为这对于手头的演示用例是可管理的。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 数据去噪

接下来，我们将对我们的股票价格数据进行降噪，以消除当前存在的有些不相关的市场波动。我们可以通过以指数递减的方式对数据点进行加权来做到这一点(也称为**指数平滑**)。这允许我们让最近的事件比遥远过去的事件对当前数据点具有更高的影响，以便每个数据点可以被表示(或平滑)为时间序列中当前值和先前值的加权递归函数。这可以用数学方法表示如下:

![](Images/df08fb55-0a55-41d4-a7c1-1c160813228c.png)

前面的等式表示给定数据点的平滑变换( *x [t]* )作为加权项γ的函数。结果( *S [t]* )是给定数据点的平滑值，而伽马项表示 0 和 1 之间的平滑因子。衰减项允许我们将之前对特定时间间隔内发生的数据变化(即季节性)的假设编码到我们的预测建模工作中。因此，我们将平滑中期股票价格随时间变化的曲线。这是时间序列建模中常用的信号预处理技术，有助于从数据中去除高频噪声。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 实施指数平滑

因此，我们通过循环每个中间价格值、更新平滑系数，然后将其应用于当前价格值来转换我们的训练数据。请注意，我们使用之前显示的公式更新平滑系数，该公式允许我们将时间序列中的每个观察值作为当前和先前观察值的加权函数进行加权:

```
Smoothing = 0.0     #Initialize smoothing value as zero

gamma = 0.1         #Define decay

for i in range(1000):

    Smoothing = gamma*train_data[i] + (1-gamma)*Smoothing   # Update   
                                                       smoothing value

    train_data[i] = Smoothing # Replace datapoint with smoothened value
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 可视化曲线

使用下图，我们可以看到平滑数据点前后的曲率差异。正如你所看到的，紫色图显示了一条更平滑的曲线，同时保持了股票价格随时间的一般运动。

如果我们使用不平滑的数据点，我们很可能很难使用任何类型的 ML 技术来训练预测模型:

![](Images/ea4c43a3-f7f1-429a-a0f7-ed1f54abae42.png)

代表性是关键，在准确性和效率之间总会有一个最佳的平衡。一方面，使用简化的表示可以让机器更快地从数据中学习。然而，下采样到更易管理的表示的过程可能导致有价值的信息的丢失，这些信息可能不再被我们的统计模型捕获。另一方面，处理各种各样的信息会带来大量的计算复杂性，这种复杂性既没有必要的资源来建模，也没有必要考虑来解决手头的问题。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 执行单步预测

接下来，我们将解释一些基线模型。这将有助于我们更好地评估 LSTM 网络的有效性。我们执行的平滑过程将帮助我们实施这些基线模型，这些模型将用于对我们的 LSTM 模型的性能进行基准测试。我们将尝试使用一些相对简单的算法。为此，我们将使用两种技术，即简单移动平均和指数移动平均算法。这两种方法本质上都是执行一步预测，将我们训练数据中的下一个时间序列值预测为前一序列值的平均值。

为了评估每种方法的有效性，我们可以使用**均方误差** ( **MSE** )函数来评估预测值和实际值之间的差异。回想一下，这个函数，确切地说，是在给定的时间步长下，预测结果和实际结果之间的误差的平方。我们还将通过将预测的时间序列级数叠加到股票价格的实际时间序列级数上来直观地验证我们的预测。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 简单移动平均预测

在简单移动平均的情况下，当预测时间序列序列中的下一个值时，我们在给定的窗口中对过去的观察值进行同等加权。这里，我们计算给定时间间隔内股票价格的算术平均值。这个简单的算法可以用数学方法表示如下:

![](Images/cb9f19b3-8518-4e73-a8fd-3c3055a981f7.png)

取短期平均值(即几个月内的平均值)将允许模型对价格变化做出快速反应，而长期平均值(即几年内的平均值)往往对价格变化反应较慢。在 Python 中，该操作转化为以下内容:

```
window_size = 26            # Define window size
N = train_data.size         # and length of observations

std_avg_predictions = []    # Empty list to catch std
mse_errors = []             # and mse

for i in range(window_size,N):
    # Append the standard mean per window
    std_avg_predictions.append(np.mean(train_data[i-window_size:i]))                                                                                                         

    # Compute mean squared error per batch 
    mse_errors.append((std_avg_predictions[-1]-train_data[i])**2) 

print('MSE error for standard averaging: %.5f'  
      (0.5*np.mean(mse_errors)))

MSE error for standard averaging: 0.00444
```

我们再次通过使用预定义的窗口大小循环遍历我们的训练数据来收集简单的平均预测，并收集训练集中每个数据点的分批平均值以及 MSE。如 MSE 值所示，我们的简单平均预测模型的表现并不太差。接下来，我们可以绘制出这些预测，并将其叠加到我们股票价格的真实时间序列上，为我们提供这种方法性能的可视化说明:

```
plt.figure(figsize = (19,6))
plt.plot(range(train_data.shape[0]),train_data,color='darkblue',label='Actual')
plt.plot(range(window_size,N),std_avg_predictions,color='orange',label='Predicted')
plt.xticks(range(0,aal.shape[0]-len(test_data),50),aal['date'].loc[::50],rotation=45)

plt.xlabel('Date')
plt.ylabel('Mid Price')
plt.legend(fontsize=18)
plt.show()
```

我们得到下面的图表:

![](Images/8dee4561-2e58-48fc-b755-477c6c970f24.png)

在简单的平均预测图中，我们注意到我们的预测确实捕捉到了股票价格的一般趋势，但并没有在时间序列的所有独立点上提供准确可靠的预测。有些预测可能看起来很准确，但大多数都偏离了目标，而且它们相对于真实预测的变化速度太慢，无法做出任何有利可图的预测。如果您希望从数字上更清楚地了解预测实际上有多远，还可以打印出预测数组的单独值，并将它们与来自定型数据的实际值进行比较。接下来，我们将继续我们的第二条基线。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 指数移动平均预测

指数移动平均线比它的简单对应物稍微复杂一些；然而，我们已经熟悉了将要使用的公式。本质上，我们将使用与我们用来平滑数据的等式相同的等式。但是，这一次我们将使用指数平均来预测时间序列中的下一个数据点，而不是重新调整当前数据点的比例:

```
ema_avg_predictions = []
mse_errors = []

EMA = 0.0
ema_avg_predictions.append(EMA)

gamma = 0.5
window_size = 100
N = len(train_data)

for i in range(1,N):
    EMA = EMA*gamma + (1.0-gamma)*train_data[i-1]
    ema_avg_predictions.append(EMA)
    mse_errors.append((ema_avg_predictions[-1]-train_data[i])**2)

print('MSE error for EMA averaging: %.5f'%(0.5*np.mean(mse_errors)))

MSE error for EMA averaging: 0.00018
```

我们可以看到，简单移动平均([https://en . Wikipedia . org/wiki/Moving _ average # Simple _ Moving _ average](https://en.wikipedia.org/wiki/Moving_average#Simple_moving_average))对过去的观测值进行了同等的加权。相反，在预测未来数据点时，我们使用指数函数来控制先前数据点的影响程度。换句话说，随着时间的推移，我们能够将指数递减的权重分配给较早的数据点。这种技术允许建模者通过修改衰减率(γ)将先前的假设(例如季节性需求)编码到预测算法中。一步前指数平均值和真实价格之间的 MSE 比简单平均得到的值低得多。让我们绘制一个图表来直观地检查我们的结果:

```
plt.figure(figsize = (19,6))
plt.plot(range(train_data.shape[0]),train_data,color='darkblue',label='True')
plt.plot(range(0,N),ema_avg_predictions,color='orange', label='Prediction')
plt.xticks(range(0,aal.shape[0]-len(test_data),50),aal['date'].loc[::50],rotation=45)

plt.xlabel('Date')
plt.ylabel('Mid Price')
plt.legend(fontsize=18)
plt.show()

```

我们得到下面的图表:

![](Images/efdfe4ce-e94c-4e7e-ba21-f67c9c527fe0.png)

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 提前一步预测的问题是

惊人的！看起来我们几乎能够完美地预测给定前几天的第二天的股票价格。我们甚至不需要训练一个复杂的神经网络！所以，何必继续呢？事实证明，提前一天预测股价并不能让我们成为百万富翁。均线本质上是滞后指标。只有在股票价格开始遵循特定趋势后，它们才是反映市场重大变化的指标。由于我们的预测和事件的实际发生之间的时间跨度很短，当这种模型反映出显著趋势时，市场进入的最佳点已经过去了。

另一方面，使用这种方法试图预测未来的多个时间步长也是行不通的。我们实际上可以用数学来说明这个概念。假设我们有一个数据点，我们想用指数移动平均法提前预测两步。换句话说，我们将不会使用(X [t + 1] 的真实值，而是使用我们的预测来计算第二天的股票价格。回想一下，定义提前一步预测的等式定义如下:

![](Images/396dd755-ac1c-4402-92d6-19d4a6086e5e.png)

我们假设数据点*X[t]的值为 0.6，在 *X [t-1]* 处的 *EMA* 给定为 0.2，我们选择的衰变率(γ)为 0.3。然后，我们对*X[t-1]的预测可以计算如下:**

*   = 0.3 x 0.2+(1–0.3)x 0.6
*   = 0.06 + (0.7 x 0.6)
*   = 0.06 + 0.42 = 0.48

所以，0.48 既是我们对*X[t-1]的预测，也是当前时间步长的*均线*。如果我们使用相同的公式来计算我们对下一时间步(X [t-2] )的股票价格的预测，我们会遇到一些问题。下面的等式说明了这个困难，其中*EMA[t]= X[t+1]= 0.48*:*

![](Images/d195eaa5-f652-404b-b976-5f0541dbf653.png)

因此，无论我们选择什么样的伽马值，由于*EMA[t]和 *X [t + 1]* 的值相同，因此 *X [t + 2]* 的预测值将与 *X [t + 1]* 的预测值相同。这适用于预测超过一个时间步长的*X[t]的任何尝试。在实践中，指数移动平均线通常被日内交易者用作健全检查，他们用它来评估和验证重大的市场波动，通常是在快速波动的市场中。因此，现在我们已经使用一步移动平均预测建立了一个简单的基线，我们可能会建立更复杂的模型，可以看到更远的未来。**

很快，我们将建立一套神经网络并评估它们的性能，以了解 LSTMs 在预测股票价格运动的任务中的表现。我们将再次建立一个简单的前馈神经网络基线，并逐步建立更复杂的 LSTMs 来比较它们的性能。然而，在我们开始之前，我们必须准备好我们的数据。我们需要确保我们的网络可以接收一系列训练数据，然后才能对以下序列值(我们股票的比例中间价)进行预测。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 创建观察序列

我们使用以下函数来创建训练和测试序列，我们将使用这些序列来训练和测试我们的网络。该函数获取一组时间序列的股票价格，并按照给定的顺序将它们组织成由 *n* 个连续值组成的片段。关键的区别在于，每个训练序列的标签将对应于未来四个时间步的股票价格！这与我们用移动平均线方法所做的有很大不同，因为它们只能提前一步预测股票价格。因此，我们生成我们的数据序列，以便我们的模型被训练来预测未来四个时间步的股票价格。

我们定义一个`look_back`值，它指的是我们在给定的观察中保留的股票价格的数量。在我们的例子中，我们实际上是让网络以过去的`7`价格值`look_back`，在我们要求它预测四个时间步之后我们的股票价格会发生什么之前:

```
def create_dataset(dataset, look_back=7, foresight=3):   
    X, Y = [], []
    for i in range(len(dataset)-look_back-foresight): 
        obs = dataset[i:(i+look_back), 0] # Sequence of 7 stock prices  
                                     as features forming an observation    
       # Append sequence
        X.append(obs)
       # Append stock price value occurring 4 time-steps into future
        Y.append(dataset[i + (look_back+foresight), 0]) 
    return np.array(X), np.array(Y)
```

我们使用`create_dataset`函数来生成序列及其相应标签的数据集。这个函数在我们的时间序列数据(即`train_data`变量)上被调用，并带有两个额外的参数。第一个(`look_back`)是指我们想要的每个观察序列的数据点的数量。在我们的例子中，我们将创建每个都有七个数据点的序列，引用时间序列中给定点的过去七个中间价格值。类似地，第二个(`foresight`)变量是观察序列中最后一个数据点和我们要预测的数据点之间的步数。因此，对于每个训练和测试序列，我们的标签将反映未来四个时间步长的滞后。我们重复这种从原始训练数据创建训练序列及其标签的方法，步长为 1。因此，我们留下了 990 个观察序列的训练数据，每个序列都有一个标签，对应于未来四个时间步长的股票价格。虽然我们的`look_back`和`foresight`值有些随意，但我们鼓励您尝试不同的值，以评估更大的`look_back`和`foresight`值如何影响您的模型的预测能力。在实践中，你将体验到这两种价值的收益递减。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 重塑数据

接下来，我们简单地为我们的网络重塑我们的训练和测试序列。我们准备一个三维张量维度(时间步长，1，特征)，这将在功能上用于测试不同的神经网络模型:

```
x_train = np.reshape(x_train, (x_train.shape[0], 1,  x_train.shape[1]))
x_test = np.reshape(x_test, (x_test.shape[0], 1,  x_test.shape[1]))
x_train.shape

(990, 1, 7)
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 做一些进口

现在，我们准备最终构建和测试一些神经网络架构，看看它们如何完成预测股票趋势的任务。我们将从导入相关的 Keras 层以及一些回调开始，这些回调允许我们与训练中的模型进行交互，以便在我们认为适当的时候保存它们或停止训练会话:

```
from keras.models import Sequential
from keras.layers import LSTM, GRU, Dense
from keras.layers import Dropout, Flatten

from keras.callbacks import ModelCheckpoint, EarlyStopping
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 基线神经网络

正如我们前面提到的，在进展到更复杂的模型之前，从更简单的模型开始执行健全性检查总是好的。数据建模师往往会被所谓的**强大的模型**所吸引，然而很多时候它们对于手头的任务来说可能并不必要。在这些场景中，最好使用功能较弱(通常计算强度较低)的模型来形成适当的基线，以衡量使用任何更复杂的东西所带来的增值收益。本着这种精神，我们将构建两个基线模型。每条基线将显示特定类型的网络在当前任务中的性能。我们将使用简单的前馈网络来建立所有神经网络的初步基线。然后，我们将使用基本 GRU 网络来建立循环网络基线。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 构建前馈网络

虽然前馈网络是您非常熟悉的网络，但这种架构进行了一些修改，使其适合手头的任务。例如，最后一层是只有一个神经元的回归层。它还使用线性激活函数。至于损失函数，我们选择的是**平均绝对误差** ( **MAE** )。我们还为此任务选择了`adam`优化器。所有未来的网络都将实施相同的最后一层、损耗和优化器。我们还将在一个函数中嵌套一个模型的构建和编译，以允许我们轻松地测试多个网络，就像我们到目前为止所做的那样。下面的代码块显示了如何实现这一点:

```
def feed_forward():
    model = Sequential()
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dense(1, activation='linear'))
    model.compile(loss='mae', optimizer='adam')
    return model
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 重复基线

接下来，我们将构建一个简单的 GRU 网络来建立一个循环基线。我们指定正确的输入形状，并添加一小部分经常性丢失。回想一下，这将相同的丢弃方案应用于后续时间步长，比简单的丢弃方案更好地保留了时间信息。我们还包括了一小部分随机退出的神经元。我们鼓励您单独进行实验(除了我们目前正在进行的实验),以了解 RNNs 在不同退出策略下的性能差异:

```
def simple_gru():
    model = Sequential()
    model.add(GRU(32,  input_shape=(1, 7), dropout=0.1, recurrent_dropout=0.1))

    model.add(Dense(1, activation='linear'))

    model.compile(loss='mae', optimizer='adam', metrics = 
                  ['mean_absolute_error'])
    return model
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 建筑垃圾邮件

现在我们已经有了一些基本模型，让我们继续构建本章的内容:LSTM。我们将首先从一个简单的无脱落策略的单层 LSTM 开始，它配备有 32 个神经元，如下所示:

```
def simple_lstm():
    model = Sequential()
    model.add(LSTM(32, input_shape=(1, 7)))

    model.add(Dense(1, activation='linear'))

    model.compile(loss='mae', optimizer='adam')
    return model
```

我们将 LSTM 层连接到密集回归层，并继续使用相同的损失、优化器和损失函数。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# Stacked LSTM

接下来，我们简单地将两个 LSTM 层堆叠在一起，就像我们在前一章中对 GRUs 所做的那样。我们将看看这是否有助于网络记住我们股票数据中更复杂的时间相关信号。我们将辍学和经常辍学方案应用于两个 LSTM 层，如下所示:

```
def lstm_stacked():
    model = Sequential()
    model.add(LSTM(16, input_shape=(1, 7), dropout=0.1, recurrent_dropout=0.2, return_sequences=True))
    model.add(LSTM(16, dropout=0.1, recurrent_dropout=0.2))

    model.add(Dense(1, activation='linear'))

    model.compile(loss='mae', optimizer='adam')
    return model
```

现在我们准备运行我们的实验并评估结果。我们可以通过 MSE 度量来评估它们，也可以直观地解释模型预测对实际预测的影响。我们继续构建了一些函数，帮助我们在每次训练结束时可视化我们的结果。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 使用助手功能

在我们开始训练我们的网络之前，我们可以构造几个辅助函数，一旦它们被训练好，就可以通知我们模型的性能。前面的`plot_losses`函数使用我们模型的`history`对象简单地绘制了训练损失和验证损失。回想一下，这是一个默认回调，它提供对包含在会话中计算的训练和验证损失的字典的访问:

```
def plot_losses(network):
    plt.plot(network.history['loss'], label='loss')
    plt.plot(network.history['val_loss'], label='val loss')
    plt.legend()
    plt.show()
```

接下来，我们将使用`plot_predictions`函数在我们隐蔽的测试集上绘制出模型的预测，并将它们叠加在我们测试集的实际标签上。这在精神上类似于我们之前所做的一步预测。现在唯一的区别是，我们将通过我们的网络提前三个时间步预测趋势，如下所示:

```
def plot_predictions(model, y_test=y_test):

    preds = model.predict(x_test)
    plt.figure(figsize = (12,6))
    plt.plot(scaler.inverse_transform(preds.reshape(-1,1)), 
             label='generated', color='orange')
    plt.plot(scaler.inverse_transform(y_test.reshape(-1,1)),   
             label='Actual')
    plt.legend()
    plt.show()
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 训练模型

最后，我们构建一个训练函数，它将帮助我们启动每个网络的训练会话，保存每个时期的模型权重，并在训练会话停止时可视化模型性能。

该函数可以获取模型列表，并对每个模型执行所描述的步骤。因此，在运行以下代码单元后，准备好进行一次简短/广泛的漫步(取决于您的硬件配置):

```
def train_network(list, x_train, y_train, epochs=5):
    for net in list:               

        network_name = str(net).split(' ')[1]
        filepath = network_name + "_epoch-{epoch:02d}-loss-
                   {loss:.4f}-.hdf5"
        print('Training:', network_name)

        checkpoint = ModelCheckpoint(filepath, monitor='loss', 
                     verbose=0, save_best_only=True, mode='min')
        callbacks_list = [checkpoint] 
        model = net()                  

        network = model.fit(x_train, y_train,
                            validation_data=(x_test, y_test),
                            epochs=epochs,
                            batch_size=64,
                            callbacks=callbacks_list)
        model.summary()
        plot_predictions(model, y_test)

    return network, model

all_networks = [feed_forward, simple_gru, simple_lstm, lstm_stacked]
train_network(all_networks, x_train, y_train, epochs=50)
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 可视化结果

最后，我们将显示模型对实际价格的预测，如下图所示。注意，虽然简单的 LSTM 执行得最好(MAE 为 0.0809)，但是它与简单的前馈神经网络非常接近，该前馈神经网络通过设计具有比 LSTM 网络更少的可训练参数。

为什么你可能会想。虽然 LSTMs 非常擅长编码复杂的时间相关信号，但这些信号首先必须存在于我们的数据中:

![](Images/9a5f02c4-8376-4e8e-b919-06aabdc980c1.png)

在预测未来时，通过查看过去的七个中间价只能传递这么多信息。在我们的例子中，似乎我们的 LSTM 为预测任务所能召唤的表征类型或多或少与前馈网络所召唤的表征相匹配。在这种情况下，LSTM 可能会模拟许多复杂的信号，但它们似乎不在我们的数据集中。例如，在预测 *x [t + 3]* 的标签时，我们并没有按照设计纳入任何关于在时间 *t+1* 或 *t+2* 市场发生了什么的信息。此外，除了过去的中期股票价格之外，还可能存在与股票市场的未来运动更好相关的变量。举例来说，社交媒体情绪(在 Twitter 上，读作:[https://arxiv.org/pdf/1010.3003.pdf](https://arxiv.org/pdf/1010.3003.pdf))已经被证明与提前 7 天的股票价格走势相关联！事实证明，获胜的情绪是冷静，而不是快乐或神经质，这与一周前的市场走势最吻合。因此，与基线模型相比，包含代表其他类型和信息源的特征可能有助于提高我们的 LSTM 的性能。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 结束语

请注意，这并不一定意味着所有行业的所有股票的走势都可以通过纳入社交媒体数据来更好地预测。然而，它确实说明了我们的观点，即基于启发式的特征生成有一些空间，这可能允许利用额外的信号来获得更好的预测结果。为了对我们的实验提供一些结论，我们还注意到简单 GRU 和堆叠 LSTMs 都具有更平滑的预测曲线，并且不太可能受噪声输入序列的影响。他们在保持股票的总体趋势方面表现得非常出色。这些模型的误差精度(用预测值和实际值之间的平均误差进行评估)告诉我们，它们的性能比前馈网络和简单 LSTM 稍差。然而，根据具体的使用情况，我们可能更喜欢使用曲线更平滑的模型来进行决策，而不是噪声更大的预测模型。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 摘要

在这一章中，我们深入探究了 LSTM 网络的内部运作。我们探索了与这些网络相关的概念和数学实现，了解了信息在 LSTM 细胞中是如何处理的，并使用了事件的短期和长期记忆。我们也看到了这个网络之所以得名的原因，它擅长在很远的时间间隔内保存相关的细胞状态。虽然我们讨论了该架构的一些变体，如窥视孔连接，但它很少出现在最常见的 LSTM 候选场景中。虽然我们用一个简单的时间序列数据集进行了演示，但是我们强烈建议您实现这个架构来解决您可能已经熟悉的其他问题(例如 IMDB 情感分类数据集)，并将结果与我们之前的工作进行比较。

LSTMs 在自然语言处理任务中表现出色。你可以尝试用维基百科电影数据集生成电影脚本，或者甚至尝试用 music21 库和一些带有训练歌曲的 MIDI 文件来生成音乐。

一些进一步的编码可以在这里找到:

*   **窥视孔伪代码**:【https://gist.github.com/EderSantana/f07fa7a0371d0e1c4ef1】T2

LSTMs 背后的理论概念仍然很有启发性——考虑到它们在各种顺序和非顺序任务中的出色表现，就更是如此。就 RNNs 而言，我们会成为 LSTMs 的终极冠军吗？不完全是。下一个伟大的想法之一，与 RNNs 领域相邻，来自注意力模型领域，在这里，我们，毫不夸张地说，试图引导我们的神经网络的注意力，同时它处理一系列信息。这种方法在图像字幕的情况下非常有用，因为我们需要将给定输入中图像的重要部分与连贯输出中必须包含的单词相关联。我们将在接下来的章节中更详细地探讨注意力模型这个话题。对于感兴趣的读者，你可以通过阅读一篇优秀的论文来跟进机器图像字幕的任务，*方等人* 2016 年发表的题为*带语义注意的图像字幕*。

然而，在下一章，我们将把注意力集中在神经网络和深度学习的另一部分:强化学习。这是机器学习的一个非常有趣的领域，研究人工智能体必须如何在设计好的环境中行动，才能累积最大化一些回报。这种方法可以应用于无数的用例，比如教机器做手术、开玩笑或玩视频游戏。拥有能够利用与人类相当(或超过)的身体或心理灵活性水平的机器，可以让我们建立非常复杂和智能的系统。这种系统维护与系统运行的环境相关的内部状态，并且能够在优化特定目标的同时，通过研究它们的动作对环境的影响来更新它们的内部状态。因此，每种行为组合都会触发不同的奖励信号，学习系统可以利用这些信号来提高自我。

正如我们将很快看到的那样，设计允许通过奖励信号得到强化的系统可以导致非常复杂的行为，使机器执行高度智能的行动，即使在人类倾向于占主导地位的地方。我想起了 AlphaGo 与 Lee Sedol(曾经受人尊敬的中国古代围棋世界冠军)的故事。随着 AlphaGo 系统在 2016 年以五比一击败其人类竞争者，这一事件本身与 IBM 的深蓝战胜加里·卡斯帕罗夫(1997 年)的胜利截然不同。许多观看过 AlphaGo 与 Lee Sedol 比赛的人看到了这台机器操作方式的一些特别之处。有些人甚至称之为直觉。

在下一章中，我们将看到这样的系统，在环境和可能的行动的一些相当简单的统计属性上操作，如何能产生美丽复杂的结果，有时超越我们自己的期望。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 练习

*   检查模型收敛所需的时间。不同型号差别大吗？
*   检查模型之间的训练和验证损失。你注意到了什么？
*   尝试缩小和扩大架构，注意这如何影响学习。
*   尝试不同的优化和损失指标，并注意这如何影响学习。
*   在用于情感分类的 IMBD 数据集上实现 LSTM。
*   在 Wikimovies 数据集上实现 LSTM，以构建角色/单词级别的语言模型并生成人工电影情节。
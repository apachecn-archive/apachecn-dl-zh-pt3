        

# 八、图像生成

在前面的章节中，我们学习了预测图像的类别和检测对象在整个图像中的位置。如果我们逆向工作，如果给我们一个类，我们应该能够生成一个图像。在这种情况下，我们试图创建看起来与原始图像非常相似的新图像，生成网络就派上了用场。

在本章中，我们将介绍以下配方:

*   使用对抗性攻击生成可以欺骗神经网络的图像
*   生成图像的 DeepDream 算法
*   图像间的神经风格转移
*   使用生成对抗网络生成数字图像
*   使用深度卷积 GAN 生成数字图像
*   使用深度卷积 GAN 的人脸生成
*   面临从一个到另一个的转变
*   对生成的图像执行矢量运算

        

# 介绍

在前面的章节中，我们确定了将图像分类到正确类别的最佳权重。图像的输出类别可以通过改变以下内容来更改:

*   将输入连接到输出图层的权重，而输入像素保持不变
*   权重保持不变时的输入像素值

在这一章中，我们将使用这两种技术来生成图像。

在对抗性攻击的案例研究中，神经类型转移和 DeepDream 将利用改变输入像素值的技术。在涉及**生成对抗网络** ( **甘**)的技术中，我们将利用改变将输入像素值连接到输出的某些权重的技术。

本章中的前三个案例研究将利用更改输入像素值的技术，而其余案例研究将利用连接输入和输出的权重的更改。

        

# 使用对抗性攻击生成可以欺骗神经网络的图像

为了理解如何对图像进行对抗性攻击，让我们首先理解如何使用迁移学习进行常规预测，然后我们将弄清楚如何调整输入图像，以便图像的类别完全不同，即使我们几乎没有改变输入图像。

        

# 做好准备

让我们看一个例子，在这个例子中，我们将尝试识别图像中对象的类别:

1.  阅读一只猫的图像
2.  对图像进行预处理，使其能够被传递到初始网络
3.  导入预先培训的 Inception v3 模型
4.  预测图像中存在的对象的类别
5.  该图像将被预测为一只波斯猫，因为 Inception v3 在预测属于 ImageNet 类之一的对象方面表现良好

当前的任务是改变图像，使其符合以下两个标准:

*   使用相同网络的新图像的预测应该是具有非常高概率的非洲象
*   人类在视觉上应该无法区分新图像和原始图像

为此，我们将遵循以下策略:

1.  定义损失函数:
    *   损失是图像(波斯猫的)属于非洲象类的概率
    *   损失越大，我们就离目标越近
    *   因此，在这种情况下，我们将最大化我们的损失函数
2.  计算相对于输入变化的损耗变化梯度:
    *   这一步有助于理解将输出移向目标的输入像素
3.  基于计算的梯度更新输入图像:
    *   确保原始图像中的像素值在最终图像中的平移不超过 3 个像素
    *   这确保了生成的图像与原始图像无法区分
4.  重复步骤 2 和步骤 3，直到更新图像的预测是置信度至少为 0.8 的非洲象

        

# 怎么做...

让我们继续用代码实现这个策略(代码文件在 GitHub 中以`Adversarial_attack.ipynb`的形式提供):

1.  阅读一只猫的图像:

```py
import matplotlib.pyplot as plt
%matplotlib inline
img = cv2.imread('/content/cat.JPG')
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img = cv2.resize(img, (299,299))
plt.imshow(img)
plt.axis('off')
```

图像的情节看起来如下:

![](Images/33c46965-bc81-4b5e-aec1-f52dacb165dc.png)

2.  对图像进行预处理，以便随后可以将其传递到初始网络:

```py
original_image = cv2.resize(img,(299,299)).astype(float)
original_image /= 255.
original_image -= 0.5
original_image *= 2.
original_image = np.expand_dims(original_image, axis=0)
```

3.  导入预训练模型:

```py
import numpy as np
from keras.preprocessing import image
from keras.applications import inception_v3
model = inception_v3.InceptionV3()
```

4.  预测图像中存在的对象的类别:

```py
predictions = model.predict(original_image)
predicted_classes = inception_v3.decode_predictions(predictions, top=1)
imagenet_id, name, confidence = predicted_classes[0][0]
print("This is a {} with {:.4}% confidence".format(name, confidence * 100))
```

上述代码会产生以下结果:

```py
" This is a Persian_cat with 95.45% confidence"
```

5.  定义输入和输出:

```py
model = inception_v3.InceptionV3()
model_input_layer = model.layers[0].input
model_output_layer = model.layers[-1].output
```

`model_input_layer`是模型的输入，`model_output_layer`是输入图像的各种类别的概率(softmax 激活的最后一层)。

6.  设定原始图像的更改限制:

```py
max_change_above = np.copy(original_image) + 0.01
max_change_below = np.copy(original_image) - 0.01
hacked_image = np.copy(original_image)
```

在前面的代码中，我们指定了原始图像可以更改的限制。

7.  初始化成本函数，使得要伪造的对象类型是非洲象(预测向量中的第 386 ^个索引值):

```py
learning_rate = 0.1
object_type_to_fake = 386
cost_function = model_output_layer[0, object_type_to_fake]
```

`model_output_layer`的输出是感兴趣图像的各种类别的概率。在这种情况下，我们指定代价函数将由我们试图将对象伪装成的对象的索引位置决定。

8.  初始化成本相对于输入的梯度函数:

```py
gradient_function = K.gradients(cost_function, model_input_layer)[0]
```

该代码计算`cost_function`相对于`model_input_layer`(即输入图像)变化的梯度。

9.  根据输入映射成本和梯度函数:

```py
grab_cost_and_gradients_from_model = K.function([model_input_layer], [cost_function, gradient_function])
cost = 0.0
```

在前面的代码中，我们计算了`cost_function`的值(图像属于非洲象类的概率)和相对于输入图像的梯度。

10.  根据梯度不断更新输入图像，直到得到的图像是非洲象的概率至少为 80%:

```py
while cost < 0.80:
    cost, gradients = grab_cost_and_gradients_from_model([hacked_image, 0])
    hacked_image += gradients * learning_rate
    hacked_image = np.clip(hacked_image, max_change_below, max_change_above)
    print("Model's predicted likelihood that the image is an African elephant: 
{:.8}%".format(cost * 100))
```

在前面的代码中，我们获得了对应于输入图像(`hacked_image`)的成本和梯度。此外，我们通过梯度(乘以学习率)来更新输入图像。最后，如果被篡改的图像超过了输入图像的最大变化阈值，我们将对其进行裁剪。

不断循环这些步骤，直到输入图像的概率至少为 0.8。

波斯猫图像被检测为非洲象图像的概率在增加的时期内的变化如下:

```py
epochs = range(1, len(prob_elephant) + 1)
plt.plot(epochs, prob_elephant, 'b')
plt.title('Probability of African elephant class')
plt.xlabel('Epochs')
plt.ylabel('Probability')
plt.grid('off')
```

属于非洲象类的修改图像的概率变化如下:

![](Images/a8c81887-f7bb-4364-8ea0-27f4321ada37.png)

11.  预测更新图像的类别:

```py
model.predict(hacked_image)[0][386]
```

`predict`方法的输出是 0.804，它提供了修改后的图像属于非洲象类的概率。

12.  对更新后的输入图像进行去处理(因为它经过了缩放的预处理),以便它可以被可视化:

```py
hacked_image = hacked_image/2
hacked_image = hacked_image + 0.5
hacked_image = hacked_image*255
hacked_image = np.clip(hacked_image, 0, 255).astype('uint8')

plt.subplot(131)
plt.imshow(img)
plt.title('Original image')
plt.axis('off')
plt.subplot(132)
plt.imshow(hacked_image[0,:,:,:])
plt.title('Hacked image')
plt.axis('off')
plt.subplot(133)
plt.imshow(img - hacked_image[0,:,:,:])
plt.title('Difference')
plt.axis('off')
```

原始图像、修改的(被篡改的)图像以及两个图像之间的差异的组合打印如下:

![](Images/1db1140a-75c9-4b31-9012-aeba89a7bb24.png)

请注意，输出现在在视觉上与原始图像无法区分。

有趣的是，在原始图像的像素值几乎没有任何变化的情况下，我们愚弄了神经网络(inception v3 模型)，以至于它现在预测了不同的类别。这是一个很好的例子，说明了如果用来做出预测的算法暴露给那些可以构建图像来欺骗系统的用户，您可能会遇到的一些安全缺陷。

        

# 生成图像的 DeepDream 算法

在上一节中，我们稍微调整了输入图像的像素。在这一节中，我们将对输入图像进行一些调整，这样我们就可以得到一个仍然是相同物体的图像，但是比原始图像更有艺术感。这种算法形成了使用神经网络的风格转换技术的主干。

让我们通过直觉了解一下 DeepDream 是如何工作的。

我们将通过一个预先训练好的模型(在这个例子中是 VGG19)传递我们的图像。我们已经了解到，根据输入图像，预训练模型中的某些过滤器激活最多，而某些过滤器激活最少。

我们将提供我们最想激活的神经网络层。

神经网络调整输入像素值，直到我们获得所选层的最大值。

但是，我们也将确保最大可能激活不超过某个值，因为在这种情况下，结果图像可能会与原始图像非常不同。

        

# 做好准备

有了这种直觉，让我们来看看实现 DeepDream 算法的步骤:

1.  选择您最想激活的神经网络层，并为这些层对总损失计算的贡献量分配权重。
2.  当图像通过给定图层时，提取该图层的输出，并计算每个图层的损失值:
    *   当该层中的图像输出的平方和最大时，图像最大程度地激活该层
3.  提取输入像素值相对于损失的变化梯度。
4.  根据上一步提取的梯度更新输入像素值。
5.  为更新的输入像素值提取所有所选图层的损失值(激活的平方和)。
6.  如果损失值(激活平方的加权和)大于预定义的阈值，则停止更新图像。

        

# 怎么做...

让我们用代码实现这些步骤(代码文件在 GitHub 中以`Deepdream.ipynb`的形式提供):

1.  导入相关包并导入映像:

```py
import keras.backend as K
import multiprocessing
import tensorflow as tf
import warnings
from keras.applications.vgg19 import VGG19
from keras.applications.imagenet_utils import preprocess_input
from scipy.optimize import minimize
from skimage import img_as_float, img_as_ubyte
from skimage.io import imread, imsave
from skimage.transform import pyramid_gaussian, rescale
import scipy
from keras.preprocessing import image
from keras.applications.vgg19 import preprocess_input
import matplotlib.pyplot as plt
%matplotlib inline
```

对图像进行预处理，以便将其传递给 VGG19 模型:

```py
def preprocess_image(image_path):
     img = image.load_img(image_path, target_size=(img_nrows, img_ncols))
     img = image.img_to_array(img)
     img = np.expand_dims(img, axis=0)
     img[:, :, :, 0] -= 103.939
     img[:, :, :, 1] -= 116.779
     img[:, :, :, 2] -= 123.68
     img = img[:, :, :, ::-1]/255
     return img
```

构建一个对处理后的图像进行解处理的函数:

```py
def deprocess_image(x):
     x = x[:,:,:,::-1]*255
     x[:, :, :, 0] += 103.939
     x[:, :, :, 1] += 116.779
     x[:, :, :, 2] += 123.68
     x = np.clip(x, 0, 255).astype('uint8')
     return x
```

预处理图像:

```py
img = preprocess_image('/content/cat.png')
```

2.  定义影响总损失值计算的层:

```py
layer_contributions = {
    'block2_pool':0.3,
    'block5_pool': 1.5}
```

在前面的代码中，我们向您展示了我们将使用第二个和第五个池层，并分配这两个层将对整体损失值产生影响的权重。

3.  初始化损失函数:

```py
layer_dict = dict([(layer.name, layer) for layer in model.layers])
loss = K.variable(0.)
```

在前面的步骤中，我们初始化了模型中各层的损失值和字典。

计算激活的总损失值:

```py
for layer_name in layer_contributions:
     coeff = layer_contributions[layer_name]
     activation = layer_dict[layer_name].output
     scaling = K.prod(K.cast(K.shape(activation), 'float32'))
     loss += coeff * K.sum(K.square(activation)) / scaling
     print(loss)
```

在前面的代码中，我们循环遍历我们感兴趣的层(`layer_contributions`)，并记下我们分配给每个层的权重(`coeff`)。此外，我们正在计算感兴趣图层的输出(`activation`)，并在缩放后使用激活值的平方和更新损失值。

4.  初始化渐变值:

```py
dream = model.input
grads = K.gradients(loss, dream)[0]
```

`K.gradients`方法给出了相对于输入变化的损耗梯度`dream`。

5.  归一化梯度值，使梯度变化缓慢:

```py
grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)
```

6.  创建一个函数，将输入图像映射到损失值和损失值相对于输入像素值变化的梯度(其中输入图像为`dream`):

```py
outputs = [loss, grads]
fetch_loss_and_grads = K.function([dream], outputs)
```

7.  定义一个为给定输入图像提供损失和梯度值的函数:

```py
def eval_loss_and_grads(img):
      outs = fetch_loss_and_grads([img])
      loss_value = outs[0]
      grad_values = outs[1]
      return loss_value, grad_values
```

8.  基于多次迭代获得的损失和梯度值更新原始图像。

在下面的代码中，我们将图像循环 100 次。我们正在定义改变图像的学习率和可能发生的最大可能损失(图像改变):

```py
for i in range(100):
      learning_rate=0.01
      max_loss=20
```

在下面的代码中，我们提取图像的损失和梯度值，然后如果损失值大于定义的阈值，则停止图像中的变化:

```py
     loss_value, grad_values = eval_loss_and_grads(img)
     if max_loss is not None and loss_value > max_loss:
         print(loss_value)
         break
     print('...Loss value at', i, ':', loss_value)
```

在下面的代码中，我们根据渐变值更新图像，并对图像进行解处理和打印:

```py
    img += learning_rate * grad_values
    img2 = deprocess_image(img.copy())
    plt.imshow(img2[0,:,:,:])
    plt.axis('off')
    plt.show()
```

前面的代码生成了如下所示的图像:

![](Images/d34a9836-cc7c-49dd-8afb-fe8cc5ac2545.png)

请注意，上图中的波浪形图案是潜在的，因为这些图案可以最大限度地激活各种网络层。

在这里，我们看到了另一个扰动输入像素的应用，在这种情况下，它产生了一个稍微更艺术的图像。

        

# 图像间的神经风格转移

在之前的配方中，修改的像素值试图最大化过滤器激活。然而，它没有给我们指定图像样式的灵活性；在这种情况下，神经类型转移就派上了用场。

在神经风格转移中，我们有一个内容图像和一个风格图像，我们试图以这样一种方式组合这两个图像，即保留内容图像中的内容，同时保持风格图像的风格。

        

# 做好准备

神经风格转移的直觉如下。

我们尝试以类似于 DeepDream 算法的方式修改原始图像。但是，额外的一步是将损失值拆分为内容损失和样式损失。

内容丢失指的是生成的图像与内容图像有多大的不同。风格损失指的是风格图像与生成的图像的相关程度。

虽然我们提到损失是基于图像的差异来计算的，但在实践中，我们通过确保损失是使用图像的激活而不是原始图像来计算的，来稍微修改它。例如，当通过第二层时，第二层的内容损失将是内容图像和生成图像的激活之间的平方差。

虽然计算内容损失似乎很简单，但是让我们试着理解如何计算生成的图像和样式图像之间的相似性。

一种叫做 gram matrix 的技术出现了。Gram matrix 计算生成的图像和风格图像之间的相似度，计算如下:

![](Images/5754caec-464d-4b8e-a375-65df6ffdc898.png)

其中 *GM(l)* 是风格图像 *S* 和生成图像 *G* 在 *l* 层的克矩阵值。

格拉姆矩阵是矩阵与其自身的转置相乘的结果。

既然我们能够计算样式损失和内容损失，那么最终修改的输入图像是使总体损失最小化的图像，即样式和内容损失的加权平均值。

神经类型转移通过以下步骤实现:

1.  将图像传递给预先训练好的模型。
2.  提取预定义图层的图层值。
3.  将生成的图像初始化为与内容图像相同。
4.  将生成的图像传递给模型，并在完全相同的层提取其值。
5.  计算内容损失。
6.  将样式图像传递到模型的多个层，并计算样式图像的 gram 矩阵值。
7.  将生成的图像通过样式图像通过的相同层，并计算其对应的 gram 矩阵值。
8.  提取两幅图像的 gram 矩阵值的平方差。这将是风格的损失。
9.  总体损失将是样式损失和内容损失的加权平均值。
10.  最小化总损失的输入图像将是最终感兴趣的图像。

        

# 怎么做...

1.  导入需要组合成艺术形象的相关包和内容、风格图片，如下(代码文件在 GitHub 中为`Neural_style_transfer.ipynb`):

```py
from keras.preprocessing.image import load_img, save_img, img_to_array
import numpy as np
import time
from keras.applications import vgg19
from keras.applications.imagenet_utils import preprocess_input
from keras import backend as K
import tensorflow as tf
import keras

style_img = cv2.imread('/content/style image.png')
style_img = cv2.cvtColor(style_img, cv2.COLOR_BGR2RGB)
style_img = cv2.resize(style_img,(224,224))

base_img = cv2.imread('/content/cat.png')
base_img = cv2.cvtColor(base_img, cv2.COLOR_BGR2RGB)
base_img = cv2.resize(base_img,(224,224))
```

样式和基础图像如下所示:

![](Images/6e087838-928d-476e-b7e8-a1153df3d213.png) ![](Images/470f0a29-7b89-40ca-a2ba-33d574883c08.png)

2.  初始化`vgg19`模型，以便图像可以通过其网络传递:

```py
from keras.applications import vgg19
model = vgg19.VGG19(include_top=False, weights='imagenet')
```

3.  重塑基础图像并提取 VGG19 模型的`block3_conv4`层的特征值:

```py
base_img = base_img.reshape(1,224,224,3)/255
from keras import backend as K
get_3rd_layer_output = K.function([model.layers[0].input],
[model.get_layer('block3_conv4').output])
layer_output_base = get_3rd_layer_output([base_img])[0]
```

在前面的代码中，我们定义了一个函数，它获取输入图像并提取预定义层的输出。

4.  定义需要提取的层，以计算内容和样式损失，以及需要分配给每个层的相应权重:

```py
layer_contributions_content = {'block3_conv4': 0.1}

layer_contributions_style =    { 'block1_pool':1,
                                 'block2_pool':1,
                                 'block3_conv4':1}
```

在前面的代码中，我们定义了计算内容和样式损失的层，并分配了与每个层产生的损失相关的权重。

5.  定义 gram 矩阵和风格损失函数:

在以下代码中，我们定义了一个函数，该函数将 gram matrix 输出计算为通过拼合图像获得的要素的点积:

```py
def gram_matrix(x):
    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))
    gram = K.dot(features, K.transpose(features))
    return gram
```

在下面的代码中，我们按照*准备好*一节中指定的风格损失公式计算风格损失:

```py
def style_loss(style, combination):
    S = gram_matrix(style)
    C = gram_matrix(combination)
    channels = 3
    size = img_nrows * img_ncols
    return K.sum(K.square(S - C)) / (4\. * (pow(channels,2)) * (pow(size,2)))
```

6.  初始化损失值函数:

计算内容损失:

```py
layer_dict = dict([(layer.name, layer) for layer in model.layers])
loss = K.variable(0.)
for layer_name in layer_contributions_content:
      coeff = layer_contributions_content[layer_name]
      activation = layer_dict[layer_name].output
      scaling = K.prod(K.cast(K.shape(activation), 'float32'))
      loss += coeff * K.sum(K.square(activation - layer_output_base)) / scaling
```

在前面的代码中，我们根据计算内容损失的层的损失来更新损失值。请注意，`layer_output_base`是我们通过内容层传递原始基础图像时的输出(如步骤 3 中所定义)。

激活(基于修改的图像)和`layer_output_base`(基于原始图像)之间的差异越大，与图像相关的内容损失越大。

计算风格损失:

```py
for layer_name in layer_contributions_style:
    coeff = layer_contributions_style[layer_name]
    activation = layer_dict[layer_name].output
    scaling = K.prod(K.cast(K.shape(activation), 'float32'))
    style_layer_output = K.function([model.layers[0].input],
model.get_layer(layer_name).output])
    layer_output_style = style_layer_output([style_img.reshape(1,224,224,3)/255])[0][0]
    loss += style_loss(layer_output_style, activation[0])
```

在前面的代码中，我们计算样式损失的方式与计算内容损失的方式相同，但是是在不同的层上，并且使用了我们构建的不同的自定义函数:`style_loss`。

7.  构建将输入图像映射到损失值和相应梯度值的函数:

```py
dream = model.input
grads = K.gradients(loss, dream)[0]
grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)
outputs = [loss, grads]
fetch_loss_and_grads = K.function([dream], outputs)

def eval_loss_and_grads(img):
      outs = fetch_loss_and_grads([img])
      loss_value = outs[0]
      grad_values = outs[1]
      return loss_value, grad_values
```

前面的代码以非常类似于 *DeepDream 算法的方式获取损失和梯度值，以生成图像*配方。

8.  运行多个时期的模型:

```py
for i in range(2000):
      step=0.001
      loss_value, grad_values = eval_loss_and_grads(img)
      print('...Loss value at', i, ':', loss_value)
      img -= step * grad_values
      if(i%100 ==0):
            img2 = img.copy().reshape(224,224,3)
            img2 = np.clip(img2*255, 0, 255).astype('uint8')
            plt.imshow(img2)
            plt.axis('off')
            plt.show()
```

前面的代码生成了一个由内容和样式图像组合而成的图像:

![](Images/03042fd3-6db8-40c1-bfe4-071359915494.png)

由于选择不同的层来计算内容和样式损失，并且在它们各自的样式或内容贡献中为层的系数分配不同的权重，因此最终生成的图像可能是不同的。

在前面的三个案例研究中，我们看到了如何通过改变输入像素值来生成新图像。在本章的其余部分，我们将采用不同的方法来生成新的图像:使用 GANs。

        

# 使用生成对抗网络生成数字图像

GAN 使用一组神经网络来产生一个新的图像，该图像看起来与原始图像非常相似。它在图像生成方面有多种应用，GAN 研究领域的进展非常快，很难将图像与真实图像区分开来。在本节中，我们将了解 GAN 的基础知识——它是如何工作的，以及 GAN 变体之间的差异。

GAN 包括两个网络:发生器和鉴别器。生成器尝试生成图像，鉴别器尝试确定作为输入给出的图像是真实图像还是生成的(伪造)图像。

为了获得进一步的直觉，让我们假设鉴别器模型试图从包含数千个人脸图像和非人脸图像的数据集中，将图片分类为人脸图像，或者不是人脸。

一旦我们训练模型来分类人脸和非人脸，如果我们向模型展示新的人脸，它仍然会将其分类为人脸，而它会学习将非人脸分类为非人脸。

生成器网络的任务是生成看起来与原始图像集非常相似的图像，以至于鉴别者可能会被愚弄，以为生成的图像实际上来自原始数据集。

        

# 做好准备

我们将采用以下策略来生成图像:

1.  使用生成器网络生成合成图像，在初始步骤中，它是通过将一组噪声值整形为我们的图像的形状而生成的有噪声的图像。

2.  将生成的图像与原始图像集连接，其中鉴别器预测每个图像是生成的图像还是原始图像-这确保鉴别器经过训练:
    *   注意，鉴别器网络的权重在该迭代中被训练
    *   鉴别器网络的损耗是图像的预测值和实际值的二进制交叉熵
    *   生成图像的输出值将是假的(0)，而原始图像的值将是实的(1)
3.  既然鉴频器已经训练了一次迭代，那么训练一个生成器网络来修改输入噪声，使其看起来更像真实图像，而不是合成图像——这种图像有可能欺骗鉴频器。该过程经历以下步骤:
    1.  输入噪声通过发生器网络，该网络将输入整形为图像。
    2.  从发生器网络生成的图像然后通过鉴别器网络，但是，请注意，鉴别器网络中的权重在此迭代中被冻结，因此它们不会在此迭代中被训练(因为它们已经在步骤 2 中被训练)。
    3.  从鉴别器输出的生成图像的值将是实数(1 ),因为它的任务是欺骗鉴别器。
    4.  生成器网络的损耗是来自输入图像和实际值(对于所有生成的图像，实际值为 1)的预测的二进制交叉熵，这确保了生成器网络权重得到微调:
        *   请注意，鉴别器网络权重在此步骤中被冻结
        *   冻结鉴别器确保了发生器网络从鉴别器提供的反馈中学习
    5.  多次重复这些步骤，直到生成真实的图像。

        

# 怎么做...

在*对抗攻击以欺骗神经网络部分*中，我们讨论了如何生成与原始图像非常相似的图像的策略。在本节中，我们将实现从 MNIST 数据集生成手指图像的过程(代码文件在 GitHub 中以`Vanilla_and_DC_GAN.ipynb`的形式提供):

1.  导入相关包:

```py
import numpy as np
from keras.datasets import mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization
from keras.layers.advanced_activations import LeakyReLU
from keras.models import Sequential
from keras.optimizers import Adam
import matplotlib.pyplot as plt
%matplotlib inline
plt.switch_backend('agg')
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Reshape
from keras.layers.core import Activation
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import UpSampling2D
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.layers.core import Flatten
from keras.optimizers import SGD
from keras.datasets import mnist
import numpy as np
from PIL import Image
import argparse
import math
```

2.  定义参数:

```py
shape = (28, 28, 1)
epochs = 400
batch = 32
save_interval = 100
```

3.  定义发生器和鉴别器网络:

```py
def generator():
    model = Sequential()
    model.add(Dense(256, input_shape=(100,)))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(512))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(1024))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(28 * 28 * 1, activation='tanh'))
    model.add(Reshape(shape))
    return model
```

对于生成器，我们正在构建一个模型，该模型采用一个形状为 100 维的噪声向量，并将它转换为一个形状为 28 x 28 x 1 的图像。注意，我们在模型中使用了`LeakyReLU`激活。发电机网络概述如下:

![](Images/bee45c41-5ea7-4026-b15b-ef627ff7902a.png)

在下面的代码中，我们构建了一个鉴别器模型，在该模型中，我们获取一个形状为 28 x 28 x 1 的输入图像，并生成一个 1 或 0 的输出，该输出指示输入图像是原始图像还是伪图像:

```py
def discriminator():
     model = Sequential()
     model.add(Flatten(input_shape=shape))
     model.add(Dense((28 * 28 * 1), input_shape=shape))
     model.add(LeakyReLU(alpha=0.2))
     model.add(Dense(int((28 * 28 * 1) / 2)))
     model.add(LeakyReLU(alpha=0.2))
     model.add(Dense(1, activation='sigmoid'))
     return model
```

鉴别器网络概述如下:

![](Images/cf8f01e2-d615-49af-9cae-12915b038e85.png)

编译生成器和鉴别器模型:

```py
Generator = generator()
Generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8))
```

```py
Discriminator = discriminator()
Discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8),metrics=['accuracy'])
```

4.  定义堆叠发生器鉴别器模型，该模型有助于优化发生器的权重，同时冻结鉴别器网络的权重。堆叠发生器鉴别器将我们传递给模型的随机噪声作为输入，并使用发生器网络将该噪声转换为 28 x 28 形状的图像。此外，它还确定 28 x 28 图像是真实图像还是伪造图像:

```py
def stacked_generator_discriminator(D, G):
    D.trainable = False
    model = Sequential()
    model.add(G)
    model.add(D)
    return model

stacked_generator_discriminator = stacked_generator_discriminator(Discriminator, Generator)
stacked_generator_discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8))
```

5.  定义一个函数来绘制生成的图像:

```py
def plot_images(samples=16, step=0):
    noise = np.random.normal(0, 1, (samples, 100))
    images = Generator.predict(noise)
    plt.figure(figsize=(10, 10))
    for i in range(images.shape[0]):
        plt.subplot(4, 4, i + 1)
        image = images[i, :, :, :]
        image = np.reshape(image, [28, 28])
        plt.imshow(image, cmap='gray')
        plt.axis('off')
    plt.tight_layout()
    plt.show()
```

6.  提供输入图像:

```py
(X_train, _), (_, _) = mnist.load_data()
X_train = (X_train.astype(np.float32) - 127.5) / 127.5
X_train = np.expand_dims(X_train, axis=3)
```

我们正在丢弃`y_train`数据集，因为我们不需要输出标签，因为我们的模型基于给定的图像集(即`X_train`)生成新图像。

7.  通过在多个时期运行图像来优化图像:

在下面的代码中，我们正在获取真实图像(`legit_images`)并生成假图像(`synthetic_images`)数据，我们将通过修改作为输入的噪声数据(`gen_noise`)来尝试将其转换为真实图像，如下所示:

```py
for cnt in range(4000):
      random_index = np.random.randint(0, len(X_train) - batch / 2)
      legit_images = X_train[random_index: random_index + batch // 2].reshape(batch // 2, 28, 28, 1)
      gen_noise = np.random.normal(-1, 1, (batch // 2, 100))/2
      synthetic_images = Generator.predict(gen_noise)
```

在下面的代码中，我们正在训练鉴别器(使用`train_on_batch`方法)，在输出中，真实图像的值预计为 1，虚假图像的值预计为零:

```py
x_combined_batch = np.concatenate((legit_images, synthetic_images))
y_combined_batch = np.concatenate((np.ones((batch // 2, 1)), np.zeros((batch // 2, 1))))
d_loss = Discriminator.train_on_batch(x_combined_batch, y_combined_batch)
```

在下面的代码中，我们准备了一组新的数据，其中`noise`是输入，`y_mislabeled`是输出，用于训练生成器(注意，输出与我们训练鉴别器时的输出正好相反):

```py
noise = np.random.normal(-1, 1, (batch, 100))/2
y_mislabled = np.ones((batch, 1))
```

在下面的代码中，我们训练生成器和鉴别器的堆叠组合，其中鉴别器权重被冻结，而生成器的权重被更新以最小化损失值。生成器的任务是生成可以欺骗鉴别器输出值 1:

```py
g_loss = stacked_generator_discriminator.train_on_batch(noise, y_mislabled)
```

在以下代码中，我们将查看不同时期的发电机损耗和鉴频器损耗的输出:

```py
logger.info('epoch: {}, [Discriminator: {}], [Generator: {}]'.format(cnt, d_loss[0], g_loss))
    if cnt % 100 == 0:
          plot_images(step=cnt)
```

![](Images/135e0b94-6745-46c3-8bd1-e9adfdcd07b4.jpg)

鉴别器和发生器损耗随增加的历元的变化如下:

![](Images/37f6d676-e678-494b-a8e3-9856cbc10712.png)

请注意，前面的输出在生成的图像的逼真程度方面有很大的改进空间。

        

# 还有更多...

我们在这里看到的输出也是模型架构的一个功能。例如，在模型的不同层中改变激活函数以进行 tanh，并查看结果输出看起来如何，以了解结果生成的图像看起来像什么。

        

# 使用深度卷积 GAN 生成图像

在上一节中，我们讨论了如何使用标准发生器和鉴别器网络来产生数字。然而，我们可以有一个场景，其中网络可以通过使用卷积架构更好地学习图像中的特征，因为 CNN 中的滤波器学习图像中的特定细节。**深度卷积生成对抗网络** ( **DCGANs** )利用这种现象提出新的图像。

        

# 怎么做...

虽然 DCGAN 如何工作的直觉与 GAN(我们在之前的配方中使用过)非常相似，但主要区别在于 DCGAN 的生成器和鉴别器的架构，如下所示(代码文件在 GitHub 中以`Vanilla_and_DC_GAN.ipynb`的形式提供):

```py
def generator():
    model = Sequential()
    model.add(Dense(input_dim=100, output_dim=1024))
    model.add(Activation('tanh'))
    model.add(Dense(128*7*7))
    model.add(BatchNormalization())
    model.add(Activation('tanh'))
    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(64, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(1, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    return model

def discriminator():
    model = Sequential()
    model.add(Conv2D(64, (5, 5),padding='same',input_shape=(28, 28, 1)))
    model.add(Activation('tanh'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(128, (5, 5)))
    model.add(Activation('tanh'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(1024))
    model.add(Activation('tanh'))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))
    return model
```

注意，在 DCGAN 中，我们对输入数据执行了多次卷积和汇集操作。

如果我们重新运行我们在普通 GAN 中执行的完全相同的步骤(*生成对抗网络以生成图像*配方)，但是这次使用由卷积和池化架构(以及 DCGAN)定义的模型，我们得到以下生成的图像:

![](Images/2875a289-9afe-430e-8502-c63a9c999541.png)

发生器和鉴别器损耗值在增加的时期内的变化如下:

![](Images/9a924e72-de38-489a-93be-b1fac122e4ce.png)

我们可以看到，虽然其他一切都保持不变，只有模型架构发生了变化，但通过 DCGAN 得到的图像比普通 GAN 的结果更加真实。

        

# 使用深度卷积 GAN 的人脸生成

到目前为止，我们已经看到了如何生成新图像。在本节中，我们将学习如何从现有的人脸数据集中生成一组新的人脸。

        

# 做好准备

我们将在本练习中采用的方法与我们在使用 *深度卷积 GAN* 配方生成图像的*中采用的方法非常相似:*

1.  收集包含多张人脸图像的数据集。
2.  开始时生成随机图像。

3.  通过向鉴别器显示人脸和随机图像的组合来训练鉴别器，其中期望鉴别器区分实际人脸图像和生成的人脸图像。
4.  一旦训练了鉴别器模型，就将其冻结并调整随机图像，使得鉴别器现在将属于原始人脸图像的更高概率分配给调整后的随机图像。
5.  通过多次迭代重复前面两个步骤，直到生成器不再被训练。

        

# 怎么做...

人脸生成用如下代码实现(代码文件在 GitHub 中为`Face_generation.ipynb`):

1.  下载数据集。GitHub 中提供了推荐下载的数据集和相关代码。图像示例如下:

![](Images/cba9b1ce-cca6-459e-b691-2a0b84628ee0.png)

2.  定义模型架构:

```py
def generator():
    model = Sequential()
    model.add(Dense(input_dim=100, output_dim=1024))
    model.add(Activation('tanh'))
    model.add(Dense(128*7*7))
    model.add(BatchNormalization())
    model.add(Activation('tanh'))
    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(64, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(1, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    return model
```

请注意，前面的代码与我们在*深度卷积生成对抗网络*配方中构建的生成器相同:

```py
def discriminator():
    model = Sequential()
    model.add(Conv2D(64, (5, 5),padding='same',input_shape=(28, 28, 1)))
    model.add(Activation('tanh'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(128, (5, 5)))
    model.add(Activation('tanh'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(1024))
    model.add(Activation('tanh'))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))
    return model
```

请注意，前面的架构与我们在*使用深度卷积 GAN 生成图像*部分构建的架构相同:

```py
def stacked_generator_discriminator(D, G):
    D.trainable = False
    model = Sequential()
    model.add(G)
    model.add(D)
    return model
```

3.  定义加载、预处理和去处理图像以及绘制图像的实用函数:

```py
def plot_images(samples=16, step=0):
    noise = np.random.normal(0, 1, (samples, 100))
    images = deprocess(Generator.predict(noise))
    plt.figure(figsize=(5, 5))
    for i in range(images.shape[0]):
        plt.subplot(4, 4, i + 1)
        image = images[i, :, :, :]
        image = np.reshape(image, [56, 56,3])
        plt.imshow(image, cmap='gray')
        plt.axis('off')
    plt.tight_layout()
    plt.show()
```

请注意，我们将图像的大小调整为较小的形状，以便需要通过模型调整的参数数量最少:

```py
def preprocess(x):
    return (x/255)*2-1

def deprocess(x):
    return np.uint8((x+1)/2*255)
```

4.  导入数据集并对其进行预处理:

```py
from skimage import io
import os
import glob
root_dir = '/content/lfwcrop_color/'
all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))
```

在以下代码中，我们将创建输入数据集并将其转换为数组:

```py
import numpy as np
X_train = []
for i in range(len(all_img_paths)):
  img = cv2.imread(all_img_paths[i])
  X_train.append(preprocess(img))
len(X_train)
X_train = np.array(X_train)
```

5.  编译生成器、鉴别器和堆叠生成器鉴别器模型:

```py
Generator = generator()
Generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8))

Discriminator = discriminator()
Discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8),metrics=['accuracy'])

stacked_generator_discriminator = stacked_generator_discriminator(Discriminator, Generator)
stacked_generator_discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8))
```

6.  以非常类似于我们在*深度卷积生成对抗网络*配方中采用的方式，在多个时期运行模型:

```py
%matplotlib inline
$pip install logger
from logger import logger
for cnt in range(10000):
      random_index = np.random.randint(0, len(X_train) - batch / 2)
      legit_images = X_train[random_index: random_index + batch // 2].reshape(batch // 2, 56, 56, 3)
      gen_noise = np.random.normal(0, 1, (batch // 2, 100))
      syntetic_images = Generator.predict(gen_noise)
      x_combined_batch = np.concatenate((legit_images, syntetic_images))
      y_combined_batch = np.concatenate((np.ones((batch // 2, 1)), np.zeros((batch // 2, 1))))
      d_loss = Discriminator.train_on_batch(x_combined_batch, y_combined_batch)
      noise = np.random.normal(0, 1, (batch*2, 100))
      y_mislabled = np.ones((batch*2, 1))
      g_loss = stacked_generator_discriminator.train_on_batch(noise, y_mislabled)
      logger.info('epoch: {}, [Discriminator: {}], [Generator: {}]'.format(cnt, d_loss[0], g_loss))
      if cnt % 100 == 0:
          plot_images(step=cnt)
```

前面的代码生成如下所示的图像:

![](Images/c8296899-5777-40c5-ac1d-5f259a7dae53.png)

请注意，虽然这些图像看起来非常模糊，但图片是原始数据集中不存在的原始图片。通过改变模型架构和更深的层次，在这个输出中有很大的改进空间。

鉴频器和发生器损耗值在增加的时期内的变化如下:

![](Images/807a0f3c-24e4-42f7-87fa-48fffa9fff7e.png)

请注意，根据上图，我们可能希望为更少的历元数训练模型，以便发电机损耗不会很高。

        

# 面临从一个到另一个的转变

现在我们已经可以生成人脸了，让我们继续在生成的图像上执行一些矢量运算。

在这个练习中，我们将执行从一个人脸到另一个人脸的人脸生成过渡。

        

# 做好准备

我们将继续我们在*面部生成中使用深度卷积 GAN* 部分构建的图像生成模型。

假设我们希望看到一个生成的人脸图像过渡到另一个生成的人脸图像。通过将向量从第一向量(第一生成图像的向量)缓慢改变到第二向量(第二生成图像的向量)来实现该过程。你可以把每一个潜在的(向量)维度想象成代表了图像的某个方面。

我们将采取的策略如下:

1.  生成两幅图像
2.  在 10 个步骤中将第一个生成的图像转换为第二个生成的图像
3.  在第一步骤中，将权重 1 分配给第一生成图像，将权重 0 分配给第二生成图像
4.  在第二步中，将权重 0.9 分配给第一个生成的图像，将权重 0.1 分配给第二个生成的图像
5.  重复前面的步骤，直到我们为第一个生成的图像分配权重 0，为第二个生成的图像分配权重 1

        

# 怎么做...

我们将对我们在*准备好*部分中制定的策略进行编码，如下所示(代码文件在 GitHub 中以`Face_generation.ipynb`的形式提供):

1.  从随机噪声生成第一幅图像(注意，我们将从*使用深度卷积 GAN 生成人脸*部分的步骤 6 继续):

```py
gen_noise = np.random.normal(0, 1, (1, 100))
syntetic_images = Generator.predict(gen_noise)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
```

生成的图像如下所示:

![](Images/0f786cff-d1c3-4593-acf5-c2471595c8c2.png)

2.  从随机噪声生成第二图像:

```py
gen_noise2 = np.random.normal(0, 1, (1, 100))
syntetic_images = Generator.predict(gen_noise2)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.show() 
```

以下是上述代码片段的输出:

![](Images/f6450874-5966-4739-9766-ea1b6f6c4997.png)

3.  生成从第一图像获得第二图像的可视化；

```py
plt.figure(figsize=(10, 8))
for i in range(10):
  gen_noise3 = gen_noise + (gen_noise2 - gen_noise)*(i+1)/10
  syntetic_images = Generator.predict(gen_noise3)
  plt.subplot(1, 10, i+1)
  plt.imshow(deprocess(syntetic_images)[0])
  plt.axis('off')
```

我们将获得以下输出:

![](Images/dfcd4d0b-296b-45d5-b28a-8ad685a06a23.jpg)

注意，在前面的输出中，我们已经慢慢地将第一个图像转换为第二个图像。

        

# 对生成的图像执行矢量运算

既然我们已经理解了潜在向量表示在改变生成图像的结果中起着关键作用，那么让我们进一步用具有特定面部对齐的图像来建立我们的直觉。

        

# 做好准备

我们将采用以下策略对生成的图像执行矢量运算:

1.  基于 100 个向量值的随机噪声生成三幅图像
2.  确保三个图像中的两个生成了向左看的面，一个生成了向右看的面
3.  计算一个新的向量，该向量是沿相同方向对齐的图像的总和，再从沿相反方向对齐的图像中减去该向量
4.  根据上一步获得的结果向量生成图像

        

# 怎么做...

我们将对列出的策略进行编码，如下所示(代码文件在 GitHub 中以`Face_generation.ipynb`的形式提供)。注意，我们将从使用深度卷积 GAN 部分的*面部生成中的步骤 6 继续:*

1.  生成三个向量(通过改变生成的噪声，确保两个图像在一个方向上对齐，另一个在相反方向上对齐):

```py
gen_noise = np.random.normal(0, 1, (1, 100))
gen_noise2 = np.random.normal(0, 1, (1, 100))
gen_noise3 = np.random.normal(0, 1, (1, 100))
syntetic_images = Generator.predict(gen_noise4)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.show()
```

2.  绘制生成的图像:

```py
plt.subplot(131)
syntetic_images = Generator.predict(gen_noise)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 1')
plt.subplot(132)
syntetic_images = Generator.predict(gen_noise2)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 2')
plt.subplot(133)
syntetic_images = Generator.predict(gen_noise3)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 3')
```

生成的三幅图像如下:

![](Images/424f17c6-4b45-4a97-a375-f043c7af965f.png)

我们可以看到，图像 2 和 3 的脸看向右边，而图像 1 的脸看着正前方。

3.  对这些图像的矢量表示执行矢量运算，以查看结果:

```py
gen_noise4 = gen_noise + gen_noise2 - gen_noise3
syntetic_images = Generator.predict(gen_noise4)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.show()  
```

前面的代码生成一个面，如下所示:

![](Images/78804f8b-9305-493a-a5fb-fb140c532770.png)

前面的算法表明，生成图像的矢量算法(图像 1 的矢量+图像 2 的矢量-图像 3)具有直视前方的面部，从而加强了我们对潜在矢量表示工作的直觉。

        

# 还有更多...

我们仅仅触及了 GAN 的基础；有多种基于 GAN 的技术目前正变得流行。我们将讨论其中一些的应用:

*   想象一个场景，你涂鸦(画)一个物体的结构，这个物体以各种各样的形式出现。pix2pix 是一种有助于实现这一点的算法。
*   **Cycle GAN** :想象一个场景，你希望一个物体看起来像一个完全不同的物体(比如你希望一匹马的物体看起来像斑马，反之亦然)。您还希望确保图像的所有其他方面保持不变，除了对象的变化。在这种情况下，循环 GAN 就派上了用场。
*   BigGAN 是最近开发的一种技术，可以生成非常逼真的图像。
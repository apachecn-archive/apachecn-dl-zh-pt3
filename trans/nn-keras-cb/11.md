<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 构建循环神经网络

在前一章中，我们研究了将文本表示为向量的多种方法，然后在这些表示的基础上进行情感分类。

这种方法的一个缺点是我们没有考虑单词的顺序——例如，句子 *A 比 B 快*与 *B 比 A 快*具有相同的表示，因为两个句子中的单词完全相同，而单词的顺序不同。

**循环神经网络** ( **RNNs** )在需要保留词序的场景中派上了用场。在本章中，您将了解以下主题:

*   用 Python 从头开始构建 RNN 和 LSTM
*   实现用于情感分类的 RNN
*   实现用于情感分类的 LSTM
*   实现用于情感分类的堆叠 LSTM

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 介绍

RNN 可以用多种方式来设计。一些可能的方法如下:

![](Images/79db1776-f471-4fe6-89b0-67cbae844bfc.png)

底部的框是输入层，后面是隐藏层(作为中间的框)，顶部的框是输出层。一对一架构是典型的神经网络，在输入和输出层之间有一个隐藏层。不同架构的示例如下:

| **架构** | **例子** |
| 一对多 | 输入是图像，输出是图像的标题 |
| 多对一 | 输入是一部电影的评论(输入中有多个单词),输出是与评论相关联的情感 |
| 多对多 | 把一种语言的句子翻译成另一种语言的句子 |

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# RNN 建筑的直觉

当我们想在已知一系列事件的情况下预测下一个事件时，RNN 很有用。

一个例子是预测在*后面的单词，这是一个 _____* 。

假设，在现实中，句子是*这是一个例子*。

传统的文本挖掘技术将通过以下方式解决这个问题:

1.  对每个单词进行编码，同时为潜在的新单词提供额外的索引:

```
This: {1,0,0,0}
is: {0,1,0,0}
an: {0,0,1,0}
```

2.  对短语`This is an`进行编码:

```
This is an: {1,1,1,0}
```

3.  创建训练数据集:

```
Input --> {1,1,1,0}
Output --> {0,0,0,1}
```

4.  建立一个有输入和输出的模型

该模型的一个主要缺点是输入表示在输入句子中不变；不是`this is an`，就是`an is this`，或者是`this an is`。

但是，直观上，我们知道前面的每一个句子都是不同的，在数学上不能用相同的结构来表示。这需要不同的架构，如下所示:

![](Images/a4da81fc-763e-4ed2-b638-f3694aebd985.png)

在前面的体系结构中，句子中的每个单词进入输入框中的单个框中。然而，句子的结构将被保留，例如`this`进入第一个框，`is`进入第二个框，`an`进入第三个框。

顶部的输出框将是`example`的输出。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 解读 RNN

你可以把 RNN 想象成一种保存记忆的机制——记忆包含在隐藏层中。可以想象如下:

![](Images/ef7343c2-b306-43b0-8e2d-3dc8f10fa443.png)

右边的网络是左边网络的展开版本。右侧的网络在每个时间步长中获取一个输入，并在每个时间步长提取输出。但是，如果我们对第四个时间步长的输出感兴趣，我们将提供前三个时间步长的输入，第三个时间步长的输出是第四个时间步长的预测值。

请注意，在预测第三个时间步长的输出时，我们通过隐藏层合并前三个时间步长的值，隐藏层连接跨时间步长的值。

让我们来看看前面的图表:

*   **U** 权重表示连接输入层和隐藏层的权重
*   **W** 权重表示隐藏层到隐藏层的连接
*   **V** 权重表示隐藏层到输出层的连接

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 为什么要存储内存？

需要存储记忆，如在前面的例子中或者甚至在一般的文本生成中，下一个单词不一定仅仅依赖于前面的单词，而是依赖于单词前面的单词的上下文来预测。

鉴于我们看的是前面的单词，应该有办法把它们保存在记忆中，这样我们就能更准确地预测下一个单词。

而且，我们还应该有条理地记忆；也就是说，通常情况下，最近的单词比距离要预测的单词较远的单词更有助于预测下一个单词。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 用 Python 从头开始构建 RNN

在这个食谱中，我们将使用一个玩具例子从零开始构建一个 RNN，这样你就可以直观地了解 RNN 是如何帮助解决考虑事件(单词)顺序的问题的。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 做好准备

请注意，典型的 NN 有一个输入层，然后是隐藏层中的激活，然后是输出层中的 softmax 激活。

RNN 遵循类似的结构，修改的方式是在当前时间步中考虑先前时间步的隐藏层。

我们将用一个简单的例子构建 RNN 的工作细节，然后在更实际的用例上实现它。

让我们考虑一个如下所示的示例文本:`This is an example`。

手头的任务是预测给定两个单词序列的第三个单词。

因此，数据集转换如下:

| **输入** | **输出** |
| `this, is` | `an` |
| `is, an` | `example` |

给定一个输入`this is`，我们期望预测`example`作为输出。

我们将采用以下策略来构建 RNN:

1.  一键编码单词
2.  确定输入的最大长度:
    *   将输入的剩余部分填充到最大长度，这样所有输入的长度都相同
3.  将输入中的单词转换成一次性编码的版本
4.  将输出中的单词转换成一次性编码的版本
5.  处理输入和输出数据，然后拟合 RNN 模型

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 怎么做...

上面讨论的策略编码如下(代码文件在 GitHub 中以`Building_a_Recurrent_Neural_Network_from_scratch-in_Python.ipynb`的形式提供):

1.  让我们用代码定义输入和输出，如下所示:

```
#define documents
docs = ['this, is','is an']
# define class labels
labels = ['an','example']
```

2.  让我们对数据集进行预处理，以便将其传递给 RNN:

```
from collections import Counter
counts = Counter()
for i,review in enumerate(docs+labels):
      counts.update(review.split())
words = sorted(counts, key=counts.get, reverse=True)
vocab_size=len(words)
word_to_int = {word: i for i, word in enumerate(words, 1)}
```

在前面的步骤中，我们在给定的数据集中识别所有唯一的单词及其相应的频率(计数),并为每个单词分配一个 ID 号。前面代码中`word_to_int`的输出如下所示:

```
print(word_to_int)
# {'an': 2, 'example': 4, 'is': 1, 'this': 3}
```

3.  用相应的 id 修改输入和输出单词，如下所示:

```
encoded_docs = []
for doc in docs:
      encoded_docs.append([word_to_int[word] for word in doc.split()])
encoded_labels = []
for label in labels:
      encoded_labels.append([word_to_int[word] for word in label.split()])
print('encoded_docs: ',encoded_docs)
print('encoded_labels: ',encoded_labels)
# encoded_docs: [[3, 1], [1, 2]]
# encoded_labels: [[2], [4]]
```

在前面的代码中，我们将输入句子中每个单词的 ID 附加到一个列表中，从而使输入(`encoded_docs`)成为一个列表列表。

类似地，我们将输出的每个单词的 ID 附加到一个列表中。

4.  对输入进行编码时需要注意的一个额外因素是输入长度。在情感分析的情况下，输入文本的长度可以随着评论的不同而不同。但是，神经网络期望输入大小是固定的。为了解决这个问题，我们在输入的顶部执行填充。填充确保所有输入都被编码为具有相似的长度。虽然在我们的例子中，两个例子的长度都是 2，但实际上，我们很可能会遇到输入长度不同的情况。在代码中，我们执行如下填充:

```
# pad documents to a max length of 2 words
max_length = 2
padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='pre')
```

在前面的代码中，我们将`encoded_docs`传递给`pad_sequences`函数，这确保了所有输入数据点都具有相同的长度，即等于`maxlen`参数。此外，对于那些短于`maxlen`的参数，它用值 0 填充这些数据点以获得总长度`maxlen`，并且补零完成`pre`—即，在原始编码句子的左侧。

既然已经创建了输入数据集，那么让我们对输出数据集进行预处理，以便可以将其传递到模型训练步骤。

5.  对输出的典型处理是将它们转换成虚拟值，也就是说，生成输出标签的一次热编码版本，其操作如下:

```
one_hot_encoded_labels = to_categorical(encoded_labels, num_classes=5)
print(one_hot_encoded_labels)
# [[0\. 0\. 1\. 0\. 0.] [0\. 0\. 0\. 0\. 1.]]
```

注意，给定输出值(`encoded_labels`)为`{2, 4}`，输出向量在第二和第四位置分别具有值 1。

6.  让我们建立模型:
    1.  RNN 期望输入的形状是(`batch_size`、`time_steps`和`features_per_timestep`)。因此，我们首先将`padded_docs`输入整形为以下格式:

```
padded_docs = padded_docs.reshape(2,2,1)
```

注意，理想情况下，我们应该为每个单词创建一个词嵌入(在这个特定的例子中是 ID)。然而，考虑到这个菜谱的目的只是为了理解 RNN 的工作细节，我们将排除 ID 的嵌入，并假设每个输入不是 ID 而是值。说到这里，我们将在下一个菜谱中学习如何执行 id 嵌入。

```
# define the model
embed_length=1
max_length=2
model = Sequential()
model.add(SimpleRNN(1,activation='tanh', return_sequences=False,recurrent_initializer='Zeros',input_shape=(max_length,embed_length),unroll=True))
```

在前面的步骤中，我们明确地将`recurrent_initializer`指定为零，以便我们更容易理解 RNN 的工作细节。实际上，我们不会将递归初始化器初始化为 0。

`return_sequences`参数指定我们是否想要获得每个时间步长的隐藏层值。`return_sequences`的假值指定我们只希望在最后的时间步长输出隐藏层。

通常，在多对一任务中，有许多输入(每个时间步一个输入)和输出，`return_sequences`将为假，导致仅在最后一个时间步获得输出。这方面的一个例子可能是第二天的股票价格，给定一系列五天的历史股票价格。

然而，如果我们试图在每个时间步中获得隐藏层值，`return_sequences`将被设置为`True`。机器翻译就是一个例子，它有许多输入和输出。

```
model.add(Dense(5, activation='softmax'))
```

我们已经执行了`Dense(5)`，因为有五个可能的输出类别(每个示例的输出有 5 个值，其中每个值对应于它属于单词 ID `0`到单词 ID `4`的概率)。

```
# compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])
# summarize the model
print(model.summary())
```

模型总结如下:

![](Images/54388466-b7f3-4314-a618-964e8acfd193.png)

现在我们已经定义了模型，在拟合输入和输出之前，让我们了解一下为什么每一层都有一定数量的参数。

模型的简单 RNN 部分有一个输出形状`(None, 1)`。输出形状中的`None`代表`batch_size`。None 是指定`batch_size`可以是任何数字的一种方式。假设我们已经指定从简单 RNN 输出一个隐藏单元，列的数量是一。

既然了解了`simpleRNN`的输出形状，那就来了解一下为什么`simpleRNN`层的参数个数是三个。请注意，隐藏层值是在最后一个时间步长输出的。假设输入在每个时间步长中的值为 1(每个时间步长一个要素)，输出也是一个值，则输入实际上是乘以一个单一值的权重。如果输出(隐藏层值)是 40 个单位的隐藏层值，则输入应该乘以 40 个单位以得到输出(关于这一点的更多信息，请参见*实现用于情感分类的 RNN*
配方)。除了将输入连接到隐藏层值的一个权重之外，还有一个伴随权重的偏差项。另一个 1 参数来自前一个时间步长的隐藏层值与当前时间步长的隐藏层的连接，总共有三个参数。

从隐藏层到最终输出有 10 个参数，因为有五个可能的类，导致连接隐藏层值(为一个单位)的五个权重和五个偏差，总共 10 个参数。

```
model.fit(padded_docs,np.array(one_hot_encoded_labels),epochs=500)
```

7.  提取对第一个输入数据点的预测

```
model.predict(padded_docs[0].reshape(1,2,1))
```

提取的输出如下:

```
array([[0.3684635, 0.33566403, 0.61344165, 0.378485, 0.4069949 ]],      dtype=float32)
```

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 验证输出

既然模型是合适的，让我们通过逆向工作来了解 RNN 是如何工作的——也就是说，提取模型的权重，通过权重前馈输入，以使用 NumPy 匹配预测值(代码文件在 GitHub 中以`Building_a_Recurrent_Neural_Network_from_scratch_in_Python.ipynb`的形式提供)。

1.  检查重量:

```
model.weights
[<tf.Variable 'simple_rnn_2/kernel:0' shape=(1, 1) dtype=float32_ref>,
 <tf.Variable 'simple_rnn_2/recurrent_kernel:0' shape=(1, 1) dtype=float32_ref>,
 <tf.Variable 'simple_rnn_2/bias:0' shape=(1,) dtype=float32_ref>,
 <tf.Variable 'dense_2/kernel:0' shape=(1, 5) dtype=float32_ref>,
 <tf.Variable 'dense_2/bias:0' shape=(5,) dtype=float32_ref>]
```

前面的内容让我们直观地了解了权重在输出中呈现的顺序。

在前面的示例中，`kernel`表示权重，`recurrent`表示隐藏层从一个步骤到另一个步骤的连接。

注意，`simpleRNN`具有将输入连接到隐藏层的权重，以及将前一时间步的隐藏层连接到当前时间步的隐藏层的权重。

`dense_2`层中的内核和偏差表示将隐藏层值连接到最终输出的层:

```
model.get_weights()
```

前面的代码行给出了每个权重的计算值。

2.  通过第一个时间步长传递输入-输入如下:

```
padded_docs[0]
#array([3, 1], dtype=int32)
```

在前面的代码中，第一个时间步长的值为`3`，第二个时间步长的值为`1`。我们将在第一个时间步初始化该值，如下所示:

```
input_t0 = 3
```

```
input_t0_kernel_bias = input_t0*model.get_weights()[0] + model.get_weights()[2]
```

```
hidden_layer0_value = np.tanh(input_t0_kernel_bias)
```

4.  计算时间步长 2 的隐藏层值；其中输入的值为`1`(注意`padded_docs[0]`的值为`[3, 1]`):

```
input_t1 = 1
```

```
input_t1_kernel_bias = input_t1*model.get_weights()[0] + model.get_weights()[2]
```

请注意，与输入相乘的权重保持不变，与所考虑的时间步长无关。

![](Images/0fe5cacd-023b-479f-8a90-874d5b0f3c42.png)

其中*φ*是执行的激活(一般使用`tanh`激活)。

从输入层到隐藏层的计算包括两个部分:

给定时间步长的隐藏层值的最终计算将是前面两个矩阵乘法的总和。通过 tanh 激活函数传递结果:

```
input_t1_recurrent = hidden_layer0_value*model.get_weights()[1]
```

通过`tanh`激活前的总值如下:

```
total_input_t1 = input_t1_kernel_bias + input_t1_recurrent
```

隐藏层值的输出通过将前面的输出通过`tanh`激活来计算，如下所示:

```
output_t1 = np.tanh(total_input_t1)
```

5.  将最后一个时间步长的隐藏层输出通过密集层，该层将隐藏层连接到输出层:

```
final_output = output_t1*model.get_weights()[3] + model.get_weights()[4]
```

注意，`model.get_weights()`方法的第四个和第五个输出对应于从隐藏层到输出层的连接。

6.  将前面的输出通过 softmax 激活(如模型中所定义的)来获得最终输出:

```
np.exp(final_output)/np.sum(np.exp(final_output))
# array([[0.3684635, 0.33566403, 0.61344165, 0.378485, 0.40699497]], dtype=float32)
```

您应该注意到，我们通过网络前向传递输入获得的输出与`model.predict`函数给出的输出相同。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 实现用于情感分类的 RNN

为了理解 RNN 是如何在 Keras 中实现的，让我们实现我们在第十章[、*使用词向量的文本分析*章节中执行的航空公司-推特情感分类练习。](79b072ff-23b6-47ef-80bc-d9400a855714.xhtml)

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 怎么做...

该任务将按如下方式执行(代码文件在 GitHub 中以`RNN_and_LSTM_sentiment_classification.ipynb`的形式提供):

1.  导入相关的包和数据集:

```
from keras.layers import Dense, Activation
from keras.layers.recurrent import SimpleRNN
from keras.models import Sequential
from keras.utils import to_categorical
from keras.layers.embeddings import Embedding
from sklearn.cross_validation import train_test_split
import numpy as np
import nltk
from nltk.corpus import stopwords
import re
import pandas as pd
data=pd.read_csv('https://www.dropbox.com/s/8yq0edd4q908xqw/airline_sentiment.csv')
data.head()
```

2.  预处理文本以删除标点符号，将所有单词规范化为小写，并删除停用词，如下所示:

```
import nltk
nltk.download('stopwords')
stop = nltk.corpus.stopwords.words('english')
def preprocess(text):
    text=text.lower()
    text=re.sub('[^0-9a-zA-Z]+',' ',text)
    words = text.split()
    words2=[w for w in words if (w not in stop)]
    #words3=[ps.stem(w) for w in words]
    words4=' '.join(words2)
    return(words4)
data['text'] = data['text'].apply(preprocess)
```

3.  提取构成数据集的所有单词的单词到整数的映射:

```
from collections import Counter
counts = Counter()
for i,review in enumerate(t['text']):
    counts.update(review.split())
words = sorted(counts, key=counts.get, reverse=True
```

在前面的步骤中，我们提取了数据集中所有单词的频率。提取的单词示例如下:

![](Images/f9b4e5b9-a37a-4944-941f-6647af1ba595.jpg)

```
nb_chars = len(words)
word_to_int = {word: i for i, word in enumerate(words, 1)}
int_to_word = {i: word for i, word in enumerate(words, 1)}
```

在前面的代码中，我们循环遍历所有单词，并为每个单词分配一个索引。整数到单词字典的示例如下:

![](Images/c12eb915-d624-4999-b83c-6daeff8e36e0.jpg)

4.  将给定句子中的每个单词映射到与之相关的相应单词:

```
mapped_reviews = []
for review in data['text']:
    mapped_reviews.append([word_to_int[word] for word in review.split()])
```

在前面的步骤中，我们将文本评论转换为列表的列表，其中每个列表构成了一个句子中包含的单词的 ID。原始和映射审查的示例如下:

![](Images/04c3a122-9b47-4e60-87a5-bf3bed019521.jpg)

5.  提取句子的最大长度，并通过填充将所有句子规范化为相同的长度。在下面的代码中，我们遍历所有的评论，并存储每个评论对应的长度。此外，我们还计算了评论(推文)的最大长度:

```
length_sent = []
for i in range(len(mapped_reviews)):
      length_sent.append(len(mapped_reviews[i]))
sequence_length = max(length_sent)
```

我们要注意，不同的推文有不同的长度。然而，RNN 期望每个输入的时间步数是相同的。在下面的代码中，如果评论的长度小于数据集中所有评论的最大长度，我们将使用值 0 填充映射的评论。这样，所有输入都将具有相同的长度。

```
from keras.preprocessing.sequence import pad_sequences
X = pad_sequences(maxlen=sequence_length, sequences=mapped_reviews, padding="post", value=0)
```

6.  准备训练和测试数据集:

```
y=data['airline_sentiment'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)
y_train2 = to_categorical(y_train)
y_test2 = to_categorical(y_test)
```

在前面的步骤中，我们将原始数据分为训练和测试数据集，并将因变量转换为一次性编码变量。

7.  构建 RNN 架构并编译模型:

```
embedding_vecor_length=32
max_review_length=26
model = Sequential()
model.add(Embedding(input_dim=12533, output_dim=32, input_length = 26))
```

请注意，嵌入将不同单词的总数作为输入，并为每个单词创建一个向量，其中`output_dim`表示表示单词的维数。`input_length`代表每句话的字数:

```
model.add(SimpleRNN(40, return_sequences=False))
```

注意，在 RNN 层，如果我们想要提取每个时间步的输出，我们说`return_sequences`参数是`True`。然而，在我们现在正在解决的用例中，我们仅在通读所有输入单词之后提取输出，因此`return_sequences = False`:

```
model.add(Dense(2, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
```

模型总结如下:

![](Images/7d2328cb-7549-4f74-9844-a2f5f3d89b04.png)

我们先来了解一下为什么嵌入层会有`401056`参数需要估计。总共有 12，532 个唯一的单词，如果我们认为没有索引为 0 的单词，则总共有 12，533 个可能的单词，其中每个单词都以 32 维表示，因此要估计(12，533×32 = 401，056)个参数。

现在，让我们试着理解为什么在`simpleRNN`层有 2920 个参数。

有一组权重将输入连接到 40 个 RNN 单位。假设每个时间步长有 32 个输入(其中相同的权重集在每个时间步长重复)，则总共使用 32 x 40 个权重将输入连接到隐藏层。这为每个输入提供了尺寸为 1 x 40 的输出。

另外，对于将要发生的 *X * W [xh]* 和*h[(t-1)*]W[hh]*之间的求和(其中 *X* 是输入值，*W*[*xh*]是连接输入层和隐藏层的权重， *W [hh]* 是权重) 而 *h [(t-1)]* 是上一时间步的隐藏层)——鉴于 *X W [xh]* 输入的输出是 1 x 40——*h[(t-1)]X W[hh]*的输出大小也应该是 1 X 40。 因此，*W[hh]矩阵的尺寸将是 40×40，因为 *h [(t-1)]* 的尺寸是 1×40。*

除了权重，我们还将有 40 个偏差项与 40 个输出中的每一个相关联，因此总共有(32 x 40 + 40 x 40 + 40 = 2，920)个权重。

最终层中总共有 82 个权重，因为最终时间步长的 40 个单位连接到两个可能的输出，导致 40 x 2 个权重和 2 个偏差，因此总共有 82 个单位。

8.  符合模型:

```
model.fit(X_train, y_train2, validation_data=(X_test, y_test2), epochs=10, batch_size=32)
```

训练、测试数据集中的准确度和损失值的曲线如下:

![](Images/afc6244e-0a9d-463a-956d-c6b4956c784d.jpg)

前面模型的输出也是大约 89%,并且与我们在第*章使用单词向量进行文本分析中构建的基于单词向量的网络相比，没有提供任何显著的改进。*

然而，随着数据点数量的增加，预计它将具有更好的准确性。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 还有更多...

考虑多个时间步长进行预测的传统 RNN 可以如下所示:

![](Images/a7fcb1be-8d05-49f7-811f-8f716f209092.png)

请注意，随着时间步长的增加，更早层输入的影响将会降低。在这里可以看到这种直觉(暂且让我们忽略偏差项):

*h[5]= WX[5]+Uh[4]= WX5+UWX[4]+U²WX[3]+U³WX[2]+U⁴WX[1]*

你可以看到，随着时间步长的增加，如果 *U > 1* ，隐藏层的值高度依赖于*X[1]T3，或者如果 *U < 1* ，隐藏层的值很少依赖于*X[1]。**

当 *U* 的值非常小时，对 U 矩阵的依赖还会导致消失梯度，并且当 *U* 的值非常高时，会导致爆炸梯度。

当在预测下一个单词时存在长期依赖性时，上述现象导致了一个问题。为了解决这个问题，我们将在下一个菜谱中使用**长短期记忆** ( **LSTM** )架构。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 用 Python 从头开始构建 LSTM 网络

在上一节关于传统 RNN 的问题中，我们了解了当存在长期依赖时，RNN 是如何不提供帮助的。例如，想象输入的句子如下:

我住在印度。我会说 ____。

可以通过查看关键字 *India* 来填补前面语句中的空白，该关键字比我们要预测的单词早三个时间步。

以类似的方式，如果关键词远离要预测的词，则需要解决消失/爆炸梯度问题。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 做好准备

在这份食谱中，我们将了解 LSTM 如何帮助克服 RNN 架构的长期依赖性缺点，并构建一个玩具示例，以便我们了解 LSTM 的各种组件。

LSTM 的长相如下:

![](Images/f2243925-4b0f-400b-bb2d-6d485e0d1401.png)

您可以看到，虽然隐藏层的输入 **X** 和输出( **h** )保持不变，但隐藏层中发生了不同的激活(在某些情况下是 sigmoid 激活，而在其他情况下是 tanh 激活)。

让我们仔细检查在其中一个时间步骤中发生的各种激活:

![](Images/4c51bfa7-310d-4ee5-97dd-aff0de7c9669.png)

在上图中， **X** 和 **h** 代表输入层和隐藏层。

长期记忆存储在单元状态 **C** 中。

需要遗忘的内容通过遗忘门获得:

*f[t]=σ(W[xf]x^((t))+W[HF]h^((t-1))+b[f])*

Sigmoid 激活使网络能够选择性地识别需要忘记的内容。

在我们确定需要忘记的内容后，更新的单元格状态如下:

*c[t]=(c[t-1]f)*

注意，![](Images/dc04ccba-f496-4601-93a6-3f1f35655156.png)代表元素间的乘法。

比如句子的输入输入顺序是*我住在印度。我说 __* ，空格可以根据输入单词*印*来填充。填空后，我们不一定需要国名的具体信息。

我们根据当前时间步长需要忘记的内容来更新单元状态。

在下一步中，我们将根据当前时间步长中提供的输入向单元状态添加附加信息。此外，更新幅度(正或负)通过 tanh 激活获得。

输入可以指定如下:

*I[t]=σ(W[Xi]x【T5(t)+W[hi]h^((t-1))+bi)*

调制(输入更新幅度)可规定如下:

*g[t]= tanh(W[XG]x^((t))+W[Hg]h^((t-1))+BG)*

单元状态——我们在一个时间步长中忘记某些事情，并在同一时间步长中添加附加信息——更新如下:

![](Images/b2688aa0-958e-4f11-9c52-f6661cacac20.png)

在最终门，我们需要指定输入组合(当前时间步输入和前一时间步的隐藏层值的组合)的哪一部分和单元状态需要输出到下一个隐藏层:

![](Images/9f52fca7-fe04-4a8f-a16a-ae6386c325f1.png)

最终的隐藏层表示如下:

![](Images/962e9401-a248-417f-8f8d-0ebdfff4aff3.png)

这样，我们就可以利用 LSTM 的各种通道，有选择地识别需要存储在内存中的信息，从而克服 RNN 的限制。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 怎么做...

为了获得这个理论如何工作的实际直觉，让我们看看我们在理解 RNN 时所做的同样的例子，但是这次使用 LSTM。

请注意，这两个示例的数据预处理步骤是相同的。因此，我们将重用预处理部分(*步骤 1* 到*步骤 4* 在 Python 中*从头开始构建 RNN)并直接进入模型构建部分(代码文件在 GitHub 中以`LSTM_working_details.ipynb`的形式提供):*

1.  定义模型:

```
embed_length=1
max_length=2
model = Sequential()
model.add(LSTM(1,activation='tanh',return_sequences=False,
recurrent_initializer='Zeros',recurrent_activation='sigmoid',
input_shape=(max_length,embed_length),unroll=True))
```

注意，在前面的代码中，我们将递归初始化器和递归激活初始化为某些值，只是为了使这个例子更简单；目的只是帮助您理解后端发生了什么。

```
model.add(Dense(5, activation='softmax'))
```

```
# compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
# summarize the model
print(model.summary())
```

模型总结如下:

![](Images/04377b35-d2b0-4091-9dae-5d5558039585.png)

LSTM 层中的参数数量是`12`，因为有四个门(遗忘、输入、单元和输出)，这导致将输入连接到隐藏层的四个权重和四个偏置。此外，递归层包含对应于四个门的权重值，这为我们提供了总共`12`个参数。

密集层总共有 10 个参数，因为有五个可能的类作为输出，因此对应于从隐藏层到输出层的每个连接的五个权重和五个偏差。

2.  让我们来拟合模型:

```
model.fit(padded_docs.reshape(2,2,1),np.array(one_hot_encoded_labels),epochs=500)
```

3.  该模型的权重顺序如下:

```
model.weights[<tf.Variable 'lstm_19/kernel:0' shape=(1, 4) dtype=float32_ref>,
 <tf.Variable 'lstm_19/recurrent_kernel:0' shape=(1, 4) dtype=float32_ref>,
 <tf.Variable 'lstm_19/bias:0' shape=(4,) dtype=float32_ref>,
 <tf.Variable 'dense_18/kernel:0' shape=(1, 5) dtype=float32_ref>,
 <tf.Variable 'dense_18/bias:0' shape=(5,) dtype=float32_ref>]
```

重量可以通过以下方式获得:

```
model.get_weights()
```

从前面的代码(`model.weights`)中，我们可以看到 LSTM 层中的权重顺序如下:

同样，在密集层(将隐藏层连接到输出的层)中，权重的顺序如下:

以下是权重和偏差在 LSTM 图层中出现的顺序(前面的输出中未提供，但可在 Keras 的 GitHub 资源库中找到):

3.  计算输入的预测值。

我们使用原始编码的输入值(1，2，3 ),没有将它们转换成嵌入值——只是为了看看计算是如何进行的。实际上，我们会将输入转换成嵌入值。

4.  重塑预测方法的输入，使其符合 LSTM 预期的数据格式(批量大小、时间步长数、每个时间步长的要素):

```
model.predict(padded_docs[0].reshape(1,2,1))
# array([[0.05610514, 0.11013522, 0.38451442, 0.0529648, 0.39628044]], dtype=float32)

```

上面代码中的注释行提供了 predict 方法的输出。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 验证输出

既然我们已经从模型中获得了一个预测的概率，那么让我们使用 NumPy 通过权重的前向传递来运行输入，以获得与刚才相同的输出。

这样做是为了验证我们对 LSTM 如何在幕后工作的理解。我们验证所建模型输出的步骤如下:

1.  在时间步骤 1 中更新遗忘门。该步骤查看输入，然后提供对到目前为止已知的多少单元状态(存储器)将被遗忘的估计(注意 sigmoid 函数的使用):

```
input_t0 = 3
cell_state0 = 0
forget0 = input_t0*model.get_weights()[0][0][1] + model.get_weights()[2][1]
forget1 = 1/(1+np.exp(-(forget0)))
```

2.  基于更新的遗忘门更新单元状态。这里使用上一步的输出来指示要从单元状态(内存)中遗忘的值的数量:

```
cell_state1 = forget1 * cell_state0
```

3.  更新时间步长 1 中的输入门值。该步骤基于当前输入给出了将多少新信息注入单元状态的估计:

```
input_t0_1 = input_t0*model.get_weights()[0][0][0] + model.get_weights()[2][0]
input_t0_2 = 1/(1+np.exp(-(input_t0_1)))
```

4.  基于更新的输入值更新单元状态。在该步骤中，前一步骤的输出用于指示单元状态(存储器)的信息更新量:

```
input_t0_cell1 = input_t0*model.get_weights()[0][0][2] +model.get_weights()[2][2]
input_t0_cell2 = np.tanh(input_t0_cell1)
```

前面的`tanh`激活有助于确定来自输入的更新将增加还是减少单元状态(存储器)。这提供了一个额外的杠杆，因为如果某些信息已经在当前时间步骤中被传达并且在未来时间步骤中没有用，我们最好从单元状态中擦除它，以便从存储器中擦除这些额外的信息(在下一步骤中可能没有帮助):

```
input_t0_cell3 = input_t0_cell2*input_t0_2
input_t0_cell4 = input_t0_cell3 + cell_state1
```

5.  更新输出门。这一步提供了当前时间步中将要传递的信息量的估计值(注意 sigmoid 函数在这方面的用法):

```
output_t0_1 = input_t0*model.get_weights()[0][0][3] + model.get_weights()[2][3]
output_t0_2 = 1/(1+np.exp(-output_t0_1))
```

6.  计算时间步长 1 的隐藏层值。请注意，一个时间步长的最终隐藏层值是当前时间步长中有多少内存和输出用于传递单个时间步长的组合:

```
hidden_layer_1 = np.tanh(input_t0_cell4)*output_t0_2
```

我们已经完成了从第一时间步输出的隐藏层值的计算。在接下来的步骤中，我们将传递时间步骤 1 中更新的单元状态值和时间步骤 1 中隐藏层值的输出，作为时间步骤 2 的输入。

7.  将时间步骤 2 的输入值和单元格状态值传递到时间步骤 2:

```
input_t1 = 1
cell_state1 = input_t0_cell4
```

8.  更新忘记门值:

```
forget21 = hidden_layer_1*model.get_weights()[1][0][1] + model.get_weights()[2][1] + input_t1*model.get_weights()[0][0][1]
forget_22 = 1/(1+np.exp(-(forget21)))
```

9.  更新时间步长 2 中的单元状态值:

```
cell_state2 = cell_state1 * forget_22
input_t1_1 = input_t1*model.get_weights()[0][0][0] + model.get_weights()[2][0] + hidden_layer_1*model.get_weights()[1][0][0]
input_t1_2 = 1/(1+np.exp(-(input_t1_1)))
input_t1_cell1 = input_t1*model.get_weights()[0][0][2] + model.get_weights()[2][2]+ hidden_layer_1*model.get_weights()[1][0][2]
input_t1_cell2 = np.tanh(input_t1_cell1)
input_t1_cell3 = input_t1_cell2*input_t1_2
input_t1_cell4 = input_t1_cell3 + cell_state2
```

10.  基于更新的单元状态和要进行的输出的幅度的组合来更新隐藏层输出值:

```
output_t1_1 = input_t1*model.get_weights()[0][0][3] + model.get_weights()[2][3]+ hidden_layer_1*model.get_weights()[1][0][3]
output_t1_2 = 1/(1+np.exp(-output_t1_1))
hidden_layer_2 = np.tanh(input_t1_cell4)*output_t1_2
```

11.  通过密集层传递隐藏层输出:

```
final_output = hidden_layer_2 * model.get_weights()[3][0] +model.get_weights()[4]
```

12.  在我们刚刚获得的输出之上运行 softmax:

```
np.exp(final_output)/np.sum(np.exp(final_output))
```

```
# array([0.05610514, 0.11013523, 0.3845144, 0.05296481, 0.39628044],dtype=float32)
```

您应该注意到，这里获得的输出与我们从`model.predict`方法获得的输出完全相同。

通过这次练习，我们可以更好地了解 LSTM 的工作细节。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 实现用于情感分类的 LSTM

在*实现用于情感分类的 RNN*配方中，我们使用 RNN 实现了情感分类。在这个菜谱中，我们将看看如何使用 LSTM 来实现它。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 怎么做...

我们将采用的步骤如下(代码文件在 GitHub 中以`RNN_and_LSTM_sentiment_classification.ipynb`的形式提供):

1.  定义模型。我们在*中看到的对情感分类*实现 RNN 的代码的唯一变化将是在模型架构部分从`simpleRNN`到 LSTM 的变化(我们将重用在*实现情感分类*配方中从*步骤 1* 到*步骤 6* 的代码):

```
embedding_vecor_length=32
max_review_length=26
model = Sequential()
model.add(Embedding(input_dim=12533, output_dim=32, input_length = 26))
```

嵌入层的输入是数据集中存在的唯一 id 的总数以及每个单词需要转换到的预期维度(`output_dim`)。

此外，我们还将指定输入的最大长度，以便下一步中的 LSTM 图层具有所需的信息-批量大小、时间步长数(`input_length`)和每次要素数(`step(output_dim)`):

```
model.add(LSTM(40, return_sequences=False))
model.add(Dense(2, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
```

该模型的摘要如下:

![](Images/b4e00271-4c1b-464a-bdc1-6dbc45594704.png)

虽然第一层和最后一层中的参数与在*实现用于情感分类的 RNN*配方中看到的相同，但是 LSTM 层具有不同数量的参数。

让我们了解一下 LSTM 层中的 11，680 个参数是如何获得的:

```
W = model.layers[1].get_weights()[0]
U = model.layers[1].get_weights()[1]
b = model.layers[1].get_weights()[2]
print(W.shape,U.shape,b.shape)
```

输出将如下所示:

```
((32, 160), (40, 160), (160,))
```

注意前面权重的总和有*(32 * 160)+(40 * 160)+160 = 11680*个参数。

`W`表示将输入连接到四个单元(`i`、`f`、`c`、`o`)的权重，`U`表示隐藏层到隐藏层的连接，`b`表示每个门的偏置。

输入门、遗忘门、单元状态门和输出门的单个权重可通过下式获得:

```
units = 40
W_i = W[:, :units]
W_f = W[:, units: units * 2]
W_c = W[:, units * 2: units * 3]
W_o = W[:, units * 3:]
```

```
U_i = U[:, :units]
U_f = U[:, units: units * 2]
U_c = U[:, units * 2: units * 3]
U_o = U[:, units * 3:]
```

```
b_i = b[:units]
b_f = b[units: units * 2]
b_c = b[units * 2: units * 3]
b_o = b[units * 3:]
```

2.  按照以下方式拟合模型:

```
model.fit(X_train, y_train2, validation_data=(X_test, y_test2), epochs=50, batch_size=32)
```

在训练和测试数据集中，丢失和准确性随增加的时期的变化如下:

![](Images/ffc8b5d6-d220-487e-b635-67ce7423dddf.jpg)

当使用 LSTM 层时，预测精度为 91%，这比我们使用 simpleRNN 层时的预测精度稍好。潜在地，我们可以通过微调 LSTM 单元的数量来进一步改善结果。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 实现用于情感分类的堆叠 LSTM

在上一个配方中，我们在 Keras 中使用 LSTM 实现了情感分类。在这个菜谱中，我们将看看如何实现相同的东西，但是堆叠多个 LSTMs。叠加多个 LSTMs 可能会捕捉到数据中更多的变化，从而可能获得更好的精度。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 怎么做...

堆叠 LSTM 实现如下(代码文件在 GitHub 中以`RNN_and_LSTM_sentiment_classification.ipynb`的形式提供):

1.  我们之前看到的代码中唯一的变化是将`return_sequences`参数改为 true。这确保了第一个 LSTM 返回一个输出序列(与 LSTM 单元的数量一样多的输出)，然后该序列可以被传递给另一个 LSTM，作为模型架构部分中原始 LSTM 之上的输入(关于`return_sequences`参数的更多细节可以在*序列到序列学习*章节中找到):

```
embedding_vecor_length=32
max_review_length=26
model = Sequential()
model.add(Embedding(input_dim=12533, output_dim=32, input_length = 26))
model.add(LSTM(40, return_sequences=True))
model.add(LSTM(40, return_sequences=False))
model.add(Dense(2, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
```

模型架构概述如下:

![](Images/5e6ca342-8153-47a5-92ed-a04e9dcd64d8.png)

请注意，在前面的架构中，有一个额外的 LSTM 堆叠在另一个 LSTM 之上。第一 LSTM 在每个时间步的输出为`40`值，因此输出形状为(`None`、`26`、`40`)，其中`None`代表`batch_size`、`26`代表时间步数，`40`代表考虑的 LSTM 单位数。

现在有了`40`输入值，第二个 LSTM 中的参数数量以与前一个配方相同的方式考虑，如下所示:

```
W = model.layers[2].get_weights()[0]
U = model.layers[2].get_weights()[1]
b = model.layers[2].get_weights()[2]
print(W.shape,U.shape,b.shape)
```

以下是我们通过执行前面的代码获得的值:

```
((40, 160), (40, 160), (160,))
```

这导致总共 12，960 个参数，如输出所示。

w 的形状是 40×160，因为它有 40 个输入映射到 40 个输出，还有 4 个不同的门要控制，因此总共有 40×40×4 个权重。

2.  实现模型，如下所示:

```
model.fit(X_train, y_train2, validation_data=(X_test, y_test2), epochs=50, batch_size=32)
```

在训练和测试数据集中，丢失和准确性随增加的时期的变化如下:

![](Images/d2377a1a-3446-4819-bc41-7a6583e1c92e.jpg)

这导致了 91%的准确性，正如我们看到的单个 LSTM 层；然而，随着数据的增多，堆叠 LSTM 可能会比普通 LSTM 捕捉到更多的数据变化。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 还有更多...

**门控循环单元** ( **GRU** )是我们可以使用的另一种架构，具有与 LSTM 类似的精确度。想了解更多关于 GRU 的信息，请访问 https://arxiv.org/abs/1412.3555。
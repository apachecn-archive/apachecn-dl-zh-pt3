

# 前言

*深度学习与 TensorFlow 和 Keras，第三版*，是一个简明而全面的现代神经网络，人工智能和深度学习技术的介绍，专为软件工程师和数据科学家设计。这本书是同一作者以前写的书*深度学习与 Keras*【1】和 *TensorFlow 1.x 深度学习食谱*【2】的自然延续。

这本书提供了过去六年来学习技术发展的一个非常详细的全景。这本书介绍了几十个使用 TensorFlow 2.x 用 Python 编码的工作深度神经网络，tensor flow 2 . x 是一个基于 Keras-like API 的模块化网络库[1]。

人工智能为这本书讨论的一切奠定了基础。**机器学习** ( **ML** )是 AI 的一个分支，**深度学习** ( **DL** )又是 ML 的子集。本节将简要讨论这三个概念，这三个概念在本书的其余部分中会经常遇到。

人工智能表示机器模仿人类通常表现出的智能行为的任何活动。更正式地说，它是一个研究领域，其中机器旨在复制认知能力，如学习行为、与环境的主动交互、推理和演绎、计算机视觉、语音识别、解决问题、知识表示和感知。人工智能建立在计算机科学、数学、统计学、心理学和其他研究人类行为的科学的基础上。构建人工智能有多种策略。在 20 世纪 70 年代和 80 年代，“专家”系统变得非常流行。这些系统的目标是通过用大量手动定义的 if-then 规则来表示知识，从而解决复杂的问题。这种方法适用于非常特定领域的小问题，但是不能扩展到更大的问题和多个领域。后来，人工智能越来越关注基于统计方法的方法，这些方法是最大似然法的一部分。

ML 是人工智能的一个分支学科，专注于教会计算机如何在不需要为特定任务编程的情况下学习。ML 背后的关键思想是，有可能创建从数据中学习并对数据进行预测的算法。ML 有三个不同的大类:

*   **监督学习**，向机器提供输入数据和期望的输出，目标是从那些训练样本中学习，以便可以对机器以前从未观察到的数据做出有意义的预测。
*   **无监督学习**，仅向机器提供输入数据，机器随后必须自己找到一些有意义的结构，无需外部监督或输入。
*   **强化学习**，机器充当代理，与环境交互。机器被提供以期望的方式表现的“奖励”和以不期望的方式表现的“惩罚”。机器试图通过学习相应地发展其行为来最大化回报。

DL 在 2012 年风靡全球。在那一年，推出了 ImageNet 2012 挑战赛，目标是使用大型手绘数据集的子集来预测照片的内容。一个名为 AlexNet 的深度学习模型取得了 15.3%的前 5 名错误率，相对于之前的最先进结果有了显著改善。据《经济学人》报道，*人们突然开始关注，不仅是在人工智能社区，而是在整个技术行业。*

这仅仅是开始。如今，DL 技术成功应用于异构领域，包括但不限于医疗保健、环境、绿色能源、计算机视觉、文本分析、多媒体、金融、零售、游戏、模拟、工业、机器人和自动驾驶汽车。在这些领域中的每一个领域中，DL 技术都能够以使用以前的方法不可能达到的精确度水平来解决问题。

回顾过去的八年，看到 DL 对科学和工业做出的贡献是令人着迷和兴奋的。没有理由相信未来八年的贡献会减少；事实上，随着数字图书馆领域的不断发展，我们预计我们将会看到数字图书馆做出更多令人激动和着迷的贡献。

这本书向你介绍了深度学习的魔力。我们将从简单的模型开始，逐步引入越来越复杂的模型。这种方法将永远是亲自动手的，有大量的代码可以使用。

# 这本书是给谁的

如果你是有 ML 经验的数据科学家或者对神经网络有一些接触的 AI 程序员，你会发现这本书是使用 TensorFlow 进入 DL 的一个有用的切入点。如果您是一名对 DL tsunami 越来越感兴趣的软件工程师，您会发现这本书是拓宽您在该主题上的知识的基础平台。这本书需要 Python 的基础知识。

# 这本书涵盖的内容

*第 1 章*，*带 TF* 的神经网络基础，是我们学习 TensorFlow 基础知识的地方，tensor flow 是 Google 为机器学习和深度学习开发的开源库。此外，我们介绍了神经网络和深度学习的基础知识，这是机器学习的两个领域，在过去几年中有了令人难以置信的增长。本章背后的想法是提供进行基本但完全动手的深度学习所需的所有工具。

*第 2 章*、*回归和分类*，重点介绍 ML 技术中的基本任务:回归和分类。我们将学习如何使用 TensorFlow 建立简单的、多重的和多元的回归模型。我们将使用逻辑回归来解决多类分类问题。

*第三章*，*卷积神经网络*，讲述如何使用深度学习卷积网络高精度识别 MNIST 手写字符。我们使用 CIFAR 10 数据集来构建具有 10 个类别的深度学习分类器，使用 ImageNet 数据集来构建具有 1000 个类别的精确分类器。此外，我们研究如何使用大型深度学习网络，如 VGG16 和非常深度的网络，如 InceptionV3。最后，我们将讨论迁移学习

*第 4 章*，*单词嵌入*，我们在这里描述了分布式表示和单词嵌入的起源和背后的理论，并绘制了单词嵌入从静态的基于单词的嵌入到基于句子和段落的更动态和更有表现力的嵌入的过程。我们还探索了如何将单词嵌入的概念扩展到非单词序列，例如图中的节点或 web 应用程序中的用户会话。本章还包含了使用各种单词嵌入的多个例子。

*第 5 章*，*递归神经网络*，描述了神经网络的一个重要架构子类，它针对处理自然语言或时间序列等序列数据进行了优化。我们描述了这种类型中的重要架构，例如 **LSTM** ( **长短期记忆**)和 **GRU** ( **门控循环单元**)，并展示了如何扩展它们来处理双向状态和跨批状态。我们还提供了使用具有各种拓扑结构的 rnn 完成特定任务的例子，比如生成文本、情感分析和词性标注。我们还描述了流行的 seq2seq 架构，它在编码器-解码器管道中使用一对 rnn 来解决各种 NLP 任务。

*第 6 章*，*变形金刚*，涵盖了变形金刚，一种深度学习架构，彻底改变了传统的自然语言处理领域。我们首先回顾架构背后的关键直觉和各种类别的变压器，并深入探讨最流行的模型。然后，我们关注基于香草架构和流行库的实现，比如 Hugging Face 和 TensorFlow Hub。之后，我们简要讨论评估、优化，以及使用变压器时通常采用的一些最佳实践。最后一节专门讨论如何使用变形金刚来执行计算机视觉任务，这是一个与 NLP 完全不同的领域。这需要仔细定义注意机制。最终，你需要的只是关注！而注意力的核心，无非就是向量之间的余弦相似度。

*第七章*、*无监督学习*，深入探讨无监督学习模型。它将涵盖聚类和降维所需的技术，如 PCA、k-means 和自组织映射。它将进入玻尔兹曼机器的细节和他们使用 TensorFlow 的实现。涵盖的概念将扩展到构建**受限玻尔兹曼机器** ( **RBMs** )。

*第 8 章*，*自动编码器*，描述了自动编码器，一类试图重建输入作为目标的神经网络。它将涵盖不同种类的自动编码器，如稀疏自动编码器、卷积自动编码器和去噪自动编码器。本章将训练一个去噪自动编码器来去除输入图像中的噪声。它将演示如何使用自动编码器来创建 MNIST 数字。它还将涵盖构建 LSTM 自动编码器以生成句子向量所涉及的步骤。最后，我们将学习如何建立一个变分自动编码器来生成图像。

*第九章*、*生成模型*，重点介绍**生成对抗网络** ( **GANs** )。我们从第一个提出的 GAN 模型开始，并使用它来伪造 MNIST 字符。本章向你展示了如何使用深度卷积 GANs 来创建名人图像。本章讨论了各种 GAN 架构，如 SRGAN、InfoGAN 和 CycleGAN。本章涵盖一系列冷 GAN 应用。最后，本章以 TensorFlow 实现 CycleGAN 来转换冬夏图像作为结束。

*第十章*，**f-Supervised Learning*，概述了在计算机视觉、音频和自然语言处理中用于自监督学习的各种策略。它涵盖了通过自回归生成、掩蔽生成、关系预测和这些方法的混合等策略进行的自我预测。它还包括对比学习，一种自我监督学习的流行技术，及其在各种应用领域中对各种借口任务的应用。*

 **第 11 章*、*强化学习*，重点介绍强化学习，涵盖 Q 学习算法和贝尔曼方程。本章涵盖了折扣奖励，勘探和开发，以及折扣因素。它解释了基于策略和基于模型的强化学习。我们将建立一个**深度 Q 学习网络** ( **DQN** )来玩一个雅达利游戏。最后，我们学习如何使用策略梯度算法来训练代理。

*第 12 章*，*概率张量流*，介绍张量流概率，在张量流基础上构建的库，用于执行概率推理和统计分析。本章演示了如何使用张量流概率生成合成数据。我们将建立贝叶斯网络并进行推理。本章还介绍了不确定性、偶然性和认知性的概念，以及如何计算训练模型的不确定性。

*第十三章*，*AutoML 简介*，介绍了 AutoML，其目标是让不熟悉机器学习技术的领域专家能够轻松使用 ML 技术。我们将使用谷歌云平台进行一次实践练习，并在简要讨论基础知识后做一些实际操作。本章涵盖自动数据准备、自动特征工程和自动模型生成。然后，我们介绍 AutoKeras 和 Google Cloud AutoML 及其针对表格、视觉、文本、翻译和视频处理的多种解决方案。

*第 14 章*、*深度学习背后的数学*，涵盖了深度学习背后的数学。这个题目挺高级的，对从业者不一定有要求。然而，建议阅读以了解当我们玩神经网络时“引擎盖下”发生了什么。我们从历史介绍开始，然后我们将回顾导数和梯度的高中概念，并介绍常用于优化深度学习网络的梯度下降和反向传播算法。

*第十五章*、*张量处理单元*，讨论 TPUs。TPU 是谷歌开发的非常特殊的 ASIC 芯片，用于以超快的方式执行神经网络数学运算。计算的核心是一个脉动乘法器，它并行计算多个点积(行*列)，从而加速基本深度学习操作的计算。可以把 TPU 想象成深度学习的专用协处理器，专注于矩阵或张量运算。我们将回顾到目前为止的四代 TPU，以及一个额外的物联网 Edge TPU。

*第十六章*、*其他有用的深度学习库*，介绍其他深度学习框架。我们将探索拥抱脸、OpenAI 的 GPT3 和 DALL-E 2。该章介绍了另一个非常流行的深度学习框架 PyTorch。我们还将介绍 H2O.ai 及其 AutoML 模块。本章还简要讨论了深度学习模型的 ONNX 开源格式。

*第十七章*、*图神经*、 *l 网络*，介绍图和图机器学习，特别强调图神经网络和现在流行的**深度图库** ( **DGL** )。我们描述了 GNNs(在 DGL 可用)中使用的各种常用图形层背后的理论，并提供了用于节点分类、链路预测和图形分类的 GNNs 示例。我们还将展示如何使用您自己的图形数据集和自定义图形图层来创建新颖的 GNN 架构。然后，我们将介绍图 ML 领域的更多前沿进展，如异构图和时态图。

*第 18 章*、*机器学习最佳实践*，重点介绍在培训和生产中获得最佳模型应遵循的策略和实践。本章从两个不同的角度讨论了最佳实践:数据的最佳实践和模型的最佳实践。

*第 19 章*、 *TensorFlow 2 生态系统*，展示了 TensorFlow 生态系统的不同组成部分。我们介绍了 TensorFlow Hub，这是一个预训练深度学习模型的存储库。本章讨论了 TensorFlow 数据集——即用型数据集的集合。我们还将讨论 TensorFlow Lite 和 tensor flow JS——移动和嵌入式系统以及 web 的框架。最后，本章谈到了联邦学习，一个分散的机器学习框架。

*第 20 章*，*高级卷积神经网络*，展示了**卷积神经网络**(**CNN**)更高级的用途。我们将探索如何在计算机视觉、视频、文本文档、音频和音乐领域应用 CNN。我们将以总结卷积运算的一节来结束。

## 下载示例代码文件

这本书的代码包托管在 https://packt.link/dltf 的 GitHub 上。我们在 https://github.com/PacktPublishing/的[也有来自我们丰富的书籍和视频目录的其他代码包。看看他们！](https://github.com/PacktPublishing/)

## 下载彩色图像

我们还提供了一个 PDF 文件，其中有本书中使用的截图/图表的彩色图像。可以在这里下载:[https://static . packt-cdn . com/downloads/9781803232911 _ color images . pdf](https://static.packt-cdn.com/downloads/9781803232911_ColorImages.pdf)。

## 使用的惯例

本书通篇使用了许多文本约定。

`CodeInText`:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄。例如:“每个神经元可以通过`'kernel_initializer'`参数用特定的权重初始化。”

代码块设置如下:

```
# Build the model.

model = tf.keras.models.Sequential()

model.add(keras.layers.Dense(NB_CLASSES,

            input_shape=(RESHAPED,),

            name='dense_layer', 

            activation='softmax')) 
```

当我们希望您注意代码块的特定部分时，相关的行或项目会突出显示:

```
# Build the model.

model = tf.keras.models.Sequential()

model.add(keras.layers.Dense(NB_CLASSES,

            input_shape=(RESHAPED,),

            **name=****'****dense_layer'****,** 

            **activation=****'softmax'****))** 
```

任何命令行输入或输出都按如下方式编写:

```
pip install gym 
```

**粗体**:表示一个新术语、一个重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词出现在文本中，如下所示。比如:“一个**深度卷积神经网络** ( **DCNN** )由许多神经网络层组成。”

警告或重要提示如下所示。

提示和技巧是这样出现的。

# 取得联系

我们随时欢迎读者的反馈。

**总体反馈**:发送电子邮件`feedback@packtpub.com`，在邮件主题中提及书名。如果您对本书的任何方面有疑问，请发邮件至`questions@packtpub.com`联系我们。

**勘误表**:虽然我们已经尽力确保内容的准确性，但错误还是会发生。如果您在本书中发现了错误，请向我们报告，我们将不胜感激。请访问 http://www.packtpub.com/submit-errata[的](http://www.packtpub.com/submit-errata)，点击**提交勘误表**，填写表格。

**盗版**:如果您在互联网上遇到我们作品的任何形式的非法拷贝，如果您能提供我们的地址或网站名称，我们将不胜感激。请通过`copyright@packtpub.com`联系我们，并提供材料链接。

**如果你有兴趣成为一名作家**:如果有你擅长的主题，并且你有兴趣写书或投稿，请访问 http://authors.packtpub.com。

# 参考

1.  【Keras 深度学习:利用 Python 的力量实现深度学习模型和神经网络，平装本–2017 年 4 月 26 日，Antonio Gulli，Sujit Pal
2.  *TensorFlow 1.x 深度学习食谱* : *超过 90 种独特的食谱，用 Python 解决人工智能驱动的问题*，安东尼奥·古利，前岛亚美·卡普尔*  *# 分享你的想法

一旦你阅读了*深度学习与 TensorFlow 和 Keras，第三版*，我们很想听听你的想法！请[点击这里直接进入亚马逊对这本书的评论页面](https://packt.link/r/1803232919)，并分享你的反馈。

您的评论对我们和技术社区非常重要，将有助于我们确保提供高质量的内容。*